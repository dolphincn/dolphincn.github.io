<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[strongswan 安装配置]]></title>
    <url>%2Fstrongswan%2Fstrongswan%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[配置epel源12345678910111213cat &gt; /etc/yum.repos.d/epel.repo &lt;&lt; EOF [epel] name=Extra Packages for Enterprise Linux 7 - \$basearch #baseurl=http://download.fedoraproject.org/pub/epel/7/\$basearch baseurl=http://dl.fedoraproject.org/pub/epel/7Server/x86_64/ failovermethod=priority enabled=1 gpgcheck=1 gpgkey=http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7Server EOF 安装Strongswanyum -y install strongswan openssl openssl-devel 环境变量123456789101112cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF ## 开启转发 net.ipv4.ip_forward=1 net.ipv6.conf.all.forwarding=1## 禁止重定向，比如禁止ICMP重定向报文 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0EOFsysctl -p 防火墙配置firewall-cmd --permanent --add-service=ipsec firewall-cmd --permanent --add-masquerade firewall-cmd --reload cat /usr/lib/firewalld/services/ipsec.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;service&gt; &lt;short&gt;IPsec&lt;/short&gt; &lt;description&gt;Internet Protocol Security (IPsec) incorporates security for network transmissions directly into the Internet Protocol (IP). IPsec provides methods for both encrypting data and authentication for the host or network it sends to. If you plan to use a vpnc server or FreeS/WAN, do not disable this option.&lt;/description&gt; &lt;port protocol=&quot;ah&quot; port=&quot;&quot;/&gt; &lt;port protocol=&quot;esp&quot; port=&quot;&quot;/&gt; &lt;port protocol=&quot;udp&quot; port=&quot;500&quot;/&gt; &lt;port protocol=&quot;udp&quot; port=&quot;4500&quot;/&gt; &lt;/service&gt; ## 或者 #启用ip伪装 # firewall-cmd --permanen --add-rich-rule=&apos;rule family=&quot;ipv4&quot; source address=&quot;10.100.100.0/24&quot; masquerade&apos; #添加 nat 转发 # firewall-cmd --permanen --add-rich-rule=&apos;rule family=&quot;ipv4&quot; source address=&quot;10.100.100.0/24&quot; forward-port port=&quot;4500&quot; protocol=&quot;udp&quot; to-port=&quot;4500&quot;&apos; # firewall-cmd --permanen --add-rich-rule=&apos;rule family=&quot;ipv4&quot; source address=&quot;10.100.100.0/24&quot; forward-port port=&quot;500&quot; protocol=&quot;udp&quot; to-port=&quot;500&quot;&apos; 配置文件ipsec.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160cat &gt;/etc/strongswan/ipsec.conf &lt;&lt;EOFconfig setup ## 如果同一个用户在不同的设备上重复登录,yes 断开旧连接,创建新连接; ## no 保持旧连接,并发送通知; ## never 同 no, 但不发送通知. uniqueids=yes ## 开启调试，记录日志 # charondebug="cfg 2, dmn 2, ike 2, net 0"conn %default ikelifetime=120m keylife=30m rekeymargin=3m keyingtries=1 keyexchange=ike compress = yes #是否启用压缩, yes 表示如果支持压缩会启用. dpdaction = hold #当意外断开后尝试的操作, hold, 保持并重连直到超时. dpddelay = 30s #意外断开后尝试重连时长 dpdtimeout = 60s #意外断开后超时时长, 只对 IKEv1 起作用 inactivity = 300s #闲置时长,超过后断开连接. left = %any #服务端公网ip, 可以是魔术字 %any，表示从本地ip地址表中取. right = %any #客户端ip, 同上 #指定服务端与客户端的dns, 多个用","分隔 leftdns = 8.8.8.8,8.8.4.4 rightdns = 8.8.8.8,8.8.4.4 #leftikeport = &lt;port&gt; #服务端用于ike认证时使用的端口, 默认为500,如果使用了nat 转发, 则使用4500 #leftsourceip = %config #服务器端虚拟ip地址 rightsourceip = 10.100.100.0/24 #客户端虚拟ip段 #服务器端子网, 魔术字 0.0.0.0/0. 如果为客户端分配虚拟 IP 地址的话，那表示之后要做 iptables 转发，那么服务器端就必须是用魔术字 leftsubnet = 0.0.0.0/0 #rightsubnet = &lt;ip subnet&gt;[[&lt;proto/port&gt;]][,...]conn ikev1-ipsec keyexchange=ikev1 fragmentation=yes #开启对 iOS 拆包的重组支持 left=%defaultroute leftsubnet=0.0.0.0/0 leftfirewall=yes right=%any rightsourceip=10.100.100.0/24 #authby=xauthpsk #xauth=server leftauth=psk rightauth=psk rightauth2=xauth auto=addconn ikev2-eap-tls-wall keyexchange=ikev2 fragmentation=yes #开启IKE 消息分片，开启对 iOS 拆包的重组支持 ike=aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024! esp=aes256-sha256,aes256-sha1,3des-sha1! #leftca="C=CA, O=WORKER, CN=WORKER CA" #服务器端根证书DN名称，可以不需设置 leftca=caCert.pem #服务器端根证书,功能同上，可以不需设置 leftsigkey=serverPubKey.pem #指定服务器证书的公钥，可以不需设置 leftcert=serverCert.pem #服务器证书, 可以是 PEM 或 DER 格式 leftauth=pubkey #服务端认证方法,使用证书 leftid=@wall.suroot.com #IKEID (group name) used for vpn client,服务端id, 可以任意指定, 默认为服务器证书的 subject, 还可以是魔术字 %any，表示什么都行. left=%defaultroute #local IP used to connect to vpn client, 就是连接vpn客户端的网卡IP. 服务端公网ip, 可以是魔术字 %any，表示从本地ip地址表中取. leftsubnet=0.0.0.0/0 #服务器端子网, 魔术字 0.0.0.0/0. 如果为客户端分配虚拟 IP 地址的话，那表示之后要做 iptables 转发，那么服务器端就必须是用魔术字 leftfirewall=yes leftsendcert=always #是否发送服务器证书到客户端 right=%any rightid=@wallclient #客户端id, 任意 rightsourceip=10.100.100.0/24 #客户端虚拟ip段 #rightsubnet = &lt;ip subnet&gt;[[&lt;proto/port&gt;]][,...] rightauth=eap-tls rightsendcert=never #客户端不发送证书 rightsigkey=clientPubKey.pem #指定客户端公钥，可以不需设置 rightcert=clientCert.pem #指定客户端证书路径 #eap_identity=%any #对windows有用，设置windows rightid auto=add #当服务启动时, 应该如何处理这个连接项. add 添加到连接表中.## 用于windows认证conn ikev2-eap-mschapv2-win keyexchange=ikev2 ike=aes256-sha1-modp1024,aes128-sha1-modp1024,3des-sha1-modp1024! esp=aes256-sha256,aes256-sha1,3des-sha1! rekey=no #不自动重置密钥,服务器对 Windows 发出 rekey 请求会断开连接 fragmentation=yes #leftca="C=CA, O=WORKER, CN=WORKER CA" leftca=caCert.pem leftcert=serverCert.pem leftsigkey=serverPubKey.pem leftauth=pubkey leftid=@wall.suroot.com left=%defaultroute leftsubnet=0.0.0.0/0 leftfirewall=yes leftsendcert=always right=%any rightid = %any eap_identity=%any rightsourceip=10.100.100.0/24 #rightsubnet = &lt;ip subnet&gt;[[&lt;proto/port&gt;]][,...] rightauth=eap-mschapv2 #客户端认证使用 EAP 扩展认证 , 貌似 eap-mschapv2 比较通用 rightsendcert=never #客户端不发送证书 #rightsigkey = &lt;raw public key&gt; | &lt;path to public key&gt; #rightcert = &lt;path&gt; #不指定客户端证书路径 auto=add## 站点到站点模式conn tunnel left=%defaultroute leftsubnet=0.0.0.0/0 leftfirewall=yes right=139.219.239.51 rightsubnet=192.168.222.0/26 keyexchange=ikev2 ike=aes256-sha2_256-modp1024! esp=aes256-sha2_256! authby=secret keyingtries=0 ikelifetime=1h lifetime=8h dpddelay=30 dpdtimeout=120 dpdaction=clear auto=add type=tunnelEOF 密码配置文件123456789101112cat &gt;/etc/strongswan/ipsec.secrets &lt;&lt;EOF ## RSA PSK 需要分别对应客户端认证密码 : RSA serverKey.pem : RSA clientKey.pem : PSK "test1234" user1 %any : EAP "test1234" user2 %any : EAP "test1234" user1 %any : XAUTH "test1234" user2 %any : XAUTH "test1234"EOF 配置文件strongswan.conf12345678910111213141516171819202122232425262728cat &gt;/etc/strongswan/strongswan.conf &lt;&lt;EOFcharon &#123; load_modular = yes duplicheck.enable = no #冗余检查关闭，以允许同时连接多个设备 compress = yes #传输启用压缩 plugins &#123; include strongswan.d/charon/*.conf &#125; dns1 = 8.8.8.8 #给远程端指定DNS服务器 dns2 = 8.8.4.4 nbns1 = 8.8.8.8 #指定Windows的WINS服务器 nbns2 = 8.8.4.4 filelog &#123; #配置strongSwan日志级别和路径 /var/log/strongswan.log &#123; time_format = %b %e %T default = 5 # 日志最高等级5 append = no flush_line = yes &#125; &#125;&#125;include strongswan.d/*.confEOF 生成服务器和客户端证书1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#! /bin/bashserverCN="wall.suroot.com"serverIP="104.194.86.148"clientCN="wallclient"dn="C=CA, O=WORKER, CN="ca_dn="$&#123;dn&#125;WORKER CA"server_dn="$&#123;dn&#125;$&#123;serverCN&#125;"client_dn="$&#123;dn&#125;$&#123;clientCN&#125;"days=3650ipsec_d="/etc/strongswan/ipsec.d"caKeyfile="$&#123;ipsec_d&#125;/private/caKey.pem"caCertfile="$&#123;ipsec_d&#125;/cacerts/caCert.pem"serverKeyfile="$&#123;ipsec_d&#125;/private/serverKey.pem"serverPubKeyfile="$&#123;ipsec_d&#125;/certs/serverPubKey.pem"serverCertfile="$&#123;ipsec_d&#125;/certs/serverCert.pem"clientKeyfile="$&#123;ipsec_d&#125;/private/clientKey.pem"clientPubKeyfile="$&#123;ipsec_d&#125;/certs/clientPubKey.pem"clientCertfile="$&#123;ipsec_d&#125;/certs/clientCert.pem"#生成CA证书:#生成一个私钥strongswan pki --gen --type rsa --size 4096 --outform pem &gt; $&#123;caKeyfile&#125;#使用私钥生成自签名根证书strongswan pki --self --ca --lifetime $&#123;days&#125; --in $&#123;caKeyfile&#125; --type rsa --dn "$&#123;ca_dn&#125;" --outform pem &gt; $&#123;caCertfile&#125;## 显示CA证书内容strongswan pki --print --in $&#123;caCertfile&#125;#生成服务端证书:#生成一个私钥strongswan pki --gen --type rsa --size 2048 --outform pem &gt; $&#123;serverKeyfile&#125;#用私钥生成公钥strongswan pki --pub --in $&#123;serverKeyfile&#125; --type rsa --outform pem &gt; $&#123;serverPubKeyfile&#125;#用根证书给公钥签名生成服务器证书strongswan pki --issue --lifetime $&#123;days&#125; --cacert $&#123;caCertfile&#125; --cakey $&#123;caKeyfile&#125; --in $&#123;serverPubKeyfile&#125; --dn "$&#123;server_dn&#125;" --san="$&#123;serverCN&#125;" --san="$&#123;serverIP&#125;" --flag serverAuth --flag ikeIntermediate --outform pem &gt; $&#123;serverCertfile&#125;## 显示服务器证书内容strongswan pki --print --in $&#123;serverCertfile&#125;#生成客户端证书:#生成一个私钥strongswan pki --gen --type rsa --size 2048 --outform pem &gt; $&#123;clientKeyfile&#125;#用私钥生成公钥strongswan pki --pub --in $&#123;clientKeyfile&#125; --type rsa --outform pem &gt; $&#123;clientPubKeyfile&#125;#用根证书给公钥签名生成服务器证书strongswan pki --issue --lifetime $&#123;days&#125; --cacert $&#123;caCertfile&#125; --cakey $&#123;caKeyfile&#125; --in $&#123;clientPubKeyfile&#125; --dn "$&#123;client_dn&#125;" --san $&#123;clientCN&#125; --flag clientAuth --outform pem &gt; $&#123;clientCertfile&#125;strongswan pki --print --in $&#123;clientCertfile&#125;#为iPhone生成一个p12格式的客户端证书openssl pkcs12 -export -inkey $&#123;clientKeyfile&#125; -in $&#123;clientCertfile&#125; -name "$&#123;clientCN&#125;" -certfile $&#123;caCertfile&#125; -caname "$&#123;serverCN&#125;" -out $&#123;clientCertfile&#125;.p12## 变更证书权限chmod -R 0600 "$&#123;ipsec_d&#125;/private/" 重启strongswansystemctl restart strongswan systemctl enabble strongswan 显示当前接入动态信息swanctl --log iptables 配置方法firewalld 要比 iptables 占太多内存. 小内存的 vps 用 firewalld 有点奢侈. 还是换回 iptables 了. 将下面几条规则加入 iptables 规则中, 适当使用 -I 参数替换 -A 参数, 确保所有的项目位置都在拒绝项前面. #开放端口 iptables -A INPUT -p udp --dport 500 -j ACCEPT iptables -A INPUT -p udp --dport 4500 -j ACCEPT #启用ip伪装 iptables -t nat -I POSTROUTING -s 10.1.0.0/16 -o eth0 -m policy --dir out --pol ipsec -j ACCEPT iptables -t nat -A POSTROUTING -s 10.1.0.0/16 -o eth0 -j MASQUERADE #添加转发 iptables -A FORWARD -s 10.1.0.0/16 -j ACCEPT #保存规则 service iptables save #重启服务 systemctl restart iptables 如果嫌上面的操作麻烦, 可以直接编辑 iptables 规则文件. # vi /etc/sysconfig/iptables 将下面的规则部分贴进去, 不要整个复制粘贴, 根据原有规则适当调整每条规则的位置, 确保规则在拒绝项前, 使之能生效. *nat :PREROUTING ACCEPT [0:0] :INPUT ACCEPT [0:0] :OUTPUT ACCEPT [0:0] :POSTROUTING ACCEPT [0:0] -A POSTROUTING -s 10.1.0.0/16 -o eth0 -m policy --dir out --pol ipsec -j ACCEPT -A POSTROUTING -s 10.1.0.0/16 -o eth0 -j MASQUERADE COMMIT *filter :INPUT DROP [0:0] :FORWARD DROP [0:0] :OUTPUT ACCEPT [0:0] -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT -A INPUT -p udp -m udp --dport 500 -j ACCEPT -A INPUT -p udp -m udp --dport 4500 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -s 10.1.0.0/16 -j ACCEPT -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT 保存退出, 重启 iptables 使之生效. # systemctl restart iptables 配置说明证书使用配置说名. IKEv2有两个很总要的信息需要确认，一个是数字证书，证书必须正确配置ca、crt和key三个文件。其中服务器证书serverCert.crt中subject DN或subjectAltName字段必须包含服务器的IP或域名。 . left|rightid应该在用户认证过程中进行鉴别，同时left|rightcert的值应该是left|rightcert数字证书中的subject DN或subjectAltName中的值。left|rightid可以是IP地址、域名、邮箱地址甚至是证书中可以辨识的名称。 生成证书说明生成证书 # mkdir /cert &amp;&amp; cd /cert 下面所有的(--type rsa --size 2048|4096 )可以省略, me.touzhi.work 可以换成IP 地址 1) 生成 CA 根证书 A. 生成一个私钥，用于CA证书自签: yum安装的strongswan，命令已经变成&quot;strongswan --help&quot;了，而手动编译的还是&quot;ipsec --help&quot;，不要弄混，否则就是命令不存在了。 # strongswan pki --gen --type rsa --size 4096 --outform pem &gt; ca_key.pem B. 基于这个私钥自己签一个 CA 根证书： # strongswan pki --self --ca --flag serverAuth --lifetime 3650 --in ca_key.pem --type rsa --dn &quot;C=CN, O=WTO, CN=me.touzi.work&quot; --outform pem &gt;ca_cert.pem –self 表示自签证书 –in 是输入的私钥 –dn 是判别名 C 表示国家名，同样还有 ST 州/省名，L 地区名，STREET（全大写） 街道名 O 组织名称 CN 友好显示的通用名 –ca 表示生成 CA 根证书 –lifetime 为有效期, 单位是天 C. 显示CA 根证书内容 # strongswan pki --print --in ca_cert.pem 2) 生成服务器端证书 A. 生成一个私钥，用于服务端证书自签 # strongswan pki --gen --type rsa --size 2048 --outform pem &gt; server_key.pem B. 从私钥生成公钥 # strongswan pki --pub --in server_key.pem --type rsa --outform pem &gt; server_pub.pem C. 用刚生成的公钥生成服务器证书 # strongswan pki --issue --lifetime 1200 --in server_pub.pem \ --cacert ca_cert.pem --cakey ca_key.pem --dn &quot;C=CN, O=WTO, CN=me.touzi.work&quot; \ --san=&quot;me.touzi.work&quot; --san &quot;162.219.120.136&quot; --flag serverAuth --flag ikeIntermediate --outform pem &gt; server_cert.pem –issue, –cacert 和 –cakey 就是表明要用刚才自签的 CA 证书来签这个服务器证书。 –dn, –san，–flag 是一些客户端方面的特殊要求： . iOS 客户端要求 CN 也就是通用名必须是你的服务器的 URL 或 IP 地址; . Windows 7 不但要求了上面，还要求必须显式说明这个服务器证书的用途（用于与服务器进行认证），–flag serverAuth; . 非 iOS 的 Mac OS X 要求了“IP 安全网络密钥互换居间（IP Security IKE Intermediate）”这种增强型密钥用法（EKU），–flag ikdeIntermediate; . Android 和 iOS 都要求服务器别名（serverAltName）就是服务器的 URL 或 IP 地址，–san。 所以这里C、O的值要跟第一步的一致，CN值及--san值是服务器公网地址或url,另外这里可以设置多个--san值。否则会出现错误 13801:IKE身份验证凭证不可接受. D. 显示服务器证书内容 # strongswan pki --print --in server_cert.pem 3) 生成客户端证书(可选), 如果需要很高的安全性, 可以用客户端证书 A 生成客户端证书的私钥 # strongswan pki --gen --type rsa --size 2048 --outform pem &gt; client_key.pem 6) 用CA证书签发客户端证书 A. 从私钥生成公钥 # strongswan pki --pub --in client_key.pem --type rsa --outform pem &gt; client_pub.pem B. 签发客户端证书,这里就不需要上面那一堆特殊参数了 # strongswan pki --issue --in client_pub.pem \ --cacert ca_cert.pem --cakey ca_key.pem --dn &quot;C=CN, O=WTO, CN=dolphin@126.com&quot; \ --san dolphin@126.com --lifetime 1200 --outform pem &gt; client_cert.pem --flag serverAuth --flag ikeIntermediate --san dolphin@126.com 可以省略,--san CN= 可以是邮箱地址，也可以是me.touzhi.work C. 打包证书为 pkcs12，生成 pkcs12 证书 # openssl pkcs12 -export -inkey client_key.pem -in client_cert.pem -name &quot;WTO Client&quot; \ -certfile ca_cert.pem -caname &quot;me.touzi.work&quot; -out client_cert.p12 CA证书转换,以防部分客户端不支持 # openssl x509 -inform PEM -outform DER -in ca_cert.pem -out ca.crt 8) 安装证书, 把证书复制到strongswan目录下 # cp -r ca_key.pem /etc/strongswan/ipsec.d/private/ # cp -r ca_cert.pem /etc/strongswan/ipsec.d/cacerts/ # cp -r server_cert.pem /etc/strongswan/ipsec.d/certs/ # cp -r server_key.pem /etc/strongswan/ipsec.d/private/ # cp -r server_pub.pem /etc/strongswan/ipsec.d/certs/ # cp -r client_cert.pem /etc/strongswan/ipsec.d/certs/ # cp -r client_key.pem /etc/strongswan/ipsec.d/private/ 把 CA 证书(ca_cert.pem)、客户端证书(client_cert.pem)和 .p12 证书(client_cert.p12)用 FTP 复制出来给客户端用 配置验证方式的用户名与密码下面添加用户 # vi /etc/strongswan/ipsec.secrets #使用证书验证时的服务器端私钥 #格式 : RSA &lt;private key file&gt; [ &lt;passphrase&gt; | %prompt ] : RSA server_key.pem #使用预设加密密钥, 越长越好 #格式 [ &lt;id selectors&gt; ] : PSK &lt;secret&gt; %any : PSK &quot;预设加密密钥&quot; #EAP 方式, 格式同 psk 相同 用户名 : EAP &quot;密码&quot; #XAUTH 方式, 只适用于 IKEv1 #格式 [ &lt;servername&gt; ] &lt;username&gt; : XAUTH &quot;&lt;password&gt;&quot; 用户名 : XAUTH &quot;密码&quot; 示例： 创建了VPN用户john和他的密码。在添加用户的时候，请注意在冒号（：）左右两边都需要一个空格。 : RSA server_key.pem : PSK &quot;PSK_KEY&quot; john %any : EAP &quot;John&apos;s Password&quot; john %any : XAUTH &quot;John&apos;s Password&quot; : RSA server_key.pem #使用证书验证时的服务器端私钥 : PSK &quot;123456&quot; #使用预设密钥时, 8-63位ASCII字符 : XAUTH &quot;123456&quot; #这里是使用XAUTH验证时的用户名和密码 VPN %any : EAP &quot;123456&quot; #这里是使用EAP验证时的用户名和密码 客户端配置在客户端安装(client_cert.p12,ca_cert.pem)两个证书如果你是使用iPhone, 可以通过邮件将这个两个证书发送到iPhone上然后安装。 先下载安装一开始生成的CA证书ca_cert.pem,可能需要改扩展名,如ca.crt IOS 9.x: 类型 IKEv2 服务器是 IP 或是 URL 远程ID是 IP 或是 URL 账户和密码填 ipsec.secrets 里 EAP 前后的那两个 IOS 9 以下: 类型 IPSec iPhone, Android, Windows PC都可以通过证书加密码的方式登录VPN； Mac OS X可以通过PSK key加密码的方式登录。 1) IOS: 先导入 CA 证书 将之前创建的 ca_cert.pem 用 ftp 导出 , 写邮件以附件的方式发到邮箱, 在 ios 浏览器登录邮箱, 下载附件, 安装 ca 证书. 1. 使用 IKEv2 + EAP 认证 找到手机上 “设置-&gt;VPN-&gt;添加配置”, 选 IKEv2 描述: 随便填 服务器: 填url或ip 远程ID: ipsec.conf 中的 leftid 用户鉴定: 用户名 用户名: EAP 项用户名 密码: EAP 项密码 2. 使用 IKEv2 + 客户端证书 认证 把之前的 .p12 证书(里面包含ca证书)发到邮箱在手机上打开. 导入到手机(此时需要之前设置的证书密码). 找到手机上 “设置-&gt;VPN-&gt;添加配置”, 选 IKEv2 描述: 随便填 服务器: 填url或ip 远程ID: ipsec.conf 中的 leftid 用户鉴定: 证书 证书: 选择安装完的客户端证书 3. 使用 IKEv2 + 预设密钥 认证 找到手机上 “设置-&gt;VPN-&gt;添加配置”, 选 IKEv2 描述: 随便填 服务器: 填url或ip 远程ID: ipsec.conf 中的 leftid 用户鉴定: 无 使用证书: 关 密钥: PSK 项密钥 2) Windows 10 导入证书： 将 CA 根证书 ca_cert.pem 重命名为 ca_cert.crt 双击 ca_cert.crt 开始安装证书 点击安装证书 “存储位置” 选择 “本地计算机”, 下一步 选择 “将所有的证书都放入下列存储区”, 点浏览, 选择 “受信任的根证书颁发机构”, 确定, 下一步, 完成. 建立连接： “控制面板”-“网络和共享中心”-“设置新的连接或网络”-“连接到工作区”-“使用我的 Internet 连接” Internet 地址写服务器 IP 或 URL。 描述随便写。 用户名密码写之前配置的 EAP 的那个。 确定 转到 控制面板网络和 Internet网络连接 在新建的 VPN 连接上右键属性然后切换到“安全”选项卡 VPN 类型选 IKEv2 数据加密选“需要加密” 身份认证这里需要说一下，如果想要使用 EAP 认证的话就选择“Microsoft:安全密码(EAP-MSCHAP v2)”; 想要使用私人证书认证的话就选择“使用计算机证书”。 再切换到 “网络” 选项卡, 双击 “Internet 协议版本 4” 以打开属性窗口, 这里说一下, 如果你使用的是老版本的 win10, 可能会打不开属性窗口, 这是已知的 bug, 升级最新版本即可解决. 点击 “高级” 按钮, 勾选 “在远程网络上使用默认网关”, 确定退出. VPN 配置完成 3) Windows 7 导入证书略有不同 开始菜单搜索「cmd」，打开后输入 mmc（Microsoft 管理控制台）。 「文件」-「添加/删除管理单元」，添加「证书」单元 证书单元的弹出窗口中一定要选「计算机账户」，之后选「本地计算机」，确定。 在左边的「控制台根节点」下选择「证书」-「受信任的根证书颁发机构」-「证书」，右键 -「所有任务」-「导入」打开证书导入窗口。 选择 CA 证书 ca_cert.crt 导入即可 注意 千万不要双击 .p12 证书导入！因为那样会导入到当前用户而不是本机计算机中，ipsec 守护精灵是访问不了它的。 其它配置参考## 参考配置11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950config setup uniqueids=never charondebug="cfg 2, dmn 2, ike 2, net 0" conn %default left=%defaultroute leftsubnet=0.0.0.0/0 leftcert=vpnHostCert.pem right=%any rightsourceip=10.0.0.0/24 conn xauth_pubkey_ikev1 keyexchange=ikev1 fragmentation=yes rightauth=pubkey rightauth2=xauth leftsendcert=always rekey=no auto=add conn xauth_psk_ikev1 keyexchange=ikev1 leftauth=psk rightauth=psk rightauth2=xauth auto=add dpdaction=hold dpddelay=600s dpdtimeout=5s lifetime=24h ikelifetime=240h rekey=no conn pubkey_ikev2 keyexchange=ikev2 leftauth=pubkey rightauth=pubkey leftsendcert=always auto=add conn eap_ikev2 keyexchange=ikev2 ike=aes256-sha1-modp1024! rekey=no leftauth=pubkey leftsendcert=always rightauth=eap-mschapv2 eap_identity=%any auto=add ## 站点到站点tunnel配置1234567891011121314151617181920212223242526272829303132333435## https://help.aliyun.com/document_detail/65374.html?spm=a2c4g.11186623.6.569.H47Tmw# vi /etc/strongswan/ipsec.conf# ipsec.conf - strongSwan IPsec configuration file# basic configurationconfig setup uniqueids=neverconn %default authby=psk type=tunnelconn tomyidc keyexchange=ikev1 left=59.110.165.70 leftsubnet=172.16.2.0/24 leftid=59.110.165.70（IDC网关设备的公网IP） right=119.23.227.125 rightsubnet=192.168.10.0/24 rightid=119.23.227.125（VPN网关的公网IP） auto=route ike=aes-sha1-modp1024 ikelifetime=86400s esp=aes-sha1-modp1024 lifetime=86400s type=tunnel# vi /etc/strongswan/ipsec.secrets59.110.165.70 119.23.227.125 : PSK yourpassword# 打开系统转发配置。# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 参考文档搭建strongswan服务器 http://www.bewindoweb.com/123.html https://expats-in-china.com/t/setup-a-vpn-ipsec-on-centos-7-using-strongswan/27]]></content>
      <categories>
        <category>strongswan</category>
      </categories>
      <tags>
        <tag>strongswan</tag>
        <tag>ipsec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用strongswan 搭建站点到站点tunnel]]></title>
    <url>%2Fstrongswan%2F%E4%BD%BF%E7%94%A8strongswan%20%E6%90%AD%E5%BB%BA%E7%AB%99%E7%82%B9%E5%88%B0%E7%AB%99%E7%82%B9tunnel%2F</url>
    <content type="text"><![CDATA[搭建环境：两台strongswang 运行在Azure云上一个虚拟网络的虚机里，有内部IP和公网IP strongswan服务器vpn1 网络空间 10.250.250.0/24 内部IP地址 10.250.250.69 外部公网IP地址 139.219.133.12 共享密匙 /etc/strongswan/ipsec.secrets strongswan 服务器vpn2 网络空间 10.10.50.0/24 内部IP地址 10.10.50.4 外部公网IP地址 42.159.93.91 共享密匙 /etc/strongswan/ipsec.secrets 架构图子网[10.250.250.0/24]----&gt;[可配对内网卡]vpn1[10.250.250.69]--|防火墙|--[139.219.133.12]---&gt;internet---[42.159.93.91]--|防火墙|--&gt;[10.10.50.4]vpn2[可配对内网卡]----&gt;子网[10.10.50.0/24] 环境变量## 两台vpn服务器上设置123456789101112cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF ## 开启转发 net.ipv4.ip_forward=1 net.ipv6.conf.all.forwarding=1 ## 禁止重定向，比如禁止ICMP重定向报文 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0 EOFsysctl -p 防火墙配置## 两台vpn服务器上设置 firewall-cmd --permanent --add-service=ipsec firewall-cmd --permanent --add-masquerade firewall-cmd --reload 共享密匙## 两台vpn服务器上设置 ## psk 前面的是leftid 和 rightid, 两服务器都一样1234cat &gt; /etc/strongswan/ipsec.secrets &lt;&lt; EOF192.168.222.4 139.219.99.158 : PSK 'sharedsecret' EOF strongswan 服务器1 配置123456789101112131415161718192021222324252627282930313233cat &gt; /etc/strongswan/ipsec.conf &lt;&lt; EOFconfig setup uniqueids = noconn ss closeaction=restart dpdaction=restart ike=aes256-sha1-modp1024 esp=aes256-sha1 reauth=no keyexchange=ikev2 # Mandatory for Dynamic / Route-based gateway mobike=no ikelifetime=28800s keylife=3600s keyingtries=%forever authby=secret #auto=route # 这不知有何所用，所以先不用 ## strongswan在防火墙后通过NAT转发，必须设置leftid rightid left=10.250.250.69 # 如果vpn服务器在防火墙后,只配有内网IP, 此处必须填虚机面向vpn连接的内网IP，而不是strongswan虚机所在Azure云的外网IP；如果虚机上直接配有公网IP，则填公网IP,如阿里云。 leftsubnet=10.250.250.0/24 # 内部子网,多网段用逗号隔开 leftid=139.219.133.12 # local instance ip (strongswan), 此处填公网IP，也可以填内网IP，也可以设置一个字符id，比如vpn1，但必须和ipsec.secrets里对应 right=42.159.93.91 # 这里必须填对端vpn服务器的公网IP rightid=42.159.93.91 # 此值必须对应ipsec.secrets, 可以是公网IP地址，也可以设置一个字符id，比如vpn2，但必须和ipsec.secrets里对应 rightsubnet=10.10.50.0/24 # 对端VPN服务器子网,多网段用逗号隔开 auto=startEOF strongswan 服务器2 配置12345678910111213141516171819202122232425262728293031cat &gt; /etc/strongswan/ipsec.conf &lt;&lt; EOFconfig setup uniqueids = noconn ss closeaction=restart dpdaction=restart ike=aes256-sha1-modp1024 esp=aes256-sha1 reauth=no keyexchange=ikev2 mobike=no ikelifetime=28800s keylife=3600s keyingtries=%forever authby=secret #auto=route left=10.10.50.4 leftsubnet=10.10.50.0/24 leftid=42.159.93.91 right=139.219.133.12 rightid=139.219.133.12 rightsubnet=10.250.250.0/24 auto=startEOF vpn 服务器上系统路由添加## vpn 1: ip route add 10.10.50.0/26 dev &lt;连接对端vpn的网卡设备名&gt; ## vpn 2: ip route add 10.250.250.0/26 dev &lt;连接对端vpn的网卡设备名&gt; 子网客户端系统路由添加## vpn 1 所在子网的客户端添加路由, 10.250.250.69是vpn服务的连接内网的ip地址(如果双网卡) ip route add 10.10.50.0/26 via 10.250.250.69 ## vpn 2 所在子网的客户端添加路由, 10.10.50.4是vpn服务的连接内网的ip地址(如果双网卡) ip route add 10.250.250.0/26 via 10.10.50.4 Azure平台设置平台不做设置，只能vpn服务器ping通对端子网地址，而子网内的客户端不能ping通对端子网或对端VPN服务器 如果VPN是架在Azure平台上，必须设置： 1. vpn虚机连接对端vpn网卡上的转发功能必须开启。 2. 添加路由表 服务器1 端的路由表的设置： 地址前缀: 10.10.50.0/24 ## 对端vpn的子网 下一跳类型: 虚拟设备 下一跳地址: 10.250.250.69 ## VPN服务器的连接内网的IP地址(如果是采用双网卡) 在把路由表绑定到本端子网，这些子网需要通过此vpn连接对端子网。 服务器2 端的路由表的设置： 地址前缀: 10.250.250.0/24 ## 对端vpn的子网 下一跳类型: 虚拟设备 下一跳地址: 10.10.50.4 ## VPN服务器的连接内网的IP地址(如果是采用双网卡) 在把路由表绑定到本端子网，这些子网需要通过此vpn连接对端子网。 3. 安全组需要开通4500/udp 500/udp aws 平台需要关闭VPN服务器网卡默认的“源/目标检查”，默认为开启状态 需要设置平台路由表和安全组 具体没操作过，此略。 参考https://wiki.strongswan.org/projects/strongswan/wiki/UsableExamples]]></content>
      <categories>
        <category>strongswan</category>
      </categories>
      <tags>
        <tag>strongswan</tag>
        <tag>ipsec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用strongswan 与 Azure gateway 建立 ipsec vpn 连接]]></title>
    <url>%2Fstrongswan%2F%E4%BD%BF%E7%94%A8strongswan%20%E4%B8%8E%20Azure%20gateway%20%E5%BB%BA%E7%AB%8B%20ipsec%20vpn%20%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[搭建环境：strongswang 运行在Azure云上一个虚拟网络的虚机里，有内部IP和公网IP，Azure vpn gateway 有公网IP Azure 端的虚拟网络地址空间 192.168.120.0/24 Azure VPN getaway 公网IP 139.219.99.158 内网Ip：192.168.120.126 运行strongswan的办公点或其他公有云的网络空间 192.168.222.0/24 运行strongswan内部IP地址 192.168.222.4 运行strongswan外部公网IP地址 139.219.239.51 共享密匙 /etc/strongswan/ipsec.secrets strongswan 的配置# vi /etc/strongswan/ipsec.conf config setup # strictcrlpolicy=yes uniqueids = no conn office-network-to-azure-southeast-asia closeaction=restart dpdaction=restart ike=aes256-sha1-modp1024 esp=aes256-sha1 reauth=no keyexchange=ikev2 # Mandatory for Dynamic / Route-based gateway mobike=no ikelifetime=28800s keylife=3600s keyingtries=%forever authby=secret #auto=route # 这不知有何所用，所以先不用 left=192.168.222.4 # local instance ip (strongswan), 此处必须填虚机的内网IP，而不是strongswan虚机所在Azure云的外网IP leftsubnet=192.168.222.0/24 leftid=192.168.222.4 # local instance ip (strongswan), 此处填公网IP，也可以填内网IP，但必须和ipsec.secrets里对应 right=139.219.99.158 # vpn gateway ip (azure), 这里必须填对端的公网IP rightid=139.219.99.158 # vpn gateway ip (azure) rightsubnet=192.168.120.0/24,192.168.130.0/24 # private ip segment (azure),azure vpn gateway 后端的虚拟网络的地址空间,多网段用逗号隔开 auto=start # vi /etc/strongswan/ipsec.secrets 192.168.222.4 139.219.99.158 : PSK &apos;sharedsecret&apos; azure vpn gateway 设置1) 创建一个本地网络网关名为test-azure-strongswan，用于设置对端strongswan 的配置信息 IP address：:139.219.239.51（就是对端网关strongswan外网地址) Address space: 192.168.222.0/24 （就是对端虚拟网络的地址空间范围，用于路由) Configure BGP settings：这个是用于动态路由，strongswan不一定支持 Autonomous system number (ASN)：7773 （就是对端网关test-gw03n ASN） BGP peer IP address：192.168.120.126 （就是对端网关 内网IP(BGP peer IP address),可以在虚拟网络网关配置项（Configuration)里看到) 2） 在Azure VPN getaway网关的portal面板上找到connections配置项，添加一个connection connection type: site-to-site(ipsec) virtual network gateway: 自动选择本端网关test-gw03n Local network gateway ：选择上面创建的本地网关test-azure-strongswan, 用于连接对应的对端网关test-gw03n shared key （psk)： sharedsecret 保存后，（启用BGP就不需要了：在新建的连接con-02n-03n 配置面板里找到 configuration配置项，启用BGP。） 3） 等等一会，看刚才建的连接状态为connected就表示vpn连通了，可以进行互相ping [root@cdd0-vm-zbs01pe strongswan]# ping 192.168.120.4 PING 192.168.120.4 (192.168.120.4) 56(84) bytes of data. 64 bytes from 192.168.120.4: icmp_seq=1 ttl=63 time=32.8 ms 64 bytes from 192.168.120.4: icmp_seq=2 ttl=63 time=32.4 ms [root@test-gw-vm03n ~]# ping 192.168.222.4 PING 192.168.222.4 (192.168.222.4) 56(84) bytes of data. 64 bytes from 192.168.222.4: icmp_seq=1 ttl=63 time=32.7 ms 64 bytes from 192.168.222.4: icmp_seq=2 ttl=63 time=32.4 ms]]></content>
      <categories>
        <category>strongswan</category>
      </categories>
      <tags>
        <tag>strongswan</tag>
        <tag>ipsec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firewalld 详解]]></title>
    <url>%2Flinux%2Ffirewall%2Ffirewalld%20%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[官网https://firewalld.org 使用ipset## 获取ipset类型(hash:net hash:ip) firewall-cmd --get-ipset-types ## 创建ipset,名为blacklist, 采用ip hash方式 firewall-cmd --permanent --new-ipset=blacklist --type=hash:ip firewall-cmd --permanent --add-rich-rule=&apos;rule source ipset=blacklist drop&apos; firewall-cmd --reload firewall-cmd --ipset=blacklist --add-entry=118.186.17.9 --permanent ## 查看被ipset 中的IP firewall-cmd --info-ipset=blacklist ## ipv6 firewall-cmd --permanent --new-ipset=blacklist6 --type=hash:ip --option=family=inet6 firewall-cmd --reload firewall-cmd --ipset=blacklist6 --add-entry=fe80::07FF:0004 firewall-cmd --ipset=blacklist6 --add-entry=fe80::07FF:0006 firewall-cmd --ipset=blacklist6 --add-entry=fe80::07FF:0008 firewall-cmd --ipset=blacklist6 --add-entry=fe80::07FF:0010 firewall-cmd --add-rich-rule=&apos;rule source ipset=blacklist6 drop&apos; # firewall-cmd --permanent --add-rich-rule=&quot;rule family=ipv4 source address=43.229.53.61 reject&quot;]]></content>
      <categories>
        <category>linux</category>
        <category>firewall</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived和LVS]]></title>
    <url>%2Fkeepalived%2FKeepalived%E5%92%8CLVS%2F</url>
    <content type="text"><![CDATA[安装yum install keepalived ipvsadm psmisc 防火墙firewall-cmd --zone=public --add-rich-rule=&apos;rule family=&quot;ipv4&quot; destination address=&quot;224.0.0.18&quot; protocol value=&quot;vrrp&quot; accept&apos; --permanent firewall-cmd --reload LVS相关术语：1. DS：Director Server。指的是前端负载均衡器节点。 2. RS：Real Server。后端真实的工作服务器。 3. VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。 4. DIP：Director Server IP，主要用于和内部主机通讯的IP地址。 5. RIP：Real Server IP，后端服务器的IP地址。 6. CIP：Client IP，访问客户端的IP地址。 LVS集群方式：lvs-nat：修改请求报文的目标IP；多目标IP的DNAT lvs-dr：操纵封装新的MAC地址 lvs-tun：在原请求IP报文之外新加一个IP首部 lvs-fullnat：修改请求报文的源和目标IP IPVS的调度算法根据其调度时是否考虑各RS当前的负载状态，可分为静态方法和动态方法两种： 静态方法：仅根据算法本身进行调度 RR：roundrobin，轮询 WRR：Weighted RR，加权轮询 SH：Source Hashing，实现session sticy，源IP地址hash；将来自于同一个IP地址的请求始终发往第一次挑中的RS，从而实现会话绑定 DH：Destination Hashing；目标地址哈希，将发往同一个目标地址的请求始终转发至第一次挑中的RS，典型使用场景是正向代理缓存场景中的负载均衡 动态方法：主要根据每个RS当前的负载状态及调度算法进行调度 LC：least connections 最小连接调度 Overhead=activeconns*256+inactiveconns WLC：Weighted LC 加权最小连接调度 Overhead=(activeconns*256+inactiveconns)/weight SED：Shortest Expection Delay Overhead=(activeconns+1)*256/weight NQ：Never Queue LBLC：Locality-Based LC，动态的DH算法；基于局部性的最少链接 LBLCR：LBLC with Replication，带复制功能的LBLC,带复制的基于局部性最少链接 lvs-dr说明 Direct Routing，直接路由,通过为请求报文重新封装一个MAC首部进行转发，源MAC是DIP所在的接口的MAC，目标MAC是某挑选出的RS的RIP所在接口的MAC地址；源IP/PORT，以及目标IP/PORT均保持不变。 Director和各RS都得配置使用VIP； (1) 确保前端路由器将目标IP为VIP的请求报文发往Director； (a) 在前端网关做静态绑定； (b) 在RS上使用arptables； (c) 在RS上修改内核参数以限制arp通告及应答级别； arp_announce arp_ignore (2) RS的RIP可以使用私网地址，也可以是公网地址；RIP与DIP在同一IP网络；RIP的网关不能指向DIP，以确保响应报文不会经由Director； (3) RS跟Director要在同一个物理网络； (4) 请求报文要经由Director，但响应不能经由Director，而是由RS直接发往Client； (5) 不支持端口映射。 ip地址配置示例： Director： eht0 --DIP： 192.168.1.101 eth0:0 --VIP：192.168.1.100 Real Server1: eth0 --RIP: 192.168.1.102 lo:0 --VIP： 192.168.1.100 Real Server2: eth0 --RIP: 192.168.1.103 lo:0 --VIP： 192.168.1.100 需要解决两个问题： 1) Real Server上的VIP对外不可见: 即对网络内的VIP的ARP请求，Real Server不响应，只有Director响应，这样Client的请求就能首先路由到Director，再由Director转发到Real Server； echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce 说明： arp_ignore和arp_announce 默认值都为0 arp_ignore: 定义接收到ARP请求时的响应级别； 0：只要本地配置的有相应地址，就给予响应；默认； 1：仅在请求的目标地址配置在到达的接口上的时候，才给予响应； arp_announce：定义将自己地址向外通告时的通告级别； 0：将本地任何接口上的任何地址向外通告；默认； 1：试图仅向目标网络通告与其网络匹配的地址； 2：仅向与本地接口上地址匹配的网络进行通告； 2) Real Server直接返回Client Director转发client的请求到Real Server后，Real Server通过eth0--RIP接收处理，而响应回去的源地址需要为VIP，即通过lo:0--VIP接口返回，而不是RIP接口； route add -host 192.168.1.100 dev lo:0 注意：假如VIP与RIP不在同一网段（RIP为私有网络IP）,Real Server转发Client的需要经由另外一个私有网关接口出去； Director 和 real server 配置的虚拟VIP的广播地址必须相同 ifconfig eth0:0 192.168.1.100 broadcast 192.168.1.100 netmask 255.255.255.255 up ## Real Server服务器的lvs_real_dr.sh脚本 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bash#chkconfig: 2345 79 20#description:realserver#定义虚拟IP变量Vip=192.168.1.100source /etc/rc.d/init.d/functionscase "$1" instart) echo "Start Real Server..." # 在Real服务器上基于回环虚拟网卡lo建立一个虚拟网络接口 /sbin/ifconfig lo:1 $Vip broadcast $Vip netmask 255.255.255.255 up # 将虚拟地址添加到路由表 /sbin/route add -host $Vip dev lo:1 # 定义对目标地址为本地IP的ARP询问的应答模式(1表示只应答目标Ip是接收请求的网络接口(非网卡，双接口可共用一个网卡)本地地址的ARP查询请求) echo "1" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore # 控制系统在对外发送arp请求时，如何选择arp请求数据包的源IP地址(2表示忽略Ip数据包源地址，选择可能接收到该ARP回应的网络接口来进行发送) echo "2" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo "1" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo "2" &gt;/proc/sys/net/ipv4/conf/all/arp_announce ;; stop) echo "Close Real Server..." # 关闭这个网卡 ifconfig lo:1 down # 恢复arp_ignore和arp_announce的值 echo "0" &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore echo "0" &gt;/proc/sys/net/ipv4/conf/lo/arp_announce echo "0" &gt;/proc/sys/net/ipv4/conf/all/arp_ignore echo "0" &gt;/proc/sys/net/ipv4/conf/all/arp_announce ;; *) echo "Usage: "$1" &#123;start|stop&#125;" ;; esacexit 0 ## 调度服务器的lvs_serv_dr.sh脚本123456789101112131415161718192021222324252627282930313233343536373839404142#! /bin/bash#定义虚拟IP和实服务IP变量Vip=192.168.1.100Rs1=192.168.1.102Rs2=192.168.1.103source /etc/rc.d/init.d/functionscase "$1" instart) echo "Start LVS of Server..." # 在Director服务器上基于物理网卡eth0建立一个虚拟网络接口(新增一个子网卡，设置它的虚拟IP和广播地址以及子网掩码并启动) /sbin/ifconfig eth0:1 $Vip broadcast $Vip netmask 255.255.255.255 up # 打开Director服务器上开启路由转发功能(多网卡下的网卡间数据包转发) #echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 将虚拟地址添加到路由表 /sbin/route add -host $Vip dev eth0:1 # 清除所有的虚拟服务器记录 /sbin/ipvsadm -C # 在内核虚拟服务器表中添加一台虚拟服务器(指定为tcp协议，指定虚拟ip和prot，指定调度算法) /sbin/ipvsadm -A -t $Vip:6500 -s rr # rr 表示轮询调度 # 在一台虚拟服务器中增加一台新的真实服务器(执行虚拟服务对应真实服务的关系，指定负载均衡模式) /sbin/ipvsadm -a -t $Vip:6500 -r $Rs1:6500 -g # -g 表示DR模式 /sbin/ipvsadm -a -t $Vip:6500 -r $Rs2:6500 -g # 启动LVS /sbin/ipvsadm ;; stop) echo "Close LVS of Server..." # 清除所有的虚拟服务器记录 /sbin/ipvsadm -C # 关闭这个子网卡 /sbin/ifconfig eth0:1 down ;; *) echo "Usage： $0 &#123;start|stop&#125;" ;; esac exit 0 lvs-nat说明NAT方式配置 这种方式需要Director和各Real Server在同一IP网络内（172.16.100.0/24），具体配置如下示例： Director： eht0 --VIP：192.168.0.146 gateway：局域网网关(路由器地址) eth1 --DIP：172.16.100.10 gateway：为空，不需要填 Real Server1(RS1): eth0 --RIP: 172.16.100.2 gateway：172.16.100.10 Real Server2(RS2): eth0 --RIP: 172.16.100.3 gateway：172.16.100.10 配置director打开网卡间的转发功能，echo &apos;1&apos; &gt;/proc/sys/net/ipv4/ip_forward ## LVS - 地址转换(NAT)模式示例，Director节点的lvs_serv_nat.sh脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/bin/bash # 配置实服务主机IP，调度器虚拟IP(调度器节点需要双网卡，对外地址为VIP，内网地址需要设置为RS网关)Vip=192.168.1.100Rs1=192.168.1.101Rs2=192.168.1.102 source /etc/rc.d/init.d/functions case "$1" in start) echo "Start LVS of Server..." # 打开Director服务器上开启路由转发功能(多网卡下的网卡间数据包转发) echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 清空防火墙nat表的所有链 #iptables -t nat -F # 删除防火墙nat自定义链 #iptables -t nat -X # 新增一个子网卡 /sbin/ifconfig eth0:0 $Vip netmask 255.255.240.0 up # 设置Director的ipvs /sbin/ipvsadm -C # 在内核虚拟服务器表中添加一台虚拟服务器 /sbin/ipvsadm -A -t $Vip:6500 -s rr # rr 表示轮询调度 # 在一台虚拟服务器中增加一台新的真实服务器(指定虚拟服务对应真实服务的关系，指定负载均衡模式) /sbin/ipvsadm -a -t $Vip:6500 -r $Rs1:6500 -m # -m 表示NAT模式 /sbin/ipvsadm -a -t $Vip:6500 -r $Rs2:6500 -m # 启动LVS /sbin/ipvsadm ;;stop) echo "Close LVS of Server..." echo "0" &gt;/proc/sys/net/ipv4/ip_forward /sbin/ipvsadm -C /sbin/ifconfig eth0:0 down ;; *) echo "Usage： $0 &#123;start|stop&#125;" ;; esac exit 0 修改系统参数echo &apos;net.ipv4.ip_nonlocal_bind = 1&apos; &gt;&gt; /etc/sysctl.conf echo &apos;net.ipv4.ip_forward = 1&apos; &gt;&gt; /etc/sysctl.conf sysctl -p 架构 IP分配： VIP1:172.18.67.66 VIP2:172.18.67.88 DIP1:172.18.67.13 DIP2:172.18.67.14 RIP1:172.18.67.11 RIP2:172.18.67.12 CIP:172.18.67.3 keepalived## 主备不同之处 1，router_id 不能一致 2，state MASTER/BACKUP 3, priority 权重不能一致 4, interface ens33 网络接口注意和本机对应 keepalived master123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost IT@service.com &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id lvs01 vrrp_garp_master_refresh 60 vrrp_garp_master_delay 5 vrrp_mcast_group4 224.0.0.18&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 50 priority 100 advert_int 1 #garp_master_delay 10 #garp_master_refresh 60 #nopreempt smtp_alert authentication &#123; auth_type PASS auth_pass DFwx4893Gh60 &#125; virtual_ipaddress &#123; ## &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 172.18.67.66/24 dev ens33 label ens33:1 &#125; ## mcast_src_ip &lt;IPADDR&gt; #unicast_src_ip 172.18.67.13 #unicast_peer &#123; # 172.18.67.14 #&#125; track_interface &#123; ens33 &#125; ## 可以不用执行脚本，除非需要执行某些操作。keepalived 1.5 + postfix 能够发送邮件。 #notify_master "/etc/keepalived/notify.sh master" #notify_backup "/etc/keepalived/notify.sh backup" #notify_fault "/etc/keepalived/notify.sh fault"&#125;## 设置vip地址和端口，DR架构WEB端口要和虚拟端口监听一致。否则将无法访问virtual_server 172.18.67.66 80 &#123; delay_loop 6 ## service polling的delay时间，即服务轮询的时间间隔，单位为妙 lb_algo rr ## 调度策略，支持rr|wrr|lc|wlc|lblc|sh|dh lb_kind DR ## LVS集群模式：NAT|DR|TUN persistence_timeout 0 ## 会话保持时间（持久连接，秒），同一IP在这段时间内的请求都发到同个real server,如果是mysql之类的长连接可以设置长点，比如7200 protocol TCP ## 使用TCP协议，keepalived只支持TCP协议 #net_mask 255.255.255.0 sorry_server 127.0.0.1 80 ## 所有realserver都down机，指定的备用服务器 ## 后端真实WEB服务器地址与端口 real_server 172.18.67.11 80 &#123; weight 1 ## 调度权重 #inhibit_on_failure ##表示在节点失败后，把他权重设置成0，而不是冲IPVS中删除 #notify_up &lt;STRING&gt; | &lt;QUOTED-STRING&gt; ##检查服务器正常(UP)后，要执行的脚本 #notify_down &lt;STRING&gt; | &lt;QUOTED-STRING&gt; ##检查服务器失败(down)后，要执行的脚本 #uthreshold &lt;INTEGER&gt; ## maximum number of connections to server #lthreshold &lt;INTEGER&gt; ## minimum number of connections to server ## 健康检查方式，一共HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK ## HTTP_GET检查url，SSL_GET检查https url,TCP_CHECK检查tcp连接，可用在mysql检查 HTTP_GET &#123; ## 要检查的URL，可以有多个 url &#123; path / status_code 200 ## 返回成功状态码，也可以用另外一个选项配置返回字符串 &#125; connect_timeout 2 ## 连接超时时间 nb_get_retry 3 ## 重连次数 delay_before_retry 3 ## 重连间隔 &#125; ## 通过检查TCP端口来检测 #TCP_CHECK &#123; # connect_timeout 10 ##连接超时时间 # nb_get_retry 3 # delay_before_retry 3 # connect_port 80 ## 连接端口为80，要和上面的保持一致 #&#125; &#125; real_server 172.18.67.12 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 3 &#125; &#125; &#125;##virtual_server 172.18.67.33 80 &#123;##....##&#125;EOF keepalived backup12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost IT@service.com &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id lvs02 vrrp_garp_master_refresh 60 vrrp_garp_master_delay 5 vrrp_mcast_group4 224.0.0.18&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 50 priority 90 advert_int 1 #garp_master_delay 10 #garp_master_refresh 60 #nopreempt smtp_alert authentication &#123; auth_type PASS auth_pass DFwx4893Gh60 &#125; virtual_ipaddress &#123; ## &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 172.18.67.66/24 dev ens33 label ens33:1 &#125; ## mcast_src_ip &lt;IPADDR&gt; #unicast_src_ip 172.18.67.13 #unicast_peer &#123; # 172.18.67.14 #&#125; track_interface &#123; ens33 &#125; #notify_master "/etc/keepalived/notify.sh master" #notify_backup "/etc/keepalived/notify.sh backup" #notify_fault "/etc/keepalived/notify.sh fault"&#125;virtual_server 172.18.67.66 80 &#123; delay_loop 6 lb_algo rr lb_kind DR persistence_timeout 0 protocol TCP #net_mask 255.255.255.0 sorry_server 127.0.0.1 80 real_server 172.18.67.11 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 3 &#125; &#125; real_server 172.18.67.12 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 2 nb_get_retry 3 delay_before_retry 3 &#125; &#125; &#125;EOF http 检测## 健康检查方式，一共HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK ## HTTP_GET检查url，SSL_GET检查https url,TCP_CHECK检查tcp连接，可用在mysql检查 HTTP_GET { ## 要检查的URL，可以有多个 url { path / ## 返回成功状态码，也可以用另外一个选项配置返回字符串 status_code 200 ## 用keepalived自带的genhash生成，/usr/bin/genhash -s rsIP -p port -u uri #digest 1362a91278f0806aa1d33e1e26d67763 } connect_timeout 2 ## 连接超时时间 nb_get_retry 3 ## 重连次数 delay_before_retry 3 ## 重连间隔 } tcp 检测TCP_CHECK { connect_timeout 10 nb_get_retry 3 delay_before_retry 3 #检测的端口为80 connect_port 80 } MISC_CHECKMISC_CHECK { misc_path &quot;/etc/keepalived/misc_check.sh http://192.168.2.222:6500/check/200.jsp&quot; # 外部程序或者脚本的路径和参数 misc_timeout 10 # 脚本执行的超时时间 misc_dynamic #动态权重标志。脚本返回0则检测成功权重不变，返回1表示失败权重设置为0 } misc_check.sh脚本示例： #!/bin/bash # ./misc_check.sh http://192.168.2.222:6500/check/200.jsp if [ $# -ne 1 ]; then echo &quot;Warning: command param error.&quot; exit 1 else CHECK_URL=$1 CMD=`/usr/bin/curl -I ${CHECK_URL} 2&gt;/dev/null | grep &quot;200 OK&quot; | wc -l` if [ ${CMD} -eq 1 ]; then echo &quot;Succ: Check proxy ${CHECK_URL} is succeed.&quot; exit 0 else echo &quot;Fail: check proxy ${CHECK_URL} is failed.&quot; exit 1 fi fi lvs 进程检查脚本12345678cat &gt; /etc/keepalived/chk_lvs.sh &lt;&lt; EOF#!/bin/bash[[ \$(ps -C 'lvs' --no-heading -o stat,ppid,pid,cmd | grep -ve '^[Zz]' | grep -iv 'grep' | wc -l) -ge 2 ]] &amp;&amp; exit 0 || exit 1EOFchmod u+x /etc/keepalived/chk_lvs.sh 维护脚本12345678cat &gt; /etc/keepalived/chk_down.sh &lt;&lt; EOF#!/bin/bash[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0EOFchmod u+x /etc/keepalived/chk_down.sh ipvs 超时和监控ipvs默认超时时间## 查看默认超时时间 ipvsadm -L --timeout Timeout (tcp tcpfin udp): 900 120 300 ## 调整默认超时时间 # ipvsadm --set 1 2 1 监测连接保持状态(2s刷新一次状态)watch ipvsadm -L -n -c]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装配置 HAProxy 1.8.8]]></title>
    <url>%2FHaproxy%2F%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%20HAProxy%201.8.8%2F</url>
    <content type="text"><![CDATA[文档http://cbonte.github.io/haproxy-dconv/ http://www.haproxy.org 下载安装123456789101112131415161718192021222324## 源码地址：http://www.haproxy.org/#downwget https://www.haproxy.org/download/1.8/src/haproxy-1.8.8.tar.gz## 安装依赖包yum -y install gccyum -y install pcre pcre-static pcre-devel openssl openssl-devel zlib zlib-devel## haproxy 语法检测支持包yum -y install psmisc## 编译安装tar -xzvf haproxy-1.8.8.tar.gzcd haproxy-1.8.8## 可选其它参数 USE_CRYPT_H=1 USE_LIBCRYPT=1make PREFIX=/usr/local/haproxy TARGET=linux2628 USE_STATIC_PCRE=1 USE_OPENSSL=1 USE_ZLIB=1 make install PREFIX=/usr/local/haproxycp -R ./examples/errorfiles /usr/local/haproxy 编译参数说明： TARGET 参数 : - linux22 for Linux 2.2 - linux24 for Linux 2.4 and above (default) - linux24e for Linux 2.4 with support for a working epoll (&gt; 0.21) - linux26 for Linux 2.6 and above - linux2628 for Linux 2.6.28, 3.x, and above (enables splice and tproxy) - solaris for Solaris 8 or 10 (others untested) - freebsd for FreeBSD 5 to 10 (others untested) - netbsd for NetBSD - osx for Mac OS/X - openbsd for OpenBSD 5.7 and above - aix51 for AIX 5.1 - aix52 for AIX 5.2 - cygwin for Cygwin - haiku for Haiku - generic for any other OS or version. - custom to manually adjust every setting CPU 参数： - i686 for intel PentiumPro, Pentium 2 and above, AMD Athlon - i586 for intel Pentium, AMD K6, VIA C3. - ultrasparc : Sun UltraSparc I/II/III/IV processor - native : use the build machine&apos;s specific processor optimizations. Use with extreme care, and never in virtualized environments (known to break). - generic : any other processor or no CPU-specific optimization. (default) PCRE (Perl Compatible Regular Expressions) perl正则表述式支持： - USE_PCRE=1 to use libpcre, in whatever form is available on your system(shared or static) - USE_STATIC_PCRE=1 to use a static version of libpcre even if the dynamic one is available. This will enhance portability. - with no option, use your OS libc&apos;s standard regex implementation (default). SSL 支持，需要libz支持， libssl 和 libcrypto 会自动连接 haproxy USE_OPENSSL=1 如果操作系统的libc可以使用getaddrinfo（）来解析IPv6主机名,旧版可能不支持: USE_GETADDRINFO=1 使用zlib压缩 USE_ZLIB=1 使用libslz压缩， 快单压缩率低 USE_SLZ=1 配置环境变量1234567cat &gt; /etc/profile.d/haproxy.sh &lt;&lt; EOFexport PATH=/usr/local/haproxy/sbin:$PATHEOFsource /etc/profile.d/haproxy.sh iptable 防火墙配置vi /etc/sysconfig/iptables -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 1080 -j ACCEPT -A INPUT -p tcp -m state --state NEW -m tcp --dport 1081 -j ACCEPT -A INPUT -p udp -m state --state NEW -m tcp --dport 514 -j ACCEPT 添加用户12345678910groupadd --system --gid 300 g_haproxyuseradd --system --gid 300 --uid 300 --home-dir /var/lib/haproxy --shell /sbin/nologin u_haproxymkdir /var/lib/haproxychmod 0755 /var/lib/haproxychown u_haproxy:g_haproxy /var/lib/haproxysemanage fcontext -a -t haproxy_var_lib_t "/var/lib/haproxy(/.*)?"restorecon -RFvv /var/lib/haproxy 配置启动项## yum 安装haproxy 1.8 的启动文件，安装源IUS # vi /etc/sysconfig/haproxy OPTIONS=&quot;&quot; # vi /usr/lib/systemd/system/haproxy.service [Unit] Description=HAProxy Load Balancer After=network.target [Service] Environment=&quot;CONFIG=/etc/haproxy/haproxy.cfg&quot; &quot;PIDFILE=/run/haproxy.pid&quot; EnvironmentFile=-/etc/sysconfig/haproxy ExecStartPre=/usr/sbin/haproxy -f $CONFIG -c -q ExecStart=/usr/sbin/haproxy -Ws -f $CONFIG -p $PIDFILE $OPTIONS ExecReload=/usr/sbin/haproxy -f $CONFIG -c -q ExecReload=/bin/kill -USR2 $MAINPID KillMode=mixed Type=notify [Install] WantedBy=multi-user.target ## 自定义的启动文件123456789101112131415161718192021222324252627282930313233343536373839cat &gt; /usr/lib/systemd/system/haproxy.service &lt;&lt; EOF[Unit]Description=HAProxy Load BalancerAfter=syslog.target network.target[Service]Type=forking##User=rootRuntimeDirectory=haproxyRuntimeDirectoryMode=0755Environment="CONFIG_FILE=/etc/haproxy/haproxy.cfg" "PID_FILE=/run/haproxy/haproxy.pid"EnvironmentFile=-/etc/sysconfig/haproxyExecStartPre=/usr/local/haproxy/sbin/haproxy -f \$CONFIG_FILE -c -q## -W 参数：表示haproxy 采用master-worker 工作模式ExecStart=/usr/local/haproxy/sbin/haproxy -W -f \$CONFIG_FILE -p \$PID_FILE \$OPTIONSExecReload=/usr/local/haproxy/sbin/haproxy -f \$CONFIG_FILE -c -qExecReload=/bin/kill -USR2 \$MAINPIDKillMode=mixed##ExecStop=/usr/bin/kill \`/usr/bin/cat \$PID_FILE\`[Install]WantedBy=multi-user.targetEOF## 配置haproxy 启动文件权限和selinux上下文chmod 0644 /etc/sysconfig/haproxy /usr/lib/systemd/system/haproxy.servicechown root:root /etc/sysconfig/haproxy /usr/lib/systemd/system/haproxy.servicesemanage fcontext -a -t haproxy_unit_file_t /usr/lib/systemd/system/haproxy.servicerestorecon -RFvv /usr/lib/systemd/system/haproxy.service ## 对 HAProxy 配置文件的语法做检查： /usr/local/haproxy/sbin/haproxy -c -f /usr/local/haproxy/conf/haproxy.conf ## 手动开启 HAProxy 的进程： /usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/conf/haproxy.conf Haproxy日志记录在配置前，我们先来了解一下日志的level：local0～local7 16～23保留为本地使用： emerg 0 系统不可用； alert 1 必须马上采取行动的事件； crit 2 关键的事件； err 3 错误事件； warning 4 警告事件； notice 5 普通但重要的事件； info 6 有用的信息； debug 7 调试信息。 默认 haproxy 是不记录日志的，为了记录日志还需要配置 syslog 模块，在 linux 下是 rsyslogd 服务。 如果要发送日志到远程主机，还需修改远程主机中的/etc/sysconfig/rsyslog中的参数。 安装配置rsyslog123456789101112131415161718192021222324252627282930313233## 此步centos 默认已安装，可以跳过yum -y install rsyslog ## 修改"SYSLOGD_OPTIONS"参数，## -c 2 :使用兼容模式，默认是 -c 5；## -r :开启远程日志；## -m 0 :标记时间戳，单位是分钟，0表示禁用该功能。例如240为每隔240分钟写入一次”–MARK–”信息;## -x :关闭自动解析对方日志服务器的FQDN信息,这能避免DNS不完整所带来的麻烦;## -h :默认情况下,syslog不会发送从远端接受过来的消息转发到其他主机,而使用该选项,则把该开关打开,所有接受到的信息都可根据syslog.conf中定义的@主机转发过去。cp /etc/sysconfig/rsyslog&#123;,.$(date '%F_%T')&#125;cat &gt; /etc/sysconfig/rsyslog &lt;&lt; EOFSYSLOGD_OPTIONS="-c 2 -r -m 0"EOFsed -i "s/#\$ModLoad imudp/\$ModLoad imudp/g" /etc/rsyslog.confsed -i "s/#\$UDPServerRun 514/\$UDPServerRun 514/g" /etc/rsyslog.conf## #文件最末尾的"&amp;~"，如果没有此配置，日志除写入指定文件外，会同步写入messages文件；cat &gt; /etc/rsyslog.d/haproxy.conf &lt;&lt; EOFlocal2.* /var/log/haproxy.log&amp;~EOFsystemctl restart rsyslog.service haproxy 配置## 默认安装目录下没有配置文件，只有&quot;doc&quot;，&quot;sbin&quot;，&quot;share&quot;三个目录，可手工创建目录及配置文件。 ## haproxy的配置文件主要是以下5部分： ## global全局配置、defaults默认配置、监控页面配置、frontend配置、backend配置。 global #定义全局日志, 配置在本地, 通过local0 输出, 默认是info级别，可配置两条 log 127.0.0.1 local2 warning chroot /var/lib/haproxy pidfile /run/haproxy/haproxy.pid #设置每haproxy进程的最大并发连接数, 其等同于命令行选项“-n”; “ulimit -n”自动计算的结果参照此参数设定. maxconn 4000 user u_haproxy group g_haproxy #后台运行haproxy daemon ## 设置启动的haproxy进程数量，一般设置为cpu核数, 只能用于守护进程模式的haproxy; ## 默认只启动一个进程 #nbproc 1 ## 设置绑定核心，第一个参数表示绑定id，第二个参数指定cpu核心，0开始第一个cpu核心 ## 后面用bind-process 绑定id，如将CPU核心分开以进行后端处理 ## frontend access_http ## bind 0.0.0.0:80 ## bind-process 1 ## frontend access_https ## bind 0.0.0.0:443 ssl crt /etc/yourdomain.pem ## bind-process 2 3 4 cpu-map 1 0 cpu-map 2 1 cpu-map 3 2 cpu-map 4 3 ## 调试级别, 一般只在开启单进程时调试, 且生产环境禁用. #debug ## haproxy启动后不会显示任何相关信息, 这与在命令行启动haproxy时加上参数&quot;-q&quot;相同 #quiet #定义统计信息保存位置 #stats socket /var/lib/haproxy/stats stats socket /run/haproxy/admin.sock mode 660 level admin stats timeout 30s ##===============https相关======================================== # Default SSL material locations ca-base /etc/ssl/certs crt-base /etc/ssl/private ## Default ciphers to use on SSL-enabled listening sockets. ## 参考：https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ ## 需要处理以下事： ## 禁用SSL 2.0（FUBAR）和SSL 3.0 1（POODLE）， ## 禁用TLS 1.0压缩（CRIME）， ## 禁用弱密码（DES / 3DES，RC4），更喜欢现代密码（AES），模式（GCM）和协议（TLS 1.2）。 ## OpenSSL更新为1.0.1c +，以便尽快支持TLS 1.2，GCM和ECDHE ## OpenSSL安装进行测试： ## openssl ciphers -v &apos;ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS&apos; ## ssl-default-bind-options &lt;force-sslv3|no-sslv3 no-tls-tickets|force-tlsv10|force-tlsv11|force-tlsv12&gt; ssl-default-bind-options force-tlsv12 ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS ssl-default-server-options no-sslv3 ssl-default-server-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS tune.ssl.default-dh-param 2048 ##============================================================ defaults #默认的模式【tcp:4层； http:7层； health:只返回OK】 mode http ## 日志类别, httplog log global ## 日志类别, httplog option httplog ## 如果产生了一个空连接，那这个空连接的日志将不会记录. option dontlognull ## 开启http协议中服务器端关闭功能, 每个请求完毕后主动关闭http通道, 使得支持长连接，使得会话可以被重用，使得每一个日志记录都会被记录. option http-server-close ## 这个参数我是这样理解的：使用该参数，每处理完一个request时，haproxy都会去检查http头中的Connection的值， ## 如果该值不是close，haproxy将会将其删除， ## 如果该值为空将会添加为：Connection: close。 ## 使每个客户端和服务器端在完成一次传输后都会主动关闭TCP连接。 ## 与该参数类似的另外一个参数是&quot;option forceclose&quot;，该参数的作用是强制关闭对外的服务通道， ## 因为有的服务器端收到Connection: close时，也不会自动关闭TCP连接， ## 如果客户端也不关闭，连接就会一直处于打开，直到超时。 #option httpclose #当haproxy负载很高时, 自动结束掉当前队列处理比较久的链接. option abortonclose ## 当使用了cookie时，haproxy将会将其请求的后端服务器的serverID插入到cookie中，以保证会话的SESSION持久性； ## 而此时，如果后端的服务器宕掉了，但是客户端的cookie是不会刷新的， ## 如果设置此参数，将会将客户的请求强制定向到另外一个后端server上，以保证服务的正常。 ## 当与后端服务器的会话失败(服务器故障或其他原因)时, 把会话重新分发到其他健康的服务器上; 当故障服务器恢复时, 会话又被定向到已恢复的服务器上; ## 还可以用&quot;retries&quot;关键字来设定在判定会话失败时的尝试连接的次数 option redispatch ## 定义连接后端服务器的失败重连次数，连接失败次数超过此值后将会将对应后端服务器标记为不可用 retries 3 ## Insert X-Forwarded-For header ## 如果后端服务器需要记录客户端真实ip, 需要在HTTP requests头部中添加&quot;X-Forwarded-For&quot;字段,将客户端IP发送给后端的server; ## 但haproxy自身的健康检测机制访问后端服务器时, 不应将记录访问日志，可用except来排除127.0.0.0，即haproxy本身. option forwardfor except 127.0.0.0/8 #默认http请求超时时间 timeout http-request 10s #默认队列超时时间, 后端服务器在高负载时, 会将haproxy发来的请求放进一个队列中. timeout queue 1m ## 设置haproxy成功连接到后端服务器的最长等待时间，默认单位是毫秒 timeout connect 10s #客户端与haproxy连接后, 数据传输完毕, 不再有数据传输, 即非活动连接的超时时间. timeout client 1m #haproxy与后端服务器非活动连接的超时时间. timeout server 1m #默认新的http请求连接建立的超时时间，时间较短时可以尽快释放出资源，节约资源. timeout http-keep-alive 10s #心跳检测超时时间 timeout check 10s #最大并发连接数 maxconn 3000 #设置默认的负载均衡方式 #balance source #balnace leastconn #统计页面配置, frontend和backend的组合体, 监控组的名称可按需自定义 listen admin_stats #配置监控运行模式 mode http #配置统计页面访问端口 bind 0.0.0.0:1080 #统计页面默认最大连接数 maxconn 10 #http日志格式 option httplog #开启统计 stats enable #隐藏统计页面上的haproxy版本信息 stats hide-version #监控页面自动刷新时间 stats refresh 30s #统计页面访问url stats uri /stats #统计页面密码框提示文本 stats realm Haproxy\ Statistics #监控页面的用户和密码, 可设置多个用户名 stats auth test.admin:test.admin!9595 #手工启动/禁用后端服务器, 可通过web管理节点 stats admin if TRUE #设置haproxy错误页面，复制源代码目录下错误样本文件(cp ./haproxy-1.8.8/examples/errorfiles/* /usr/local/haproxy) errorfile 400 /usr/local/haproxy/errorfiles/400.http errorfile 403 /usr/local/haproxy/errorfiles/403.http errorfile 408 /usr/local/haproxy/errorfiles/408.http errorfile 500 /usr/local/haproxy/errorfiles/500.http errorfile 502 /usr/local/haproxy/errorfiles/502.http errorfile 503 /usr/local/haproxy/errorfiles/503.http errorfile 504 /usr/local/haproxy/errorfiles/504.http #监控haproxy后端服务器的监控状态 listen site_status bind 0.0.0.0:1081 #监听端口 mode http #http的7层模式 log 127.0.0.1 local2 err #[err warning info debug] monitor-uri /site_status #网站健康检测URL，用来检测HAProxy管理的网站是否可以用，正常返回200，不正常返回503 acl site_dead nbsrv(php_server) lt 1 #定义网站down时的策略当挂在负载均衡上的指定backend的中有效机器数小于1台时返回true acl site_dead nbsrv(html_server) lt 1 acl site_dead nbsrv(backend_default) lt 1 monitor fail if site_dead #当满足策略的时候返回503，网上文档说的是500，实际测试为503 monitor-net 192.168.4.171/32 #来自192.168.4.152的日志信息不会被记录和转发 monitor-net 192.168.4.172/32 #frontend, 名字自定义 frontend HAproxy_Cluster #定义前端监听端口, 建议采用bind *:80的形式，否则做集群高可用的时候有问题，vip切换到其余机器就不能访问. bind 0.0.0.0:80 # 验证服务是否可用 option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www #acl后面是规则名称，当请求的url末尾是以.php结尾时,匹配触发php_web规则，以下两种写法均可. #当请求的url末尾是以.css、.jpg、.png、.jpeg、.js、.gif结尾时，匹配并触发static_web规则. #acl static_web path_end .gif .png .jpg .css .js .jpeg #acl static_web url_reg /*.(css|jpg|png|jpeg|js|gif)$ #-i为忽略大小写，当被请求的是以www.test.com开头的主机时，匹配并触发dns_name规则. acl html_web hdr_beg(host) -i www.haproxytest.com #acl html_web hdr_beg(host) 10.11.4.152 #当客户端的IP是x.x.x.x时，匹配并触发src_ip规则. #acl src_ip src x.x.x.x #如果匹配acl规则php_web，将请求转交到php_server组处理；如果匹配acl规则html_web，将请求转交到html_server组处理. use_backend php_server if php_web use_backend html_server if html_web #如果以上规则都不匹配时，将请求转交到default_backend组处理. default_backend backend_default #backend后端配置, 配置php_server组与html_server组 backend php_server #定义负载均衡方式为roundrobin方式, 即基于权重进行轮询调度的算法, 在服务器性能分布较均匀情况下推荐. #另有如下几种负载均衡方式： #-- static-rr: 也是基于权重进行轮转调度, 但属于静态方法, 运行时调整后端机组权重不会使用新的权重; #-- source: 基于请求源IP进行hash运算匹配后端服务器组; #-- leastconn: 不适合会话较短的环境, 如基于http的应用; #-- uri: 对整个URI进行hash运算; #-- uri_param: 对URI中的参数进行转发; #-- hdr(&lt;name&gt;):根据http头进行转发, 无该头部则转为使用roundrobin. balance roundrobin mode http #允许插入serverid到cookie中，serverid后面可定义 cookie SERVERID #心跳检测方式为检测后端服务器index.html文件，还有其他方式 option httpchk GET /index.html #后端服务器定义, maxconn 1024表示该服务器的最大连接数, cookie 1表示serverid为1, weight代表权重(默认1，最大为265，0则表示不参与负载均衡), #check inter 1500是检测心跳频率, rise 2是2次正确认为服务器可用, fall 3是3次失败认为服务器不可用. server php1 192.168.4.171:80 maxconn 1024 cookie 1 weight 3 check inter 1500 rise 2 fall 3 backend html_server balance source mode http server html1 192.168.4.172:80 maxconn 1024 cookie 1 weight 3 check inter 1500 rise 2 fall 3 backend backend_default balance source mode http server default1 192.168.4.171:80 maxconn 1024 cookie 1 weight 3 check inter 1500 rise 2 fall 3 普通代理负载frontend main *:5000 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js use_backend static if url_static default_backend app backend static balance roundrobin server static 127.0.0.1:4331 check backend app balance roundrobin server app1 127.0.0.1:5001 check server app2 127.0.0.1:5002 check server app3 127.0.0.1:5003 check server app4 127.0.0.1:5004 check ssl 代理官方示例global maxconn 100 defaults mode http timeout connect 5s timeout client 5s timeout server 5s frontend myfrontend # primary cert is /etc/cert/server.pem # /etc/cert/certdir/ contains additional certificates for SNI clients bind :443 ssl crt /etc/cert/server.pem crt /etc/cert/certdir/ bind :80 default_backend mybackend backend mybackend # a http backend server s3 10.0.0.3:80 # a https backend server s4 10.0.0.3:443 ssl verify none 适用于redis主从负载##===============适用于redis主从负载====================================== # Specifies TCP timeout on connect for use by the frontend ft_redis # Set the max time to wait for a connection attempt to a server to succeed # The server and client side expected to acknowledge or send data. defaults REDIS mode tcp timeout connect 3s timeout server 6s timeout client 6s # Specifies listening socket for accepting client connections using the default # REDIS TCP timeout and backend bk_redis TCP health check. frontend ft_redis bind *:6379 name redis default_backend bk_redis # Specifies the backend Redis proxy server TCP health settings # Ensure it only forward incoming connections to reach a master. backend bk_redis option tcp-check tcp-check connect tcp-check send AUTH\ redis\r\n tcp-check send PING\r\n tcp-check expect string +PONG tcp-check send info\ replication\r\n tcp-check expect string role:master tcp-check send QUIT\r\n tcp-check expect string +OK server redis_vm01 200.200.200.221:6381 check port 6381 inter 5s fastinter 2s downinter 5s rise 3 fall 3 server redis_vm03 200.200.200.223:6381 check port 6381 inter 5s fastinter 2s downinter 5s rise 3 fall 3 ##========================================================================== redis 主从自动failover 配置redis sentinel配置## redis 主从 自动failover 配置 ## redis 主从都需要配置masterauth 和 requirepass ## redis 从需要配置slaveof master_ip master_port ## 接下来配置redis sentinel123456789101112131415161718192021222324252627282930313233343536373839404142cat &gt; /etc/redis-sentinel.conf &lt;&lt; EOF## 必须绑定ip 或 禁用保护，否则无法实现自动主从切换# bind 127.0.0.1 192.168.1.1protected-mode noport 26379dir /tmp# 配置master名、ip、port、需要多少个sentinel才能判断[客观下线]sentinel monitor mymaster 200.200.200.221 6381 2#单位毫秒,默认值30000，配置sentinel向master发出ping，最大响应时间、超过则认为主观下线sentinel down-after-milliseconds mymaster 6000#配置在进行故障转移时，运行多少个slave进行数据备份同步(越少速度越快)sentinel parallel-syncs mymaster 1#单位毫秒，默认值180000，配置当出现failover时下一个sentinel与上一个sentinel对[同一个master监测的时间间sentinel failover-timeout mymaster 60000logfile /var/log/redis/sentinel.logsentinel auth-pass mymaster redis# sentinel client-reconfig-script mymaster /var/lib/redis/failover.sh# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;# The following arguments are passed to the script:## &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;## &lt;state&gt; is currently always "failover"# &lt;role&gt; is either "leader" or "observer"## 用于docker nat# sentinel announce-ip &lt;ip&gt;# sentinel announce-port &lt;port&gt;EOF 查看sentinel 状态# redis-cli -h 200.200.200.222 -p 26379 info sentinel # redis-cli -h 200.200.200.222 -p 26379 info Sentinel命令 PING ： 返回 PONG 。 SENTINEL masters ： 列出所有被监视的主服务器，以及这些主服务器的当前状态； SENTINEL slaves &lt;master name&gt; ： 列出给定主服务器的所有从服务器，以及这些从服务器的当前状态； SENTINEL get-master-addr-by-name &lt;master name&gt; ： 返回给定名字的主服务器的 IP 地址和端口号。 如果这个主服务器正在执行故障转移操作， 或者针对这个主服务器的故障转移操作已经完成， 那么这个 命令返回新的主服务器的 IP 地址和端口号； SENTINEL reset &lt;pattern&gt; ： 重置所有名字和给定模式 pattern 相匹配的主服务器。 pattern 参数是一个 Glob 风格的模式。 重置操作清楚主服务器目前的所有状态， 包括正在执行中的故障转移， 并移除目前已经发现和关联的， 主服务器的所有从服务器和 Sentinel ； SENTINEL failover &lt;master name&gt; ： 当主服务器失效时， 在不询问其他 Sentinel 意见的情况下， 强制开始一次自动故障迁移。 SENTINEL ckquorum &lt;master name&gt; 检查当前的Sentinel配置对于主节点的故障转移是否能达到仲裁人数，并且大多数是需要的来授权故障转移。这个命令应该在监控系统中使用来检查一个Sentinel部署是否正常。 SENTINEL flushconfig 强制Sentinel重新写入它的配置到磁盘上，包括当前Sentinel状态。 运行配置命令： SENTINEL MONITOR &lt;name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt; 这个命令告诉Sentinel开始监控一个指定名称、IP、端口号、quorum的主节点，它和sentinel.conf配置文件中的sentinel monitor配置指令是完全相同的，不同的是这里不能使用主机名作为IP，需要提供一个IPV4或IPV6地址。 SENTINEL REMOVE &lt;name&gt; 用来移除指定的主节点：主节点不再被监控，并且将被从Sentinel的内部状态中被完全移除，所以不会被SENTINEL masters列出。 SENTINEL SET &lt;name&gt; &lt;option&gt; &lt;value&gt; SET 命令和Reids的CONFIG SET指令非常相似，被用来改变一个指定主节点的配置参数。多个选项-值可以被指定。所有通过sentinel.conf配置的参数可以使用SET命令重新配置。 Sentinel命令 127.0.0.1:26379&gt; sentinel masters 127.0.0.1:26379&gt; sentinel slaves mymaster 127.0.0.1:26379&gt; SENTINEL get-master-addr-by-name mymaster 127.0.0.1:26379&gt; SENTINEL reset mymaster 127.0.0.1:26379&gt; SENTINEL failover mymaster 127.0.0.1:26379&gt; SENTINEL flushconfig SENTINEL SET mymaster down-after-milliseconds 1000 运行时的配置指令 SENTINEL MONITOR 新增监控的master，不能使用hostname代替真实的ip SENTINEL REMOVE 不再监控指定master `SENTINEL SET 哨兵的添加与删除 添加哨兵很简单，只要监控master就可以被大家发现。删除哨兵则需要一下步骤： 杀死该哨兵进程 发送SENTINEL RESET *给其他哨兵 检查所有哨兵，发送指令SENTINEL master给所有哨兵来查看活跃的哨兵数量 利用redis-sentinel自带的参数进行VIP的配置# 设置环境 # redis 绑定IP必须使用0.0.0.0 sed -i &quot;s|bind 200.200.200.223|bind 0.0.0.0|g&quot; /etc/redis2.conf # redis 配置，如果有三个redis服务器和三个 redis-sentinel，最好添加下面的配置，以防数据不一致 min-slaves-to-write 1 min-slaves-max-lag 10 # 脚本执行权限 vi /var/lib/redis/failover.sh chmod 0550 /var/lib/redis/failover.sh chown redis: /var/lib/redis/failover.sh # redis 用户的权限 echo -e &apos;redis\tALL=(ALL)\tNOPASSWD:/sbin/ip,NOPASSWD:/sbin/arping&apos; &gt; /etc/sudoers.d/redis ##echo -e &apos;Defaults!/sbin/ip !requiretty&apos; &gt;&gt; /etc/sudoers.d/redis ##echo -e &apos;Defaults!/sbin/arping !requiretty&apos; &gt;&gt; /etc/sudoers.d/redis ## sed -i &quot;s|Defaults.*requiretty|#Defaults\trequiretty|&quot; /etc/sudoers chmod 440 /etc/sudoers.d/redis ## &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt; # sentinel client-reconfig-script mymaster /var/lib/redis/failover.sh #!/bin/bash 这一行开头不能有空格，否则无法执行下面的命令1234567891011121314151617181920212223242526vi /var/lib/redis/failover.sh#!/bin/bashMASTER_IP=$&#123;6&#125;##MY_IP='200.200.200.221' # 每个Server本身的IPMY_IP=$(ip addr show | grep inet |grep -v 127.0.0.1| awk '&#123;print $2&#125;' | awk -F/ '&#123;print $1&#125;')VIP='200.200.200.240' # VIPNETMASK='24' # NetmaskINTERFACE='ens33' # 接口## 指定MY_IP##if [ $&#123;MASTER_IP&#125; = $&#123;MY_IP&#125; ]; then## 未指定MY_IP##if [[ $&#123;MY_IP&#125; =~ $&#123;MASTER_IP&#125; ]]; thenif echo $&#123;MY_IP&#125; | grep -wq $&#123;MASTER_IP&#125;; then sudo /sbin/ip addr add $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; sudo /sbin/arping -q -c 3 -A $&#123;VIP&#125; -I $&#123;INTERFACE&#125; exit 0else sudo /sbin/ip addr del $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $&#123;INTERFACE&#125; exit 0fiexit 1 手动切换slave到master## 登陆redis slave,输入 &gt; slaveof NO ONE 或者 $ redis-cli -a password -p 6379 -h 200.200.200.223 slave no one 手动切换master到slave $ redis-cli -a password -p 6379 -h 200.200.200.223 slaveof 200.200.200.223 6379 单线程SET/GET测试 $ redis-benchmark -p xxx -t set,get -r 3000 -n 1000000 -d xxx 单线程PIPELINE SET/GET测试 $ redis-benchmark -p xxx -t set,get -r 3000 -n 5000000 -P 20 -d xxx 参考：sudo: 1）Defaults requiretty，修改为 #Defaults requiretty，表示不需要控制终端。 2）Defaults requiretty，修改为 Defaults:nobody !requiretty，表示仅 nobody 用户不需要控制终端。 3）如果修改为 Defaults:%nobody !requiretty，表示仅 nobody 组不需要控制终端。 4）Defaults!/path/to/program !requiretty 表示/path/to/program 不需要控制终端。 5） 如果名带有参数必须使用别名 Cmnd_Alias MYPROGRAM = /path/to/program --option artbristol ALL = (root) /path/to/program artbristol ALL = (root) NOPASSWD: MYPROGRAM Defaults!MYPROGRAM !requiretty 6） 省略所有命令的密码 username ALL=(ALL) NOPASSWD: ALL 参考： https://www.sudo.ws/man/1.8.15/sudoers.man.html arping: 二.命令格式 arping [-AbDfhqUV] [-c count] [-w deadline] [-s source] [-I interface] destination 三.常用参数 复制代码 -A #和U参数作用相同，不过发送的是ARP应答包 -b #保持广播状态（收到arp应答之后会切换成单一传播模式） -c count #发送指定数量的ARP请求包 -D #冲突检测模式，如果返回为空，则代表该ip没有被占用 -f #当收到确认主机存活的第一个数据包时，停止发送 -I interface #指定发送ARP数据包使用的网卡设备 -h #打印帮助并退出 -q #不显示警告信息 -s source #设置源ip地址，DAD模式下为0.0.0.0，主动模式下为自己设定的ip地址，不设置则为本机实际ip地址 -U #主动发送ARP请求来更新其他主机的ARP缓存 -V #打印版本信息并退出 -w deadline #设置超时时间， ssl终结配置支持 https：frontend name（name 这里比如：http_server 和 main *:5000 等） bind 0.0.0.0:80 bind 0.0.0.0:443 ssl crt /etc/haproxy/keys/www.test.com.pem 只需要在 frontend 这里添加一行配置（监听 443 端口，再告诉 HAProxy 存放 CA 证书的位置）即可。 www.test.com.pem 这个文件应该需要如下形式，即把 key 也要附上： -----BEGIN CERTIFICATE----- BAQDAgEGM798a1UdEwEB/wQIMAYBAf8CAQAQMKYIKwYBBQUHAQEEJzAlMCMGCCsG ... k3YtCAbvmq== -----END CERTIFICATE----- -----BEGIN CERTIFICATE----- IGZvciBhdXRob3JpemVkIHVz9zBvbmx5MS4wLAYDVSSDEyVFbnRydXN0IMAlcnRp ... QnLcB= -----END CERTIFICATE----- -----BEGIN RSA PRIVATE KEY----- SnXgfbEA3wLWqbjZiGkReyuxlZs+peS644u6+vnxTbmVHH+3t3rmubDK7nEACI81 ... cckLx6AQUD/7oUbcB9wKG5sy9EhYrCkg9wYYGyPlgUuRdLZny0I0Bw== -----END RSA PRIVATE KEY----- 支持多个 https：frontend name（name 这里比如：http_server 和 main *:5000 等） bind :80 bind :443 ssl crt /etc/haproxy/keys/www.test.com.pem crt /etc/haproxy/keys/admin.test.com.pem crt /etc/haproxy/keys/passport.abc.com.pem 只需要连续不断地添加证书即可，HAProxy 会自动地根据不同的域名去使用相关的证书，不需要额外配置。 网上说 https 的配置要这么配： frontend name（name 这里比如：http_server 和 main *:5000 等） bind :80 bind :443 ssl crt /etc/haproxy/keys/www.test.com.pem crt /etc/haproxy/keys/admin.test.com.pem crt /etc/haproxy/keys/passport.abc.com.pem acl admintest_com hdr_dom(host) -i admin.test.com use_backend admin_test_com if admintest_com { ssl_fc_sni admin.test.com } acl passportabc_com hdr_dom(host) -i passport.abc.com use_backend pasport_abc_com if passport_abc_com { ssl_fc_sni passport.abc.com } ... 即在 use_backend 的后面还要添加 { ssl_fc_sni admin.test.com } ，表示 “ 指定 ” （或者说是强制）使用某个证书。其实这么做的话这个域名就没法通过 80 端口来访问了，只能通过 443 端口来访问。要想 443 端口和 80 端口都能同时访问还需要这么做： frontend name（name 这里比如：http_server 和 main *:5000 等） bind :80 bind :443 ssl crt /etc/haproxy/keys/www.test.com.pem crt /etc/haproxy/keys/admin.test.com.pem crt /etc/haproxy/keys/passport.abc.com.pem acl admintest_com hdr_dom(host) -i admin.test.com use_backend admin_test_com if admintest_com acl admintest_com hdr_dom(host) -i admin.test.com use_backend admin_test_com if admintest_com { ssl_fc_sni admin.test.com } acl passportabc_com hdr_dom(host) -i passport.abc.com use_backend pasport_abc_com if passport_abc_com acl passportabc_com hdr_dom(host) -i passport.abc.com use_backend pasport_abc_com if passport_abc_com { ssl_fc_sni passport.abc.com } ... 即再添加一个不 “ 指定 ” 证书的配置。 这么做我觉得完全没有必要，只要添加 bind :443 ssl crt /etc/haproxy/keys/www.test.com.pem … 这一行配置就行，剩下的让 HAProxy 自动地根据不同的域名去使用相关的证书即可。 http 跳转 https：#对以下站点进行 https 跳转 acl ssl hdr_reg(host) -i ^(www.test.com|admin.test.com|passport.abc.com)$ redirect scheme https code 301 if !{ ssl_fc } ssl 证书配置的安全性改进：bind 0.0.0.0:443 ssl crt 1.pem no-sslv3 ciphers AES:ALL:!aNULL:!eNULL:-RC4:-EXPORT:-DES crt 2.pem no-sslv3 ciphers AES:ALL:!aNULL:!eNULL:-RC4:-EXPORT:-DES]]></content>
      <categories>
        <category>HAProxy</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
        <tag>install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell脚本--if判断（数字条件、字符串条件）]]></title>
    <url>%2Flinux%2Fshell%2Fshell%E8%84%9A%E6%9C%AC--if%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[二元比较操作符,比较变量或者比较数字. 注意数字与字符串的区别. 整数比较-eq 等于,如:if [ &quot;$a&quot; -eq &quot;$b&quot; ] -ne 不等于,如:if [ &quot;$a&quot; -ne &quot;$b&quot; ] -gt 大于,如:if [ &quot;$a&quot; -gt &quot;$b&quot; ] -ge 大于等于,如:if [ &quot;$a&quot; -ge &quot;$b&quot; ] -lt 小于,如:if [ &quot;$a&quot; -lt &quot;$b&quot; ] -le 小于等于,如:if [ &quot;$a&quot; -le &quot;$b&quot; ] &lt; 小于(需要双括号),如:((&quot;$a&quot; &lt; &quot;$b&quot;)) &lt;= 小于等于(需要双括号),如:((&quot;$a&quot; &lt;= &quot;$b&quot;)) &gt; 大于(需要双括号),如:((&quot;$a&quot; &gt; &quot;$b&quot;)) &gt;= 大于等于(需要双括号),如:((&quot;$a&quot; &gt;= &quot;$b&quot;)) 小数据比较可使用AWK 字符串比较= 等于,如:if [ &quot;$a&quot; = &quot;$b&quot; ] == 等于,如:if [ &quot;$a&quot; == &quot;$b&quot; ],与=等价 注意： 比较两个字符串是否相等的办法是： if [ &quot;$test&quot;x = &quot;test&quot;x ]; then 这里的关键有几点： 1 使用单个等号 2 注意到等号两边各有一个空格：这是unix shell的要求 3 注意到&quot;$test&quot;x最后的x，这是特意安排的，因为当$test为空的时候，上面的表达式就变成了x = testx，显然是不相等的。而如果没有这个x，表达式就会报错：[: =: unary operator expected 注意:==的功能在[[]]和[]中的行为是不同的,如下: [[ $a == z* ]] # 如果$a以&quot;z&quot;开头(模式匹配)那么将为true [[ $a == &quot;z*&quot; ]] # 如果$a等于z*(字符匹配),那么结果为true [ $a == z* ] # File globbing 和word splitting将会发生 [ &quot;$a&quot; == &quot;z*&quot; ] # 如果$a等于z*(字符匹配),那么结果为true 一点解释,关于File globbing是一种关于文件的速记法,比如&quot;*.c&quot;就是,再如~也是. 但是file globbing并不是严格的正则表达式,虽然绝大多数情况下结构比较像. != 不等于,如:if [ &quot;$a&quot; != &quot;$b&quot; ] 这个操作符将在[[]]结构中使用模式匹配. &lt; 小于,在ASCII字母顺序下.如: if [[ &quot;$a&quot; &lt; &quot;$b&quot; ]] if [ &quot;$a&quot; \&lt; &quot;$b&quot; ] 注意:在[]结构中&quot;&lt;&quot;需要被转义. &gt; 大于,在ASCII字母顺序下.如: if [[ &quot;$a&quot; &gt; &quot;$b&quot; ]] if [ &quot;$a&quot; \&gt; &quot;$b&quot; ] 注意:在[]结构中&quot;&gt;&quot;需要被转义. 具体参考Example 26-11来查看这个操作符应用的例子. -z 字符串为&quot;null&quot;.就是长度为0. -n 字符串不为&quot;null&quot; 注意: 使用-n在[]结构中测试必须要用&quot;&quot;把变量引起来.使用一个未被&quot;&quot;的字符串来使用! -z 或者就是未用&quot;&quot;引用的字符串本身,放到[]结构中。虽然一般情况下可以工作,但这是不安全的.习惯于使用&quot;&quot;来测试字符串是一种好习惯. 举例：数字比较#!/bin/bash i=6 a=10 if [ $a -eq 10 ] then echo &quot;a = 10&quot; fi if [ $a -ne $i ] then echo &quot;a != $i&quot; fi if [ $a -gt $i ] then echo &quot;a &gt; i&quot; fi if [ $a -lt $i ] then echo &quot;a &lt; i&quot; else echo &quot;a &gt; i&quot; fi if((&quot;$a&quot; &gt; &quot;$i&quot;)) then echo &quot;(())a&gt;i&quot; fi if(($a != $i)) then echo &quot;(())a!=i&quot; fi 备注：通过sh运行脚本，[ ]运算是可以的，而（（））运行出错 chmod 777 后，直接./ 运行，都可以 字符串比较#!/bin/bash a=&quot;123&quot; b=&quot;1234&quot; c=&quot;123&quot; if [ &quot;$a&quot;x != &quot;$b&quot;x ] then echo &quot;a != b&quot; fi if [ &quot;$a&quot;x = &quot;$c&quot;x ] then echo &quot;a == c&quot; fi 判断字符串为空if [ -z &quot;$d&quot; ] then echo &quot;d is empty&quot; fi 备注-e 文件存在 -a 文件存在（已被弃用） -f 被测文件是一个regular文件（正常文件，非目录或设备） -s 文件长度不为0 -d 被测对象是目录 -b 被测对象是块设备 -c 被测对象是字符设备 -p 被测对象是管道 -h 被测文件是符号连接 -L 被测文件是符号连接 -S(大写) 被测文件是一个socket -t 关联到一个终端设备的文件描述符。用来检测脚本的stdin[-t0]或[-t1]是一个终端 -r 文件具有读权限，针对运行脚本的用户 -w 文件具有写权限，针对运行脚本的用户 -x 文件具有执行权限，针对运行脚本的用户 -u set-user-id(suid)标志到文件，即普通用户可以使用的root权限文件，通过chmod +s file实现 -k 设置粘贴位 -O 运行脚本的用户是文件的所有者 -G 文件的group-id和运行脚本的用户相同 -N 从文件最后被阅读到现在，是否被修改 f1 -nt f2 文件f1是否比f2新 f1 -ot f2 文件f1是否比f2旧 f1 -ef f2 文件f1和f2是否硬连接到同一个文件 二元比较操作符，比较变量或比较数字 整数比较： -eq 等于 if [ &quot;$a&quot; -eq &quot;$b&quot; ] -ne 不等于 if [ &quot;$a&quot; -ne &quot;$b&quot; ] -gt 大于 if [ &quot;$a&quot; -gt &quot;$b&quot; ] -ge 大于等于 if [ &quot;$a&quot; -ge &quot;$b&quot; ] -lt 小于 if [ &quot;$a&quot; -lt &quot;$b&quot; ] -le 小于等于 if [ &quot;$a&quot; -le &quot;$b&quot; ] &lt; 小于（需要双括号） (( &quot;$a&quot; &lt; &quot;$b&quot; )) &lt;= 小于等于(...) (( &quot;$a&quot; &lt;= &quot;$b&quot; )) &gt; 大于(...) (( &quot;$a&quot; &gt; &quot;$b&quot; )) &gt;= 大于等于(...) (( &quot;$a&quot; &gt;= &quot;$b&quot; )) 字符串比较： = 等于 if [ &quot;$a&quot; = &quot;$b&quot; ] == 与=等价 != 不等于 if [ &quot;$a&quot; = &quot;$b&quot; ] &lt; 小于，在ASCII字母中的顺序： if [[ &quot;$a&quot; &lt; &quot;$b&quot; ]] if [ &quot;$a&quot; \&lt; &quot;$b&quot; ] #需要对&lt;进行转义 &gt; 大于 -z 字符串为null，即长度为0 -n 字符串不为null，即长度不为0]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>if</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[proc sys net ipv4 下各项的意义]]></title>
    <url>%2Flinux%2Fconfig%2Fproc%20sys%20net%20ipv4%20%E4%B8%8B%E5%90%84%E9%A1%B9%E7%9A%84%E6%84%8F%E4%B9%89%2F</url>
    <content type="text"><![CDATA[/proc/sys/net/ipv4/icmp_timeexceed_rate这个在traceroute时导致著名的“Solaris middle star”。这个文件控制发送ICMP Time Exceeded消息的比率。 /proc/sys/net/ipv4/igmp_max_memberships主机上最多有多少个igmp (多播)套接字进行监听。 /proc/sys/net/ipv4/inet_peer_gc_maxtime求 助: Add a little explanation about the inet peer storage? Minimum interval between garbage collection passes. This interval is in effect under low (or absent) memory pressure on the pool. Measured in jiffies. /proc/sys/net/ipv4/inet_peer_gc_mintime每一遍碎片收集之间的最小时间间隔。当内存压力比较大的时候，调整这个间隔很有效。以jiffies计。 /proc/sys/net/ipv4/inet_peer_maxttlentries的最大生存期。在pool没有内存压力的情况下(比如，pool中entries的数量很少的时候)，未使用的entries经过一段时间就会过期。以jiffies计。 /proc/sys/net/ipv4/inet_peer_minttlentries的最小生存期。应该不小于汇聚端分片的生存期。当pool的大小不大于inet_peer_threshold时，这个最小生存期必须予以保证。以jiffies计。 /proc/sys/net/ipv4/inet_peer_thresholdThe approximate size of the INET peer storage. Starting from this threshold entries will be thrown aggressively. This threshold also determines entries’ time-to-live anｄ time intervals between garbage collection passes. More entries, less time-to-live, less GC interval. /proc/sys/net/ipv4/ip_autoconfig这个文件里面写着一个数字，表示主机是否通过RARP、BOOTP、DHCP或者其它机制取得其IP配置。否则就是0。 /proc/sys/net/ipv4/ip_default_ttl数据包的生存期。设置为64是安全的。如果你的网络规模巨大就提高这个值。不要因为好玩而这么做——那样会产生有害的路由环路。实际上，在很多情况下你要考虑能否减小这个值。 /proc/sys/net/ipv4/ip_dynaddr/proc/sys/net/ipv4/icmp_destunreach_rate如果你有一个动态地址的自动拨号接口，就得设置它。当你的自动拨号接口激活的时候，本地所有没有收到答复的TCP套接字会重新绑定到正确的地址上。这可以解决引发拨号的套接字本身无法工作，重试一次却可以的问题。 /proc/sys/net/ipv4/ip_forward内核是否转发数据包。缺省禁止。 /proc/sys/net/ipv4/ip_local_port_range用于向外连接的端口范围。缺省情况下其实很小：1024到4999。 /proc/sys/net/ipv4/ip_no_pmtu_disc如果你想禁止“沿途MTU发现”就设置它。“沿途MTU发现”是一种技术，可以在传输路径上检测出最大可能的MTU值。参见Cookbook一章中关于“沿途MTU发现”的内容。 /proc/sys/net/ipv4/ipfrag_high_thresh用 于IP分片汇聚的最大内存用量。分配了这么多字节的内存后，一旦用尽，分片处理程序就会丢弃分片。When ipfrag_high_thresh bytes of memory is allocated for this purpose, the fragment handler will toss packets until ipfrag_low_thresh is reached. /proc/sys/net/ipv4/ip_nonlocal_bind如果你希望你的应用程序能够绑定到不属于本地网卡的地址上时，设置这个选项。如果你的机器没有专线连接(甚至是动态连接)时非常有用，即使你的连接断开，你的服务也可以启动并绑定在一个指定的地址上。 /proc/sys/net/ipv4/ipfrag_low_thresh用于IP分片汇聚的最小内存用量。 /proc/sys/net/ipv4/ipfrag_timeIP分片在内存中的保留时间(秒数)。 /proc/sys/net/ipv4/tcp_abort_on_overflow一个布尔类型的标志，控制着当有很多的连接请求时内核的行为。启用的话，如果服务超载，内核将主动地发送RST包。 /proc/sys/net/ipv4/tcp_fin_timeout如 果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60秒。2.2 内核的通常值是180秒，你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2的危险性比FIN-WAIT-1要小，因为它最多只能吃掉1.5K内存，但是它们的生存期长些。参见tcp_max_orphans。 /proc/sys/net/ipv4/tcp_keepalive_time当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时。 /proc/sys/net/ipv4/tcp_keepalive_intvl当探测没有确认时，重新发送探测的频度。缺省是75秒。 /proc/sys/net/ipv4/tcp_keepalive_probes在认定连接失效之前，发送多少个TCP的keepalive探测包。缺省值是9。这个值乘以tcp_keepalive_intvl之后决定了，一个连接发送了keepalive之后可以有多少时间没有回应。 /proc/sys/net/ipv4/tcp_max_orphans系 统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS***，你绝对不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。This limit exists only to prevent simple DoS attacks, you must not rely on this oｒ lower the limit artificially, but rather increase it (probably, after increasing installed memory), if network conditions require more than default value, anｄ tune network services to linger anｄ kill such states more aggressively. 让我再次提醒你：每个孤儿套接字最多能够吃掉你64K不可交换的内存。 /proc/sys/net/ipv4/tcp_orphan_retries本端试图关闭TCP连接之前重试多少次。缺省值是7，相当于50秒~16分钟(取决于RTO)。如果你的机器是一个重载的WEB服务器，你应该考虑减低这个值，因为这样的套接字会消耗很多重要的资源。参见tcp_max_orphans。 /proc/sys/net/ipv4/tcp_max_syn_backlog记 录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而言，缺省值是1024，小内存的系统则是128。如果服务器不堪重负，试 试提高这个值。注意！如果你设置这个值大于1024，最好同时调整include/net/tcp.h中的TCP_SYNQ_HSIZE，以保证 TCP_SYNQ_HSIZE*16 ≤tcp_max_syn_backlo，然后重新编译内核。 /proc/sys/net/ipv4/tcp_max_tw_buckets系 统同时保持timewait套接字的最大数量。如果超过这个数字，time-wait套接字将立刻被清除并打印警告信息。这个限制仅仅是为了防止简单的 DoS***，你绝对不能过分依靠它或者人为地减小这个值，如果网络实际需要大于缺省值，更应该增加这个值(如果增加了内存之后)。 /proc/sys/net/ipv4/tcp_retrans_collapse为兼容某些糟糕的打印机设置的“将错就错”选项。再次发送时，把数据包增大一些，来避免某些TCP协议栈的BUG。/proc/sys/net/ipv4/tcp_retries1在认定出错并向网络层提交错误报告之前，重试多少次。缺省设置为RFC规定的最小值：3，相当于3秒~8分钟（取决于RIO）。 /proc/sys/net/ipv4/tcp_retries2在杀死一个活动的TCP连接之前重试多少次。RFC 1122规定这个限制应该长于100秒。这个值太小了。缺省值是15，相当于13~30分钟（取决于RIO）。 /proc/sys/net/ipv4/tcp_rfc1337这个开关可以启动对于在RFC1337中描述的“tcp的time-wait暗杀危机”问题的修复。启用后，内核将丢弃那些发往time-wait状态TCP套接字的RST包。却省为0。 /proc/sys/net/ipv4/tcp_sack特别针对丢失的数据包使用选择性ACK，这样有助于快速恢复。 /proc/sys/net/ipv4/tcp_stdurg使用TCP紧急指针的主机需求解释。因为绝大多数主机采用BSD解释，所以如果你在Linux上打开它，可能会影响它与其它机器的正常通讯。缺省是FALSE。/proc/sys/net/ipv4/tcp_syn_retries在内核放弃建立连接之前发送SYN包的数量。 /proc/sys/net/ipv4/tcp_synack_retries为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK包的数量。 /proc/sys/net/ipv4/tcp_timestamps时间戳可以避免序列号的卷绕。一个1Gbps的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。 /proc/sys/net/ipv4/tcp_tw_recycle能够更快地回收TIME-WAIT套接字。缺省值是1。除非有技术专家的建议和要求，否则不应修改。 /proc/sys/net/ipv4/tcp_window_scaling一般来说TCP/IP允许窗口尺寸达到65535字节。对于速度确实很高的网络而言这个值可能还是太小。这个选项允许设置上G字节的窗口大小，有利于在带宽*延迟很大的环境中使用。一旦内核认为它无法发包，就会丢弃这个包，并向发包的主机发送ICMP通知。 /proc/sys/net/ipv4/icmp_echo_ignore_all根本不要响应echo包。请不要设置为缺省，它可能在你正被利用成为DoS的跳板时可能有用。/proc/sys/net/ipv4/icmp_echo_ignore_broadcasts [Useful]如果你ping子网的子网地址，所有的机器都应该予以回应。这可能成为非常好用的拒绝服务工具。设置为1来忽略这些子网广播消息。/proc/sys/net/ipv4/icmp_echoreply_rate设置了向任意主机回应echo请求的比率。 /proc/sys/net/ipv4/icmp_ignore_bogus_error_responses设置它之后，可以忽略由网络中的那些声称回应地址是广播地址的主机生成的ICMP错误。 /proc/sys/net/ipv4/icmp_paramprob_rate一个相对不很明确的ICMP消息，用来回应IP头或TCP头损坏的异常数据包。你可以通过这个文件控制消息的发送比率。 tcp_syn_retries ：INTEGER默认值是5对于一个新建连接，内核要发送多少个 SYN 连接请求才决定放弃。不应该大于255，默认值是5，对应于180秒左右时间。(对于大负载而物理通信良好的网络而言,这个值偏高,可修改为2.这个值仅仅是针对对外的连接,对进来的连接,是由tcp_retries1 决定的) tcp_synack_retries ：INTEGER默认值是5对于远端的连接请求SYN，内核会发送SYN ＋ ACK数据报，以确认收到上一个 SYN连接请求包。这是所谓的三次握手( threeway handshake)机制的第二个步骤。这里决定内核在放弃连接之前所送出的 SYN+ACK 数目。不应该大于255，默认值是5，对应于180秒左右时间。(可以根据上面的 tcp_syn_retries 来决定这个值) tcp_keepalive_time ：INTEGER默认值是7200(2小时)当keepalive打开的情况下，TCP发送keepalive消息的频率。(由于目前网络等因素,造成了利用这个进行的很频繁,曾经也有cu的朋友提到过,说如果2边建立了连接,然后不发送任何数据或者rst/fin消息,那么持续的时间是不是就是2小时,空连接***? tcp_keepalive_time就是预防此情形的.我个人在做nat服务的时候的修改值为1800秒) tcp_keepalive_probes：INTEGER默认值是9TCP发送keepalive探测以确定该连接已经断开的次数。(注意:保持连接仅在SO_KEEPALIVE套接字选项被打开是才发送.次数默认不需要修改,当然根据情形也可以适当地缩短此值.设置为5比较合适) tcp_keepalive_intvl：INTEGER默认值为75探测消息发送的频率，乘以tcp_keepalive_probes就得到对于从开始探测以来没有响应的连接杀除的时间。默认值为75秒，也就是没有活动的连接将在大约11分钟以后将被丢弃。(对于普通应用来说,这个值有一些偏大,可以根据需要改小.特别是web类服务器需要改小该值,15是个比较合适的值) tcp_retries1 ：INTEGER默认值是3放弃回应一个TCP连接请求前﹐需要进行多少次重试。RFC 规定最低的数值是3﹐这也是默认值﹐根据RTO的值大约在3秒 - 8分钟之间。(注意:这个值同时还决定进入的syn连接) tcp_retries2 ：INTEGER默认值为15在丢弃激活(已建立通讯状况)的TCP连接之前﹐需要进行多少次重试。默认值为15，根据RTO的值来决定，相当于13-30分钟(RFC1122规定，必须大于100秒).(这个值根据目前的网络设置,可以适当地改小,我的网络内修改为了5) tcp_orphan_retries ：INTEGER默认值是7在近端丢弃TCP连接之前﹐要进行多少次重试。默认值是7个﹐相当于 50秒 - 16分钟﹐视 RTO 而定。如果您的系统是负载很大的web服务器﹐那么也许需要降低该值﹐这类 sockets 可能会耗费大量的资源。另外参的考 tcp_max_orphans 。(事实上做NAT的时候,降低该值也是好处显著的,我本人的网络环境中降低该值为3) tcp_fin_timeout ：INTEGER默认值是 60对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。默认值为 60 秒。过去在2.2版本的内核中是 180 秒。您可以设置该值﹐但需要注意﹐如果您的机器为负载很重的web服务器﹐您可能要冒内存被大量无效数据报填满的风险﹐FIN-WAIT-2 sockets 的危险性低于 FIN-WAIT-1 ﹐因为它们最多只吃 1.5K 的内存﹐但是它们存在时间更长。另外参考 tcp_max_orphans。(事实上做NAT的时候,降低该值也是好处显著的,我本人的网络环境中降低该值为30) tcp_max_tw_buckets ：INTEGER默认值是180000系 统在同时所处理的最大 timewait sockets 数目。如果超过此数的话﹐time-wait socket 会被立即砍除并且显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS ***﹐千万不要人为的降低这个限制﹐不过﹐如果网络条件需要比默认值更多﹐则可以提高它(或许还要增加内存)。(事实上做NAT的时候最好可以适当地增加该值) tcp_tw_recycle ：BOOLEAN默认值是0打开快速 TIME-WAIT sockets 回收。除非得到技术专家的建议或要求﹐请不要随意修改这个值。(做NAT的时候，建议打开它)tcp_tw_reuse：BOOLEAN默认值是0该文件表示是否允许重新应用处于TIME-WAIT状态的socket用于新的TCP连接(这个对快速重启动某些服务,而启动后提示端口已经被使用的情形非常有帮助) tcp_max_orphans ：INTEGER缺省值是8192系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量﹐那么不属于任何进程的连接会被立即reset，并同时显示警告信息。之所以要设定这个限制﹐纯粹为了抵御那些简单的 DoS ***﹐千万不要依赖这个或是人为的降低这个限制(这个值Redhat AS版本中设置为32768,但是很多防火墙修改的时候,建议该值修改为2000) tcp_abort_on_overflow ：BOOLEAN缺省值是0当守护进程太忙而不能接受新的连接，就象对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。(对待已经满载的sendmail,apache这类服务的时候,这个可以很快让客户端终止连接,可以给予服务程序处理已有连接的缓冲机会,所以很多防火墙上推荐打开它) tcp_syncookies ：BOOLEAN默认值是0只有在内核编译时选择了CONFIG_SYNCOOKIES时才会发生作用。当出现syn等候队列出现溢出时象对方发送syncookies。目的是为了防止syn flood。注意：该选项千万不能用于那些没有收到的高负载服务器，如果在日志中出现synflood消息，但是调查发现没有收到synflood***，而是合法用户的连接负载过高的原因，你应该调整其它参数来提高服务器性能。参考:tcp_max_syn_backlogtcp_synack_retriestcp_abort_on_overflowsyncookie严重的违背TCP协议，不允许使用TCP扩展，可能对某些服务导致严重的性能影响(如SMTP转发)。(注意,该实现与BSD上面使用的tcp proxy一样,是违反了RFC中关于tcp连接的三次握手实现的,但是对于防御syn-flood的确很有用.) tcp_stdurg ：BOOLEAN默认值为0使用 TCP urg pointer 字段中的主机请求解释功能。大部份的主机都使用老旧的 BSD解释，因此如果您在 Linux 打开它﹐或会导致不能和它们正确沟通。tcp_max_syn_backlog ：INTEGER对于那些依然还未获得客户端确认的连接请求﹐需要保存在队列中最大数目。对于超过 128Mb 内存的系统﹐默认值是 1024 ﹐低于 128Mb 的则为 128。如果服务器经常出现过载﹐可以尝试增加这个数字。警告﹗假如您将此值设为大于 1024﹐最好修改 include/net/tcp.h 里面的 TCP_SYNQ_HSIZE ﹐以保持 TCP_SYNQ_HSIZE16&lt;=tcp_max_syn_backlog ﹐并且编进核心之内。(SYN Flood**利用TCP协议散布握手的缺陷，伪造虚假源IP地址发送大量TCP-SYN半打开连接到目标系统，最终导致目标系统Socket队列资源耗 尽而无法接受新的连接。为了应付这种，现代Unix系统中普遍采用多连接队列处理的方式来缓冲(而不是解决)这种，是用一个基本队列处理正常的完 全连接应用(Connect()和Accept() )，是用另一个队列单独存放半打开连接。这种双队列处理方式和其他一些系统内核措施(例如Syn-Cookies/Caches)联合应用时，能够比较有效的缓解小规模的SYN Flood***(事实证明&lt;1000p/s)加大SYN队列长度可以容纳更多等待连接的网络连接数，所以对Server来说可以考虑增大该值.) tcp_window_scaling ：INTEGER缺省值为1该 文件表示设置tcp/ip会话的滑动窗口大小是否可变。参数值为布尔值，为1时表示可变，为0时表示不可变。tcp/ip通常使用的窗口最大可达到 65535 字节，对于高速网络，该值可能太小，这时候如果启用了该功能，可以使tcp/ip滑动窗口大小增大数个数量级，从而提高数据传输的能力(RFC 1323)。（对普通地百M网络而言，关闭会降低开销，所以如果不是高速网络，可以考虑设置为0） tcp_timestamps ：BOOLEAN缺省值为1Timestamps 用在其它一些东西中﹐可以防范那些伪造的 sequence 号码。一条1G的宽带线路或许会重遇到带 out-of-line数值的旧sequence 号码(假如它是由于上次产生的)。Timestamp 会让它知道这是个 ‘旧封包’。(该文件表示是否启用以一种比超时重发更精确的方法（RFC 1323）来启用对 RTT 的计算；为了实现更好的性能应该启用这个选项。) tcp_sack ：BOOLEAN缺省值为1使 用 Selective ACK﹐它可以用来查找特定的遗失的数据报— 因此有助于快速恢复状态。该文件表示是否启用有选择的应答（Selective Acknowledgment），这可以通过有选择地应答乱序接收到的报文来提高性能（这样可以让发送者只发送丢失的报文段）。(对于广域网通信来说这个选项应该启用，但是这会增加对 CPU 的占用。) tcp_fack ：BOOLEAN缺省值为1打开FACK拥塞避免和快速重传功能。(注意，当tcp_sack设置为0的时候，这个值即使设置为1也无效) tcp_dsack ：BOOLEAN缺省值为1允许TCP发送”两个完全相同”的SACK。 tcp_ecn ：BOOLEAN缺省值为0打开TCP的直接拥塞通告功能。 tcp_reordering ：INTEGER默认值是3TCP流中重排序的数据报最大数量 。 (一般有看到推荐把这个数值略微调整大一些,比如5) tcp_retrans_collapse ：BOOLEAN缺省值为1对于某些有bug的打印机提供针对其bug的兼容性。(一般不需要这个支持,可以关闭它) tcp_wmem(3个INTEGER变量)： min, default, maxmin：为TCP socket预留用于发送缓冲的内存最小值。每个tcp socket都可以在建议以后都可以使用它。默认值为4096(4K)。 default：为TCP socket预留用于发送缓冲的内存数量，默认情况下该值会影响其它协议使用的net.core.wmem_default 值，一般要低于net.core.wmem_default的值。默认值为16384(16K)。 max: 用于TCP socket发送缓冲的内存最大值。该值不会影响net.core.wmem_max，”静态”选择参数SO_SNDBUF则不受该值影响。默认值为131072(128K)。（对于服务器而言，增加这个参数的值对于发送数据很有帮助,在我的网络环境中,修改为了51200 131072 204800） tcp_rmem (3个INTEGER变量)： min, default, maxmin：为TCP socket预留用于接收缓冲的内存数量，即使在内存出现紧张情况下tcp socket都至少会有这么多数量的内存用于接收缓冲，默认值为8K。 default：为TCP socket预留用于接收缓冲的内存数量，默认情况下该值影响其它协议使用的 net.core.wmem_default 值。该值决定了在tcp_adv_win_scale、tcp_app_win和tcp_app_win=0默认值情况下，TCP窗口大小为65535。默认值为87380 max：用于TCP socket接收缓冲的内存最大值。该值不会影响 net.core.wmem_max，”静态”选择参数 SO_SNDBUF则不受该值影响。默认值为 128K。默认值为87380*2 bytes。（可以看出，.max的设置最好是default的两倍,对于NAT来说主要该增加它,我的网络里为 51200 131072 204800） tcp_mem(3个INTEGER变量)：low, pressure, highlow：当TCP使用了低于该值的内存页面数时，TCP不会考虑释放内存。(理想情况下，这个值应与指定给 tcp_wmem 的第 2 个值相匹配 - 这第 2 个值表明，最大页面大小乘以最大并发请求数除以页大小 (131072 * 300 / 4096)。 ) pressure：当TCP使用了超过该值的内存页面数量时，TCP试图稳定其内存使用，进入pressure模式，当内存消耗低于low值时则退出pressure状态。(理想情况下这个值应该是 TCP 可以使用的总缓冲区大小的最大值 (204800 * 300 / 4096)。 ) high：允许所有tcp sockets用于排队缓冲数据报的页面量。(如果超过这个值，TCP 连接将被拒绝，这就是为什么不要令其过于保守 (512000 * 300 / 4096) 的原因了。 在这种情况下，提供的价值很大，它能处理很多连接，是所预期的 2.5 倍；或者使现有连接能够传输 2.5 倍的数据。 我的网络里为192000 300000 732000) 一般情况下这些值是在系统启动时根据系统内存数量计算得到的。 tcp_app_win : INTEGER默认值是31保留max(window/2^tcp_app_win, mss)数量的窗口由于应用缓冲。当为0时表示不需要缓冲。 tcp_adv_win_scale : INTEGER默认值为2计算缓冲开销bytes/2^tcp_adv_win_scale(如果tcp_adv_win_scale &gt; 0)或者bytes-bytes/2^(-tcp_adv_win_scale)(如果tcp_adv_win_scale &lt;= 0）。tcp_rfc1337 :BOOLEAN缺省值为0这个开关可以启动对于在RFC1337中描述的”tcp 的time-wait暗杀危机”问题的修复。启用后，内核将丢弃那些发往time-wait状态TCP套接字的RST 包.tcp_low_latency : BOOLEAN缺省值为0允许 TCP/IP 栈适应在高吞吐量情况下低延时的情况；这个选项一般情形是的禁用。(但在构建Beowulf 集群的时候,打开它很有帮助)tcp_westwood :BOOLEAN缺省值为0启用发送者端的拥塞控制算法，它可以维护对吞吐量的评估，并试图对带宽的整体利用情况进行优化；对于 WAN 通信来说应该启用这个选项。tcp_bic :BOOLEAN缺省值为0为快速长距离网络启用 Binary Increase Congestion；这样可以更好地利用以 GB 速度进行操作的链接；对于 WAN 通信应该启用这个选项。 $ /proc/sys/net/core/wmem_max最大socket写buffer,可参考的优化值:873200$ /proc/sys/net/core/rmem_max最大socket读buffer,可参考的优化值:873200$ /proc/sys/net/ipv4/tcp_wmemTCP写buffer,可参考的优化值: 8192 436600 873200$ /proc/sys/net/ipv4/tcp_rmemTCP 读buffer,可参考的优化值: 32768 436600 873200$ /proc/sys/net/ipv4/tcp_mem同样有3个值,意思是:net.ipv4.tcp_mem[0]: 低于此值,TCP没有内存压力.net.ipv4.tcp_mem[1]:在此值下,进入内存压力阶段.net.ipv4.tcp_mem[2]: 高于此值,TCP拒绝分配socket.上述内存单位是页,而不是字节.可参考的优化值是:786432 1048576 1572864$ /proc/sys/net/core/netdev_max_backlog进入包的最大设备队列.默认是300,对重负载服务器而言,该值太低,可调整到1000.$ /proc/sys/net/core/somaxconnlisten()的默认参数,挂起请求的最大数量. 默认是128.对繁忙的服务器,增加该值有助于网络性能.可调整到256.$ /proc/sys/net/core/optmem_maxsocket buffer的最大初始化值,默认10K.$ /proc/sys/net/ipv4/tcp_max_syn_backlog进入SYN包的最大请求队列. 默认1024.对重负载服务器,增加该值显然有好处.可调整到2048.$ /proc/sys/net/ipv4/tcp_retries2TCP失败重传次数,默认值15,意味着重传 15次才彻底放弃.可减少到5,以尽早释放内核资源.$ /proc/sys/net/ipv4/tcp_keepalive_time$ /proc/sys/net/ipv4/tcp_keepalive_intvl$ /proc/sys/net/ipv4/tcp_keepalive_probes这3个参数与TCP KeepAlive有关.默认值是:tcp_keepalive_time = 7200 seconds (2 hours)tcp_keepalive_probes = 9tcp_keepalive_intvl = 75 seconds意思是如果某个TCP连接在idle 2个小时后,内核才发起probe.如果probe 9次(每次75秒)不成功,内核才彻底放弃,认为该连接已失效.对服务器而言,显然上述值太大. 可调整到:/proc/sys/net/ipv4/tcp_keepalive_time 1800/proc/sys/net/ipv4/tcp_keepalive_intvl 30/proc/sys/net/ipv4/tcp_keepalive_probes 3$ proc/sys/net/ipv4/ip_local_port_range指定端口范围的一个配置,默认是32768 61000,已够大.net.ipv4.tcp_syncookies = 1表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN***，默认为0，表示关闭；net.ipv4.tcp_tw_reuse = 1表示开启重用。允许将 TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，1表示关闭。net.ipv4.tcp_fin_timeout = 30表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。net.ipv4.tcp_keepalive_time = 1200表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。net.ipv4.ip_local_port_range = 1024 65000表示用于向外连接的端口范围。缺省情况下很小：32768到61000，改为1024到65000。net.ipv4.tcp_max_syn_backlog = 8192表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。net.ipv4.tcp_max_tw_buckets = 5000表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为 5000。对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。]]></content>
      <categories>
        <category>linux</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[smart you tube tv]]></title>
    <url>%2Fapp%2Fsmart%20you%20tube%20tv%2F</url>
    <content type="text"><![CDATA[将手机you tube 投影到 android 设备 的 apphttps://smartyoutubetv.github.io/ https://github.com/yuliskov/SmartYouTubeTV/releases/download/6.12.96/SmartYouTubeTV_Orig_v6.12.96_r.apk]]></content>
      <categories>
        <category>app</category>
      </categories>
      <tags>
        <tag>app</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查找zombie进程]]></title>
    <url>%2Flinux%2Fcommand%2F%E6%9F%A5%E6%89%BEzombie%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[可以用ps和grep命令寻找僵尸进程因为状态为 z或者Z的进程为僵尸进程，所以我们使用grep抓取stat状态为zZ进程 ps -A -ostat,ppid,pid,cmd | grep -e &apos;^[Zz]&apos; ## 统计非僵尸进程数量 ps -A -o stat,ppid,pid,cmd | grep -ve &apos;^[Zz]&apos; | grep -i &quot;haproxy&quot; | grep -iv &quot;grep&quot; | wc -l 或者 ps -C haproxy --no-heading -o stat,ppid,pid,cmd | grep -ve &quot;^[Zz]&quot; | grep -iv &quot;grep&quot; | wc -l 命令选项说明:-A 参数列出所有进程 -o 自定义输出字段 我们设定显示字段为 stat（状态）, ppid（进程父id）, pid(进程id)，cmd（命令）这四个参数 杀掉僵尸进程通过杀掉僵尸进程的父进程来杀掉僵尸进程 如，父进程ppid是 12334，那么我们就运行 kill -HUP 12334 杀掉僵尸进程]]></content>
      <categories>
        <category>linux</category>
        <category>command</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>command</tag>
        <tag>zombie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tracert 详解]]></title>
    <url>%2Flinux%2Fcommand%2Ftracert%20%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[tracert [-d] [-h maximum_hops] [-j host-list] [-w timeout] target_name -d 指定不将 IP 地址解析到主机名称。 -h maximum_hops 指定跃点数以跟踪到称为 target_name 的主机的路由。 -j host-list 指定 Tracert 实用程序数据包所采用路径中的路由器接口列表。 -w timeout 等待 timeout 为每次回复所指定的毫秒数。 target_name 目标主机的名称或 IP 地址。 traceroute -q 4 www.sina.com 表示每次向网关发送的探测数据包数量为4。 traceroute -m 10 www.wangshihai.com 表示设置的跳转数量为10次。 traceroute -n www.wangshihai.com 表示不显示主机名，只显示IP地址，跳过dns解析。 traceroute -p 7778 www.wangshihai.com 表示我们探测包使用UDP端口设置7778。 traceroute -r www.wangshihai.com 表示绕过真正的路由，直接发送到网络主机。 traceroute -w 5 www.wangshihai.com 表示我么设置对外发送探测包的等待响应时间设置为5秒。 traceroute -i eth0 -4 www.wangshihai.com，表示使用eth0网口以及IPV4协议。]]></content>
      <categories>
        <category>linux</category>
        <category>network</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tracert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[expect配合shell 实现自动分发秘钥文件]]></title>
    <url>%2Flinux%2Fcommand%2Fexpect%E9%85%8D%E5%90%88shell%20%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%88%86%E5%8F%91%E7%A7%98%E9%92%A5%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[expectExpect是一个用来处理交互的命令。它可以模拟键盘输入文本，省去人工干预交互式的指令。 整体来说大致的流程包括： 运行程序 程序要求人的判断和输入 Expect 通过关键字匹配 根据关键字向程序发送符合的字符串 代码例子如下：在Shell中引用expect，自动登陆ssh localhost，自动回复yes回车继续执行。 123456789#!/bin/bash/usr/bin/expect &gt;/dev/null 2&gt;&amp;1 &lt;&lt;EOFset time 30spawn ssh localhostexpect "*yes/no"send "yes\r"send "exit 1\r"expect eofEOF Expect解析Expect中最关键的四个命令是send,expect,spawn,interact。 spawn： spawm命令就是用来启动新的进程的。spawn后的send和expect命令都是和spawn打开的进程进行交互的。 expect： 从进程接收字符串，监听作用 send： 用于向进程发送字符串,回复作用 interact： 允许用户在适当的位置进行交互 expect命令和send命令正好相反，expect通常是用来等待一个进程的反馈。 expect可以接收一个字符串参数，也可以接收正则表达式参数。 expect脚本必须以interact或expect eof结束，执行自动化任务通常expect eof就够了 需要注意的是： expect执行完毕后，想退出执行环境，可以向进程发送&quot;exit 1\r&quot;退出环境，重新回到bash执行环境。 Expect-模式动作expect可以写成独立的格式，脚本格式为，如： #！/usr/bin/expect 也可以嵌套在shell脚本中使用 expect 使用 ‘{ }’表示一组表达式，且花括号前后要留空格 例如： expect &quot;(yes/no)&quot; {send &quot;yes\n&quot;} ## &quot;(yes/no)&quot; 是期望匹配的字符串 ## { send &quot;yes\n&quot;; exp_continue } expect 匹配到字符串后执行模拟输入的内容 expect还可以使用多字符匹配：如下 expect { &quot;(yes/no)&quot; { send &quot;yes\n&quot;; exp_continue } &quot;password:&quot; { send &quot;$password\n&quot; } } 单一分支模式：## 匹配到&quot;hi&quot;,进程自动回复&quot;you said hi&quot; expect &quot;hi&quot; { send &quot;You said hi&quot; } 多个分支模式：## 匹配到hi,hello,bye任意一个字符串时，执行相应的输出 expect &quot;hi&quot; { send &quot;You said hi\n&quot; } \ &quot;hello&quot; { send &quot;Hello yourself\n&quot; } \ &quot;bye&quot; { send &quot;That was unexpected\n&quot; } 等同于如下写法： expect { &quot;hi&quot; { send &quot;You said hi\n&quot;} &quot;hello&quot; { send &quot;Hello yourself\n&quot;} &quot;bye&quot; { send &quot;That was unexpected\n&quot;} } interactinteract作用是在一键安装的时候，可以让人为干预一键安装过程。 比如下载完ftp文件时，仍然可以停留在ftp命令行状态，以便手动的执行后续命令。 interact可以达到这些目的。下面的demo在自动登录ftp后，允许用户交互。代码如下： 123456spawn ftp ftp.test.comexpect "Name"send "user\r"expect "Password:"send "123456\r"interact expect工作方式首先使用 spawn 开启一个会话，然后使用 expect-send 对来执行交互式操作。 spawn 后面跟上一个命令操作，表示开启一个会话。 expect 等待输出特定的字符串(通常是提示符)，然后使用send 发送交互字符串。 12345password=123456spawn ssh username@host # 远程登录expect "*assword" # 提示为："username@host's password:", 等待用户输入密码send "$&#123;password&#125;\r" # 这时使用send模拟用户输入密码的字符串，完成登录验证 安装yum install expect -y 实例：自动推送秘钥文件到远程主机试想，如果要实现一些自动化的工作时，免密远程登录是必不可少的， （使用ansible的authoried_keys模块的方式推送就另说了） 假如在部署ansible前要将ansible的秘钥文件推送给100台服务器， 这个时候在脚本中使用scp指令避免不了要进行交互式地应答， 这个时候就需要使用expect来进行自动应答地执行了 编写shell脚本，在脚本中调用expect来实现自动向远处主机推送秘钥： 12345678910111213141516171819202122#!/bin/bashkeypath=/root/.ssh[ -d $&#123;keypath&#125; ] || mkdir -p $&#123;keypath&#125;rpm -q expect &amp;&gt; /dev/null || yum install expect -yssh-keygen -t rsa -f /root/.ssh/id_rsa -P ""password=fsz...while read ip;do expect &lt;&lt;EOF set timeout 5 spawn ssh-copy-id $ip expect &#123; "yes/no" &#123; send "yes\n";exp_continue &#125; "password" &#123; send "$password\n" &#125; &#125; expect eof EOFdone &lt; /home/iplist.txt 12345678cat &gt; /home/iplist.txt192.168.214.148192.168.214.143192.168.214.133192.168.214.135192.168.214.139192.168.214.134 参考https://www.cnblogs.com/anay/p/9059548.html]]></content>
      <categories>
        <category>linux</category>
        <category>command</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>command</tag>
        <tag>expect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[97条 Linux 常用命令总结]]></title>
    <url>%2Flinux%2Fcommand%2F97%E6%9D%A1%20Linux%20%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[ls [选项] [目录名 | 列出相关目录下的所有目录和文件-a 列出包括.a开头的隐藏文件的所有文件 -A 通-a，但不列出&quot;.&quot;和&quot;..&quot; -l 列出文件的详细信息 -c 根据ctime排序显示 -t 根据文件修改时间排序 ---color[=WHEN] 用色彩辨别文件类型 WHEN 可以是&apos;never&apos;、&apos;always&apos;或&apos;auto&apos;其中之一 白色：表示普通文件 蓝色：表示目录 绿色：表示可执行文件c 红色：表示压缩文件 浅蓝色：链接文件 红色闪烁：表示链接的文件有问题 黄色：表示设备文件 灰色：表示其它文件 mv [选项] 源文件或目录 目录或多个源文件 | 移动或重命名文件-b 覆盖前做备份 -f 如存在不询问而强制覆盖 -i 如存在则询问是否覆盖 -u 较新才覆盖 -t 将多个源文件移动到统一目录下，目录参数在前，文件参数在后 eg: mv a /tmp/ 将文件a移动到 /tmp目录下 mv a b 将a命名为b mv /home/zenghao test1.txt test2.txt test3.txt cp [选项] 源文件或目录 目录或多个源文件 | 将源文件复制至目标文件，或将多个源文件复制至目标目录。-r -R 递归复制该目录及其子目录内容 -p 连同档案属性一起复制过去 -f 不询问而强制复制 -s 生成快捷方式 -a 将档案的所有特性都一起复制 scp [参数] [原路径] [目标路径] | 在Linux服务器之间复制文件和目录-v 详细显示输出的具体情况 -r 递归复制整个目录 (1) 复制文件： 命令格式： scp local_file remote_username@remote_ip:remote_folder 或者 scp local_file remote_username@remote_ip:remote_file 或者 scp local_file remote_ip:remote_folder 或者 scp local_file remote_ip:remote_file 第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名 第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名 (2) 复制目录： 命令格式： scp -r local_folder remote_username@remote_ip:remote_folder 或者 scp -r local_folder remote_ip:remote_folder 第1个指定了用户名，命令执行后需要输入用户密码； 第2个没有指定用户名，命令执行后需要输入用户名和密码； eg: 从 本地 复制到 远程 scp /home/daisy/full.tar.gz root@172.19.2.75:/home/root 从 远程 复制到 本地 scp root@/172.19.2.75:/home/root/full.tar.gz /home/daisy/full.tar.gz rm [选项] 文件 | 删除文件-r 删除文件夹 -f 删除不提示 -i 删除提示 -v 详细显示进行步骤 touch [选项] 文件 | 创建空文件或更新文件时间-a 只修改存取时间 -m 值修改变动时间 -r eg:touch -r a b ,使b的时间和a相同 -t 指定特定的时间 eg:touch -t 201211142234.50 log.log -t time [[CC]YY]MMDDhhmm[.SS],C:年前两位 pwd 查看当前所在路径cd 改变当前目录- ：返回上层目录 .. :返回上层目录 回车 ：返回主目录 / :根目录 mkdir [选项] 目录… | 创建新目录-p 递归创建目录，若父目录不存在则依次创建 -m 自定义创建目录的权限 eg:mkdir -m 777 hehe -v 显示创建目录的详细信息 rmdir 删除空目录-v 显示执行过程 -p 若自父母删除后父目录为空则一并删除 11.rm [选项] 文件… | 一个或多个文件或目录 -f 忽略不存在的文件，不给出提示 -i 交互式删除 -r 将列出的目录及其子目录递归删除 -v 列出详细信息 echo：显示内容-n 输出后不换行 -e 遇到转义字符特殊处理 eg: echo &quot;hehe&quot; 显示hehe ehco -e &quot;hehe&quot; 显示he(换行了)he cat [选项] [文件]..| 一次显示整个文件或从键盘创建一个文件或将几个文件合并成一个文件-n 编号文件内容再输出 -E 在结束行提示$ tac | 反向显示more | 按页查看文章内容，从前向后读取文件，因此在启动时就加载整个文件+n 从第n行开始显示 -n 每次查看n行数据 +/String 搜寻String字符串位置，从其前两行开始查看 -c 清屏再显示 -p 换页时清屏 less | 可前后移动地逐屏查看文章内容，在查看前不会加载整个文件-m 显示类似于more命令的百分比 -N 显示行号 / 字符串：向下搜索“字符串”的功能 ? 字符串：向上搜索“字符串”的功能 n 重复前一个搜索（与 / 或 ? 有关） N 反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 nl [选项]… [文件]… | 将输出内容自动加上行号-b -b a 不论是否有空行，都列出行号（类似 cat -n) -b t 空行则不列行号（默认） -n 有ln rn rz三个参数，分别为再最左方显示，最右方显示不加0，最右方显示加0 head [参数]… [文件]… | 显示档案开头，默认开头10行-v 显示文件名 -c number 显示前number个字符,若number为负数,则显示除最后number个字符的所有内容 -number/n (+)number 显示前number行内容， -n number 若number为负数，则显示除最后number行数据的所有内容 tail [必要参数] [选择参数] [文件] | 显示文件结尾内容-v 显示详细的处理信息 -q 不显示处理信息 -num/-n (-)num 显示最后num行内容 -n +num 从第num行开始显示后面的数据 -c 显示最后c个字符 -f 循环读取 vi 编辑文件:w filename 将文章以指定的文件名保存起来 :wq 保存并退出 :q! 不保存而强制退出 命令行模式功能键 1）插入模式 按「i」切换进入插入模式「insert mode」，按&quot;i&quot;进入插入模式后是从光标当前位置开始输入文件； 按「a」进入插入模式后，是从目前光标所在位置的下一个位置开始输入文字； 按「o」进入插入模式后，是插入新的一行，从行首开始输入文字。 2）从插入模式切换为命令行模式 按「ESC」键。 3）移动光标 vi可以直接用键盘上的光标来上下左右移动，但正规的vi是用小写英文字母「h」、「j」、「k」、「l」，分别控制光标左、下、上、右移一格。 按「ctrl」+「b」：屏幕往&quot;后&quot;移动一页。 按「ctrl」+「f」：屏幕往&quot;前&quot;移动一页。 按「ctrl」+「u」：屏幕往&quot;后&quot;移动半页。 按「ctrl」+「d」：屏幕往&quot;前&quot;移动半页。 按数字「0」：移到文章的开头。 按「G」：移动到文章的最后。 按「$」：移动到光标所在行的&quot;行尾&quot;。 按「^」：移动到光标所在行的&quot;行首&quot; 按「w」：光标跳到下个字的开头 按「e」：光标跳到下个字的字尾 按「b」：光标回到上个字的开头 按「#l」：光标移到该行的第#个位置，如：5l,56l。 4）删除文字 「x」：每按一次，删除光标所在位置的&quot;后面&quot;一个字符。 「#x」：例如，「6x」表示删除光标所在位置的&quot;后面&quot;6个字符。 「X」：大写的X，每按一次，删除光标所在位置的&quot;前面&quot;一个字符。 「#X」：例如，「20X」表示删除光标所在位置的&quot;前面&quot;20个字符。 「dd」：删除光标所在行。 「#dd」：从光标所在行开始删除#行 5）复制 「yw」：将光标所在之处到字尾的字符复制到缓冲区中。 「#yw」：复制#个字到缓冲区 「yy」：复制光标所在行到缓冲区。 「#yy」：例如，「6yy」表示拷贝从光标所在的该行&quot;往下数&quot;6行文字。 「p」：将缓冲区内的字符贴到光标所在位置。注意：所有与&quot;y&quot;有关的复制命令都必须与&quot;p&quot;配合才能完成复制与粘贴功能。 6）替换 「r」：替换光标所在处的字符。 「R」：替换光标所到之处的字符，直到按下「ESC」键为止。 7）回复上一次操作 「u」：如果您误执行一个命令，可以马上按下「u」，回到上一个操作。按多次&quot;u&quot;可以执行多次回复。 8）更改 「cw」：更改光标所在处的字到字尾处 「c#w」：例如，「c3w」表示更改3个字 9）跳至指定的行 「ctrl」+「g」列出光标所在行的行号。 「#G」：例如，「15G」，表示移动光标至文章的第15行行首。 which 可执行文件名称 | 查看可执行文件的位置，在PATH变量指定的路径中查看系统命令是否存在及其位置whereis [-bmsu] [BMS 目录名 -f ] 文件名| 定位可执行文件、源代码文件、帮助文件在文件系统中的位置-b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。 locate | 通过搜寻数据库快速搜寻档案-r 使用正规运算式做寻找的条件 find find [PATH] [option] [action] | 在文件树种查找文件，并作出相应的处理选项与参数： 1. 与时间有关的选项：共有 -atime, -ctime 与 -mtime 和-amin,-cmin与-mmin，以 -mtime 说明 -mtime n ：n 为数字，意义为在 n 天之前的『一天之内』被更动过内容的档案； -mtime +n ：列出在 n 天之前(不含 n 天本身)被更动过内容的档案档名； -mtime -n ：列出在 n 天之内(含 n 天本身)被更动过内容的档案档名。 -newer file ：file 为一个存在的档案，列出比 file 还要新的档案档名 2. 与使用者或组名有关的参数： -uid n ：n 为数字，这个数字是用户的账号 ID，亦即 UID -gid n ：n 为数字，这个数字是组名的 ID，亦即 GID -user name ：name 为使用者账号名称！例如 dmtsai -group name：name 为组名，例如 users ； -nouser ：寻找档案的拥有者不存在 /etc/passwd 的人！ -nogroup ：寻找档案的拥有群组不存在于 /etc/group 的档案！ 3. 与档案权限及名称有关的参数： -name filename：搜寻文件名为 filename 的档案（可使用通配符） -size [+-]SIZE：搜寻比 SIZE 还要大(+)或小(-)的档案。这个 SIZE 的规格有： c: 代表 byte k: 代表 1024bytes。所以，要找比 50KB还要大的档案，就是『 -size +50k 』 -type TYPE ：搜寻档案的类型为 TYPE 的，类型主要有： 一般正规档案 (f) 装置档案 (b, c) 目录 (d) 连结档 (l) socket (s) FIFO (p) -perm mode ：搜寻档案权限『刚好等于』 mode的档案，这个mode为类似chmod的属性值，举例来说，-rwsr-xr-x 的属性为4755！ -perm -mode ：搜寻档案权限『必须要全部囊括 mode 的权限』的档案，举例来说， 我们要搜寻-rwxr--r-- 亦即 0744 的档案，使用-perm -0744，当一个档案的权限为 -rwsr-xr-x ，亦即 4755 时，也会被列出来，因为 -rwsr-xr-x 的属性已经囊括了 -rwxr--r-- 的属性了。 -perm +mode ：搜寻档案权限『包含任一 mode 的权限』的档案，举例来 说，我们搜寻-rwxr-xr-x ，亦即 -perm +755 时，但一个文件属性为 -rw-------也会被列出来，因为他有 -rw.... 的属性存在！ 4. 额外可进行的动作： -exec command ：command 为其他指令，-exec 后面可再接额外的指令来处理搜寻到的结果。 -print ：将结果打印到屏幕上，这个动作是预设动作！ eg: find / -perm +7000 -exec ls -l {} ; ,额外指令以-exec开头，以;结尾{}代替前面找到的内容 | xargs -i 默认的前面输出用{}代替 eg: find . -name &quot;*.log&quot; | xargs -i mv {} test4 grep ‘正则表达式’ 文件名 | 用正则表达式搜索文本，并把匹配的行打印出来-c 只输出匹配行的计数。 -I 不区分大小写(只适用于单字符)。 -l 只显示文件名 -v 显示不包含匹配文本的所有行。 -n 显示匹配行数据及其行号 file | 判断文件类型gzip [-cdtv#] 檔名 | 压缩、解压缩，源文件都不再存在-d 进行解压缩 -c 将压缩的数据输出到屏幕上 -v :显示原档案/压缩文件案的压缩比等信息 -# ：压缩等级，-1最快，但压缩比最差，=9最慢，但压缩比最好 gunzip | 解压缩bzip2 | 压缩、解压缩-d :解压 -z :压缩 -k :保留源文件 -c ：将压缩的过程产生的数据输出到屏幕上！ -v ：可以显示出原档案/压缩文件案的压缩比等信息； -# ：与 gzip 同样的，都是在计算压缩比的参数， -9 最佳， -1 最快！ bzcat 读取数据而无需解压tar [主选项+辅选项] 文件或者目录 | 多个目录或档案打包、压缩成一个大档案主选项： -c 建立打包档案，可搭配 -v 来察看过程中被打包的档名(filename) -t 察看打包档案的内容含有哪些档名，重点在察看『档名』就是了； -x 解打包或解压缩的功能，可以搭配 -C (大写) 在特定目录解开 辅选项： -j 透过 bzip2 的支持进行压缩/解压缩：此时档名最好为 *.tar.bz2 -z 透过 gzip 的支持进行压缩/解压缩：此时档名最好为 *.tar.gz -v 在压缩/解压缩的过程中，将正在处理的文件名显示出来！ -f filename -f 后面要立刻接要被处理的档名！ -C 目录 这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。 --exclude FILE：在压缩打包过程中忽略某文件 eg: tar --exclude /home/zenghao -zcvf myfile.tar.gz /home/* /etc -p 保留备份数据的原本权限与属性，常用于备份(-c)重要的配置文件 -P(大写） 保留绝对路径，亦即允许备份数据中含有根目录存在之意； eg: 压 缩：tar -jcvf filename.tar.bz2 要被压缩的档案或目录名称 查 询：tar -jtvf filename.tar.bz2 解压缩：tar -jxvf filename.tar.bz2 -C 欲解压缩的目录 exit 退出当前shelllogout 退出登录shellshutdown -h nowusers 显示当前登录系统地用户who 登录在本机的用户与来源-H或--heading 显示各栏位的标题信息列。 w 登录在本机的用户及其运行的程序-s 使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。 -h 不显示各栏位的标题信息列。 write 给当前联机的用户发消息wall 给所有登录再本机的用户发消息last 查看用户的登陆日志lastlog 查看每个用户最后的登陆时间finger [选项] [使用者] [用户@主机] | 查看用户信息-s 显示用户的注册名、实际姓名、终端名称、写状态、停滞时间、登录时间等信息 -l 除了用-s选项显示的信息外，还显示用户主目录、登录shell、邮件状态等信息，以及用户主目录下的.plan、.project和.forward文件的内容。 -p 除了不显示.plan文件和.project文件以外，与-l选项相同 hostname 查看主机名alias ii = “ls -l” | 添加别名unalias ii | 清除别名useradd [-u UID] [-g 初始群组] [-G 次要群组] [-c 说明栏] [-d 家目录绝对路径] [-s shell] 使用者账号名 | 新增用户-M 不建立用户家目录！(系统账号默认值) -m 建立用户家目录！(一般账号默认值) -r 建立一个系统的账号，这个账号的 UID 会有限制 -e 账号失效日期，格式为『YYYY-MM-DD』 -D 查看useradd的各项默认值 passwd | 修改密码-l 使密码失效 -u 与-l相对，用户解锁 -S 列出登陆用户passwd文件内的相关参数 -n 后面接天数，shadow 的第 4 字段，多久不可修改密码天数 -x 后面接天数，shadow 的第 5 字段，多久内必须要更动密码 -w 后面接天数，shadow 的第 6 字段，密码过期前的警告天数 -i 后面接『日期』，shadow 的第 7 字段，密码失效日期 使用管道刘设置密码：echo &quot;zeng&quot; | passwd --stdin zenghao userdel 删除用户-r 用户文件一并删除 chage [-ldEImMW] 账号名 | 修改用户密码的相关属性-l 列出该账号的详细密码参数； -d 后面接日期，修改 shadow 第三字段(最近一次更改密码的日期)，格式YYYY-MM-DD -E 后面接日期，修改 shadow 第八字段(账号失效日)，格式 YYYY-MM-DD -I 后面接天数，修改 shadow 第七字段(密码失效日期) -m 后面接天数，修改 shadow 第四字段(密码最短保留天数) -M 后面接天数，修改 shadow 第五字段(密码多久需要进行变更) -W 后面接天数，修改 shadow 第六字段(密码过期前警告日期) usermod [-cdegGlsuLU] username | 修改用户的相关属性-c 后面接账号的说明，即 /etc/passwd 第五栏的说明栏，可以加入一些账号的说明。 -d 后面接账号的家目录，即修改 /etc/passwd 的第六栏； -e 后面接日期，格式是 YYYY-MM-DD 也就是在 /etc/shadow 内的第八个字段数据啦！ -f 后面接天数为 shadow 的第七字段。 -g 后面接初始群组，修改 /etc/passwd 的第四个字段，亦即是GID的字段！ -G 后面接次要群组，修改这个使用者能够支持的群组 -l 后面接账号名称。亦即是修改账号名称， /etc/passwd 的第一栏！ -s 后面接 Shell 的实际档案，例如 /bin/bash 或 /bin/csh 等等。 -u 后面接 UID 数字啦！即 /etc/passwd 第三栏的资料； -L 冻结密码 -U 解冻密码 id [username] | 查看用户相关的id信息，还可以用来判断用户是否存在groups 查看登陆用户支持的群组， 第一个输出的群组为有效群组newgrp 切换有效群组groupadd [-g gid] 组名 | 添加组-g 设定添加组的特定组id groupmod [-g gid] [-n group_name] 群组名 | 修改组信息-g 修改既有的 GID 数字 -n 修改既有的组名 groupdel [groupname] | 删除群组gpasswd | 群组管理员功能root管理员动作： -gpasswd groupname 设定密码 -gpasswd [-A user1,...] [-M user3,...] groupname -A 将 groupname 的主控权交由后面的使用者管理(该群组的管理员) -M 将某些账号加入这个群组当中 -gpasswd [-r] groupname -r 将 groupname 的密码移除 群组管理员动作： - gpasswd [-ad] user groupname -a 将某位使用者加入到 groupname 这个群组当中 -d 将某位使用者移除出 groupname 这个群组当中 chfn修改个人信息mount [-t vfstype] [-o options] device dir-ro 采用只读方式挂接设备 -rw 采用读写方式挂接设备 eg:mount /home/mydisk.iso /tmp/mnt 通过mnt访问mydisk内的内容 umount 取消挂载cut-b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。 -c ：以字符为单位进行分割。 -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示哪个区域。 sort-n 依照数值的大小排序。 -o&lt;输出文件&gt; 将排序后的结果存入指定的文件。 -r 以相反的顺序来排序。 -t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。 -k 选择以哪个区间进行排序。 wc 统计指定文件中的字节数、字数、行数, 并将统计结果显示输出-l filename 报告行数 -c filename 报告字节数 -m filename 报告字符数 -w filename 报告单词数 uniq 去除文件中相邻的重复行-c或——count：在每列旁边显示该行重复出现的次数； -d或--repeated：仅显示重复出现的行列； -f&lt;栏位&gt;或--skip-fields=&lt;栏位&gt;：忽略比较指定的栏位； -s&lt;字符位置&gt;或--skip-chars=&lt;字符位置&gt;：忽略比较指定的字符； -u或——unique：仅显示出一次的行列； -w&lt;字符位置&gt;或--check-chars=&lt;字符位置&gt;：指定要比较的字符。 set 显示环境变量和普通变量env 显示环境变量export 把普通变量变成环境变量unset 删除一个环境变量aaa(){} 定义函数 read-p 接提示字符 -t 接等待的秒数 declare、typeset-i 声明为整数 -a 声明为数组 -f 声明为函数 -r 声明为只读 ulimit 限制使用者的某些系统资源-f 此 shell 可以建立的最大档案容量 (一般可能设定为 2GB)单位为 Kbytes eg: ulimit -f 1024 限制使用者仅能建立 1MBytes 以下的容量的档案 df [选项] [文件] | 显示指定磁盘文件的可用空间,如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示-a 显示全部文件系统 -h 文件大小友好显示 -l 只显示本地文件系统 -i 显示inode信息 -T 显示文件系统类型 du [选项] [文件] | 显示每个文件和目录的磁盘使用空间-h 方便阅读的方式 -s 只显示总和的大小 ln [参数] [源文件或目录] [目标文件或目录] | 某一个文件在另外一个位置建立一个同步的链接-s 建立软连接 -v 显示详细的处理过程 diff [参数] [文件1或目录1] [文件2或目录2] | 比较单个文件或者目录内容-b 不检查空格字符的不同。 -B 不检查空白行。 -i 不检查大小写 -q 仅显示差异而不显示详细信息 eg: diff a b &gt; parch.log 比较两个文件的不同并产生补丁 date [参数]… [+格式] | 显示或设定系统的日期与时间%H 小时(以00-23来表示)。 %M 分钟(以00-59来表示)。 %P AM或PM。 %D 日期(含年月日) %U 该年中的周数。 date -s “2015-10-17 01:01:01″ //时间设定 date +%Y%m%d //显示前天年月日 date +%Y%m%d --date=&quot;+1 day/month/year&quot; //显示前一天/月/年的日期 date +%Y%m%d --date=&quot;-1 day/month/year&quot; //显示后一天/月/年的日期 date -d &apos;2 weeks&apos; 2周后的日期 cal [参数] 月份] [年份] | 查看日历-1 显示当月的月历 -3 显示前、当、后一个月的日历 -m 显示星期一为一个星期的第一天 -s （默认）星期天为第一天 -j 显示当月是一年中的第几天的日历 -y 显示当前年份的日历 ps | 列出当前进程的快照a 显示所有的进程 -a 显示同一终端下的所有程序 e 显示环境变量 f 显示进程间的关系 -H 显示树状结构 r 显示当前终端的程序 T 显示当前终端的所有程序 -au 显示更详细的信息 -aux 显示所有包含其他使用者的行程 -u 指定用户的所有进程 top [参数] | 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等kill [参数] [进程号] | 杀死进程free [参数] | 显示linux系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffervmstat | 对操作系统的虚拟内存、进程、CPU活动进行监控iostat [参数] [时间t] [次数n](每隔t时间刷新一次，最多刷新n次）| 对系统的磁盘操作活动进行监视,汇报磁盘活动统计情况，同时也会汇报出CPU使用情况-p[磁盘] 显示磁盘和分区的情况 watch [参数] [命令] |重复执行某一命令以观察变化-n 时隔多少秒刷新 -d 高亮显示动态变化 at [参数] [时间] | 在一个指定的时间执行一个指定任务，只能执行一次HH:MM[am|pm] + number [minutes|hours|days|weeks] 强制在某年某月某日的某时刻进行该项任务 atq 查看系统未执行的任务 atrm n 删除编号为n的任务 at -c n 显示编号为n的任务的内容 crontab | 定时任务调度file 载入crontab -e 编辑某个用户的crontab文件内容 -l 显示某个用户的crontab文件内容 -r 删除某个用户的crontab文件 ifconfig [网络设备] [参数] | 查看和配置网络设备route | 显示和操作IP路由表ping [参数] [主机名或IP地址] | 测试与目标主机的连通性-q 只显示最后的结果 netstat | 显示与IP、TCP、UDP和ICMP协议相关的统计数据telnet [参数] [主机] | 用于远程登录，采用明文传送报文，安全性不好rcp [参数] [源文件] [目标文件] | 远程文件拷贝-r 递归复制 -p 保留源文件的属性 usage: rcp –r remote_hostname:remote_dir local_dir wget [参数] [URL地址] | 直接从网络上下载文件-o FILE 把记录写到FILE文件中 eg : wget -O a.txt URL wget --limit-rate=300k URL 限速下载 awk-F 分隔符 以分隔符分隔内容 {} 要执行的脚本内容 eg:cat /etc/passwd |awk -F &apos;:&apos; &apos;{print $1&quot;&quot;$7}&apos; sed 对数据行进行替换、删除、新增、选取等操作a 新增，在新的下一行出现 c 取代，取代 n1,n2 之间的行 eg: sed &apos;1,2c Hi&apos; ab d 删除 i 插入，在新的上一行出现 paste 合并文件，需确保合并的两文件行数相同-d 指定不同于空格或tab键的域分隔符 -s 按行合并，单独一个文件为一行 su [参数] user | 切换登陆-l 切换时连同环境变量、工作目录一起改变 -c command 执行command变回原来的使用者 sudo | 以特定用户的权限执行特定命令-l 列出当前用户可执行的命令 -u username#uid 以指定用户执行命令]]></content>
      <categories>
        <category>linux</category>
        <category>command</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived和Haproxy]]></title>
    <url>%2Fkeepalived%2FKeepalived%E5%92%8CHaproxy%2F</url>
    <content type="text"><![CDATA[安装yum install keepalived haproxy psmisc 修改系统参数echo &apos;net.ipv4.ip_nonlocal_bind = 1&apos; &gt;&gt; /etc/sysctl.conf sysctl -p 防火墙firewall-cmd --zone=public --add-rich-rule=&apos;rule family=&quot;ipv4&quot; destination address=&quot;224.0.0.18&quot; protocol value=&quot;vrrp&quot; accept&apos; --permanent Firewall-cmd --reload 架构 Haproxy反代配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146cat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOFglobal log 127.0.0.1 local2 warning chroot /var/lib/haproxy pidfile /run/haproxy/haproxy.pid maxconn 4000 user haproxy group haproxy daemon ## 设置启动的haproxy进程数量，一般设置为cpu核数, 只能用于守护进程模式的haproxy; ## 默认只启动一个进程 #nbproc 1 ## 设置绑定核心，第一个参数表示绑定id，第二个参数指定cpu核心，0开始第一个cpu核心 ## 后面用bind-process 绑定id，如将CPU核心分开以进行后端处理 ## frontend access_http ## bind 0.0.0.0:80 ## bind-process 1 ## frontend access_https ## bind 0.0.0.0:443 ssl crt /etc/yourdomain.pem ## bind-process 2 3 4 #cpu-map 1 0 #cpu-map 2 1 #cpu-map 3 2 #cpu-map 4 3 #定义统计信息保存位置 #stats socket /var/lib/haproxy/stats stats socket /run/haproxy/admin.sock mode 660 level admin stats timeout 30s ##===============https相关======================================== ca-base /etc/ssl/certs crt-base /etc/ssl/private ## Default ciphers to use on SSL-enabled listening sockets. ## 参考：https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ ## 需要处理以下事： ## 禁用SSL 2.0（FUBAR）和SSL 3.0 1（POODLE）， ## 禁用TLS 1.0压缩（CRIME）， ## 禁用弱密码（DES / 3DES，RC4），更喜欢现代密码（AES），模式（GCM）和协议（TLS 1.2）。 ## OpenSSL更新为1.0.1c +，以便尽快支持TLS 1.2，GCM和ECDHE ## OpenSSL安装进行测试： ## openssl ciphers -v 'ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS' ## ssl-default-bind-options &lt;force-sslv3|no-sslv3 no-tls-tickets|force-tlsv10|force-tlsv11|force-tlsv12&gt; ssl-default-bind-options force-tlsv12 ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS ssl-default-server-options force-tlsv12 ssl-default-server-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS tune.ssl.default-dh-param 2048 ##============================================================defaults mode http log global option httplog option dontlognull option http-server-close #option httpclose option abortonclose option redispatch retries 3 option forwardfor except 127.0.0.0/8 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 #balance source #balnace leastconn#统计页面配置, frontend和backend的组合体, 监控组的名称可按需自定义listen admin_stats bind 0.0.0.0:1080 mode http maxconn 10 option httplog stats enable stats hide-version stats refresh 30s stats uri /stats stats realm Haproxy\ Statistics stats auth test.admin:test.admin!9595 stats admin if TRUE #设置haproxy错误页面，复制源代码目录下错误样本文件(cp ./haproxy-1.8.8/examples/errorfiles/* /usr/local/haproxy) #errorfile 400 /usr/local/haproxy/errorfiles/400.http #errorfile 403 /usr/local/haproxy/errorfiles/403.http #errorfile 408 /usr/local/haproxy/errorfiles/408.http #errorfile 500 /usr/local/haproxy/errorfiles/500.http #errorfile 502 /usr/local/haproxy/errorfiles/502.http #errorfile 503 /usr/local/haproxy/errorfiles/503.http #errorfile 504 /usr/local/haproxy/errorfiles/504.httpfrontend web bind *:80 mode http maxconn 2000 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend resources if url_static default_backend appbackend resources balance roundrobin server web1 172.18.67.11:8080 check server web2 172.18.67.12:8080 checkbackend app balance roundrobin server wp1 172.18.67.11:80 check server wp2 172.18.67.12:80 checkEOF keepalived## 主备不同之处 1，router_id 不能一致 2，state MASTER/BACKUP 3, priority 权重不能一致 4, interface ens33 网络接口注意和本机对应 keepalived master12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost IT@service.com &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id haproxy01 vrrp_garp_master_refresh 60 vrrp_garp_master_delay 5 vrrp_mcast_group4 224.0.0.18&#125;vrrp_script chk_mantaince_down &#123; script "/etc/keepalived/chk_down.sh" interval 2 weight 20 fall 2 rise 1&#125;vrrp_script chk_haproxy &#123; script "/bin/killall -0 haproxy &amp;&amp; exit 0 || exit 1" interval 2 weight 20 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 50 priority 100 advert_int 1 #garp_master_delay 10 #garp_master_refresh 60 #nopreempt smtp_alert authentication &#123; auth_type PASS auth_pass DFwx4893Gh60 &#125; virtual_ipaddress &#123; ## &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 172.18.67.33/24 dev ens33 &#125; ## mcast_src_ip &lt;IPADDR&gt; #unicast_src_ip 172.18.67.13 #unicast_peer &#123; # 172.18.67.14 #&#125; track_interface &#123; ens33 &#125; track_script &#123; chk_haproxy chk_mantaince_down &#125; ## 可以不用执行脚本，除非需要执行某些操作。keepalived 1.5 + postfix 能够发送邮件。 #notify_master "/etc/keepalived/notify.sh master" #notify_backup "/etc/keepalived/notify.sh backup" #notify_fault "/etc/keepalived/notify.sh fault"&#125;EOF keepalived backup1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost IT@service.com &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id haproxy02 vrrp_garp_master_refresh 60 vrrp_garp_master_delay 5 vrrp_mcast_group4 224.0.0.18&#125;vrrp_script chk_mantaince_down &#123; script "/etc/keepalived/chk_down.sh" interval 2 weight 20 fall 2 rise 1&#125;vrrp_script chk_haproxy &#123; script "/bin/killall -0 haproxy &amp;&amp; exit 0 || exit 1" #script "/etc/keepalived/chk_haproxy.sh" interval 2 weight 20 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 50 priority 90 advert_int 1 #garp_master_delay 10 #garp_master_refresh 60 #nopreempt smtp_alert authentication &#123; auth_type PASS auth_pass DFwx4893Gh60 &#125; virtual_ipaddress &#123; ## &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 172.18.67.33/24 dev ens33 &#125; ## mcast_src_ip &lt;IPADDR&gt; #unicast_src_ip 172.18.67.14 #unicast_peer &#123; # 172.18.67.13 #&#125; track_interface &#123; ens33 &#125; track_script &#123; chk_haproxy chk_mantaince_down &#125; ## 可以不用执行脚本，除非需要执行某些操作。keepalived 1.5 + postfix 能够发送邮件。 #notify_master "/etc/keepalived/notify.sh master" #notify_backup "/etc/keepalived/notify.sh backup" #notify_fault "/etc/keepalived/notify.sh fault"&#125;EOF haproxy 进程检查脚本12345678cat &gt; /etc/keepalived/chk_haproxy.sh &lt;&lt; EOF#!/bin/bash[[ \$(ps -C 'haproxy' --no-heading -o stat,ppid,pid,cmd | grep -ve '^[Zz]' | grep -iv 'grep' | wc -l) -ge 2 ]] &amp;&amp; exit 0 || exit 1EOFchmod u+x /etc/keepalived/chk_haproxy.sh 维护脚本12345678cat &gt; /etc/keepalived/chk_down.sh &lt;&lt; EOF#!/bin/bash[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0EOFchmod u+x /etc/keepalived/chk_down.sh 通知脚本## 只是发送通知邮件，不是必须的。keepalived 1.5 + postfix 能够发送邮件。 12345678910111213141516171819202122232425262728293031323334cat &gt; /etc/keepalived/notify.sh &lt;&lt; EOF#!/bin/bashcontact='root@localhost'notify() &#123; mailsubject="$(hostname) to be $1, vip floating" mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125;case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esacEOFchmod u+x /etc/keepalived/notify.sh web 监控脚本监控web服务器脚本： #! /bin/bash ## 注意，这里需要tomcat开启了所有IP地址的web请求， ## 这里填写首页的index地址 URL= URL_STATUS=`curl -o /dev/null -s -w %{http_code} $URL` if [ $URL_STATUS != 200 ];then killall tomcat /opt/tomcat/bin/start.sh #这里是启动tomcat，当然，有其他方法也可以 sleep 3 if [ `curl -o /dev/null -s -w %{http_code} $URL` != 200 ];then killall keepalived fi fi 监控mysql脚本#! /bin/bash STATUS=`mysqladmin ping -u设置的用户名 -p设置的密码` if [ “$STATUS” != “mysqld is alive” ];then service mysql restart RE=$? sleep 3 if [ $RE != 0 ];then killall keepalived fi fi 参考https://www.cnblogs.com/mrlapulga/p/6857294.html]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy 反向代理 SSL]]></title>
    <url>%2FHaproxy%2FHAProxy%20%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%20SSL%2F</url>
    <content type="text"><![CDATA[生成haproxy 终结证书openssl genrsa -out /etc/haproxy/server.key 2048 openssl req -new -key /etc/haproxy/server.key -out /etc/haproxy/server.csr openssl x509 -req -days 3655 -in /etc/haproxy/server.csr -signkey /etc/haproxy/server.key -out /etc/haproxy/server.crt ## 以上三步合为一步操作 openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/haproxy/server.key -out /etc/haproxy/server.crt ## 除了cn需要输入网站名,其它可以随意输入 ## openssl： 这是OpenSSL提供的基本命令行工具，用于创建和管理证书，密钥，签名请求等。 ## req： 这指定了X.509证书签名请求（CSR）管理的子命令。X.509是SSL为其密钥和证书管理所遵循的公钥基础结构标准。由于我们想要创建一个新的X.509证书，这就是我们想要的。 ## -x509： 此选项指定我们要创建自签名证书文件，而不是生成证书请求。 ## -nodes： 此选项告诉OpenSSL我们不希望使用密码来保护我们的密钥文件。拥有受密码保护的密钥文件会妨碍Apache自动启动，因为每次服务重新启动时都必须输入密码。 ## -days 365： 这指定我们创建的证书有效期为一年。 ## -newkey rsa：2048：此选项将同时创建证书请求和新私钥。这是必要的，因为我们没有提前创建私钥。该rsa:2048告诉OpenSSL生成RSA密钥是2048位。 ## -keyout： 此参数为正在创建的私钥文件命名输出文件。 ## -out： 此选项为我们生成的证书命名输出文件。 ## pem文件本质上只是将证书、密钥及证书认证中心证书（可有可无）拼接成一个文件 cat /etc/haproxy/server.crt /etc/haproxy/server.key | tee /etc/haproxy/server.pem Haproxy日志记录在配置前，我们先来了解一下日志的level：local0～local7 16～23保留为本地使用： emerg 0 系统不可用； alert 1 必须马上采取行动的事件； crit 2 关键的事件； err 3 错误事件； warning 4 警告事件； notice 5 普通但重要的事件； info 6 有用的信息； debug 7 调试信息。 默认 haproxy 是不记录日志的，为了记录日志还需要配置 syslog 模块，在 linux 下是 rsyslogd 服务。 如果要发送日志到远程主机，还需修改远程主机中的/etc/sysconfig/rsyslog中的参数。 安装配置rsyslog123456789101112131415161718192021222324252627282930## 此步centos 默认已安装，可以跳过yum -y install rsyslog ## 修改"SYSLOGD_OPTIONS"参数，## -c 2 使用兼容模式，默认是 -c 5；## -r 开启远程日志；## -m 0 标记时间戳，单位是分钟，0表示禁用该功能。cp /etc/sysconfig/rsyslog&#123;,.$(date '%F_%T')&#125;cat &gt; /etc/sysconfig/rsyslog &lt;&lt; EOFSYSLOGD_OPTIONS="-c 2 -r -m 0"EOFsed -i "s/#\$ModLoad imudp/\$ModLoad imudp/g" /etc/rsyslog.confsed -i "s/#\$UDPServerRun 514/\$UDPServerRun 514/g" /etc/rsyslog.conf## #文件最末尾的"&amp;~"，如果没有此配置，日志除写入指定文件外，会同步写入messages文件；cat &gt; /etc/rsyslog.d/haproxy.conf &lt;&lt; EOFlocal2.* /var/log/haproxy.log&amp;~EOFsystemctl restart rsyslog.service 配置 Haproxy##Haproxy 基本配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141cp /etc/haproxy/haproxy.cfg&#123;,.$(date +'%F_%T')&#125;cat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOFglobal #定义全局日志, 配置在本地, 通过local0 输出, 默认是info级别，可配置两条 log 127.0.0.1 local2 warning chroot /var/lib/haproxy pidfile /var/run/haproxy.pid #设置每haproxy进程的最大并发连接数, 其等同于命令行选项“-n”; “ulimit -n”自动计算的结果参照此参数设定. maxconn 4000 user haproxy group haproxy #后台运行haproxy daemon ## 设置启动的haproxy进程数量, 只能用于守护进程模式的haproxy; ## 默认只启动一个进程 #nbproc 1 #定义统计信息保存位置 #stats socket /var/lib/haproxy/stats stats socket /run/haproxy/admin.sock mode 660 level admin stats timeout 30s ##===============https相关======================================== # Default SSL material locations ca-base /etc/ssl/certs crt-base /etc/ssl/private ## Default ciphers to use on SSL-enabled listening sockets. ## 参考：https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/ ## 需要处理以下事： ## 禁用SSL 2.0（FUBAR）和SSL 3.0 1（POODLE）， ## 禁用TLS 1.0压缩（CRIME）， ## 禁用弱密码（DES / 3DES，RC4），更喜欢现代密码（AES），模式（GCM）和协议（TLS 1.2）。 ## OpenSSL更新为1.0.1c +，以便尽快支持TLS 1.2，GCM和ECDHE ## OpenSSL安装进行测试： ## openssl ciphers -v 'ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS' ssl-default-bind-options no-sslv3 ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS ssl-default-server-options no-sslv3 ssl-default-server-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS tune.ssl.default-dh-param 2048 ##============================================================defaults #默认的模式【tcp:4层； http:7层； health:只返回OK】 mode http #日志类别, httplog log global #日志类别, httplog option httplog #如果产生了一个空连接，那这个空连接的日志将不会记录. option dontlognull #开启http协议中服务器端关闭功能, 每个请求完毕后主动关闭http通道, 使得支持长连接，使得会话可以被重用，使得每一个日志记录都会被记录. option http-server-close ## 需要长连接就注释掉此 # option httpclose #当haproxy负载很高时, 自动结束掉当前队列处理比较久的链接. option abortonclose #如果后端服务器需要记录客户端真实ip, 需要在HTTP请求中添加”X-Forwarded-For”字段; #但haproxy自身的健康检测机制访问后端服务器时, 不应将记录访问日志，可用except来排除127.0.0.0，即haproxy本身. option forwardfor except 127.0.0.0/8 #当与后端服务器的会话失败(服务器故障或其他原因)时, 把会话重新分发到其他健康的服务器上; 当故障服务器恢复时, 会话又被定向到已恢复的服务器上; #还可以用”retries”关键字来设定在判定会话失败时的尝试连接的次数 option redispatch retries 3 #默认http请求超时时间 timeout http-request 10s #默认队列超时时间, 后端服务器在高负载时, 会将haproxy发来的请求放进一个队列中. timeout queue 1m #haproxy与后端服务器连接超时时间. timeout connect 10s #客户端与haproxy连接后, 数据传输完毕, 不再有数据传输, 即非活动连接的超时时间. timeout client 1m #haproxy与后端服务器非活动连接的超时时间. timeout server 1m #默认新的http请求连接建立的超时时间，时间较短时可以尽快释放出资源，节约资源. timeout http-keep-alive 10s #心跳检测超时时间 timeout check 10s #设置默认的负载均衡方式 #balance source #balnace leastconnlisten admin_stats bind 0.0.0.0:1080 mode http option httplog maxconn 10 ## 状态监控可以直接防在default里，任何监听域名或地址都可以访问，也可以单独放在listen里 stats enable stats hide-version stats refresh 30s stats uri /stats stats realm Haproxy\ Statistics stats auth test.admin:test.admin!9595 stats refresh 30s stats admin if TRUEEOF ## HAProxy作为SSL终端123456789101112131415161718192021222324252627282930## 让负载均衡器处理SSL连接。这就意味着要将SSL证书放在负载均衡服务器上。## SSL连接终止在负载均衡器haproxy ---&gt;解码SSL连接并发送非加密连接到后端应用tomcat.## 多个不同域名的证书 bind *:443 ssl crt &lt;cert_path&gt; crt &lt;cert_path&gt; ...cat &gt;&gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOFfrontend server_ssl bind *:80 bind *:443 ssl crt /etc/haproxy/server.pem ## 将http转发至https redirect scheme https if !&#123; ssl_fc &#125; mode http default_backend serverbackend server mode http balance roundrobin option forwardfor# option httpchk HEAD / HTTP/1.1\r\nHost:localhost server web01 10.0.0.4:80 maxconn 1024 weight 1 check inter 2000 rise 2 fall 4 server web02 10.0.0.6:80 maxconn 1024 weight 1 check inter 2000 rise 2 fall 4# http-request set-header X-Forwarded-Port %[dst_port]# http-request add-header X-Forwarded-Proto https if &#123; ssl_fc &#125;EOF ## HAProxy实现SSL穿透1234567891011121314151617181920212223242526272829## 使用SSL穿透，让后台服务器处理SSL连接，而非负载均衡器来处理。## 负载均衡器的工作就只是简单地将请求转发到配置好的后台服务器。连接还保持加密状态。## 在这个配置中，需要在前端和后台配置中同时使用TCP模式而不是HTTP模式,HAProxy只会把连接当作信息流来转发到其他服务器.## 然而，这样做会让你失去增加或修改HTTP报头的能力，这意味着应用服务器会失去获取 X-Forwarded-* 报头的能力，这个报头包含了客户端IP地址、端口和使用的协议。## 可以使用ssl-hello-chk来检查连接及它处理SSL（特别是SSLv3）连接的能力## 使用SSL 穿越，不需要给HAProxy创建或使用SSL证书。## option forwardfor和http-request选项 - 这些不能用于TCP模式，而且我们也不能向已加密的请求添加报头cat &gt;&gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOFfrontend server_ssl bind *:80 bind *:443 option tcplog mode tcp default_backend serverbackend server mode tcp balance roundrobin option ssl-hello-chk server web01 10.0.0.4:80 weight 1 check inter 2000 rise 2 fall 4 server web02 10.0.0.6:80 weight 1 check inter 2000 rise 2 fall 4EOF keepalvied 高可用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071cat &gt; /etc/keepalived.conf &lt;&lt; EOF! Configuration File for keepalived global_defs &#123;notification_email &#123; root@sanyu.com&#125;notification_email_from kanotify@sanyu.comsmtp_connect_timeout 30smtp_server 127.0.0.1router_id LVS_DEVEL&#125;vrrp_script chk_haproxy &#123; script "killall -0 haproxy" interval 1 weight 2&#125;vrrp_script chk_mantaince_down &#123;script "[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0"interval 1weight 2&#125;vrrp_instance VI_1 &#123; state MASTER # BACKUP for slave routers interface eth0 virtual_router_id 70 priority 101 # 100 for BACKUP garp_master_delay 1 authentication &#123; auth_type PASS auth_pass password &#125; track_interface &#123; eth0 &#125; virtual_ipaddress &#123; 172.16.100.70/16 dev eth0 label eth0:0 &#125; track_script &#123; chk_haproxy chk_mantaince_down &#125;&#125;vrrp_instance VI_2 &#123; interface eth0 state BACKUP # BACKUP for slave routers priority 100 # 100 for BACKUP virtual_router_id 79 garp_master_delay 1 authentication &#123; auth_type PASS auth_pass password &#125; track_interface &#123; eth0 &#125; virtual_ipaddress &#123; 172.16.100.79/16 dev eth0 label eth0:1 &#125; track_script &#123; chk_haproxy chk_mantaince_down &#125; &#125;EOF ## 比对两服务器的keepalived配置文件12diff keepalived.conf keepalived.conf.ha2 123456789101112131415161718192021222324252627vi /etc/keepalived/check_haproxy.sh#!/bin/shkillall -0 haproxyif [ $? -ne 0 ]; then## if [ $(ps -C haproxy --no-header | wc -l) -eq 0 ]; then systemctl restart haproxy ## /usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/conf/haproxy.cfg## fi sleep 2 killall -0 haproxy ## if [ $(ps -C haproxy --no-header | wc -l) -eq 0 ]; then if [ $? -ne 0 ]; then killall keepalived fifikillall -0 haproxy]]></content>
      <categories>
        <category>HAProxy</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>HAProxy</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived和LVS-NAT]]></title>
    <url>%2Fkeepalived%2FKeepalived%E5%92%8CLVS-NAT%2F</url>
    <content type="text"><![CDATA[架构LVS服务器将来自的ens33的HTTP数据包(客户请求)通过NAT转发到的Backend01和Backend02服务器。 将两个后端Web服务器的默认网关更改为LVS的内部IP地址。 （示例中为10.0.0.100） LVS的内部IP地址（示例中为10.0.0.100）不需要设置网关。 +----------------+-----------------+ | | 192.168.1.10|ens33 --- VIP:192.168.1.5 --- ens33|192.168.1.11 +-------+--------+ +--------+-------+ | LVS+Keepalived | | LVS+Keepalived | +-------+--------+ +--------+-------+ 10.0.0.10|ens37 ----- VIP:10.0.0.100 ---- ens37|10.0.0.11 | | +----------------+-----------------+ | +------------+ | +------------+ | Backend01 |10.0.0.71 | 10.0.0.72| Backend02 | | Web Server +------------+-------------+ Web Server | | |ens33 ens33| | +------------+ +------------+ lvs 服务器安装配置## Install ipvsadm and keepalived12345678910yum -y install ipvsadm keepalived psmisc## 配置director打开网卡间的转发功能echo 'net.ipv4.ip_forward = 1' &gt;&gt; /etc/sysctl.conf sysctl -ptouch /etc/sysconfig/ipvsadm systemctl start ipvsadm systemctl enable ipvsadm 防火墙## 配置vrrp广播 firewall-cmd --zone=public --add-rich-rule=&apos;rule family=&quot;ipv4&quot; destination address=&quot;224.0.0.18&quot; protocol value=&quot;vrrp&quot; accept&apos; --permanent firewall-cmd --reload ## 配置防火墙，使外部网络的接口(ens33)与内部网络的接口(ens37)位于不同的区域。 firewall-cmd --get-active-zones firewall-cmd --zone=public --remove-interface=ens37 firewall-cmd --zone=internal --add-interface=ens37 firewall-cmd --permanent --zone=public --remove-interface=ens37 firewall-cmd --permanent --zone=internal --add-interface=ens37 firewall-cmd --get-active-zones ## 在外部网络接口上配置NAT模式（伪装）,区域为public firewall-cmd --zone=public --add-masquerade firewall-cmd --permanent --zone=public --add-masquerade firewall-cmd --zone=public --query-masquerade firewall-cmd --zone=internal --query-masquerade ## 如果尚未为防火墙启用，请在外部和内部网络接口之间配置转发规则，例如： firewall-cmd --direct --permanent --add-rule ipv4 filter FORWARD 0 -i ens33 -o ens37 -m state --state RELATED,ESTABLISHED -j ACCEPT firewall-cmd --direct --permanent --add-rule ipv4 filter FORWARD 0 -i ens37 -o ens33 -j ACCEPT firewall-cmd --direct --permanent --add-rule ipv4 filter FORWARD 0 -j REJECT --reject-with icmp-host-prohibited firewall-cmd --reload ## 开放访问端口 firewall-cmd --zone=public --add-service=http firewall-cmd --permanent --zone=public --add-service=http 后端服务器路由配置## 配置Keepalived NAT模式负载均衡的后端服务器路由 ## 在您打算与Keepalived负载平衡器一起使用的每个后端真实服务器上，确保路由表包含负载平衡器内部网络接口的虚拟IP地址的默认路由。 例如，如果是虚拟IP地址 10.0.0.100，则可以使用 ip命令检查路由表并设置默认路由： ＃ ip route show 10.0.0.0/24 dev enp0s8 proto kernel scope link src 10.0.0.71 ＃ip route add default via 10.0.0.100 dev enp0s8 ＃ip route show 默认通过10.0.0.100 dev enp0s8 10.0.0.0/24 dev enp0s8 proto kernel scope link src 10.0.0.71 要使enp0s8重新启动时保持默认路由，请创建该文件 /etc/sysconfig/network-scripts/route-enp0s8： ＃ echo &quot;default via 10.0.0.100 dev enp0s8&quot; &gt; /etc/sysconfig/network-scripts/route-enp0s8 keepalive 配置## Configure Keepalived123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOFglobal_defs &#123; notification_email &#123; root@localhot &#125; notification_email_from root@lvs.server smtp_server 127.0.0.1 smtp_connect_timeout 30 ## 不同服务器，分别设置一个标识 router_id LVS_Server vrrp_garp_master_refresh 60 vrrp_garp_master_delay 5 vrrp_mcast_group4 224.0.0.18&#125;vrrp_sync_group VRRP1 &#123; # group &#123; external internal &#125;&#125;vrrp_instance external &#123; state BACKUP interface ens33 virtual_router_id 60 ## 优先级设置，0-254,数值越大优先级越高，MASTER要设置高于BACKUP priority 100 nopreempt # VRRP 广播时间间隔 advert_int 1 smtp_alert authentication &#123; auth_type PASS auth_pass PassWord6409284 &#125; virtual_ipaddress &#123; 192.168.1.5 dev ens33 &#125;&#125;vrrp_instance internal &#123; state BACKUP interface ens33 virtual_router_id 70 ## 优先级设置，0-254,数值越大优先级越高，MASTER要设置高于BACKUP priority 100 nopreempt # VRRP 广播时间间隔 advert_int 1 smtp_alert authentication &#123; auth_type PASS auth_pass PassWord6409284 &#125; virtual_ipaddress &#123; 10.0.0.100/24 dev ens37 &#125;&#125;virtual_server 192.168.1.5 80 &#123; # monitored interval delay_loop 3 # lvs 调度算法，rr|wrr|lc|wlc|lblc|sh|dh lb_algo rr # lvs 转发模式，NAT|DR|TUN lb_kind NAT protocol TCP # 后端服务器 real_server 10.0.0.71 80 &#123; #inhibit_on_failure ##表示在节点失败后，把他权重设置成0，而不是冲IPVS中删除 #notify_up &lt;STRING&gt; | &lt;QUOTED-STRING&gt; ##检查服务器正常(UP)后，要执行的脚本 #notify_down &lt;STRING&gt; | &lt;QUOTED-STRING&gt; ##检查服务器失败(down)后，要执行的脚本 #uthreshold &lt;INTEGER&gt; ## maximum number of connections to server #lthreshold &lt;INTEGER&gt; ## minimum number of connections to server weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 3 ## 连接超时时间 nb_get_retry 3 ## 重连次数 delay_before_retry 3 ## 重连间隔 &#125; &#125; real_server 10.0.0.72 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 3 nb_get_retry 3 delay_before_retry 3 &#125; &#125;&#125;EOFsystemctl start keepalivedsystemctl enable keepalived lvs-nat说明NAT方式配置 这种方式需要Director和各Real Server在同一IP网络内（172.16.100.0/24），具体配置如下示例： Director： ens33 --VIP：192.168.0.146 gateway：局域网网关(路由器地址) ens37 --DIP：172.16.100.10 gateway：为空，不需要填 Real Server1(RS1): ens33 --RIP: 172.16.100.2 gateway：172.16.100.10 Real Server2(RS2): ens33 --RIP: 172.16.100.3 gateway：172.16.100.10 配置director打开网卡间的转发功能，echo &apos;1&apos; &gt;/proc/sys/net/ipv4/ip_forward ## LVS - 地址转换(NAT)模式示例，Director节点的lvs_serv_nat.sh脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/bin/bash # 配置实服务主机IP，调度器虚拟IP(调度器节点需要双网卡，对外地址为VIP，内网地址需要设置为RS网关)Vip=192.168.1.100Rs1=192.168.1.101Rs2=192.168.1.102 source /etc/rc.d/init.d/functions case "$1" in start) echo "Start LVS of Server..." # 打开Director服务器上开启路由转发功能(多网卡下的网卡间数据包转发) echo 1 &gt; /proc/sys/net/ipv4/ip_forward # 清空防火墙nat表的所有链 #iptables -t nat -F # 删除防火墙nat自定义链 #iptables -t nat -X # 新增一个子网卡 /sbin/ifconfig ens33:0 $Vip netmask 255.255.240.0 up # 设置Director的ipvs /sbin/ipvsadm -C # 在内核虚拟服务器表中添加一台虚拟服务器 /sbin/ipvsadm -A -t $Vip:6500 -s rr # rr 表示轮询调度 # 在一台虚拟服务器中增加一台新的真实服务器(指定虚拟服务对应真实服务的关系，指定负载均衡模式) /sbin/ipvsadm -a -t $Vip:6500 -r $Rs1:6500 -m # -m 表示NAT模式 /sbin/ipvsadm -a -t $Vip:6500 -r $Rs2:6500 -m # 启动LVS /sbin/ipvsadm ;;stop) echo "Close LVS of Server..." echo "0" &gt;/proc/sys/net/ipv4/ip_forward /sbin/ipvsadm -C /sbin/ifconfig ens33:0 down ;; *) echo "Usage： $0 &#123;start|stop&#125;" ;; esac exit 0 LVS该/etc/keepalived/keepalived.conf 配置文件被分成以下部分： global_defs 定义全局设置，例如发送通知消息的电子邮件地址，SMTP服务器的IP地址，SMTP连接的超时值（秒），标识主机的字符串，VRRP IPv4和IPv6多播地址以及SNMP陷阱应该启用。 static_ipaddress ， static_routes 定义静态IP地址和路由，VRRP无法更改。如果已在服务器上定义了地址和路由，并且这些服务器已具有网络连接，则不需要这些部分。 vrrp_sync_group 定义一起故障转移的VRRP备份VRRP同步组。 vrrp_instance 为VRRP同步组的内部或外部网络接口的成员定义可移动的虚拟IP地址，该状态在状态转换期间与其他组成员一起提供。每个VRRP实例必须具有唯一值virtual_router_id，该值标识主服务器和备份服务器上的哪些接口可以分配给定的虚拟IP地址。您还可以指定要在状态转换运行脚本BACKUP，MASTER以及FAULT，以及是否触发SMTP警报状态转换。 vrrp_script 定义跟踪脚本，Keepalived可以定期运行以执行来自a vrrp_instance或 vrrp_sync_groupsection的监视操作 。 virtual_server_group 定义虚拟服务器组，允许真实服务器成为多个虚拟服务器组的成员。 virtual_server 定义用于负载平衡的虚拟服务器，该服务器由多个真实服务器组成。 参考https://www.server-world.info/en/note?os=CentOS_7&amp;p=lvs&amp;f=2 https://docs.oracle.com/cd/E52668_01/E54669/html/section_xsx_wl2_4r.html]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>lvs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库的通用命令行工具 USQL]]></title>
    <url>%2Foracle%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%80%9A%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%20USQL%2F</url>
    <content type="text"><![CDATA[说明USQL 是一个使用 Go 语言开发的支持 SQL/NoSQL 数据库的通用命令行工具，支持多种主流的数据库软件。 比如：PostgreSQL、MySQL、Oracle Database、SQLite3、Microsoft SQL Server 以及许多其它的数据库（包括 NoSQL 和非关系型数据库）。 USQL 的灵感来自 PostgreSQL 的 PSQL，USQL 支持大多数 PSQL 的核心特性，比如：设置变量、反引号参数。 并具有 PSQL 不支持的其它功能，如语法高亮、基于上下文的自动补全和多数据库支持等。 项目地址：https://github.com/xo/usql 下载安装wget https://github.com/xo/usql/releases/download/v0.7.0/usql-0.7.0-linux-amd64.tar.bz2 tar -jxf usql-0.7.0-linux-amd64.tar.bz2 mv usql /usr/bin/ ## 官方编译版只带有PostgreSQL, MySQL, SQLite3 and Microsoft SQL Server驱动，如果要支持其它数据库，需要自己编译 $ sudo yum install golang git # install all drivers $ go get -u -tags all github.com/xo/usql # install with most drivers (same as all but excludes Oracle/ODBC) $ go get -u -tags most github.com/xo/usql # install with base drivers and Oracle/ODBC support $ go get -u -tags &apos;oracle odbc&apos; github.com/xo/usql # install all drivers excluding avatica and couchbase $ go get -u -tags &apos;all no_avatica no_couchbase&apos; github.com/xo/usql 连接到一个 MySQL 数据库# 使用默认信息连接到数据库 usql my:// # 使用用户名和密码连接到指定的数据库 usql my://user:pass@host/dbname # 使用用户名、密码和端口连接到指定的数据库 usql mysql://user:pass@host:port/dbname # 使用指定的套接字连接数据库 usql /var/run/mysqld/mysqld.sock 连接到一个 PostgreSQL 数据库# 使用默认信息连接到数据库 usql pg:// # 使用用户名和密码连接到指定的数据库 usql pg://user:pass@host/dbname # 使用用户名、密码和端口连接到指定的数据库 usql postgres://user:pass@host:port/dbname # 使用指定的套接字连接数据库 usql /var/run/postgresql 连接到一个 Oracle 数据库# 使用默认信息连接到数据库 usql or:// # 使用用户名和密码连接到指定的数据库 usql or://user:pass@host/sid # 使用用户名、密码和端口连接到指定的数据库 usql oracle://user:pass@host:port/sid 连接到一个 SQL Server 数据库# 使用默认信息连接到数据库 usql ms:// # 使用用户名和密码连接到指定的数据库 usql ms://user:pass@host/dbname # 使用用户名、密码和端口连接到指定的数据库 usql mssql://user:pass@host:port/dbname # 使用用户名和密码连接到指定实例的数据库 usql ms://user:pass@host/instancename/dbname mysql 使用示例## 创建一个名为 test 的数据库，并在这个数据库中建立的名为 test 的表中新增一行数据。 usql my://root:000000@localhost my:root@localhost=&gt; create database test; my:root@localhost=&gt; use test; my:root@localhost=&gt; CREATE TABLE IF NOT EXISTS `test`( my:root@localhost(&gt; `test_id` INT, my:root@localhost(&gt; `name` VARCHAR(100) NOT NULL my:root@localhost(&gt; )ENGINE=InnoDB DEFAULT CHARSET=utf8; my:root@localhost=&gt; insert into test (test_id, name) values (1, &apos;hello&apos;); my:root@localhost=&gt; select * from test; ## 连接到一个 MySQL 数据库并运行一个名为 script.sql 的脚本 usql my://root:000000@localhost/wordpress -f script.sql ## 打印并执行缓充区中的 SQL 语句 my:root@localhost=&gt; select * my:root@localhost-&gt; from test my:root@localhost-&gt; \p select * from test my:root@localhost-&gt; \g ## 快速切换到另一个数据库连接 ms:mike@192.168.100.210:1433/testdb=&gt; \c my://root:000000@localhost/wordpress my:root@localhost/wordpress=&gt; select * from wp_postmeta limit 5; ## 使用变量进行条件查询 # 设置变量 my:root@localhost/wordpress=&gt; \set meta 2179 # 查看当前已设置的变量 my:root@localhost/wordpress=&gt; \set meta = &apos;2179&apos; # 使用变量做为条件进行查询 my:root@localhost/wordpress=&gt; select * from wp_postmeta where meta_value=:&apos;m ## 变量调用支持 :NAME、:’NAME’、和 :”NAME” 这三种方式进行调用。 ## 使用反引号参数 my:root@localhost/wordpress=&gt; \echo Welcome `echo $USER` -- &apos;currently:&apos; &quot;(&quot; `date` &quot;)&quot; ## 反引号参数的执行结果也可以直接设置为一个变量的值： my:root@localhost=&gt; \set MYVAR `date &quot;+%Y-%m-%d&quot;` my:root@localhost=&gt; \echo :MYVAR 2018-06-19 my:root@localhost=&gt; select id,post_author,post_date from wp_posts where post_date &lt; :&apos;MYVAR&apos; limit 2;]]></content>
      <categories>
        <category>USQL</category>
      </categories>
      <tags>
        <tag>USQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keepalived和Nginx]]></title>
    <url>%2Fkeepalived%2FKeepalived%E5%92%8CNginx%2F</url>
    <content type="text"><![CDATA[安装yum install keepalived nginx psmisc 修改系统参数echo &apos;net.ipv4.ip_nonlocal_bind = 1&apos; &gt;&gt; /etc/sysctl.conf sysctl -p 防火墙firewall-cmd --zone=public --add-rich-rule=&apos;rule family=&quot;ipv4&quot; destination address=&quot;224.0.0.18&quot; protocol value=&quot;vrrp&quot; accept&apos; --permanent Firewall-cmd --reload 架构 Nginx反代配置nginx MASTER:upstream websrvs { server 172.18.67.11:80; server 172.18.67.12:80; server 127.0.0.1:80 backup; } server { listen 80 ; location / { proxy_pass http://websrvs; } } nginx BACKUP:upstream websrvs { server 172.18.67.11:80; server 172.18.67.12:80; server 127.0.0.1:80 backup; } server { listen 80 ; location / { proxy_pass http://websrvs; } } keepalived## 主备不同之处 1，router_id 不能一致 2，state MASTER/BACKUP 3, priority 权重不能一致 4, interface ens33 网络接口注意和本机对应 keepalived master12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost IT@service.com &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id nginx01 vrrp_garp_master_refresh 60 vrrp_garp_master_delay 5 vrrp_mcast_group4 224.0.0.18&#125;vrrp_script chk_mantaince_down &#123; script "/etc/keepalived/chk_down.sh" interval 2 weight 20 fall 2 rise 1&#125;vrrp_script chk_nginx &#123; script "/bin/killall -0 nginx &amp;&amp; exit 0 || exit 1" interval 2 weight 20 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state MASTER interface ens33 virtual_router_id 50 priority 100 advert_int 1 #garp_master_delay 10 #garp_master_refresh 60 #nopreempt smtp_alert authentication &#123; auth_type PASS auth_pass DFwx4893Gh60 &#125; virtual_ipaddress &#123; ## &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 172.18.67.33/24 dev ens33 &#125; ## mcast_src_ip &lt;IPADDR&gt; #unicast_src_ip 172.18.67.13 #unicast_peer &#123; # 172.18.67.14 #&#125; track_interface &#123; ens33 &#125; track_script &#123; chk_nginx chk_mantaince_down &#125; ## 可以不用执行脚本，除非需要执行某些操作。keepalived 1.5 + postfix 能够发送邮件。 #notify_master "/etc/keepalived/notify.sh master" #notify_backup "/etc/keepalived/notify.sh backup" #notify_fault "/etc/keepalived/notify.sh fault"&#125;EOF keepalived backup1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980cat &gt; /etc/keepalived/keepalived.conf &lt;&lt; EOF! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost IT@service.com &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id nginx02 vrrp_garp_master_refresh 60 vrrp_garp_master_delay 5 vrrp_mcast_group4 224.0.0.18&#125;vrrp_script chk_mantaince_down &#123; script "/etc/keepalived/chk_down.sh" interval 2 weight 20 fall 2 rise 1&#125;vrrp_script chk_nginx &#123; script "/bin/killall -0 nginx &amp;&amp; exit 0 || exit 1" #script "/etc/keepalived/chk_nginx.sh" interval 2 weight 20 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state BACKUP interface ens33 virtual_router_id 50 priority 90 advert_int 1 #garp_master_delay 10 #garp_master_refresh 60 #nopreempt smtp_alert authentication &#123; auth_type PASS auth_pass DFwx4893Gh60 &#125; virtual_ipaddress &#123; ## &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 172.18.67.33/24 dev ens33 &#125; ## mcast_src_ip &lt;IPADDR&gt; #unicast_src_ip 172.18.67.14 #unicast_peer &#123; # 172.18.67.13 #&#125; track_interface &#123; ens33 &#125; track_script &#123; chk_nginx chk_mantaince_down &#125; ## 可以不用执行脚本，除非需要执行某些操作。keepalived 1.5 + postfix 能够发送邮件。 #notify_master "/etc/keepalived/notify.sh master" #notify_backup "/etc/keepalived/notify.sh backup" #notify_fault "/etc/keepalived/notify.sh fault"&#125;EOF nginx 进程检查脚本12345678cat &gt; /etc/keepalived/chk_nginx.sh &lt;&lt; EOF#!/bin/bash[[ \$(ps -C 'nginx' --no-heading -o stat,cmd | grep -ve '^[Zz]' | grep -iv 'grep' | wc -l) -gt 1 ]] &amp;&amp; exit 0 || exit 1EOFchmod u+x /etc/keepalived/chk_nginx.sh 维护脚本12345678cat &gt; /etc/keepalived/chk_down.sh &lt;&lt; EOF#!/bin/bash[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0EOFchmod u+x /etc/keepalived/chk_down.sh 通知脚本## 只是发送通知邮件，不是必须的。keepalived 1.5 + postfix 能够发送邮件。 12345678910111213141516171819202122232425262728293031323334cat &gt; /etc/keepalived/notify.sh &lt;&lt; EOF#!/bin/bashcontact='root@localhost'notify() &#123; mailsubject="$(hostname) to be $1, vip floating" mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125;case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esacEOFchmod u+x /etc/keepalived/notify.sh 参考https://www.cnblogs.com/mrlapulga/p/6857294.html]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[keepalived 配置]]></title>
    <url>%2Fkeepalived%2Fkeepalived%20%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[yum 安装yum install keepalived -y yum install tcpdump psmisc 编译安装cd /opt yum -y install gcc libnfnetlink-devel libnl3-devel openssl openssl-devel net-snmp-devel wget wget http://www.keepalived.org/software/keepalived-2.0.5.tar.gz tar xvf keepalived-2.0.5.tar.gz cd keepalived-2.0.5 ./configure --prefix=/usr/local/keepalived make make install 开启接口共享IP功能和内核转发功能## 修改内核参数： /etc/sysctl.conf net.ipv4.ip_nonlocal_bind = 1 net.ipv4.ip_forward = 1 ## 允许程序绑定到不属于本地网卡的地址上 echo &apos;net.ipv4.ip_nonlocal_bind = 1&apos; &gt;&gt; /etc/sysctl.conf echo &apos;net.ipv4.ip_forward = 1&apos; &gt;&gt; /etc/sysctl.conf 防火墙配置## 如果防火墙屏蔽了keepalived间的通讯，可能导致两台master ## keepalived 默认需要使用D类多播地址224.0.0.18 进行心跳通信 ## keepalived 使用vrp协议进行通信（协议号码为112） ## VRRP协议既不属于TCP也不属于UDP，在协议类型选项需要选“All traffice”的选项来防止由于防火墙原因造成通信问题。 ## 使用单播避免部分网络不允许组播，但vrrp_strict禁用单播，所有不能设置此项 ## firewall 配置方法 firewall-cmd --permanent --new-service=vrrp firewall-cmd --permanent --service=vrrp --set-description=&quot;Virtual Router Redundancy Protocol&quot; firewall-cmd --permanent --service=vrrp --set-short=vrrp firewall-cmd --permanent --service=vrrp --add-protocol=vrrp firewall-cmd --permanent --service=vrrp --set-destination=ipv4:224.0.0.18 firewall-cmd --add-service=vrrp --permanent --zone=internal firewall-cmd --reload ## 或者 oracle 介绍的方式,此方式重启失效 echo &quot;net.ipv4.ip_forward = 1&quot; &gt;&gt; /etc/sysctl.conf sysctl -p firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface &quot;your interface&quot; --destination 224.0.0.18 --protocol vrrp -j ACCEPT firewall-cmd --direct --permanent --add-rule ipv4 filter OUTPUT 0 --out-interface &quot;your interface&quot; --destination 224.0.0.18 --protocol vrrp -j ACCEPT firewall-cmd --reload ## 修改配置文件方式 vi /etc/firewalld/direct.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;direct&gt; &lt;rule priority=&quot;0&quot; table=&quot;filter&quot; ipv=&quot;ipv4&quot; chain=&quot;OUTPUT&quot;&gt;&apos; --out-interface&apos; [ens33] --destination 224.0.0.18 --protocol vrrp -j ACCEPT&lt;/rule&gt; &lt;rule priority=&quot;1&quot; table=&quot;filter&quot; ipv=&quot;ipv4&quot; chain=&quot;IN_public_allow&quot;&gt;-d 224.0.0.18 -j ACCEPT&lt;/rule&gt; &lt;/direct&gt; ## 或者 firewall-cmd --zone=public --add-rich-rule=&apos;rule family=&quot;ipv4&quot; destination address=&quot;224.0.0.18&quot; protocol value=&quot;vrrp&quot; accept&apos; --permanent Firewall-cmd --reload ## iptables 配置方法 iptables -A INPUT -d 224.0.0.18 -j ACCEPT ## keepalvied 使用 112 端口通信，加上防火墙规则 iptables -A INPUT -i ens37 -p 112 -j ACCEPT # /sbin/iptables -I INPUT -i ens37 -d 224.0.0.0/8 -j ACCEPT # /sbin/iptables -A INPUT -p 112 -i ens37 -j ACCEPT # /sbin/iptables -A OUTPUT -p 112 -o ens37 -j ACCEPT # /sbin/service iptables save Haproxy 结合使用问题haproxy 监听绑定IP最好用，如*:80 或 0.0.0.0:80，否则无法在绑定vip:80 建立监听。 如果直接绑定vip:80，如果不是master，haproxy启动前机器是backup没有获得vip，那haproxy可能启动不了。 如果不是master，Haproxy 绑定vip:80，又能启动，解决办法就是： 允许程序绑定到不属于本地网卡的地址上 echo &apos;net.ipv4.ip_nonlocal_bind = 1&apos; &gt;&gt; /etc/sysctl.conf haproxy代理服务器同时也要打开内核的转发功能。 ## 检查广播问题，vrrp广播不通会导致脑裂 tcpdump -vvv -n -i ens37 host 224.0.0.18 日志设置## 修改 /etc/sysconfig/keepalived ## 把KEEPALIVED_OPTIONS=&quot;-D&quot; 修改为KEEPALIVED_OPTIONS=&quot;-D -d -S 0&quot; # --vrrp -P Only run with VRRP subsystem. # --check -C Only run with Health-checker subsystem. # --dont-release-vrrp -V Dont remove VRRP VIPs &amp; VROUTEs on daemon stop. # --dont-release-ipvs -I Dont remove IPVS topology on daemon stop. # --dump-conf -d Dump the configuration data. # --log-detail -D Detailed log messages. # --log-facility -S 0-7 Set local syslog facility (default=LOG_DAEMON) 1234567891011121314151617cat &gt; /etc/sysconfig/keepalivedKEEPALIVED_OPTIONS="-D -d -S 3"EOFsed -i "s/#\$ModLoad imudp/\$ModLoad imudp/g" /etc/rsyslog.confsed -i "s/#\$UDPServerRun 514/\$UDPServerRun 514/g" /etc/rsyslog.conf## #文件最末尾的"&amp;~"，如果没有此配置，日志除写入指定文件外，会同步写入messages文件；cat &gt; /etc/rsyslog.d/keepalived.conf &lt;&lt; EOFlocal3.* /var/log/keepalived.log&amp;~EOFsystemctl restart rsyslog.service 全局配置global_defs { ## 全局配置 notification_email { ## 定义报警邮件地址 tom@service.com IT@service.com } notification_email_from IT@service.com ## 定义发送邮件的地址 smtp_server 127.0.0.1 ## 邮箱服务器 smtp_connect_timeout 30 ## 定义超时时间 router_id haproxy01 ## 运行Keepalived服务器的一个标识，是发邮件时显示在邮件主题中的信息。 vrrp_garp_master_refresh 60 ## secs, default 0 (no refreshing) vrrp_garp_master_delay 5 ## seconds, default 5, 0 for no second set #vrrp_iptables ##禁止keepalived启动生成默认的iptables规则 #vrrp_mcast_group4 224.17.17.17 ##定义主备节点通过组播地址进行通告状态 } 监控检查## 多个检查脚本，每个脚本权重都会添加，最终优先级=初始优先级+脚本1的权重+脚本2的权重+... vrrp_script chk_haproxy { ## 检测该服务器上haproxy服务的健康状态的 script &quot;/bin/killall -0 haproxy &amp;&amp; exit 0 || exit 1&quot; #script &quot;/etc/keepalived/chk_haproxy.sh&quot; interval 2 ## 每2秒检测一次 weight 20 ## 默认是2. 当脚本执行码为0，权重大于0时，vrrp实例优先级增加；当脚本执行码为非0，权重小于0时，vrrp实例优先级减小，其他情况优先级不变。 fall 2 ## 检测两次都失败才失败 rise 1 ## 检测一次成功就成功 } ## 检测端口是否开启可以用，如：script &quot;&lt;/dev/tcp/127.0.0.1/6379&quot; ## 判断非僵尸进程bash 语句, haproxy 采用master-worker模式，所以进程数要大于112345678cat &gt; /etc/keepalived/chk_haproxy.sh &lt;&lt; EOF#!/bin/bash[[ \$(ps -C 'haproxy' -o stat,cmd | grep -ve '^[Zz]' | grep -iv 'grep' | wc -l) -ge 2 ]] &amp;&amp; exit 0 || exit 1EOFchmod u+x /etc/keepalived/chk_haproxy.sh 维护检查vrrp_script chk_mantaince_down { script &quot;/etc/keepalived/chk_down.sh&quot; interval 2 ## 每2秒检测一次 weight 20 ## 默认是2. 当脚本执行码为0，权重大于0时，vrrp实例优先级增加；当脚本执行码为非0，权重小于0时，vrrp实例优先级减小，其他情况优先级不变。 fall 2 ## 检测两次都失败才失败 rise 1 ## 检测一次成功就成功 } 1234567cat &gt; /etc/keepalived/chk_down.sh &lt;&lt; EOF#!/bin/bash[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0EOFchmod u+x /etc/keepalived/chk_down.sh 同步组vrrp_sync_group G1 { group { VI_1 VI_2 VI_5 } notify_backup &quot;/usr/local/bin/vrrp.back arg1 arg2&quot; notify_master &quot;/usr/local/bin/vrrp.mast arg1 arg2&quot; notify_fault &quot;/usr/local/bin/vrrp.fault arg1 arg2&quot; } 虚拟ip配置 vrrp## 在主备节点设置优先级的时候，要确保当MASTER节点降级后的优先级要比BACKUP的优先级低，否则，VIP是无法进行漂移的。 ## 主备不同之处 1，router_id 不能一致 2，state MASTER/BACKUP 3, priority 权重不能一致 4, interface ens33 网络接口注意和本机对应 vrrp_instance VI_1 { ## 定义实例，用来定义对外提供服务的VIP区域及其相关属性。 state BACKUP ## 状态参数 MASTER|BACKUP interface ens33 ## 绑定VIP的网卡 virtual_router_id 50 ## 取值在0-255之间，用来区分多个instance的VRRP组播。主备此值要相同，同一个集群id一致，不同集群必须不一样。 priority 100 ## 节点优先级，值范围0～254，MASTER要比BACKUP高。抢占模式中，优先级高就切换为master。 advert_int 1 ## 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒 #garp_master_delay 10 ## 当切为主状态后多久更新ARP缓存，默认5秒。通知设备它现在控制新MAC地址的那些IP，覆盖他们的ARP缓存。 #garp_master_refresh 60 ## 单位秒，默认0，不再发送ARP。表示master每隔多久发送一次arp更新。 nopreempt ## 默认是抢占模式，要是用非抢占式的，master主机加上nopreempt，同时主备机器的state状态都必须是BACKUP。经测试使用此参数会导致主备不会自动切换，必须关闭keepalive才行。 smtp_alert ## 状态转换时，利用global里的邮件配置，发送邮件通知 authentication { ## 认证 auth_type PASS ## 认证方式 auth_pass 1111 ## 密码 } virtual_ipaddress { ## VIP会绑定在物理网卡，所以不需要新建一个网卡。 ## &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 200.200.200.240/24 dev ens33 ## 设备之间使用的虚拟ip地址 #192.168.200.17/24 dev ens33 label ens33:3 } ## mcast_src_ip &lt;IPADDR&gt; ## 指定多播源ip地址，用于多播 ## 配置单播 unicast_src_ip 200.200.200.212 ## 指定单播源ip地址，本机IP unicast_peer { 200.200.200.213 ## 对端IP地址,必须是绑定vip网卡上的ip，通过单播发送vrrp信息给对端 } track_interface { ## 监控以下网卡，如果任何一个不通就会切换到FALT状态。 ens33 } track_script { chk_haproxy chk_mantaince_down } #notify_master /home/keepshell/notify_master.sh ## 作用：当成为MASTER时，以指定的用户和组执行脚本。 #notify_backup /home/keepshell/notify_backup.sh ## 作用：当成为BACKUP时，以指定的用户和组执行脚本。 #notify_fault /home/keepshell/notify_fault.sh ## 作用：当该同步组Fault时，以指定的用户和组执行脚本。 #notify /home/keepshell/notify_stop.sh ## 作用：在任何状态都会以指定的用户和组执行脚本。最后执行。 } 配置说明全局定义模块! Configuration File for keepalived global_defs { notification_email { acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc #邮件报警 } notification_email_from Alexandre.Cassen@firewall.loc 指定发件人 smtp_server 192.168.200.1 #指定smtp服务器地址 smtp_connect_timeout 30 指定smtp连接超时时间 router_id LVS_DEVEL #负载均衡标识，在局域网内应该是唯一的。 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0 } 说明： notification_email：指定当keepalived出现问题时，发送邮件给哪些用户。 notification_emai_from：发送邮件时，邮件的来源地址。 smtp_server &lt;DOMAIN|IP&gt; [&lt;PORT&gt;]：smtp服务器的地址或域名。默认端口为25.如：smtp_server smtp.felix.com 25 smtp_helo_name &lt;HOST_NAME&gt;：指定在HELO消息中所使用的名称。默认为本地主机名。 smtp_connect_timeout：指定smtp服务器连接的超时时间。单位是秒。 router_id：指定标识该机器的route_id. 如：route_id LVS_01 vrrp_mcast_group4 224.0.0.18：指定发送VRRP组播消息使用的IPV4组播地址。默认是224.0.0.18 vrrp_mcast_group6 ff02::12 指定发送VRRP组播消息所使用的IPV6组播地址。默认是ff02::12 default_interface eth0：设置静态地址默认绑定的端口。默认是eth0。 lvs_sync_daemon &lt;INTERFACE&gt; &lt;VRRP_INSTANCE&gt; [id &lt;SYNC_ID&gt;] [maxlen &lt;LEN&gt;] [port &lt;PORT&gt;] [ttl &lt;TTL&gt;] [group &lt;IP ADDR&gt;] 设置LVS同步服务的相关内容。可以同步LVS的状态信息。 INTERFACE：指定同步服务绑定的接口。 VRRP_INSTANCE：指定同步服务绑定的VRRP实例。 id &lt;SYNC_ID&gt;：指定同步服务所使用的SYNCID，只有相同的SYNCID才会同步。范围是0-255. maxlen：指定数据包的最大长度。范围是1-65507 port：指定同步所使用的UDP端口。 group：指定组播IP地址。 lvs_flush： 在keepalived启动时，刷新所有已经存在的LVS配置。 vrrp_garp_master_delay 10： 当转换为MASTER状态时，延迟多少秒发送第二组的免费ARP。默认为5s，0表示不发送第二组免的免费ARP。 vrrp_garp_master_repeat 1： 当转换为MASTER状态时，在一组中一次发送的免费ARP数量。默认是5. vrrp_garp_lower_prio_delay 10： 当MASTER收到更低优先级的通告时，延迟多少秒发送第二组的免费ARP。 vrrp_garp_lower_prio_repeat 1： 当MASTER收到更低优先级的通告时，在一组中一次发送的免费ARP数量。 vrrp_garp_master_refresh 60： 当keepalived成为MASTER以后，刷新免费ARP的最小时间间隔(会再次发送免费ARP)。默认是0，表示不会刷新。 vrrp_garp_master_refresh_repeat 2： 当keepalived成为MASTER以后，每次刷新会发送多少个免费ARP。默认是1. vrrp_garp_interval 0.001： 在一个接口发送的两个免费ARP之间的延迟。可以精确到毫秒级。默认是0. vrrp_lower_prio_no_advert true|false：默认是false。如果收到低优先级的通告，不发送任何通告。 vrrp_version 2|3： 设置默认的VRRP版本。默认是2. vrrp_check_unicast_src： 在单播模式中，开启对VRRP数据包的源地址做检查，源地址必须是单播邻居之一。 vrrp_skip_check_adv_addr： 默认是不跳过检查。检查收到的VRRP通告中的所有地址可能会比较耗时，设置此命令的意思是，如果通告与接收的上一个通告来自相同的master路由器，则不执行检查(跳过检查)。 vrrp_strict： 严格遵守VRRP协议。 下列情况将会阻止启动Keepalived：1. 没有VIP地址。2. 单播邻居。3. 在VRRP版本2中有IPv6地址。 vrrp_iptables： 不添加任何iptables规则。默认是添加iptables规则的。 如果vrrp进程或check进程超时，可以用下面的4个选项。可以使处于BACKUP状态的VRRP实例变成MASTER状态，即使MASTER实例依然在运行。因为MASTER或BACKUP系统比较慢，不能及时处理VRRP数据包。 vrrp_priority &lt;-20 -- 19&gt;： 设置VRRP进程的优先级。 checker_priority &lt;-20 -- 19&gt;： 设置checker进程的优先级。 vrrp_no_swap： vrrp进程不能够被交换。 checker_no_swap： checker进程不能够被交换。 script_user &lt;username&gt; [groupname]：设置运行脚本默认用户和组。如果没有指定，则默认用户为keepalived_script(需要该用户存在)，否则为root用户。默认groupname同username。 enable_script_security： 如果脚本路径的任一部分对于非root用户来说，都具有可写权限，则不会以root身份运行脚本。 nopreempt 默认是抢占模式 要是用非抢占式的就加上nopreempt 注意：上述为global_defs中的指令 VRRPD配置VRRPD的配置包括如下子块： 1. vrrp_script 2. vrrp_sync_group 3. garp_group 4. vrrp_instance vrrp_script配置作用：添加一个周期性执行的脚本。脚本的退出状态码会被调用它的所有的VRRP Instance记录。 注意：至少有一个VRRP实例调用它并且优先级不能为0.优先级范围是1-254. vrrp_script &lt;SCRIPT_NAME&gt; { ... } 选项说明： scrip &quot;/path/to/somewhere&quot;：指定要执行的脚本的路径。 interval &lt;INTEGER&gt;：指定脚本执行的间隔。单位是秒。默认为1s。 timeout &lt;INTEGER&gt;：指定在多少秒后，脚本被认为执行失败。 weight &lt;-254 --- 254&gt;：调整优先级。默认为2. rise &lt;INTEGER&gt;：执行成功多少次才认为是成功。 fall &lt;INTEGER&gt;：执行失败多少次才认为失败。 user &lt;USERNAME&gt; [GROUPNAME]：运行脚本的用户和组。 init_fail：假设脚本初始状态是失败状态。 解释： weight： 1. 如果脚本执行成功(退出状态码为0)，weight大于0，则priority增加。 2. 如果脚本执行失败(退出状态码为非0)，weight小于0，则priority减少。 3. 其他情况下，priority不变。 vrrp_sync_group作用：将所有相关的VRRP实例定义在一起，作为一个VRRP Group，如果组内的任意一个实例出现问题，都可以实现Failover。 vrrp_sync_group VG_1 { group { inside_network # vrrp instance name outside_network # vrrp instance name ... } ... } 说明： 如果username和groupname没有指定，则以默认的script_user所指定的用户和组。 1. notify_master /path/to_master.sh [username [groupname]] 作用：当成为MASTER时，以指定的用户和组执行脚本。 2. notify_backup /path/to_backup.sh [username [groupname]] 作用：当成为BACKUP时，以指定的用户和组执行脚本。 3. notify_fault &quot;/path/fault.sh VG_1&quot; [username [groupname]] 作用：当该同步组Fault时，以指定的用户和组执行脚本。 4. notify /path/notify.sh [username [groupname]] 作用：在任何状态都会以指定的用户和组执行脚本。 说明：该脚本会在notify_*脚本后执行。 notify可以使用3个参数，如下： $1：可以是GROUP或INTANCE，表明后面是组还是实例。 $2：组名或实例名。 $3：转换后的目标状态。有：MASTER、BACKUP、FAULT。 5. smtp_alert：当状态发生改变时，发送邮件。 6. global_tracking：所有的VRRP实例共享相同的tracking配置。 注意：脚本文件要加上x权限，同时指令最好写绝对路径。 vrrp_instance命令说明： state MASTER|BACKUP：指定该keepalived节点的初始状态。 interface eth0：vrrp实例绑定的接口，用于发送VRRP包。 use_vmac [&lt;VMAC_INTERFACE&gt;]：在指定的接口产生一个子接口，如vrrp.51，该接口的MAC地址为组播地址，通过该接口向外发送和接收VRRP包。 vmac_xmit_base：通过基本接口向外发送和接收VRRP数据包，而不是通过VMAC接口。 native_ipv6：强制VRRP实例使用IPV6.(当同时配置了IPV4和IPV6的时候) dont_track_primary：忽略VRRP接口的错误，默认是没有配置的。 track_interface { eth0 eth1 weight &lt;-254-254&gt; ... }：如果track的接口有任何一个出现故障，都会进入FAULT状态。 track_script { &lt;SCRIPT_NAME&gt; &lt;SCRIPT_NAME&gt; weight &lt;-254-254&gt; }：添加一个track脚本(vrrp_script配置的脚本。) mcast_src_ip &lt;IPADDR&gt;：指定发送组播数据包的源IP地址。默认是绑定VRRP实例的接口的主IP地址。 unicast_src_ip &lt;IPADDR&gt;：指定发送单薄数据包的源IP地址。默认是绑定VRRP实例的接口的主IP地址。 version 2|3：指定该实例所使用的VRRP版本。 unicast_peer { &lt;IPADDR&gt; ... }：采用单播的方式发送VRRP通告，指定单播邻居的IP地址。 virtual_router_id 51：指定VRRP实例ID，范围是0-255. priority 100：指定优先级，优先级高的将成为MASTER。 advert_int 1：指定发送VRRP通告的间隔。单位是秒。 authentication { auth_type PASS|AH：指定认证方式。PASS简单密码认证(推荐),AH:IPSEC认证(不推荐)。 auth_pass 1234：指定认证所使用的密码。最多8位。 } virtual_ipaddress { &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 192.168.200.17/24 dev eth1 192.168.200.18/24 dev eth2 label eth2:1 }：指定VIP地址。 nopreempt：设置为不抢占。默认是抢占的，当高优先级的机器恢复后，会抢占低优先级的机器成为MASTER，而不抢占，则允许低优先级的机器继续成为MASTER，即使高优先级的机器已经上线。如果要使用这个功能，则初始化状态必须为BACKUP。 preempt_delay：设置抢占延迟。单位是秒，范围是0---1000，默认是0.发现低优先级的MASTER后多少秒开始抢占。 通知脚本： notify_master &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]] notify_backup &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]] notify_fault &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]] notify &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]] # 当停止VRRP时执行的脚本。 notify_stop &lt;STRING&gt;|&lt;QUOTED-STRING&gt; [username [groupname]] smtp_alert LVS配置virtual_servervirtual_server IP Port | virtual_server fwmark int | virtual_server group string { delay_loop &lt;INT&gt;：健康检查的时间间隔。 lb_argo rr|wrr|lc|wlc|lblc|sh|dh：LVS调度算法。 lb_kind NAT|DR|TUN：LVS模式。 persistence_timeout 360：持久化超时时间，单位是秒。默认是6分钟。 persistence_granularity：持久化连接的颗粒度。 protocol TCP|UDP|SCTP：4层协议。 ha_suspend：如果virtual server的IP地址没有设置，则不进行后端服务器的健康检查。 virtualhost &lt;STRING&gt;：为HTTP_GET和SSL_GET执行要检查的虚拟主机。如virtualhost www.felix.com sorry_server &lt;IPADDR&gt; &lt;PORT&gt;：添加一个备用服务器。当所有的RS都故障时。 sorry_server_inhibit：将inhibit_on_failure指令应用于sorry_server指令。 alpha：在keepalived启动时，假设所有的RS都是down，以及健康检查是失败的。有助于防止启动时的误报。默认是禁用的。 omega：在keepalived终止时，会执行quorum_down指令所定义的脚本。 quorum &lt;INT&gt;：默认值1. 所有的存活的服务器的总的最小权重。 quorum_up &lt;STRING&gt;：当quorum增长到满足quorum所定义的值时，执行该脚本。 quorum_down &lt;STRING&gt;：当quorum减少到不满足quorum所定义的值时，执行该脚本。 } real_serverreal_server IP Port { weight &lt;INT&gt;：给服务器指定权重。默认是1. inhibit_on_failure：当服务器健康检查失败时，将其weight设置为0，而不是从Virtual Server中移除。 notify_up &lt;STRING&gt;：当服务器健康检查成功时，执行的脚本。 notify_down &lt;STRING&gt;：当服务器健康检查失败时，执行的脚本。 uthreshold &lt;INT&gt;：到这台服务器的最大连接数。 lthreshold &lt;INT&gt;：到这台服务器的最小连接数。 } real_server中的健康检查HTTP_GET | SSL_GET { url { path &lt;STRING&gt;：指定要检查的URL的路径。如path / or path /mrtg2 digest &lt;STRING&gt;：摘要。计算方式：genhash -s 172.17.100.1 -p 80 -u /index.html status_code &lt;INT&gt;：状态码。 } nb_get_retry &lt;INT&gt;：get尝试次数。 delay_before_retry &lt;INT&gt;：在尝试之前延迟多长时间。 connect_ip &lt;IP ADDRESS&gt;：连接的IP地址。默认是real server的ip地址。 connect_port &lt;PORT&gt;：连接的端口。默认是real server的端口。 bindto &lt;IP ADDRESS&gt;：发起连接的接口的地址。 bind_port &lt;PORT&gt;：发起连接的源端口。 connect_timeout &lt;INT&gt;：连接超时时间。默认是5s。 fwmark &lt;INTEGER&gt;：使用fwmark对所有出去的检查数据包进行标记。 warmup &lt;INT&gt;：指定一个随机延迟，最大为N秒。可防止网络阻塞。如果为0，则关闭该功能。 } TCP_CHECK { connect_ip &lt;IP ADDRESS&gt;：连接的IP地址。默认是real server的ip地址。 connect_port &lt;PORT&gt;：连接的端口。默认是real server的端口。 bindto &lt;IP ADDRESS&gt;：发起连接的接口的地址。 bind_port &lt;PORT&gt;：发起连接的源端口。 connect_timeout &lt;INT&gt;：连接超时时间。默认是5s。 fwmark &lt;INTEGER&gt;：使用fwmark对所有出去的检查数据包进行标记。 warmup &lt;INT&gt;：指定一个随机延迟，最大为N秒。可防止网络阻塞。如果为0，则关闭该功能。 retry &lt;INIT&gt;：重试次数。默认是1次。 delay_before_retry &lt;INT&gt;：默认是1秒。在重试之前延迟多少秒。 } SMTP_CHECK { connect_ip &lt;IP ADDRESS&gt;：连接的IP地址。默认是real server的ip地址。 connect_port &lt;PORT&gt;：连接的端口。默认是real server的端口。 默认是25端口 bindto &lt;IP ADDRESS&gt;：发起连接的接口的地址。 bind_port &lt;PORT&gt;：发起连接的源端口。 connect_timeout &lt;INT&gt;：连接超时时间。默认是5s。 fwmark &lt;INTEGER&gt;：使用fwmark对所有出去的检查数据包进行标记。 warmup &lt;INT&gt;：指定一个随机延迟，最大为N秒。可防止网络阻塞。如果为0，则关闭该功能。 retry &lt;INT&gt;：重试次数。 delay_before_retry &lt;INT&gt;：在重试之前延迟多少秒。 helo_name &lt;STRING&gt;：用于SMTP HELO请求的字符串。 } DNS_CHECK { connect_ip &lt;IP ADDRESS&gt;：连接的IP地址。默认是real server的ip地址。 connect_port &lt;PORT&gt;：连接的端口。默认是real server的端口。 默认是25端口 bindto &lt;IP ADDRESS&gt;：发起连接的接口的地址。 bind_port &lt;PORT&gt;：发起连接的源端口。 connect_timeout &lt;INT&gt;：连接超时时间。默认是5s。 fwmark &lt;INTEGER&gt;：使用fwmark对所有出去的检查数据包进行标记。 warmup &lt;INT&gt;：指定一个随机延迟，最大为N秒。可防止网络阻塞。如果为0，则关闭该功能。 retry &lt;INT&gt;：重试次数。默认是3次。 type &lt;STRING&gt;：DNS query type。A/NS/CNAME/SOA/MX/TXT/AAAA name &lt;STRING&gt;：DNS查询的域名。默认是(.) } MISC_CHECK { misc_path &lt;STRING&gt;：外部的脚本或程序路径。 misc_timeout &lt;INT&gt;：脚本执行超时时间。 user USERNAME [GROUPNAME]：指定运行该脚本的用户和组。如果没有指定GROUPNAME，则GROUPNAME同USERNAME。 misc_dynamic：根据退出状态码动态调整权重。 0，健康检查成功，权重不变。 1，健康检查失败。 2-255，健康检查成功。权重设置为退出状态码减去2.如退出状态码是250，则权重调整为248 warmup &lt;INT&gt;：指定一个随机延迟，最大为N秒。可防止网络阻塞。如果为0，则关闭该功能。 } 实例global_defs { router_id LVS_Server 指定标识该机器的route_id } vrrp_instance VI_1 { state MASTER 指定该keepalived节点的初始状态 interface ens8 vrrp实例绑定的接口，用于发送VRRP包 virtual_router_id 51 指定VRRP实例ID priority 150 指定优先级，优先级高的将成为MASTER nopreempt 设置为不抢占。默认是抢占的 advert_int 1 advert_int 1 authentication { auth_type PASS 指定认证方式 auth_pass password 指定认证所使用的密码。 } virtual_ipaddress { 192.168.1.217 dev ens8 指定VIP地址 } } virtual_server 192.168.1.217 443 { delay_loop 3 delay_loop lvs_sched rr LVS的调度算法 lvs_method DR LVS 模式 protocol TCP 4层协议 real_server 192.168.1.211 443 { weight 1 TCP_CHECK { connect_port 443 connect_timeout 3 nb_get_retry 3 get尝试次数 delay_before_retry 10 在尝试之前延迟多长时间 } } real_server 192.168.1.212 443 { weight 1 TCP_CHECK { connect_port 443 connect_timeout 3 nb_get_retry 3 delay_before_retry 10 } } } virtual_server 192.168.1.217 80 { delay_loop 3 lvs_sched rr lvs_method DR protocol TCP real_server 192.168.1.211 80 { weight 1 TCP_CHECK { connect_port 80 connect_timeout 3 nb_get_retry 3 delay_before_retry 10 } } } real_server 192.168.1.212 80 { weight 1 调整优先级。默认为2 TCP_CHECK { connect_port 80 连接的端口 connect_timeout 3 连接超时时间。默认是5s。 nb_get_retry 3 get尝试次数。 delay_before_retry 10 } } } redis 检测脚本check_redis.sh脚本: #!/bin/sh CHECK_PROCESS=`ps -C redis-server --no-heading| wc -l` if [ $CHECK_PROCESS -eq 0 ];then echo &quot;Redis is stop&quot; sleep 2 CHECK_PROCESS=`ps -C redis-server --no-heading| wc -l` if [ $CHECK_PROCESS -eq 0 ];then /etc/init.d/keepalived stop fi fi check_port.sh脚本 #!/bin/bash #keepalived 监控端口脚本 #使用方法： #在keepalived的配置文件中 #vrrp_script check_port CHK_PORT=$1 echo $CHK_PORT if [ &quot;$CHK_PORT&quot; != &quot;&quot; ];then PORT_PROCESS=`lsof -i:$CHK_PORT|wc -l` if [ $PORT_PROCESS -eq 0 ];then echo &quot;Port $CHK_PORT Is Not Used,End.&quot; sleep 2 PORT_PROCESS=`lsof -i:$CHK_PORT|wc -l` if [ $PORT_PROCESS -eq 0 ];then /etc/init.d/keepalived stop fi fi else echo &quot;Check Port Cant Be Empty!&quot; fi 进程检测脚本# vi /etc/keepalived/chk_app.sh #!/bin/sh num=`ps -C nginx --no-header |wc -l` if [ $num -eq 0 ];then systmectl restart nginx sleep 3 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then systmectl stop keepalived fi fi vrrp_vmac用法：https://github.com/acassen/keepalived/blob/master/doc/NOTE_vrrp_vmac.txt]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install Oracle Database 12c on centos 7]]></title>
    <url>%2Foracle%2FOracle%20Database%2012c%2C%20install%20on%20centos%207%2F</url>
    <content type="text"><![CDATA[下载地址：oracle: http://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html sql developer http://www.oracle.com/technetwork/developer-tools/sql-developer/downloads/index.html PL/SQL Developer http://files.allroundautomations.com/plsqldev1207x64.msi ## 通过wget下载，首先需要用chrome 登陆下载Oracle安装包，然后通过chrome查看下载内容获取下载连接地址, 这个地址包含AuthParam，这个值是变的 ## Oracle Database 12c Release 2 (12.2.0.1.0) for Linux x86-64 (cksum - 4170261901) wget &quot;http://download.oracle.com/otn/linux/oracle12c/122010/linuxx64_12201_database.zip?AuthParam=1531550179_0b36f7a93d74a319d16d912549e8f200&quot; -O linuxx64_12201_database.zip ## 或者 wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn/linux/oracle12c/122010/linuxx64_12201_database.zip?AuthParam=1531550179_0b36f7a93d74a319d16d912549e8f200&quot; ## Oracle Database 12c Release 2 Grid Infrastructure (12.2.0.1.0) for Linux x86-64 (cksum - 1523222538) wget &quot;http://download.oracle.com/otn/linux/oracle12c/122010/linuxx64_12201_gsm.zip?AuthParam=1531550996_aafa7bf31f418173242a4d5220592b4b&quot; ## Oracle Database Gateways 12c Release 2 (12.2.0.1.0) for Linux x86-64 (cksum - 2671223080) wget &quot;http://download.oracle.com/otn/linux/oracle12c/122010/linuxx64_12201_gateways.zip?AuthParam=1531551201_626b9d693e0e19eaa903a50d34774984&quot; ## Oracle Database 12c Release 2 Examples (12.2.0.1.0) for Linux x86-64 wget &quot;http://download.oracle.com/otn/linux/oracle12c/122010/linuxx64_12201_examples.zip?AuthParam=1531551390_b6f3aa6b20993c7afabe834d72459cc9&quot; ## 解压 yum install -y zip unzip mkdir /data/install unzip linuxx64_12201_database.zip -d /data/install/ 官方帮助文档http://www.oracle.com/technetwork/database/enterprise-edition/documentation/index.html 配置计算机名，添加host解析hostnamectl set-hostname db.test.com cat /etc/hostname db.test.com sestatus echo &quot;127.0.0.1 db.test.com&quot; &gt;&gt; /etc/hosts echo &quot;200.200.200.50 db.test.com&quot; &gt;&gt; /etc/hosts ## 关闭防火墙和selinux , 否则安装会有问题 防火墙firewall-cmd --get-active-zones firewall-cmd --zone=public --add-port={1521/tcp,5500/tcp,5520/tcp,3938/tcp --permanent firewall-cmd --reload firewall-cmd --list-ports 安装环境## 安装需要的包12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849yum -y install binutils compat-libcap1 compat-libstdc++-33 gcc gcc-c++ \glibc glibc-devel ksh libaio libaio-devel libgcc libstdc++ \libstdc++-devel libXext libXtst libX11 libXau libXi make sysstat## 或者yum install -y binutils \compat-libcap1 \compat-libstdc++-33 \compat-libstdc++-33.i686 \glibc \glibc.i686 \glibc-devel \glibc-devel.i686 \gcc \gcc-c++ \ksh \libaio \libaio.i686 \libaio-devel \libaio-devel.i686 \libX11 \libX11.i686 \libXau \libXau.i686 \libXi \libXi.i686 \libXtst \libXtst.i686 \libgcc \libgcc.i686 \libstdc++ \libstdc++.i686 \libstdc++-devel \libstdc++-devel.i686 \libXext \libXext.i686 \make \sysstat \libxcb \libxcb.i686 \unixODBC \unixODBC-devel \zlib-devel \zlib-devel.i686 \nfs-utils \net-tools \smartmontools ## 安装sqlplus wrapb包，方便光标移动（上下键，退格键）12345678yum install rlwrapcat &gt; /home/oracle/.bash_profile &lt;&lt; EOFalias sqlplus='rlwrap sqlplus'alias rman='rlwrap rman'EOF 查看CentOS自带JDK是否已安装。命令：yum list installed |grep java若有自带安装的JDK，如何卸载CentOS系统自带Java环境？ 卸载JDK相关文件输入：yum -y remove java-1.7.0-openjdk* 卸载tzdata-java输入：yum -y remove tzdata-java.noarch 查看yum库中的Java安装包 命令：yum -y list java* 添加oracle用户groupadd -g 54321 oinstall groupadd -g 54322 dba # 数据库管理员 groupadd -g 54323 oper # 数据库操作员 groupadd -g 54324 backupdba # 数据备份恢复管理员 groupadd -g 54325 dgdba # 数据库卫士 groupadd -g 54326 kmdba # 加密密钥管理员 groupadd -g 54327 asmdba groupadd -g 54328 asmoper groupadd -g 54329 asmadmin groupadd -g 54330 racdba useradd -u 54321 -g oinstall -G dba,oper,backupdba,dgdba,kmdba,racdba,asmdba,asmoper,asmadmin oracle passwd oracle 修改内核参数## 查看系统信息 ## 默认分页大小 getconf PAGESIZE 4096 sysctl -a | grep sem kernel.sem = 250 32000 32 128 kernel.sem_next_id = -1 sysctl -a | grep shm kernel.shm_next_id = -1 kernel.shm_rmid_forced = 0 kernel.shmall = 18446744073692774399 kernel.shmmax = 18446744073692774399 kernel.shmmni = 4096 vm.hugetlb_shm_group = 0 sysctl -a | grep file-max fs.file-max = 96145 sysctl -a | grep ip_local_port_range net.ipv4.ip_local_port_range = 32768 60999 ## 修改内核参数 123456789101112131415161718192021222324cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOFfs.aio-max-nr = 1048576fs.file-max = 6815744## 4G, 大概使用系统内存的一半kernel.shmmax = 4294967296## kernel.shmmax/PAGESIZEkernel.shmall = 1048576## getconf PAGESIZEkernel.shmmni = 4096kernel.sem = 250 32000 100 128net.ipv4.ip_local_port_range = 9000 65500net.core.rmem_default = 262144net.core.rmem_max = 4194304net.core.wmem_default = 262144net.core.wmem_max = 1048586vm.hugetlb_shm_group = 54322EOF ## 使之生效 sysctl -p shmmax - Half the server memory shmmni - 4096 (or greater) fs.file-max - 6815744 (or greater) fs.aio-max-nr - 1048576 (or greater) net.core.rmem_default - 262144 (or greater) net.core.rmem_max - 4194304 or greater) net.core.wmem_default - 262144 (or greater) net.core.wmem_max - 1048576 (or greater) sem - 250 32000 100 128 (or greater) net.ipv4.ip_local_port_range - 9000 65535 注： vm.hugetlb_shm_group 与 dba 组id一致，hugetlb_shm_group contains group id that is allowed to create SysV shared memory segment using hugetlb page sem 4个参数依次为SEMMSL(每个用户拥有信号量最大数)； SEMMNS(系统信号量最大数)； SEMOPM(每次semopm系统调用操作数)； SEMMNI(系统辛苦量集数最大数)。 Shmmax 最大共享内存2GB, 物理内存如果小的话可以设置成512M, 即: 536870912。 Shmmni 最小共享内存 4096KB。 Shmall 所有内存大小。shmall 的大小为 kernel.shmmax/4096(getconf PAGESIZE可得到)= 3774873 一般情况下可以设置最大共享内存为物理内存的一半，如果物理内存是 2G，则可以设置最大共享内存为 1073741824，如上；如物理内存是 1G，则可以设置最大共享内存为 512 * 1024 * 1024 = 536870912；以此类推。 在redhat上最大共享内存不建议超过 4*1024*1024*1024-1=4294967295 设置完成后用命令 more /etc/sysctl.conf |grep kernel.s 检查。 kernel.shmall: 共享内存页数的最大值 Linux共享内存页大小为4KB， 共享内存段的大小都是共享内存页大小的整数倍。一个共享内存段的最大大小是16G，需要共享内存页数是 16GB/4KB=16777216KB/4KB=4194304(页) kernel.shmmax:单个共享内存段的最大值 shmmax是核心参数中最重要的参数之一，用于定义单个共享内存段的最大值，shmmax设置应足够大，能在一个共享内存段下容纳下整个的SGA，设置的过低可能会导致需要创建多个共享内存段，可能导致系统性能的下降 。 kernel.shmmni:共享内存段的最大数量 注意该参数不是shmmin，是shmmni，shmmin 表示内存段最小大小 ） shmmni缺省值4096 足够。 shmmax(bytes) = shmmni(page size, default 4k) * shmall (page的个数） 下面专门说说kernel.sem：对应4个值 SEMMSL、SEMMNS、SEMOPM、SEMMNI SEMMSL: 每个信号集的最大信号数量 数据库最大 PROCESS 实例参数的设置值再加上 10 。 Oracle 建议将 SEMMSL 的值设置为不少于 100 。 SEMMNS：用于控制整个 Linux 系统中信号（而不是信号集）的最大数。 Oracle 建议将 SEMMNS 设置为：系统中每个数据库的 PROCESSES 实例参数设置值的总和，加上最大 PROCESSES 值的两倍，最后根据系统中 Oracle 数据库的数量，每个加 10 。 使用以下计算式来确定在 Linux 系统中可以分配的信号的最大数量。它将是以下两者中较小的一个值：SEMMNS 或 (SEMMSL * SEMMNI) SEMOPM： 内核参数用于控制每个 semop 系统调用可以执行的信号操作的数量。semop 系统调用（函数）提供了利用一个 semop 系统调用完成多项信号操作的功能。一个信号集能够拥有每个信号集中最大数量的SEMMSL 信号，因此建议设置 SEMOPM 等于SEMMSL 。 Oracle 建议将 SEMOPM 的值设置为不少于 100 。 SEMMNI ：内核参数用于控制整个 Linux 系统中信号集的最大数量。 Oracle 建议将 SEMMNI 的值设置为不少于 100 。 ## 设置oracle 用户限制，改文件限制：vilink12345678910111213cat &gt;&gt; /etc/security/limits.conf &lt;&lt; EOForacle soft nproc 16384oracle hard nproc 16384oracle soft nofile 20480oracle hard nofile 65536oracle soft stack 10240oracle hard stack 32768oracle hard memlock 134217728oracle soft memlock 134217728EOF 123456cat &gt;&gt; /etc/pam.d/login &lt;&lt; EOF#session required /lib64/security/pam_limits.sosession required pam_limits.soEOF 修改ulimit：vi /etc/profile，添加： if [ $USER = &quot;oracle&quot; ]; then if [ $SHELL = &quot;/bin/ksh&quot; ]; then ulimit -u 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fi fi 修改环境变量12345678910111213141516171819202122232425cat &gt;&gt; /home/oracle/.bash_profile &lt;&lt; EOFexport TMP=/tmpexport TMPDIR=\$TMPORACLE_HOSTNAME=db.test.com ORACLE_UNQNAME=orcl ORACLE_BASE=/data/oracleORACLE_HOME=\$ORACLE_BASE/product/db12cORACLE_SID=orclexport ORACLE_BASE ORACLE_HOME ORACLE_SIDPATH=\$ORACLE_HOME/bin:\$PATHexport PATHexport LD_LIBRARY_PATH=\$ORACLE_HOME/lib:/lib:/usr/lib export CLASSPATH=\$ORACLE_HOME/jlib:\$ORACLE_HOME/rdbms/jlib alias cdob='cd $ORACLE_BASE'alias cdoh='cd $ORACLE_HOME'alias tns='cd $ORACLE_HOME/network/admin'alias envo='env | grep ORACLE'umask 022EOF 准备安装目录# oracle/oraInventory是存放oracle 安装日志和脚本的临时目录 # oracle/product/db12c是Oracle 软件二进制程序安装保存路径 # oracle/flush_recovery_area 数据恢复目录 # oradata 存放数据库文件 mkdir -p /data/oracle/{oradata,product/db12c,flush_recovery_area,oraInventory} chown -R oracle:oinstall /data/oracle chmod -R 775 /data/oracle 准备安装应答文件db_install.rsp - 用于安装oracle二进制文件，以静默方式安装/升级数据库 dbca.rsp - 用于以静默方式安装/配置/删除数据库 netca.rsp - 用于在静默模式下为oracle数据库配置简单网络 应答文件配置在本文后面 以oracle用户登录，开始安装：su oracle cd /opt/oracle unzip linuxx64_12201_database.zip export LANG=&quot;en_US&quot; ## 安装，如果提示系统符合安装要求，可以添加-ignoreSysPreReqs ./runInstaller -force -silent -noconfig -responseFile /data/oracle/db_install.rsp ## -silent 表示以静默方式安装,不会有任何提示 ## -force 允许安装到一个非空目录 ## -noconfig 表示不运行配置助手netca ## -responseFile 表示使用哪个响应文件,必需使用绝对路径 ## 安装成功后，以 root 用户的身份执行以下脚本: exist /data/oracle/oraInventory/orainstRoot.sh /data/oracle/product/db12c/root.sh 创建数据库## 使用应答文件创建数据 ## 应答文件(dbca.rsp)配置在本文后面 dbca -silent -createDatabase -responseFile /data/oracle/dbca.rsp ## 通过命令行创建数据库 ## 创建一个数据库 testdb ，所有管理员密码都为welcome 12345678910111213141516171819dbca -silent \-createDatabase \-templateName General_Purpose.dbc \-gdbName db.test.com \-sid orcl \-createAsContainerDatabase true \-numberOfPdbs 1 \-pdbName testdb \-pdbadminUsername pdba \-pdbadminPassword lion.net \-SysPassword lion.net \-SystemPassword lion.net \-emConfiguration NONE \-recoveryAreaDestination $ORACLE_BASE/flush_recovery_area \-characterSet "AL32UTF8" \-nationalCharacterSet "AL16UTF16" \-enableArchive true \-redoLogFileSize 100 ## 登陆数据库，查看一下数据库实例的状态： ## 以 DBA 身份进入 sqlplus $ sqlplus / as sysdba SQL&gt; select instance_name, status from v$instance; SQL&gt; show pdbs SQL&gt; select name from v$datafile; SQL&gt; select name from v$controlfile; SQL&gt; select member from v$logfile; ## 错误排查： 安装数据库实例的时候日志文件中显示的错误内容： ORA-27104: system-defined limits for shared memory was misconfigured 解决方案：修改/etc/sysctl.conf中kernel.shmall的值为536870912。 在服务器上使用sqlplus访问数据库，中文不能正常显示（显示问号） 解决方案：导出环境变量export NLS_LANG=&quot;AMERICAN_AMERICA.AL32UTF8&quot; 配置监听## 以静默方式配置监听 netca -silent -responsefile /data/oracle/netca.rsp ## 启动命令 /data/oracle/product/db12c/bin/lsnrctl start LISTENER ## 查看监听状态 lsnrctl status 启动数据库## 启动过程，先启动监听，验证数据库管理员身份后，才能启动数据库 su - oracle ## 切换到 oracle 用户且切换到它的环境 lsnrctl status ## 查看监听及数据库状态 lsnrctl start ## 启动监听 sqlplus / as sysdba ## 以 DBA 身份进入 sqlplus SQL&gt;startup ## 启动 db ## 停止 su - oracle ## 切换到 oracle 用户且切换到它的环境 lsnrctl stop ## 停止监听 sqlplus / as sysdba ## 以 DBA 身份进入 sqlplus SQL&gt;SHUTDOWN IMMEDIATE ## 关闭 db ## 运行startup, 遇到的问题 LRM-00109: could not open parameter file &apos;/data/oracle/product/db12c/dbs/initorcl.ora ## 解决方法 cp /data/oracle/product/db12c/dbs/init.ora /data/oracle/product/db12c/dbs/initorcl.ora oracle 三种身份验证：系统验证（默认首先采用的身份验证，如果当前用户是oracle管理员，就直接登陆，不需要再验证用户和密码） 密码文件验证（验证oracle管理员) 数据库验证（验证普通用户） sqlplus登陆方式sqlplus有几种登陆方式 比如： &gt; sqlplus &quot;/as sysdba&quot; --以操作系统权限认证的oracle sys管理员登陆 &gt; sqlplus /nolog --不在cmd或者terminal当中暴露密码的登陆方式 SQL&gt; conn /as sysdba &amp; SQL&gt; conn sys/password as sysdba &gt; sqlplus scott/tiger --非管理员用户登陆 &gt; sqlplus scott/tiger@orcl --非管理员用户使用tns别名登陆 &gt; sqlplus sys/password@orcl as sysdba --管理员用户使用tns别名登陆 &gt; sqlplus --不显露密码的登陆方式 Enter user-name：sys Enter password：password as sysdba --以sys用户登陆的话 必须要加上 as sysdba 子句 创建数据库的应答文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758cat &gt; /data/oracle/dbca.rsp &lt;&lt; EOF## global database nameGDBNAME = "db.test.com"## instance database nameSID = "orcl"CREATEASCONTAINERDATABASE = trueNUMBEROFPDBS = 1PDBNAME = testdbPDBADMINUSERNAME = "testuser"PDBADMINPASSWORD = "lion.net"## template name used to create databaseTEMPLATENAME = "General_Purpose.dbc"## password for user sys,system,SYSPASSWORD = "lion.net"SYSTEMPASSWORD = "lion.net"## configure dbexpress with port 5500EMCONFIGURATION = "DBEXPRESS"EMEXPRESSPORT = "5500"## password for dbsnmp user and sysman userSYSMANPASSWORD = "lion.net"DBSNMPPASSWORD = "lion.net"## default directory for oracle database datafilesDATAFILEDESTINATION = /data/oracle/oradata## default directory for flashback dataRECOVERYAREADESTINATION = /data/oracle/flush_recovery_area## storage used for database installation## FS - OS filesystemSTORAGETYPE = FS## database character setCHARACTERSET = "AL32UTF8"## national database character setNATIONALCHARACTERSET = "AL16UTF16"## listener name to register database toLISTENERS = "LISTENER"## specify database type## has influence on some instance parametersDATABASETYPE = "OLTP"## AUTOMATICMEMORYMANAGEMENT = "TRUE"TOTALMEMORY = "512"EOF 监听配置文件1234567891011121314151617181920cat &gt; /data/oracle/netca.rsp &lt;&lt; EOF[GENERAL]RESPONSEFILE_VERSION="12.2"CREATE_TYPE="CUSTOM"SHOW_GUI=false[oracle.net.ca]INSTALLED_COMPONENTS=&#123;"server","net8","javavm"&#125;INSTALL_TYPE=""typical""LISTENER_NUMBER=1LISTENER_NAMES=&#123;"LISTENER"&#125;LISTENER_PROTOCOLS=&#123;"TCP;1521"&#125;LISTENER_START=""LISTENER""NAMING_METHODS=&#123;"TNSNAMES","ONAMES","HOSTNAME"&#125;NSN_NUMBER=1NSN_NAMES=&#123;"EXTPROC_CONNECTION_DATA"&#125;NSN_SERVICE=&#123;"PLSExtProc"&#125;NSN_PROTOCOLS=&#123;"TCP;HOSTNAME;1521"&#125;EOF 重启时自动启动数据库 以root用户，修改/etc/oratab的最后一行，将N改成Y，保证数据库在系统重启之后自动启动。 # vi /etc/oratab orcl:/data/oracle/product/db12c:Y 创建自启动脚本/etc/init.d/dbora # vi /etc/init.d/dbora ORA_HOME=/data/oracle/product/db12c ORA_OWNER=oracle case &quot;$1&quot; in &apos;start&apos;) # Start the Oracle databases: # The following command assumes that the oracle login # will not prompt the user for any values # Remove &quot;&amp;&quot; if you don&apos;t want startup as a background process. su - $ORA_OWNER -c &quot;$ORA_HOME/bin/dbstart $ORA_HOME&quot; &amp; touch /var/lock/subsys/dbora ;; &apos;stop&apos;) # Stop the Oracle databases: # The following command assumes that the oracle login # will not prompt the user for any values su - $ORA_OWNER -c &quot;$ORA_HOME/bin/dbshut $ORA_HOME&quot; &amp; rm -f /var/lock/subsys/dbora ;; esac # EM express 开启 $ sqlplus / as sysdba SQL&gt; show parameter dispatchers SQL&gt; exec DBMS_XDB_CONFIG.setHTTPPort(5500); # web 访问管理界面 http://200.200.200.50:5500/em 注意，登录的时候使用用户名sys，密码welcome，不指定容器名，并选择以sysdba身份登录。 http://xintq.net/2017/04/18/install-db12c-ol73/#%E9%87%8D%E5%90%AF%E6%97%B6%E8%87%AA%E5%8A%A8%E5%90%AF%E5%8A%A8%E6%95%B0%E6%8D%AE%E5%BA%93 静默安装应答文件## 复制oracle 安装目录下的db_install.rsp cp ./database/response/db_install.rsp ./db_install.rsp ## 简单配置 oracle.install.responseFileVersion=/oracle/install/rspfmt_dbinstall_response_schema_v12.2.0 oracle.install.option=INSTALL_DB_SWONLY ORACLE_HOSTNAME=db.test.com UNIX_GROUP_NAME=oinstall INVENTORY_LOCATION=/data/oracle/oraInventory SELECTED_LANGUAGES=en,zh_CN ORACLE_HOME=/data/oracle/product/db12c ORACLE_BASE=/data/oracle oracle.install.db.InstallEdition=EE oracle.install.db.OSDBA_GROUP=dba oracle.install.db.OSOPER_GROUP=oper oracle.install.db.OSBACKUPDBA_GROUP=backupdba oracle.install.db.OSDGDBA_GROUP=dgdba oracle.install.db.OSKMDBA_GROUP=kmdba oracle.install.db.OSRACDBA_GROUP=racdba oracle.install.db.config.starterdb.globalDBName=db.test.com oracle.install.db.config.starterdb.SID=orc1 oracle.install.db.config.starterdb.characterSet=AL32UTF8 oracle.install.db.config.starterdb.memoryOption=true oracle.install.db.config.starterdb.memoryLimit=1024 oracle.install.db.config.starterdb.installExampleSchemas=false oracle.install.db.config.starterdb.password.ALL=lion.net SECURITY_UPDATES_VIA_MYORACLESUPPORT=false DECLINE_SECURITY_UPDATES=true ## 详细配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455cat &gt; /data/oracle/db_install.rsp &lt;&lt; EOF###################################################################### Copyright(c) Oracle Corporation 1998,2017. All rights reserved.#### #### Specify values for the variables listed below to customize #### your installation. #### #### Each variable is associated with a comment. The comment #### can help to populate the variables with the appropriate #### values. #### #### IMPORTANT NOTE: This file contains plain text passwords and #### should be secured to have read permission only by oracle user #### or db administrator who owns this installation. #### #######################################################################-------------------------------------------------------------------------------# Do not change the following system generated value. #-------------------------------------------------------------------------------oracle.install.responseFileVersion=/oracle/install/rspfmt_dbinstall_response_schema_v12.2.0#-------------------------------------------------------------------------------# Specify the installation option.# It can be one of the following:# - INSTALL_DB_SWONLY# - INSTALL_DB_AND_CONFIG# - UPGRADE_DB#-------------------------------------------------------------------------------oracle.install.option=INSTALL_DB_SWONLY#-------------------------------------------------------------------------------# Specify the Unix group to be set for the inventory directory. #-------------------------------------------------------------------------------UNIX_GROUP_NAME=oinstall#-------------------------------------------------------------------------------# Specify the location which holds the inventory files.# This is an optional parameter if installing on# Windows based Operating System.#-------------------------------------------------------------------------------INVENTORY_LOCATION=/data/oracle/oraInventory#-------------------------------------------------------------------------------# Specify the complete path of the Oracle Home. #-------------------------------------------------------------------------------ORACLE_HOME=/data/oracle/product/db12c#-------------------------------------------------------------------------------# Specify the complete path of the Oracle Base. #-------------------------------------------------------------------------------ORACLE_BASE=/data/oracle#-------------------------------------------------------------------------------# Specify the installation edition of the component. # # The value should contain only one of these choices. # - EE : Enterprise Edition # - SE2 : Standard Edition 2#-------------------------------------------------------------------------------oracle.install.db.InstallEdition=EESELECTED_LANGUAGES=en,zh_CNORACLE_HOSTNAME=db.test.com################################################################################ ## PRIVILEGED OPERATING SYSTEM GROUPS ## ------------------------------------------ ## Provide values for the OS groups to which SYSDBA and SYSOPER privileges ## needs to be granted. If the install is being performed as a member of the ## group "dba", then that will be used unless specified otherwise below. ## ## The value to be specified for OSDBA and OSOPER group is only for UNIX based ## Operating System. ## #################################################################################------------------------------------------------------------------------------# The OSDBA_GROUP is the OS group which is to be granted SYSDBA privileges.#-------------------------------------------------------------------------------oracle.install.db.OSDBA_GROUP=dba#------------------------------------------------------------------------------# The OSOPER_GROUP is the OS group which is to be granted SYSOPER privileges.# The value to be specified for OSOPER group is optional.#------------------------------------------------------------------------------oracle.install.db.OSOPER_GROUP=oper#------------------------------------------------------------------------------# The OSBACKUPDBA_GROUP is the OS group which is to be granted SYSBACKUP privileges.#------------------------------------------------------------------------------oracle.install.db.OSBACKUPDBA_GROUP=backupdba#------------------------------------------------------------------------------# The OSDGDBA_GROUP is the OS group which is to be granted SYSDG privileges.#------------------------------------------------------------------------------oracle.install.db.OSDGDBA_GROUP=dgdba#------------------------------------------------------------------------------# The OSKMDBA_GROUP is the OS group which is to be granted SYSKM privileges.#------------------------------------------------------------------------------oracle.install.db.OSKMDBA_GROUP=kmdba#------------------------------------------------------------------------------# The OSRACDBA_GROUP is the OS group which is to be granted SYSRAC privileges.#------------------------------------------------------------------------------oracle.install.db.OSRACDBA_GROUP=racdba################################################################################ ## Grid Options ## #################################################################################------------------------------------------------------------------------------# Specify the type of Real Application Cluster Database# # - ADMIN_MANAGED: Admin-Managed# - POLICY_MANAGED: Policy-Managed# # If left unspecified, default will be ADMIN_MANAGED #------------------------------------------------------------------------------oracle.install.db.rac.configurationType=#------------------------------------------------------------------------------# Value is required only if RAC database type is ADMIN_MANAGED# # Specify the cluster node names selected during the installation.# Leaving it blank will result in install on local server only (Single Instance)# # Example : oracle.install.db.CLUSTER_NODES=node1,node2#------------------------------------------------------------------------------oracle.install.db.CLUSTER_NODES=#------------------------------------------------------------------------------# This variable is used to enable or disable RAC One Node install.## - true : Value of RAC One Node service name is used.# - false : Value of RAC One Node service name is not used.## If left blank, it will be assumed to be false.#------------------------------------------------------------------------------oracle.install.db.isRACOneInstall=#------------------------------------------------------------------------------# Value is required only if oracle.install.db.isRACOneInstall is true.# # Specify the name for RAC One Node Service#------------------------------------------------------------------------------oracle.install.db.racOneServiceName=#------------------------------------------------------------------------------# Value is required only if RAC database type is POLICY_MANAGED# # Specify a name for the new Server pool that will be configured# Example : oracle.install.db.rac.serverpoolName=pool1#------------------------------------------------------------------------------oracle.install.db.rac.serverpoolName=#------------------------------------------------------------------------------# Value is required only if RAC database type is POLICY_MANAGED# # Specify a number as cardinality for the new Server pool that will be configured# Example : oracle.install.db.rac.serverpoolCardinality=2#------------------------------------------------------------------------------oracle.install.db.rac.serverpoolCardinality=################################################################################ ## Database Configuration Options ## #################################################################################-------------------------------------------------------------------------------# Specify the type of database to create.# It can be one of the following:# - GENERAL_PURPOSE # - DATA_WAREHOUSE # GENERAL_PURPOSE: A starter database designed for general purpose use or transaction-heavy applications.# DATA_WAREHOUSE : A starter database optimized for data warehousing applications.#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.type=GENERAL_PURPOSE#-------------------------------------------------------------------------------# Specify the Starter Database Global Database Name. #-------------------------------------------------------------------------------oracle.install.db.config.starterdb.globalDBName=db.test.com#-------------------------------------------------------------------------------# Specify the Starter Database SID.#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.SID=orc1#-------------------------------------------------------------------------------# Specify whether the database should be configured as a Container database.# The value can be either "true" or "false". If left blank it will be assumed# to be "false".#-------------------------------------------------------------------------------oracle.install.db.ConfigureAsContainerDB=#-------------------------------------------------------------------------------# Specify the Pluggable Database name for the pluggable database in Container Database.#-------------------------------------------------------------------------------oracle.install.db.config.PDBName=#-------------------------------------------------------------------------------# Specify the Starter Database character set.# 通常中文选择的有ZHS16GBK简体中文库，建议选择unicode的AL32UTF8国际字符集# One of the following# AL32UTF8, WE8ISO8859P15, WE8MSWIN1252, EE8ISO8859P2,# EE8MSWIN1250, NE8ISO8859P10, NEE8ISO8859P4, BLT8MSWIN1257,# BLT8ISO8859P13, CL8ISO8859P5, CL8MSWIN1251, AR8ISO8859P6,# AR8MSWIN1256, EL8ISO8859P7, EL8MSWIN1253, IW8ISO8859P8,# IW8MSWIN1255, JA16EUC, JA16EUCTILDE, JA16SJIS, JA16SJISTILDE,# KO16MSWIN949, ZHS16GBK, TH8TISASCII, ZHT32EUC, ZHT16MSWIN950,# ZHT16HKSCS, WE8ISO8859P9, TR8MSWIN1254, VN8MSWIN1258#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.characterSet=AL32UTF8#------------------------------------------------------------------------------# This variable should be set to true if Automatic Memory Management # in Database is desired.# If Automatic Memory Management is not desired, and memory allocation# is to be done manually, then set it to false.# 自动内存管理，也就是SGA_TARGET和PAG_AGGREGATE_TARGET都不用设置了，Oracle会自动调配两部分大小。#------------------------------------------------------------------------------oracle.install.db.config.starterdb.memoryOption=true#-------------------------------------------------------------------------------# Specify the total memory allocation for the database. Value(in MB) should be# at least 256 MB, and should not exceed the total physical memory available # on the system.# Example: oracle.install.db.config.starterdb.memoryLimit=512# 指定Oracle自动管理内存的大小，最小是256MB#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.memoryLimit=1024#-------------------------------------------------------------------------------# This variable controls whether to load Example Schemas onto# the starter database or not.# The value can be either "true" or "false". If left blank it will be assumed# to be "false".# 是否载入模板示例#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.installExampleSchemas=false################################################################################ ## Passwords can be supplied for the following four schemas in the ## starter database: ## SYS ## SYSTEM ## DBSNMP (used by Enterprise Manager) ## ## Same password can be used for all accounts (not recommended) ## or different passwords for each account can be provided (recommended) ## 设置数据库用户密码 #################################################################################------------------------------------------------------------------------------# This variable holds the password that is to be used for all schemas in the# starter database.# 设定所有数据库用户使用同一个密码，其它数据库用户就不用单独设置了#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.password.ALL=lion.net#-------------------------------------------------------------------------------# Specify the SYS password for the starter database.#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.password.SYS=#-------------------------------------------------------------------------------# Specify the SYSTEM password for the starter database.#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.password.SYSTEM=#-------------------------------------------------------------------------------# Specify the DBSNMP password for the starter database.# Applicable only when oracle.install.db.config.starterdb.managementOption=CLOUD_CONTROL#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.password.DBSNMP=#-------------------------------------------------------------------------------# Specify the PDBADMIN password required for creation of Pluggable Database in the Container Database.#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.password.PDBADMIN=#-------------------------------------------------------------------------------# Specify the management option to use for managing the database.# Options are:# 1. CLOUD_CONTROL - If you want to manage your database with Enterprise Manager Cloud Control along with Database Express.# 2. DEFAULT -If you want to manage your database using the default Database Express option.#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.managementOption=#-------------------------------------------------------------------------------# Specify the OMS host to connect to Cloud Control.# Applicable only when oracle.install.db.config.starterdb.managementOption=CLOUD_CONTROL#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.omsHost=#-------------------------------------------------------------------------------# Specify the OMS port to connect to Cloud Control.# Applicable only when oracle.install.db.config.starterdb.managementOption=CLOUD_CONTROL#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.omsPort=#-------------------------------------------------------------------------------# Specify the EM Admin user name to use to connect to Cloud Control.# Applicable only when oracle.install.db.config.starterdb.managementOption=CLOUD_CONTROL#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.emAdminUser=#-------------------------------------------------------------------------------# Specify the EM Admin password to use to connect to Cloud Control.# Applicable only when oracle.install.db.config.starterdb.managementOption=CLOUD_CONTROL#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.emAdminPassword=################################################################################ ## SPECIFY RECOVERY OPTIONS ## ------------------------------------ ## Recovery options for the database can be mentioned using the entries below ## #################################################################################------------------------------------------------------------------------------# This variable is to be set to false if database recovery is not required. Else # this can be set to true.#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.enableRecovery=#-------------------------------------------------------------------------------# Specify the type of storage to use for the database.# It can be one of the following:# - FILE_SYSTEM_STORAGE# - ASM_STORAGE# 要求指定使用的文件系统存放数据库文件还是ASM#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.storageType=#-------------------------------------------------------------------------------# Specify the database file location which is a directory for datafiles, control# files, redo logs. ## Applicable only when oracle.install.db.config.starterdb.storage=FILE_SYSTEM_STORAGE # 使用文件系统存放数据库文件才需要指定数据文件、控制文件、Redo log的存放目录#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.fileSystemStorage.dataLocation=#-------------------------------------------------------------------------------# Specify the recovery location.## Applicable only when oracle.install.db.config.starterdb.storage=FILE_SYSTEM_STORAGE # 使用文件系统存放数据库文件才需要指定备份恢复目录#-------------------------------------------------------------------------------oracle.install.db.config.starterdb.fileSystemStorage.recoveryLocation=#-------------------------------------------------------------------------------# Specify the existing ASM disk groups to be used for storage.## Applicable only when oracle.install.db.config.starterdb.storageType=ASM_STORAGE#-------------------------------------------------------------------------------oracle.install.db.config.asm.diskGroup=#-------------------------------------------------------------------------------# Specify the password for ASMSNMP user of the ASM instance. ## Applicable only when oracle.install.db.config.starterdb.storage=ASM_STORAGE #-------------------------------------------------------------------------------oracle.install.db.config.asm.ASMSNMPPassword=#------------------------------------------------------------------------------# Specify the My Oracle Support Account Username.## Example : MYORACLESUPPORT_USERNAME=abc@oracle.com#------------------------------------------------------------------------------MYORACLESUPPORT_USERNAME=#------------------------------------------------------------------------------# Specify the My Oracle Support Account Username password.## Example : MYORACLESUPPORT_PASSWORD=password#------------------------------------------------------------------------------MYORACLESUPPORT_PASSWORD=#------------------------------------------------------------------------------# Specify whether to enable the user to set the password for# My Oracle Support credentials. The value can be either true or false.# If left blank it will be assumed to be false.## Example : SECURITY_UPDATES_VIA_MYORACLESUPPORT=true# 用户是否可以设置metalink密码#------------------------------------------------------------------------------SECURITY_UPDATES_VIA_MYORACLESUPPORT=#------------------------------------------------------------------------------# Specify whether user doesn't want to configure Security Updates.# The value for this variable should be true if you don't want to configure# Security Updates, false otherwise.## The value can be either true or false. If left blank it will be assumed# to be true.## Example : DECLINE_SECURITY_UPDATES=false# False表示不需要设置安全更新，注意，在11.2的静默安装中疑似有一个BUG# Response File中必须指定为true，否则会提示错误,不管是否正确填写了邮件地址#------------------------------------------------------------------------------DECLINE_SECURITY_UPDATES=#------------------------------------------------------------------------------# Specify the Proxy server name. Length should be greater than zero.## Example : PROXY_HOST=proxy.domain.com #------------------------------------------------------------------------------PROXY_HOST=#------------------------------------------------------------------------------# Specify the proxy port number. Should be Numeric and at least 2 chars.## Example : PROXY_PORT=25#------------------------------------------------------------------------------PROXY_PORT=#------------------------------------------------------------------------------# Specify the proxy user name. Leave PROXY_USER and PROXY_PWD# blank if your proxy server requires no authentication.## Example : PROXY_USER=username#------------------------------------------------------------------------------PROXY_USER=#------------------------------------------------------------------------------# Specify the proxy password. Leave PROXY_USER and PROXY_PWD # blank if your proxy server requires no authentication.## Example : PROXY_PWD=password#------------------------------------------------------------------------------PROXY_PWD=#------------------------------------------------------------------------------# Specify the Oracle Support Hub URL. # # Example : COLLECTOR_SUPPORTHUB_URL=https://orasupporthub.company.com:8080/#------------------------------------------------------------------------------COLLECTOR_SUPPORTHUB_URL=EOF 参考https://blog.csdn.net/gengyuntuo/article/details/79607595 http://xintq.net/2017/09/22/silent-install-ora12c-ol7/ https://docs.oracle.com/en/database/oracle/oracle-database/index.html https://www.jianshu.com/p/309bb3504285?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation http://blog.csdn.net/github_39294367/article/details/77057149 http://www.gimoo.net/t/1803/5a975ea1b3e13.html https://wiki.centos.org/HowTos/Oracle12onCentos7 http://blog.csdn.net/jssg_tzw/article/details/53402743 http://blog.csdn.net/jc_benben/article/details/69911904]]></content>
      <categories>
        <category>oracle</category>
        <category>install</category>
      </categories>
      <tags>
        <tag>oracle</tag>
        <tag>install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习网站]]></title>
    <url>%2Flinux%2F%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[linux任我乐 https://renwole.com 鱼夫 http://www.cnblogs.com/anay/ http://www.cnblogs.com/clsn/ 运维时间 http://www.ttlsa.com]]></content>
      <categories>
        <category>study</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web缓存知识体系]]></title>
    <url>%2Fnginx%2FWeb%E7%BC%93%E5%AD%98%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>cache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[确保Tomcat安全的途径]]></title>
    <url>%2Ftomcat%2F%E7%A1%AE%E4%BF%9DTomcat%E5%AE%89%E5%85%A8%E7%9A%84%E9%80%94%E5%BE%84%2F</url>
    <content type="text"><![CDATA[首先，新建一个帐户 用”ITOMCAT_计算机名”建立一个普通用户 为其设置一个密码 保证”密码永不过期”(Password Never Expires)被选中 修改Tomcat安装文件夹的访问权限 选定环境参数CATALINA_HOME或TOMCAT_HOME指向的Tomcat安装文件夹。 为”ITOMCAT_计算机名”用户赋予读、写、执行的访问权限。 为”ITOMCAT_计算机名”用户赋予对WebApps文件夹的只读访问权限。 如果某些Web应用程序需要写访问权限，单独为其授予对那个文件夹的写访问权限。 当你需要Tomcat作为系统服务运行时，采取以下步骤： 到”控制面板”，选择”管理工具”，然后选择”服务”。 找到Tomcat：比如Apache Tomcat.exe等等，打开其”属性”。 选择其”登录”(Log)标签。 选择”以…登录”(Log ON Using)选项。 键入新建的”ITOMCAT_计算机名”用户作为用户名。 输入密码。 重启机器。 当你需要在一个DOS窗口下运行Tomcat时，采取以下步骤： 在”开始”按钮的”运行”框中键入CMD以打开一个DOS窗口。 键入”RunAs /user：ITOMCAT_计算机名 CMD.exe”命令。 在询问”ITOMCAT_计算机名”用户的密码时输入设置的密码。 这将打开一个新的DOS窗口。 在新开的DOS窗口中，转换到Tomcat的bin文件夹内。 键入”catalina run”命令。 关闭第一个DOS窗口。 以”ITOMCAT_计算机名”用户在新的DOS窗口内运行只授予该用户相应的权限；当你在这个新的DOS窗口中运行Tomcat时，它只取得了这个选定用户的权限。这样Tomcat就安全了。]]></content>
      <categories>
        <category>tomcat</category>
      </categories>
      <tags>
        <tag>tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install Microsoft SQL Server On CentOS Linux]]></title>
    <url>%2Fmssql%2FInstall%20Microsoft%20SQL%20Server%20On%20CentOS%2F</url>
    <content type="text"><![CDATA[配置安装源## sql server wget https://packages.microsoft.com/config/rhel/7/mssql-server-2017.repo -O /etc/yum.repos.d/mssql-server.repo ## mssql-tools wget https://packages.microsoft.com/config/rhel/7/prod.repo -O /etc/yum.repos.d/prod.repo 安装mssql server## 安装mssql server yum install mssql-server -y ## 执行配置脚本 ## 请确保为SA帐户指定一个强密码（最小长度为8个字符，包括大写字母和小写字母，基本10位数字和/或非字母数字符号）,按提示设置SA密码。 /opt/mssql/bin/mssql-conf setup ## 验证服务是否正在运行 systemctl status mssql-server 安装命令行管理工具## 安装SQL Server工具，如果需要可以选择安装unixODBC-utf16-devel unixODBC-devel msodbcsql yum install mssql-tools -y ## 创建符号链接也叫软链接 ln -sfn /opt/mssql-tools/bin/sqlcmd /usr/bin/sqlcmd ln -sfn /opt/mssql-tools/bin/bcp /usr/bin/bcp ## 或者，配置SqlCmd环境变量 echo &apos;export PATH=$PATH:/opt/mssql-tools/bin&apos; &gt; /etc/profile.d/mssql.sh source /etc/profile.d/mssql.sh ## 或者： echo &apos;export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;&apos; &gt;&gt; ~/.bash_profile echo &apos;export PATH=&quot;$PATH:/opt/mssql-tools/bin&quot;&apos; &gt;&gt; ~/.bashrc source ~/.bashrc 开启防护墙端口firewall-cmd --add-port=1433/tcp --permanent firewall-cmd --reload ## 或者（使用iptables ）： iptables -A INPUT -p tcp --dport 1433 -j ACCEPT iptables-save 查询安装包rpm -ql mssql-server rpm -ql mssql-tool rpm -ql msodbcsql rpm -ql unixODBC 管理工具下载地址https://go.microsoft.com/fwlink/?linkid=875802 https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-2017 官方安装文件https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-setup?view=sql-server-linux-2017 登陆测试## 查看数据库版本 sqlcmd -S localhost -U SA -Q &apos;select @@VERSION&apos; ## 可以不加-P &lt;密码&gt; , 后面会提示要求输入密码。 ## use 切换数据库 ## go 表示执行前面输入的语句 sqlcmd -S 200.200.200.50 -U sa -P your_password &gt; use master &gt; go 已将数据库上下文更改为 &apos;master&apos;。 ## 创建数据库并查询 &gt; CREATE DATABASE DataTest; &gt; GO &gt; SELECT Name from sys.Databases; &gt; GO 命令模式执行sqlsqlcmd -S 200.200.200.50\mssqlserver -d DataTest -Q &quot;SELECT FirstName, LastName FROM Person.Person WHERE PersonType = &apos;em&apos; ORDER BY LastName, FirstName&quot; -o C:\DataFiles\Employees.txt 命令模式执行sql文件和使用变量参数vi EmployeeQuery2.sql SELECT FirstName, LastName FROM Person.Person WHERE PersonType = &apos;$(type)&apos; AND LastName = &apos;$(name)&apos; sqlcmd -S localhost\sqlsrv2012 -d AdventureWorks2012 -i ./EmployeeQuery2.sql -v type=&quot;em&quot; id=&quot;smith&quot;&quot; -o ./Employees2.txt 备份和恢复数据库## 备份数据 demodb sqlcmd -S localhost -U SA -Q &quot;BACKUP DATABASE [demodb] TO DISK = N&apos;/var/opt/mssql/data/demodb.bak&apos; WITH NOFORMAT, NOINIT, NAME = &apos;demodb-full&apos;, SKIP, NOREWIND, NOUNLOAD, STATS = 10&quot; ## 备份数据库 transaction log， 如果数据库运行在full recovery 模式 sqlcmd -S localhost -U SA -Q &quot;BACKUP LOG [demodb] TO DISK = N&apos;/var/opt/mssql/data/demodb_LogBackup.bak&apos; WITH NOFORMAT, NOINIT, NAME = N&apos;demodb_LogBackup&apos;, NOSKIP, NOREWIND, NOUNLOAD, STATS = 5&quot; ## 恢复数据库，如果不要另外恢复transaction log，就不需要添加NORECOVERY sqlcmd -S localhost -U SA -Q &quot;RESTORE DATABASE [demodb] FROM DISK = N&apos;/var/opt/mssql/data/demodb.bak&apos; WITH FILE = 1, NOUNLOAD, REPLACE, NORECOVERY, STATS = 10&quot; ## 恢复数据库 transaction log sqlcmd -S localhost -U SA -Q &quot;RESTORE LOG demodb FROM DISK = N&apos;/var/opt/mssql/data/demodb_LogBackup.bak&apos;&quot; 从windows 迁移到 centos## 备份数据库uni_pttw ## 在centos上用sqlcmd 连上windows mssql数据，然后执行如下命令 ## 也可以在windows 上用ssms备份 BACKUP DATABASE uni_pttw TO DISK = N&apos;C:\java\uni_pttw.bak&apos; WITH NOFORMAT, NOINIT, NAME = N&apos;uni_pttw-Full Database Backup&apos;, SKIP, NOREWIND, NOUNLOAD, STATS = 10 GO ## 从windows复制文件到centos 上 ## 恢复数据uni_pttw ## 在centos上用sqlcmd 连上centos上的 mssql数据，然后执行如下命令 CREATE DATABASE uni_pttw; GO RESTORE DATABASE uni_pttw FROM DISK = &apos;/var/opt/mssql/backup/uni_pttw.bak&apos; WITH REPLACE, MOVE &apos;uni_pttw&apos; TO &apos;/var/opt/mssql/data/uni_pttw.mdf&apos;, MOVE &apos;uni_pttw_Log&apos; TO &apos;/var/opt/mssql/data/uni_pttw_Log.ldf&apos; GO 配置变更参考： https://docs.microsoft.com/zh-cn/sql/linux/sql-server-linux-configure-mssql-conf?view=sql-server-linux-2017 所有数据库的排序规则## 创建自定义目录及更改目录权限 mkdir -p /data/mssql_data/ chown -R mssql:mssql /data/mssql_data/ /opt/mssql/bin/mssql-conf set filelocation.defaultdatadir /data/mssql_data/ systemctl restart mssql-server ## 如果需要单独更改日志的目录（如/tmp） /opt/mssql/bin/mssql-conf set filelocation.defaultlogdir /tmp/ 使用存储过程来分离和加载数据库## 分离 exec sp_detach_db db1; go ## 加载 exec sp_attach_db &apos;db1&apos;,&apos;/data/mssql_data/db1.mdf&apos;,&apos;/data/mssql_data/db1_log.ldf&apos;; go 更改SQL Server排序规则## 查询当前数据库实例的排序规则 SELECT CONVERT(NVARCHAR(50),SERVERPROPERTY(&apos;Collation&apos;)); ## 步骤如下： ## 备份所有用户数据库。（如果是刚刚安装好的实例没有用户数据库可以跳过这一步。） ## 停止数据库实例 ## 运行/opt/mssql/bin/mssql-conf set-collation命令修改排序规则 ## 启动数据库实例 ## 还原用户数据库（没有用户数据库可跳过） systemctl stop mssql-server /opt/mssql/bin/mssql-conf set-collation Enter the collation: Chinese_PRC_CI_AS systemctl start mssql-server ## 查询当前所有数据库的排序规则 SELECT CONVERT(NVARCHAR(30),name), CONVERT(NVARCHAR(50),collation_name) FROM sys.databases; 更改内存限制## 单位MB /opt/mssql/bin/mssql-conf set memory.memorylimitmb 3328 更改端口/opt/mssql/bin/mssql-conf set network.tcpport 1444 systemctl restart mssql-server sqlcmd -S localhost,1444 -U sa 删除设置/opt/mssql/bin/mssql-conf unset network.tcpport /opt/mssql/bin/mssql-conf unset memory.memorylimitmb systemctl restart mssql-server 查看当前设置及配置文件cat /var/opt/mssql/mssql.conf 官方配置样本12345678910111213141516171819202122232425262728293031323334353637383940414243444546[EULA]accepteula = Y[coredump]captureminiandfull = truecoredumptype = full[filelocation]defaultbackupdir = /var/opt/mssql/data/defaultdatadir = /var/opt/mssql/data/defaultdumpdir = /var/opt/mssql/data/defaultlogdir = /var/opt/mssql/data/[hadr]hadrenabled = 0[language]lcid = 1033[memory]memorylimitmb = 4096[network]forceencryption = 0ipaddress = 10.192.0.0kerberoskeytabfile = /var/opt/mssql/secrets/mssql.keytabtcpport = 1401tlscert = /etc/ssl/certs/mssql.pemtlsciphers = ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHAtlskey = /etc/ssl/private/mssql.keytlsprotocols = 1.2,1.1,1.0[sqlagent]databasemailprofile = defaulterrorlogfile = /var/opt/mssql/log/sqlagentlog.logerrorlogginglevel = 7[telemetry]customerfeedback = trueuserrequestedlocalauditdirectory = /tmp/audit[traceflag]traceflag0 = 1204traceflag1 = 2345traceflag = 3456 自动安装脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#!/bin/bash# Use the following variables to control your install:# Password for the SA user (required)MSSQL_SA_PASSWORD='&lt;YourStrong!Passw0rd&gt;'# Product ID of the version of SQL server you're installing# Must be evaluation, developer, express, web, standard, enterprise, or your 25 digit product key# Defaults to developerMSSQL_PID='evaluation'# Install SQL Server Agent (recommended)SQL_INSTALL_AGENT='y'# Install SQL Server Full Text Search (optional)# SQL_INSTALL_FULLTEXT='y'# Create an additional user with sysadmin privileges (optional)# SQL_INSTALL_USER='&lt;Username&gt;'# SQL_INSTALL_USER_PASSWORD='&lt;YourStrong!Passw0rd&gt;'if [ -z $MSSQL_SA_PASSWORD ]thenecho Environment variable MSSQL_SA_PASSWORD must be set for unattended installexit 1fiecho Adding Microsoft repositories...sudo curl -o /etc/yum.repos.d/mssql-server.repo https://packages.microsoft.com/config/rhel/7/mssql-server-2017.reposudo curl -o /etc/yum.repos.d/msprod.repo https://packages.microsoft.com/config/rhel/7/prod.repoecho Installing SQL Server...sudo yum install -y mssql-serverecho Running mssql-conf setup...sudo MSSQL_SA_PASSWORD=$MSSQL_SA_PASSWORD \ MSSQL_PID=$MSSQL_PID \ /opt/mssql/bin/mssql-conf -n setup accept-eulaecho Installing mssql-tools and unixODBC developer...sudo ACCEPT_EULA=Y yum install -y mssql-tools unixODBC-devel# Add SQL Server tools to the path by default:echo Adding SQL Server tools to your path...echo PATH="$PATH:/opt/mssql-tools/bin" &gt;&gt; ~/.bash_profileecho 'export PATH="$PATH:/opt/mssql-tools/bin"' &gt;&gt; ~/.bashrcsource ~/.bashrc# Optional SQL Server Agent installation:if [ ! -z $SQL_INSTALL_AGENT ]thenecho Installing SQL Server Agent...sudo yum install -y mssql-server-agentfi# Optional SQL Server Full Text Search installation:if [ ! -z $SQL_INSTALL_FULLTEXT ]then echo Installing SQL Server Full-Text Search... sudo yum install -y mssql-server-ftsfi# Configure firewall to allow TCP port 1433:echo Configuring firewall to allow traffic on port 1433...sudo firewall-cmd --zone=public --add-port=1433/tcp --permanentsudo firewall-cmd --reload# Example of setting post-installation configuration options# Set trace flags 1204 and 1222 for deadlock tracing:#echo Setting trace flags...#sudo /opt/mssql/bin/mssql-conf traceflag 1204 1222 on# Restart SQL Server after making configuration changes:echo Restarting SQL Server...sudo systemctl restart mssql-server# Connect to server and get the version:counter=1errstatus=1while [ $counter -le 5 ] &amp;&amp; [ $errstatus = 1 ]doecho Waiting for SQL Server to start...sleep 5s/opt/mssql-tools/bin/sqlcmd \ -S localhost \ -U SA \ -P $MSSQL_SA_PASSWORD \ -Q "SELECT @@VERSION" 2&gt;/dev/nullerrstatus=$?((counter++))done# Display error if connection failed:if [ $errstatus = 1 ]thenecho Cannot connect to SQL Server, installation abortedexit $errstatusfi# Optional new user creation:if [ ! -z $SQL_INSTALL_USER ] &amp;&amp; [ ! -z $SQL_INSTALL_USER_PASSWORD ]thenecho Creating user $SQL_INSTALL_USER/opt/mssql-tools/bin/sqlcmd \ -S localhost \ -U SA \ -P $MSSQL_SA_PASSWORD \ -Q "CREATE LOGIN [$SQL_INSTALL_USER] WITH PASSWORD=N'$SQL_INSTALL_USER_PASSWORD', DEFAULT_DATABASE=[master], CHECK_EXPIRATION=ON, CHECK_POLICY=ON; ALTER SERVER ROLE [sysadmin] ADD MEMBER [$SQL_INSTALL_USER]"fiecho Done!]]></content>
      <categories>
        <category>mssql</category>
      </categories>
      <tags>
        <tag>mssql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum install java on centos 7]]></title>
    <url>%2Fjava%2Fyum%20install%20java%20on%20centos%207%2F</url>
    <content type="text"><![CDATA[tar 包安装方式## 下载地址： ## oracle jdk: http://www.oracle.com/technetwork/java/javase/downloads/index.html ## open jdk: http://jdk.java.net/10/ ## oracle jdk 10 cd /opt wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/10.0.1+10/fb4372174a714e6b8c52526dc134031e/jdk-10.0.1_linux-x64_bin.tar.gz&quot; ## oracle jdk 8 wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u171-b11/512cd62ec5174c3487ac17c61aaa89e8/jdk-8u171-linux-x64.tar.gz&quot; ## openjdk 10 wget https://download.java.net/java/GA/jdk10/10.0.1/fb4372174a714e6b8c52526dc134031e/10/openjdk-10.0.1_linux-x64_bin.tar.gz ## 解压 tar -zxf jdk-10.0.1_linux-x64_bin.tar.gz -C /usr/local ls /usr/local/jdk-10.0.1/ ## 添加JAVA JDK环境变量: 123456789cat &gt; /etc/profile.d/jdk.sh &lt;&lt; EOFJAVA_HOME=/usr/local/jdk-10.0.1JRE_HOME=/usr/local/jdk-10.0.1/jreCLASSPATH=.:\$JAVA_HOME/jre/lib/rt.jar:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar:\$JRE_HOME/libPATH=\$PATH:\$JAVA_HOME/bin:\$JRE_HOME/binexport JAVA_HOME JRE_HOME PATH CLASSPATHEOF cat /etc/profile.d/jdk.sh JAVA_HOME=/usr/local/jdk-10.0.1 JRE_HOME=/usr/local/jdk-10.0.1/jre CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin export JAVA_HOME JRE_HOME PATH CLASSPATH ## 手动加载java环境变量 chmod 644 /etc/profile.d/jdk.sh source /etc/profile.d/jdk.sh ## 验证 # java -version java 10.0.1 2018-04-17 Java(TM) SE Runtime Environment 18.3 (build 10.0.1+10) Java HotSpot(TM) 64-Bit Server VM 18.3 (build 10.0.1+10, mixed mode) yum 本地安装方式## 如果rpm 或 yum 安装过jdk, 清理 ## 查询 rpm -qa | grep -E &apos;^open[jre|jdk]|j[re|dk]&apos; .... jdk1.8.0_131-1.8.0_131-fcs.x86_64 .... ## 移除 yum -y remove jdk1.8.0_131-1.8.0_131-fcs.x86_64 ##==========================================## ## rpm 方式安装jdk 10 ##==========================================## ## orcle jdk 10 wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/10.0.1+10/fb4372174a714e6b8c52526dc134031e/jdk-10.0.1_linux-x64_bin.rpm&quot; ## orcle jdk 8 wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u171-b11/512cd62ec5174c3487ac17c61aaa89e8/jdk-8u171-linux-x64.rpm&quot; ## yum 本地安装方便以后反安装 yum localinstall jdk-10.0.1_linux-x64_bin.rpm ## rpm 安装也可以 rpm -ivh jdk-10.0.1_linux-x64_bin.rpm ## 安装目录：/usr/java/jdk-10.0.1 多版本切换usage: alternatives --install &lt;link&gt; &lt;name&gt; &lt;path&gt; &lt;priority&gt; [--initscript &lt;service&gt;] [--family &lt;family&gt;] [--slave &lt;link&gt; &lt;name&gt; &lt;path&gt;]* alternatives --remove &lt;name&gt; &lt;path&gt; alternatives --auto &lt;name&gt; # 将手动设置为自动选择最高优先级的，如:alternatives --auto java alternatives --config &lt;name&gt; # 手动设置版本 alternatives --display &lt;name&gt; # 选项的功能就是查看一个命令链接组的所有信息，包括链接的模式(自动还是手动)、链接priority值、所有可用的链接命令等等 alternatives --set &lt;name&gt; &lt;path&gt; # 直接设置路径，像config，但不是通过交互式选择 alternatives --list # 列出所有命令当前设置 说明： alternatives --install &lt;link&gt; &lt;name&gt; &lt;path&gt; &lt;priority&gt; 其中， install: 表示安装,就是增加一组新的系统命令链接符了 link: 是符号链接，为系统中功能相同软件的公共链接目录 name: 为命令链接符名称，比如java path: 为你所要使用新命令、新软件的所在目录 priority: 则表示优先级,数值标识 slave： 为从alternative ## 比如通过tar包安装jdk8,路径 /usr/local/jdk-8/， 优先级为2，最后调整为系统默认的版本 cd /usr/local/jdk-8/ alternatives --install /usr/bin/java java /usr/local/jdk-8/bin/java 2 alternatives --install /usr/bin/javac javac /usr/local/jdk-8/bin/javac 2 alternatives --install /usr/bin/jar jar /usr/local/jdk-8/bin/jar 2 alternatives --set jar /usr/local/jdk-8/bin/jar alternatives --set javac /usr/local/jdk-8/bin/javac ## config 选项功能为在现有的命令链接选择一个作为系统默认的，使用语法为：alternatives --config name alternatives --config java There are 2 programs which provide &apos;java&apos;. Selection Command ----------------------------------------------- *+ 1 /usr/java/jdk-10.0.1/bin/java 2 /usr/java/jdk1.8.0_171-amd64/jre/bin/java ## 删除 alternatives --remove java java /usr/local/jdk-8/bin/java rpm 包安装方式1. 到oracle官网下载RPM 包 ## http://www.oracle.com/technetwork/java/javase/downloads/index.html ## --------------- For 64-bit Systems --------------- cd /opt wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u45-b14/jdk-8u45-linux-x64.rpm&quot; wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u45-b14/jre-8u45-linux-x64.rpm&quot; wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; &quot;http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm&quot; ## http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm 2. 安装 ## --------------- For 64-bit Systems --------------- rpm -Uvh jdk-8u45-linux-x64.rpm rpm -Uvh jre-8u45-linux-x64.rpm 3. 检查 java -version javac -version 4. Enable Java JDK / JRE 8u45 Support in Firefox ## For 32-Bit OS ## alternatives --install /usr/lib/mozilla/plugins/libjavaplugin.so libjavaplugin.so /usr/java/jdk1.8.0_45/jre/lib/i386/libnpjp2.so 20000 ## For 64-Bit OS ## alternatives --install /usr/lib/mozilla/plugins/libjavaplugin.so libjavaplugin.so /usr/java/jdk1.8.0_45/jre/lib/amd64/libnpjp2.so 20000 安装open jdk1) Installing Java JRE on CentOS 7, 下面选一个版本安装 sudo yum install java-1.8.0-openjdk sudo yum install java-1.7.0-openjdk sudo yum install java-1.6.0-openjdk 2) Installing Java JDK on CentOS 7 sudo yum install java-1.8.0-openjdk-devel sudo yum install java-1.7.0-openjdk-devel sudo yum install java-1.6.0-openjdk-devel Installing Oracle Java JRE on CentOS 7cd /opt sudo wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; \ &quot;http://download.oracle.com/otn-pub/java/jdk/8u51-b16/jre-8u51-linux-x64.tar.gz&quot; sudo tar xvf jre-8u51-linux-x64.tar.gz sudo chown -R root: jre1.8.0_51 sudo alternatives --install /usr/bin/java java /opt/jre1.8.0_51/bin/java 1 We also recommend to setup javac and jar commands path using alternatives # alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_51/bin/jar 2 # alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_51/bin/javac 2 # alternatives --set jar /opt/jdk1.8.0_51/bin/jar # alternatives --set javac /opt/jdk1.8.0_51/bin/javac alternatives command is available in chkconfig package. Installing Oracle Java JDK on CentOS 7cd /opt sudo wget --no-cookies --no-check-certificate --header &quot;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&quot; \ &quot;http://download.oracle.com/otn-pub/java/jdk/8u51-b16/jdk-8u51-linux-x64.tar.gz&quot; sudo tar xvf jdk-8u51-linux-x64.tar.gz sudo chown -R root: jdk1.8.0_51 # 使用alternatives安装 sudo alternatives --install /usr/bin/java java /opt/jdk1.8.0_51/bin/java 1 Select your default Java Version on CentOS 7# 如果系统安装了多个版本，查看各个版本的安装路径 sudo update-alternatives --config java /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.51-1.b16.el7_1.x86_64 /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.85-2.6.1.2.el7_1.x86_64 /usr/lib/jvm/jre-1.6.0-openjdk.x86_64 Setup JAVA_HOME on CentOS 7#重新编辑配置文件 sudo vi /etc/profile export JAVA_HOME=&quot;/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.51-1.b16.el7_1.x86_64&quot; #重新加载配置文件 source /etc/profile # 查看运行状态下的变量值 echo $JAVA_HOME 修改 profile 文件vi /etc/profile 在文件的末尾修改 export JAVA_HOME=/usr/java/jdk1.8.0_45 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 为 export JAVA_HOME=/usr/java/jdk1.8.0_45 export CATALINA_HOME=/usr/local/apache-tomcat-8.0.22 export PATH=$JAVA_HOME/bin:$PATH:$CATALINA_HOME/lib export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$CATALINA_HOME/bin 注意 JAVA_HOME 是你的 JDK 安装目录 Linux 下用冒号“:”来分隔路径 $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值 export 是把这三个变量导出为全局变量。 方法2 上述修改 放到 .bash_profile 文件末尾中 这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的 .bash_profile文件就可以了。 参考：https://www.digitalocean.com/community/tutorials/how-to-install-java-on-centos-and-fedora]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Azure cli 通过复制的vhd重建虚机]]></title>
    <url>%2Fazure%2Fazure_cli_vm%2FAzure%20cli%20%E9%80%9A%E8%BF%87%E5%A4%8D%E5%88%B6vhd%E9%87%8D%E5%BB%BA%E8%99%9A%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[说明本文适合跨账户迁移虚机。 原理通过公开的sas url 复制磁盘镜像到存储账户里，然后再从存储账户的vhd文件创建托管磁盘，再利用托管磁盘创建虚机 需要注意的是：虚机加载的额外磁盘需要卸掉，或者在fstab 磁盘加载项添加 nofail, 如 centos配置： UUID=1037feaf-5034-446c-bbdc-e1958be6b35a /data xfs defaults,nofail,nodev,nouser,noexec,nosuid,noatime,nodiratime 0 0 如果没修改，可以在已启动的虚机里加载 vhd文件 或 托管磁盘，修改fstab后在创建虚机 参考： https://docs.microsoft.com/zh-cn/cli/azure/reference-index?view=azure-cli-latest Azure 登陆## 切换到中国云 az cloud set -n AzureChinaCloud ## 登陆 az login ## 浏览器打开，先用账户登陆Azure portal，然后在新tab page里打开 ## https://microsoft.com/deviceloginchina ## 如果需要设置订阅 az account set --subscription $s_SubscriptionId 用到的变量## t_ 表示target_, 代表目标资源 ## s_ 表示source_, 代表源资源 ##--源资源变量------------------------------------------------------ ## 源订阅 s_SubscriptionId=ddrt394e-0463-4eta5-8d04-c94wetfd879dc ## 源区域 s_Location=&quot;chinaeast&quot; ## 源资源组 s_ResourceGroupName=&quot;server_rg&quot; ## 源托管磁盘镜像名 s_SnapshotName=&quot;server01_OsDisk-hdd201801&quot; ##--目标资源变量------------------------------------------------------ ## 目标订阅 t_SubscriptionId=653gfb1f7-f219-4sgfeb-eret-31wrtwe1efb0 ## 目标区域, chinanorth chinaeast t_Location=&quot;chinaeast&quot; ## 目标资源组 t_ResourceGroupName=&quot;test_rg&quot; ##--目标存储账户变量------------------------------------------------------ ## 目标存储账户名 t_StorageAccountName=&quot;serverstg01&quot; ## 目标存储账户容器名 t_StorageContainerName=&quot;data&quot; ## 存储账户访问密匙，这里随便几个字符表示一下 t_StorageAccountKey=&quot;aA8bfS4CnG0t7tW+QudkMYYt+IBbp6ha7iPzo9mNFDGp7M4u2UBw==&quot; ##--目标网络资源变量------------------------------------------------------ ## 高可用集名 t_HASetName=&quot;HASet&quot; ## 安全组名 t_NSGName=&quot;test_ng&quot; ## 公网IP t_PIPName1=&quot;test01_IP1&quot; t_PIPName2=&quot;test02_IP1&quot; ## 虚拟网卡名 t_NICName1=&quot;test01_nic1&quot; t_NICName2=&quot;test02_nic1&quot; ## 虚拟网络名 t_VnetName=&quot;test01-vnet-101e&quot; ## 虚拟网络地址空间 t_VnetAddressPrefix=&quot;10.10.10.0/24 10.10.11.0/24 10.10.12.0/24&quot; ## 子网1名 t_SubnetName1=&quot;test01-snet-101e&quot; ## 子网1地址 t_SubnetNamePrefix1=&quot;10.10.10.0/24&quot; ## 子网2名和子网2地址 t_SubnetName2=&quot;test_app_gatewy&quot; t_SubnetNamePrefix2=&quot;10.10.11.0/24&quot; ##--新建资源变量------------------------------------------------------ ## 导出时间限制，过期时间，3600 秒 = 1 小时 ## 创建的sas url 连接时，设置能够访问的时间，就是说从创建开始到不能从这个sas url下载磁盘镜像的时间长度 sasExpiryDuration=3600 ## 目标 VHD 文件保存名 t_VHDFileName=&quot;osdisk.vhd&quot; ##--新建托管磁盘变量------------------------------------------------------ ## 新建的托管磁盘名 t_ManagedDiskName=&quot;test01_OsDisk_1&quot; ## 新建虚机存放格式，这里用ssd, Premium_LRS or Standard_LRS t_Sku=&quot;Premium_LRS&quot; ## 新建磁盘大小，单位GB t_DiskSize=32 ##--新建虚机变量------------------------------------------------------ ## 新建虚机名 t_VMName1=&quot;test01&quot; ## 新建虚机类型 t_OS_Type=linux ## 新建虚机大小 t_Size=&quot;Standard_DS2_v2&quot; 创建资源组## 查询资源组里的资源，不带--resource-group查询订阅的所有资源 az resource list --resource-group $t_ResourceGroupName --output table ## 创建资源组 az group create \ --name $t_ResourceGroupName \ --location $t_Location 创建安全组az network nsg create \ --location $t_Location \ --resource-group $t_ResourceGroupName \ --name $t_NSGName 开启端口3890az network nsg rule create \ --location $t_Location \ --resource-group $t_ResourceGroupName \ --nsg-name $t_NSGName \ --name RDP \ --protocol tcp \ --direction inbound \ --source-address-prefix &apos;*&apos; \ --source-port-range &apos;*&apos; \ --destination-address-prefix &apos;*&apos; \ --destination-port-range 3890 \ --access allow \ --priority 1100 开启端口22az network nsg rule create \ --location $t_Location \ --resource-group $t_ResourceGroupName \ --nsg-name $t_NSGName \ --name SSH \ --protocol tcp \ --direction inbound \ --source-address-prefix &apos;*&apos; \ --source-port-range &apos;*&apos; \ --destination-address-prefix &apos;*&apos; \ --destination-port-range 22 \ --access allow \ --priority 1100 开启80端口az network nsg rule create \ --location $t_Location \ --resource-group $t_ResourceGroupName \ --nsg-name $t_NSGName \ --name HTTP \ --protocol tcp \ --direction inbound \ --source-address-prefix &apos;*&apos; \ --source-port-range &apos;*&apos; \ --destination-address-prefix &apos;*&apos; \ --destination-port-range 80 \ --access allow \ --priority 1200 创建可用集az vm availability-set create \ --name $t_HASetName \ --resource-group $t_ResourceGroupName \ --platform-fault-domain-count 2 \ --platform-update-domain-count 5 创建虚拟网络和子网az network vnet create \ --resource-group $t_ResourceGroupName \ --name $t_VnetName \ --address-prefix $t_VnetAddressPrefix \ --subnet-name $t_SubnetName1 \ --subnet-prefix $t_SubnetNamePrefix1 ## 其它参数：DDOS防护，启用的是标准防护，需要收费，默认基础防护不需要设置。 [--ddos-protection {false, true}] [--ddos-protection-plan] [--vm-protection {false, true}] 创建子网az network vnet subnet create \ --resource-group $t_ResourceGroupName \ --vnet-name $t_VnetName \ --name t_SubnetName2 \ --address-prefix t_SubnetNamePrefix2 \ --network-security-group $t_NSGName ## 其它参数： --route-table MyRouteTable [--service-endpoints] 创建存储帐户az storage account create \ --resource-group $t_ResourceGroupName \ --location $t_Location \ --name $t_StorageAccountName \ --kind Storage \ --sku Standard_LRS 创建存储容器az storage container create \ --account-name $t_StorageAccountName \ --name $t_StorageContainerName 查询存储第一个access keystorageAccountKey=$(az storage account keys list \ --account-name $t_StorageAccountName \ --resource-group $t_ResourceGroupName \ --query [0].value --output tsv) 托管磁盘转vhd## 登陆到源订阅上操作 ## 从托管磁盘镜像创建sas url，通过此连接可用于外网用户直接访问下载镜像 ## 也可以直接从portal界面创建 s_SAS=$(az snapshot grant-access --resource-group $s_ResourceGroupName --name $s_SnapshotName --duration-in-seconds $sasExpiryDuration --query [accessSas] -o tsv) ## 此连接将会是这样一个url ## echo $s_SAS ## https://md-jzj4xh1pwpkc.blob.core.chinacloudapi.cn/d1dcd5z4mb2g/abcd?sv=2017-04-17&amp;sr=b&amp;si=4484c9bb-e110-424c-aae8-169cca49c4af&amp;sig=ARBeP4FNuhlphRB03a97c71HXQ9P8Xd1IRu9Eb0x8zU%3D ## 登陆到目标订阅上操作 ## 将sar url 复制下来，并复制给变量 s_SAS=&quot;https://md-jzj4xh1pwpkc.blob.core.chinacloudapi.cn/d1dcd5z4mb2g/abcd?sv=2017-04-17&amp;sr=b&amp;si=4484c9bb-e110-424c-aae8-169cca49c4af&amp;sig=ARBeP4FNuhlphRB03a97c71HXQ9P8Xd1IRu9Eb0x8zU%3D&quot; ## 通过异步复制，将$s_SAS 的磁盘镜像复制到存储账户里，存为一个vhd文件 az account set --subscription $t_SubscriptionId az storage blob copy start \ --destination-blob $t_VHDFileName \ --destination-container $t_StorageContainerName \ --account-name $t_StorageAccountName \ --account-key $t_StorageAccountKey \ --source-uri $s_SAS vhd转托管磁盘## 存储帐户中从 VHD 文件创建托管磁盘,如果未设置大小，默认和源镜像一样大 az account set --subscription $t_SubscriptionId ## 获取存储账户密匙 storageAccountKey=$(az storage account keys list \ --account-name $t_StorageAccountName \ --resource-group $t_ResourceGroupName \ --query [0].value --output tsv) ## 获取blob url vhd_url=$(az storage blob url \ --name $t_VHDFileName \ --account-key $storageAccountKey \ --account-name $t_StorageAccountName \ --container-name $t_StorageContainerName) ## 查看vhd_url内容 ## echo $vhd_url ## https://testserverdiag01.blob.core.chinacloudapi.cn/data/vm_os.vhd az disk create \ --resource-group $t_ResourceGroupName \ --name $t_ManagedDiskName \ --location $t_Location \ --sku $t_Sku \ --size-gb $t_DiskSize \ --source $vhd_url 从托管磁盘镜像创建托管磁盘az account set --subscription $t_SubscriptionId ## 获取托管磁盘镜像ID snapshotId=$(az snapshot show --name $s_SnapshotName --resource-group $s_ResourceGroupName --query [id] -o tsv) #通过镜像ID创建托管磁盘,如果未设置大小，默认和源镜像一样大 az disk create \ --resource-group $t_ResourceGroupName \ --name $t_ManagedDiskName \ --sku $t_Sku \ --size-gb $t_DiskSize \ --source $snapshotId 使用现有托管 OS 磁盘创建虚拟机创建对外IPaz network public-ip create \ --name $t_PIPName1 \ --resource-group $t_ResourceGroupName \ --location $t_Location \ --allocation-method Static ## 其它参数： [--dns-name] ：--dns-name Mydnsname [--idle-timeout] [--ip-tags] [--reverse-fqdn] [--sku {Basic, Standard}] [--tags] [--version {IPv4, IPv6}] [--zone {1, 2, 3}] : --zone 2 创建网卡(虚拟 NIC)az network nic create \ --name $t_NICName1 \ --location $t_Location \ --resource-group $t_ResourceGroupName \ --vnet-name $t_VnetName \ --subnet $t_SubnetName \ --network-security-group $t_NSGName \ --public-ip-address $t_PIPName1 ## 如果虚拟网络不再同一个资源组里，必须指定子网id，而不是子网名和虚拟网络名 ## --subnet &quot;/subscriptions/91913983-c6cc-4aea-a712-87dd97b5c85b/resourceGroups/tada-web-rg01e/providers/Microsoft.Network/virtualNetworks/tada-web-vnet-101e/subnets/tada-web-snet-102e&quot; 获取托管磁盘IDmanagedDiskId=$(az disk show --name $t_ManagedDiskName --resource-group $t_ResourceGroupName --query [id] -o tsv) 从托管磁盘中创建vmaz vm create --name $t_VMName1 \ --resource-group $t_ResourceGroupName \ --nics $t_NICName1 \ --attach-os-disk $managedDiskId \ --os-type $t_OS_Type \ --size $t_Size \ --availability-set $t_HASetName \ --os-disk-caching ReadOnly ## 多块网卡只需空格隔开，如：--nics $t_NICName11 $t_NICName11 上传本地vhd创建虚机## 获取存储账户密匙 storageAccountKey=$(az storage account keys list \ --account-name $t_StorageAccountName \ --resource-group $t_ResourceGroupName \ --query [0].value --output tsv) az storage blob upload --account-name $t_StorageAccountName \ --container-name $t_StorageContainerName \ --account-key $storageAccountKey \ --type page \ --file /path/to/disk/mydisk.vhd \ --name $t_VHDFileName az disk create \ --resource-group $t_ResourceGroupName \ --name $t_ManagedDiskName \ --sku $t_Sku \ --size-gb $t_DiskSize \ --source https://mystorageaccount.blob.core.chinacloudapi.cn/mydisks/myDisk.vhd 从自定义映像创建虚机## 用vhd或托管磁盘创建虚机映像 az image create --os-type Windows -g $t_ResourceGroupName -n image1 --source myManagedDisk az image create --os-type Windows -g $t_ResourceGroupName -n image1 --source https://mystorageaccount.blob.core.chinacloudapi.cn/mydisks/myDisk.vhd az image list --resource-group $t_ResourceGroupName az image show --name --resource-group [--expand] ## 查看可用虚机大小 az vm list-sizes --location $t_Location --output table az vm list-skus --location $t_Location --output table ## 查看IP地址 az vm list-ip-addresses [--name] --resource-group $t_ResourceGroupName --output table ## 查看自定义虚机映像 az image list --resource-group $t_ResourceGroupName az vm create \ --name $t_VMName1 \ --resource-group $t_ResourceGroupName \ --location $t_Location \ --image mycustomimage \ --vnet-name $t_VnetName \ --subnet $t_SubnetName1 \ --nics t_NICName1\ --availability-set $t_HASetName \ --os-type windows \ --os-disk-caching ReadOnly \ --storage-sku Premium_LRS \ --size Standard_DS2_v2 \ --os-disk-name $t_VMName1&quot;_os&quot; \ --private-ip-address 10.10.0.4/24 \ ## 利用模板创建 https://github.com/Azure/azure-quickstart-templates/tree/master/201-vm-specialized-vhd 托管磁盘复制## 最好先停止虚机或卸载托管磁盘，否则，如果磁盘正在写入数据，无法保证数据一致性，导致某些文件破坏或程序用不了。 ## 获取托管磁盘ID managedDiskId=$(az disk show --name $t_ManagedDiskName --resource-group $s_ResourceGroupName --query [id] -o tsv) ## 使用托管磁盘ID复制托管磁盘到不同的订阅或组 az account set --subscription $t_SubscriptionId az disk create --resource-group $t_ResourceGroupName --name $t_ManagedDiskName --source $managedDiskId 托管磁盘直接导出## 参考：https://docs.azure.cn/zh-cn/articles/azure-operations-guide/virtual-machines/aog-virtual-machines-howto-export-managed-disks ## 创建导出http url连接,相当于图像界面的export导出磁盘连接 ## 如果是镜像，只需把az disk 换成 az snapshot sas=$(az disk grant-access \ --duration-in-seconds 3600 \ --name $t_ManagedDiskName \ --resource-group $s_ResourceGroupName \ --query [accessSas] -o tsv) ## 复制 az storage blob copy start \ --destination-blob $t_VHDFileName \ --destination-container $t_StorageContainerName \ --account-name $t_StorageAccountName \ --account-key $storageAccountKey \ --source-uri $sas 导出blob## 可以外网直接下载访问 存储参考： https://azurecitadel.github.io/guides/cli/cli-4-bash/ blob=azuredeploy.json container=templates expiry=$(date &apos;+%Y-%m-%dT%H:%MZ&apos; --date &quot;+30 minutes&quot;) export accountName=$(az storage account list --resource-group ExampleResourceGroup --query [0].name --output tsv) storageAccountKey=$(az storage account keys list --account-name $accountName --resource-group ExampleResourceGroup --query [0].value --output tsv) sasToken=$(az storage blob generate-sas --account-name $accountName --account-key $storageAccountKey --container-name templates --name azuredeploy.json --permissions r --expiry $expiry --output tsv) shortURL=$(az storage blob url --container-name $container --name $blob) fullURL=$shortURL?$sasToken echo $fullURL]]></content>
      <categories>
        <category>azurecli</category>
        <category>vm</category>
      </categories>
      <tags>
        <tag>azurecli</tag>
        <tag>vm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Azure cli 扩展执行bash命令]]></title>
    <url>%2Fazure%2Fazure_cli%2FAzure%20cli%20%E6%89%A9%E5%B1%95%E6%89%A7%E8%A1%8Cbash%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[清空sudoers.d目录下ceph文件12345678910111213141516171819202122## 切换到中国Azure云az cloud set -n AzureChinaCloud## 登陆az login## 显示订阅az account list --output table## 通过订阅名切换活动的订阅，也可以使用订阅id。只有一个订阅的账户就可以省略订阅切换az account set --subscription &lt;Name|SubscriptionId&gt;## 通过扩展在虚机上执行bash命令az vm extension set \--publisher Microsoft.Azure.Extensions \--version 2.0 \--name CustomScript \--vm-name myvm01 \--resource-group mygroup02 \--settings '&#123;"commandToExecute":"echo &gt; /etc/sudoers.d/ceph"&#125;']]></content>
      <categories>
        <category>azurecli</category>
        <category>vm</category>
      </categories>
      <tags>
        <tag>azurecli</tag>
        <tag>vm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ceph 手动部署]]></title>
    <url>%2Fceph%2F%E6%89%8B%E5%8A%A8%E9%83%A8%E7%BD%B2Ceph%20mon%20osd%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/for_tech/article/details/77247665 https://blog.csdn.net/for_tech/article/details/77188121 https://blog.csdn.net/signmem/article/details/78565488 所有 Ceph 集群都需要至少一个监视器、且 OSD 数量不小于副本数。自举引导初始监视器是部署 Ceph 存储集群的第一步，监视器的部署也为整个集群奠定了重要框架，如存储池副本数、每个 OSD 拥有的归置组数量、心跳周期、是否需认证等，其中大多数选项都有默认值，但是建设生产集群时仍需要您熟知它们。 按照安装（快速）里的相同配置，我们能配置起监视器为 vm01（后面可以追加监视器vm02,vm03） ， OSD 节点为 vm02 、 vm03 的集群。 监视器的自举引导 自举引导监视器（理论上是 Ceph 存储集群）需要以下几个条件： 惟一标识符： fsid 是集群的惟一标识，它是 Ceph 作为文件系统时的文件系统标识符。现在， Ceph 还支持原生接口、块设备、和对象存储网关接口，所以 fsid 有点名不符实了。 集群名称： 每个 Ceph 集群都有自己的名字，它是个不含空格的字符串。默认名字是 ceph 、但你可以更改；尤其是运营着多个集群时，需要用名字来区分要操作哪一个。 比如，当你以联盟架构运营多个集群时，集群名字（如 us-west 、 us-east ）将作为标识符出现在 CLI 界面上。注意：要在命令行下指定某个集群，可以指定以集群名为前缀的配置文件（如 ceph.conf 、 us-west.conf 、 us-east.conf 等）；也可以参考 CLI 用法（ ceph --cluster {cluster-name} ）。 监视器名字： 同一集群内的各监视器例程都有惟一的名字，通常都用主机名作为监视器名字（我们建议每台主机只运行一个监视器、并且不要与 OSD 主机复用。短主机名可以用 hostname -s 获取。 监视器图： 自举引导初始监视器需要生成监视器图，为此，需要有 fsid 、集群名（或用默认）、至少一个主机名及其 IP 。 监视器密钥环： 监视器之间通过密钥通讯，所以你必须把监视器密钥加入密钥环，并在自举引导时提供。 管理密钥环： 要使用 ceph 这个命令行工具，你必须有 client.admin 用户，所以你要创建此用户及其密钥，并把他们加入密钥环。 前述必要条件并未提及 Ceph 配置文件的创建，然而，实践中最好创建个配置文件，并写好 fsid 、 mon initial members 和 mon host 配置。 你也可以查看或设置运行时配置。 Ceph 配置文件可以只包含非默认配置， Ceph 配置文件的配置将覆盖默认值，把这些配置保存在配置文件里可简化维护。 具体过程如下： 前期准备1) 配置主机名和IP123456hostnamectl set-hostname vm01;nmcli connection modify ens33 ipv4.address "200.200.200.221/24" ipv4.dns "1.1.1.1 8.8.8.8" ipv4.gateway "200.200.200.1" ipv4.method manual &amp;&amp; systemctl restart networkhostnamectl set-hostname vm02; nmcli connection modify ens33 ipv4.address "200.200.200.222/24" ipv4.dns "1.1.1.1 8.8.8.8" ipv4.gateway "200.200.200.1" ipv4.method manual &amp;&amp; systemctl restart networkhostnamectl set-hostname vm03; nmcli connection modify ens33 ipv4.address "200.200.200.223/24" ipv4.dns "1.1.1.1 8.8.8.8" ipv4.gateway "200.200.200.1" ipv4.method manual &amp;&amp; systemctl restart network 2) 配置安装源，方式一：1234567891011121314151617181920212223242526272829303132rpm='rpm-luminous'os='el7'#url=http://mirrors.aliyun.com/cephurl=https://download.ceph.comcat &gt; /etc/yum.repos.d/ceph.repo &lt;&lt;EOF[ceph]name=Ceph packages for $basearchbaseurl=$&#123;url&#125;/$&#123;rpm&#125;/$&#123;os&#125;/\$basearchenabled=1priority=1gpgcheck=1gpgkey=$&#123;url&#125;/keys/release.asc[ceph-noarch]name=Ceph noarch packagesbaseurl=$&#123;url&#125;/$&#123;rpm&#125;/$&#123;os&#125;/noarchenabled=1priority=1gpgcheck=1gpgkey=$&#123;url&#125;/keys/release.asc[ceph-source]name=Ceph source packagesbaseurl=$&#123;url&#125;/$&#123;rpm&#125;/$&#123;os&#125;/SRPMSenabled=0priority=1gpgcheck=1gpgkey=$&#123;url&#125;/keys/release.ascEOF 2) 配置安装源，方式二：1234567891011cat &gt; /etc/yum.repos.d/ceph.repo &lt;&lt;EOF[ceph-noarch]name=Ceph noarch packagesbaseurl=https://download.ceph.com/rpm/el7/x86_64#baseurl=https://download.ceph.com/rpm-luminous/el7/x86_64/enabled=1gpgcheck=1type=rpm-mdgpgkey=https://download.ceph.com/keys/release.ascEOF 3) 软件安装1234567yum install ceph -y# 系统时钟同步yum install chrony -ysystemctl enable chronydsystemctl start chronyd 4） 防火墙，selinux，权限1234## ceph Monitors 之间默认使用 6789 3300 端口通信， OSD 之间默认用 6800:7300 这个范围内的端口通信firewall-cmd --add-service=&#123;ceph,ceph-mon&#125; --permanent &amp;&amp; firewall-cmd --reload selinux 安全相关： 日志文件上下文为 ceph_log_t，默认路径:/data/ceph/log 日志文件上下文为 ceph_var_lib_t，默认路径:/data/ceph/log ceph 默认用户为ceph, 如果更改其它用户，那么/data/ceph/log /data/ceph/log 目录所有者必须改为ceph，/data/ceph/log权限默认为0750 4）创建ceph用户,在每节点ceph的用户uid gid 和用户名都要一致12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273groupadd ceph.admin --gid 2000useradd ceph.admin --uid 2000 --gid 2000# 为ceph.admin设置一个256位的密码,至少包含20个(数字,小写/大写字母,特殊字符)yum -y install expectmkpasswd -l 256 -d 20 -c 20 -C 20 -s 20 -v ceph.admin# 这里用一个32位的密码方便操作mkpasswd -l 32 -d 4 -c 4 -C 4 -s 4 -v ceph.adminecho 'i53pwDKquIVwsf^npbzxkt4z&#125;5mit%o!' | passwd --stdin ceph.admin## 同时需要修改service 文件，更改启动用户名vi /usr/lib/systemd/system/ceph-mon@.serviceExecStart=/usr/bin/ceph-mon -f --cluster $&#123;CLUSTER&#125; --id %i --setuser ceph.admin --setgroup ceph.adminvi /usr/lib/systemd/system/ceph-osd@.serviceExecStart=/usr/bin/ceph-osd -f --cluster $&#123;CLUSTER&#125; --id %i --setuser ceph.admin --setgroup ceph.adminvi /usr/lib/systemd/system/ceph-mds@.serviceExecStart=/usr/bin/ceph-mds -f --cluster $&#123;CLUSTER&#125; --id %i --setuser ceph --setgroup cephsystemctl daemon-reload## 使用sed修改启动用户sed -i "s/--setuser ceph --setgroup ceph/--setuser ceph.admin --setgroup ceph.admin/" /usr/lib/systemd/system/ceph-&#123;mon,mds,osd,mgr&#125;@.service## 使用sed 修改启动集群名sed -i "s/Environment=CLUSTER=ceph.*/Environment=CLUSTER=cephfs/" /usr/lib/systemd/system/ceph-&#123;mon,mds,osd,mgr&#125;@.service ## 修改osd存储所有者检查sed -i "s#if \[ \$owner != 'ceph' -a \$owner \!= 'root' \]; then#if [ \$owner \!= 'ceph' -a \$owner != 'ceph.admin' -a \$owner \!= 'root' ]; then#" /usr/lib/ceph/ceph-osd-prestart.sh##sed -i "s#data=\"/var/lib/ceph/osd/\$\&#123;cluster\:-ceph\&#125;-\$id\"#data=\"/data/ceph/osd/\$\&#123;cluster\:-ceph\&#125;-\$id\"#" /usr/lib/ceph/ceph-osd-prestart.sh##data=\"/data/ceph/osd/\$\&#123;cluster\:-ceph\&#125;-\$id\"#修改目录权限mkdir -p /data/ceph/&#123;mon,log,osd,mgr&#125;chown -R ceph.admin:ceph.admin /data/cephchown -R ceph.admin:ceph.admin /data/ceph/logchown -R ceph.admin:ceph.admin /var/run/cephyum -y install policycoreutils-pythonsemanage fcontext -a -t ceph_var_lib_t "/data/ceph(/.*)?"restorecon -RFv /data/cephsemanage fcontext -a -t ceph_log_t "/data/ceph/log(/.*)?"restorecon -RFv /data/ceph/logsemanage fcontext -a -t ceph_var_run_t "/var/run/ceph(/.*)?"restorecon -RFv /var/run/ceph## ceph 如果不采用默认用户，centos开机会自动创建/run/ceph目录及所有者，此时需要修改所有者权限,修改如下vi /usr/lib/tmpfiles.d/ceph-common.confd /run/ceph 0770 ceph.admin ceph.admin -或echo 'd /run/ceph 0770 ceph.admin ceph.admin -' &gt; /usr/lib/tmpfiles.d/ceph-common.conf# 说明下面仍然使用的是ceph默认创建的ceph用户，可以在配置好后启动正常，再修改成ceph.admin运行 5）授权root权限,且无须输入密码12345678910111213echo 'ceph.admin ALL = (ALL) NOPASSWD: ALL' | tee /etc/sudoers.d/cephchmod 0440 /etc/sudoers.d/ceph或者:echo 'ceph.admin ALL = (ALL) NOPASSWD: ALL' &gt;&gt; /etc/sudoers或者:这种方式 sudo -i 会提示输入密码, 所以不能用echo 'ceph.admin ALL = (ALL) ALL' &gt;&gt; /etc/sudoersecho 'ceph.admin ALL = (root) NOPASSWD: ALL' | tee /etc/sudoers.d/ceph 6) 配置无密钥登陆，切换至ceph.admin用户123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 # 分别更改计算机名sudo hostnamectl set-hostname vm01cat &gt; ~/.ssh/config &lt;&lt;EOF Host vm01 Hostname vm01 User ceph.admin Host vm02 Hostname vm02 User ceph.admin Host vm03 Hostname vm03 User ceph.adminEOFchmod 0600 ~/.ssh/configsudo cat &gt; /etc/hosts &lt;&lt;EOF 200.200.200.221 vm01 200.200.200.222 vm02 200.200.200.223 vm03EOF# 切换至ceph.admin用户，生成公钥以及私钥于当前用户.ssh目录下，id_rs is_rsa.pubcd ~/.sshssh-keygen -q -t rsa -b 2048 -C "ceph admin key" -P ''# 将生成的密钥拷贝到各个Ceph节点的ceph.admin用户的 ~/.ssh/目录下sudo ssh-copy-id -i ~/.ssh/id_rsa.pub ceph.admin@vm01sudo ssh-copy-id -i ~/.ssh/id_rsa.pub ceph.admin@vm02sudo ssh-copy-id -i ~/.ssh/id_rsa.pub ceph.admin@vm03## 或者直接复制现成的mkdir /home/ceph.admin/.sshcat &gt; /home/ceph.admin/.ssh/id_rsa &lt;&lt;EOF-----BEGIN RSA PRIVATE KEY-----MIIEpAIBAAKCAQEAtQop88+8WRyg5XrUBycsQ+hyOmEXUjKTbGbVVq8QUxeirXRTuVXgBi6yN+YBEIUmLc7mnaoHqJvgvBWbrzYOujNSqMSeFbbcgHjPpYXzouOCA+2Xz4YbJ5BwmUrm/mF9M3XAqCOpBdvpfiMc97fYBtdL1uidtay1zw4lxNURme57nuKzokZxB+IgO98Dtnflonip3kYzJuO/clBUeTWdce8smXlCSXhZuVEKqaf/DCKpUB8biAnIYoG3ipebte4vJMzMBkTmz3InRDhSzWDX8//2xv7BzVpDJNq74wz8WNZ5vp7HtgD7sDqtomtgTGgfaOB64bbDTCx4h0jVKl+srwIDAQABAoIBAFdrRwLCRvLIzjDBdOzXT5qi/bWO+JHqdiGcLlwjQMC+4wDa8SrHetvBZLF1UQJHKT5pcBal6fjS/FwWGw0qD0Z+TeXMu4FEwYkPzUTiP9lh/oAjFHFTEn2yU4zSDGS9cpWMwLDwN0fq/v63ud8sWRZElAx8WttFQK1w6W/4av1myLWjiq12ZxZjHIvUBGF+7hkkHv/rDFicQLGc+JSqlOMt7RVrW0NW+mqYzupmctADwJ7LitESVieZ2wKPv7aGyYRP+Odu5UFPkv2i7fWvUYbGGg9Oj/XKFjKoFID2R8lulzrTowX0ROIB+5xm1J7ekWhI1IkLVRG41BEI2QXvGnECgYEA57kI6cqRrs8/9tfhVRj89mFeO7RyBxC72rEpn3P1CFa1/GvWVElWU1EaIhGBELhIh9SPaVBA7DulRuoFTQYALJ7KhIGjplYIn7vYl3mWqZFOfEng4CUc47jxp+1fjY7yfyjVr1jC8fkQDImnf1wG8+Y4h+qOYfWqU/mahFNd0CUCgYEAyAHGDCsVdLvTwkY7tepy/nZD/jRcZad0VCXaFPb9O6N1wppz5FHiIt6NxweEYxqKo2lf9IOv4ski3LMO1bLWgF7w2EKSntg23t+MBFJnesgrvHzSClQLQBfPU+xFaXv4Mnz55GaRMO5cuPUm0i+pgQJnQkadIHfF7zZjTz99d0MCgYEA0CdIWXNtUIG9rMiaEu5idhRbKPjcIXqntTjF8gWhDD+QNNLN8mL6l9dXyVi9/r378YBA31KHL24Y9s3LuzfzuiFePI+T6RyJnKuKUe+YJnRv83gN+Gt+OxXshnPWDPxm21FcOqpaXDDmeMzC2MZbPIcHKxjJlDexLMQgSFP3Br0CgYAG6ljIruys/pmRzA/geFzFg51SOsk/Eo0pI63or6mN2FcIBYMgT9x7zComyZHAQ3irsccJk0wPkVjNPLu0k9xqz92P/K1JJLyw9BXJSHgffLBWchJpHQLOkoQuqKq1vP2V8VBKn2lBwdwe4QsYlWFM/qJHXl2sc7e6T60bXlyeNQKBgQDhWxjRHZZkYmi3qNiGLDNSHrNUSdYZWFT5iyqtJBtnay5L3o1VYj3yJVrTKbjpa0YEiDY5mPWZVpzP9mkUCIjkJUUENcsy7w+I151z5y4oSQZl1Xbok5zrHxBzKfMQNJ53nlil9zLJkbHqUFj5U44sCrbfLImkH9SCQUQr+qKMWA==-----END RSA PRIVATE KEY-----EOFcat &gt; /home/ceph.admin/.ssh/id_rsa.pub &lt;&lt;EOFssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC1Cinzz7xZHKDletQHJyxD6HI6YRdSMpNsZtVWrxBTF6KtdFO5VeAGLrI35gEQhSYtzuadqgeom+C8FZuvNg66M1KoxJ4VttyAeM+lhfOi44ID7ZfPhhsnkHCZSub+YX0zdcCoI6kF2+l+Ixz3t9gG10vW6J21rLXPDiXE1RGZ7nue4rOiRnEH4iA73wO2d+WieKneRjMm479yUFR5NZ1x7yyZeUJJeFm5UQqpp/8MIqlQHxuICchigbeKl5u17i8kzMwGRObPcidEOFLNYNfz//bG/sHNWkMk2rvjDPxY1nm+nse2APuwOq2ia2BMaB9o4HrhtsNMLHiHSNUqX6yv ceph admin keyEOFcat &gt; /home/ceph.admin/.ssh/authorized_keys &lt;&lt;EOFssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC1Cinzz7xZHKDletQHJyxD6HI6YRdSMpNsZtVWrxBTF6KtdFO5VeAGLrI35gEQhSYtzuadqgeom+C8FZuvNg66M1KoxJ4VttyAeM+lhfOi44ID7ZfPhhsnkHCZSub+YX0zdcCoI6kF2+l+Ixz3t9gG10vW6J21rLXPDiXE1RGZ7nue4rOiRnEH4iA73wO2d+WieKneRjMm479yUFR5NZ1x7yyZeUJJeFm5UQqpp/8MIqlQHxuICchigbeKl5u17i8kzMwGRObPcidEOFLNYNfz//bG/sHNWkMk2rvjDPxY1nm+nse2APuwOq2ia2BMaB9o4HrhtsNMLHiHSNUqX6yv ceph admin keyEOF# .ssh 目录权限0700, .ssh/authorized_keys 文件权限0440, 所有者和组权限都是ceph.adminsudo chmod 0700 /home/ceph.admin/.sshsudo chmod 0600 /home/ceph.admin/.ssh/*sudo chown -R ceph.admin:ceph.admin /home/ceph.admin/.ssh 修改配置文件1） 创建/etc/ceph/{cluster name}.conf，最小模板： [global] fsid = {fsid} mon initial members = {hostname}[,{hostname}] mon host = {ip}[,{ip}] 完整示例版： # yum 安装的ceph 默认集群名就是ceph。如果集群名为其它，比如cephfs, 那么集群配置文件名必须是cephfs.conf ## 如果集群名为其它(比如cephfs), 那么集群配置文件名必须是cephfs.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165cat &gt; /etc/ceph/cephfs.conf &lt;&lt; EOF[global] cluster = cephfs ## 用UUID生成 fsid = a7f64266-0894-4f1e-a635-d0aeaca0e993 public network = 10.100.100.0/24 cluster network = 10.100.100.0/24 auth cluster required = cephx auth service required = cephx auth client required = cephx osd pool default size = 3 osd pool default min size = 2 osd pool default pg num = 128 osd pool default pgp num = 128 ## osd pg 数量限制，pool最大pg数量=(osd数量*mon max pg per osd)/osd pool default size/pool count mon allow pool delete = true mon max pg per osd = 1024 osd max pg per osd hard ratio = 8 osd journal size = 1024 #osd pool default crush rule = 0 osd crush chooseleaf type = 1 admin socket = /var/run/ceph/\$cluster-\$name.asock pid file = /var/run/ceph/\$cluster-\$name.pid log file = /data/ceph/log/\$cluster-\$name.log log to syslog = false max open files = 131072 ## 网路地址如果使用ipv6 则改为true ms bind ipv6 = false[mon] mon initial members = web01,web02,web03 # 这里可以写IP[:port] 或者能解析的计算机名 mon host = 10.100.100.4:6789,10.100.100.5:6789,10.100.100.6:6789 mon data = /data/ceph/mon/\$cluster-\$name #mon clock drift allowed = 10 #mon clock drift warn backoff = 30 # 在被OSD进程使用之前一个硬盘的百分比​被认为是充分的。 mon osd full ratio = .95 # 在被OSD进程使用之前一个硬盘的百分比​被认为是近似充分的 mon osd nearfull ratio = .85 #mon osd down out interval = 600 #mon osd report timeout = 300 #debug ms = 20 #debug mon = 20 #debug paxos = 20 #debug auth = 20 #mon allow pool delete = true[mon.web01] host = web01 mon addr = 10.100.100.4:6789[mon.web02] host = web02 mon addr = 10.100.100.5:6789[mon.web03] host = web03 mon addr = 10.100.100.6:6789[mgr] mgr data = /data/ceph/mgr/\$cluster-\$name mgr initial modules = dashboard[mds] mds data = /data/ceph/mds/\$cluster-\$name keyring = /data/ceph/mds/\$cluster-\$name/keyring[mds.web01] host = web01 mds standby replay = true mds standby for rank = 0[mds.web02] host = web02 mds standby replay = true mds standby for rank = 0[mds.web03] host = web03 mds standby replay = true mds standby for rank = 0[osd] bluestore = true bluestore fsck on mount = true osd objectstore = bluestore osd data = /data/ceph/osd/\$cluster-\$id osd journal = /data/ceph/osd/\$cluster-\$id/journal bluestore block path = /dev/disk/by-partlabel/bluestore_block_\$id bluestore block db path = /dev/disk/by-partlabel/bluestore_block_db_\$id bluestore block wal path = /dev/disk/by-partlabel/bluestore_block_wal_\$id[osd.1] host = web01 addr = 10.100.100.4[osd.2] host = web02 addr = 10.100.100.5[osd.3] host = web03 addr = 10.100.100.6EOF## osd 其它配置方式[osd] #run_dir = /data/ceph/osd/$cluster-$id osd journal = /data/ceph/osd/$cluster-$id/journal osd data = /data/ceph/osd/$cluster-$id osd recovery max active = 3 osd max backfills = 5 osd max scrubs = 2 osd mkfs type = xfs osd mkfs options xfs = -f -i size=1024 osd mount options xfs = rw,noatime,inode64,logbsize=256k,delaylog filestore max sync interval = 5 osd op threads = 2 #debug ms = 10 #debug osd = 100 ## 如果osd存储磁盘的文件系统是ext4，不是xfs，启动会报错osd init failed (36) File name too long，则添加下面两行 #osd max object name len = 256 #osd max object namespace len = 64 ## ext4 系统文件格式必须添加，并且磁盘加载项需要添加user_xattr，如:defaults,user_xattr #filestore xattr use omap = true [osd.1] host = vm01 addr = 200.200.200.221 [osd.2] host = vm02 addr = 200.200.200.222 [osd.3] host = vm03 addr = 200.200.200.223 # 客户端keyring配置 [client.admin] keyring = /etc/ceph/ceph.client.admin.keyring 注意： 你也可以写 IPv6 地址，但是必须设置 ms bind ipv6 = true 添加第一个mon## 创建mon所需的密钥和目录1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556## 注意: keyring和conf等文件名必须以&lt;集群名&gt;.开头, 创建的目录也需要以&lt;集群名&gt;.开头## mon 权限ceph-authtool --create-keyring /etc/ceph/ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'## ceph集群管理员admin权限ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow' --cap mgr 'allow *'#ceph-authtool --create-keyring /data/ceph/bootstrap-osd/ceph.keyring --gen-key -n client.bootstrap-osd --cap mon 'profile bootstrap-osd'## 创建集群密匙文件, 没产生密匙，其实用touch创建也可以ceph-authtool --create-keyring /etc/ceph/ceph.keyring## 将密匙导入集群密匙文件中ceph-authtool /etc/ceph/ceph.keyring --import-keyring /etc/ceph/ceph.mon.keyringceph-authtool /etc/ceph/ceph.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring#ceph-authtool /etc/ceph/ceph.keyring --import-keyring /data/ceph/bootstrap-osd/ceph.keyring## 创建monmap文件# 注意，如果这里了的IP地址后面加端口号，ceph.conf ip地址后面也必须加了端口号，否则报warning,导致服务器启动不了monmonmaptool --create --add vm01 200.200.200.221:6789 --fsid a7f64266-0894-4f1e-a635-d0aeaca0e993 /etc/ceph/monmapmonmaptool --add vm02 200.200.200.222:6789 --fsid a7f64266-0894-4f1e-a635-d0aeaca0e993 /etc/ceph/monmapmonmaptool --add vm03 200.200.200.223:6789 --fsid a7f64266-0894-4f1e-a635-d0aeaca0e993 /etc/ceph/monmap## 初始化mon# 在vm01(,vm02,vm03) 虚机上分别执行，注意第三行的权限修改，否则无法启动ceph， ceph默认是使用ceph用户启动# 此步会自动根据配置文件，创建目录 /data/ceph/mon/ceph-mon.vm01 ceph-mon --cluster ceph --conf /etc/ceph/ceph.conf --mkfs -i vm01 --monmap /etc/ceph/monmap --keyring /etc/ceph/ceph.keyring## done 表示mon准备好了，upstart表示系统启动时可以自动启动touch /data/ceph/mon/ceph-mon.vm01/&#123;done,upstart&#125;chown -R ceph.admin:ceph.admin /data/ceph/monsystemctl start ceph-mon@vm01## 查看monmapmonmaptool --print /etc/ceph/monmap## 查看ceph 状态## 如果集群名不是ceph, 需要添加--cluster &lt;其它集群名&gt;ceph -sceph -s --cluster cephfsceph health detailceph health detail --cluster cephfs # 以下是解释说明： 2）创建 mon keyring： ceph-authtool --create-keyring /etc/ceph/{cluster name}.mon.keyring --gen-key -n mon. --cap mon &apos;allow *&apos; 3)创建administrator keyring： ceph-authtool --create-keyring /etc/ceph/{cluster name}.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon &apos;allow *&apos; --cap osd &apos;allow *&apos; --cap mds &apos;allow&apos; 4) 把client.admin的key加入mon.keyring： ceph-authtool /etc/ceph/{cluster name}.keyring --import-keyring /etc/ceph/{cluster name}.client.admin.keyring 5) 创建monmap：使用hostname、IP、FSID生成一个monitor map monmaptool --create --add {hostname} {ip-address} --fsid {uuid} /etc/ceph/monmap 6) 创建mon的数据路径：在monitor主机上创建默认的数据目录 mkdir /data/ceph/mon/{cluster-name}-{hostname} 7) 初始化mon,提供monmap和keyring给monitor deamon： ceph-mon [ --cluster {cluster-name} ] --mkfs -i {hostname} --monmap /etc/ceph/monmap --keyring /etc/ceph/{cluster name}.mon.keyring 8) 配标记monitor配置好了，可以启动 touch /data/ceph/mon/{cluster-name}-{hostname}/done 9） 修改权限 chown -R ceph.admin:ceph.admin /data/ceph/mon 10） 启动monitor systemctl start ceph-mon@vm01 如果启动出错，尝试运行下面命令，再重启程序 systemctl reset-failed ceph-mon@vm01.service 11） 查看集群状态，ceph -s，因为此时还没有OSD，所以集群是HEALTH_ERR状态，pg都是creating状态 添加其他monitor节点## 从第一个mon节点复制文件到新mon节点 sudo chown -R ceph.admin /etc/ceph scp /etc/ceph/{ceph*,monmap} ceph.admin@web01:/etc/ceph/ 需要从第一个节点拷贝4个文件,keyring的文件权限0600： /etc/ceph/{cluster-name}.keyring /etc/ceph/monmap /etc/ceph/{cluster-name}.client.admin.keyring /etc/ceph/{cluster-name}.conf 接下来只需要几步，具体命令参考第一个节点： 创建mon的数据路径,后面一条命令会自动创建，此命令可以不用执行 mkdir /data/ceph/mon/ceph-mon.vm02 提供monmap和keyring给monitor deamon ## 添加mon节点12345678910host_name=vm02ceph-mon --cluster ceph --conf /etc/ceph/ceph.conf --mkfs -i $host_name --monmap /etc/ceph/monmap --keyring /etc/ceph/ceph.mon.keyringtouch /data/ceph/mon/ceph-mon.$host_name/&#123;done,upstart&#125;chown -R ceph.admin:ceph.admin /data/ceph/monsystemctl start ceph-mon@$host_name 手动部署osd## 需要确保 osd 数据盘有读写权限 chown -R ceph.admin:disk /dev/sdc{2,3,4} ## bash 命令123456789101112131415161718192021222324252627282930313233osd_uuid=$(uuidgen)osd_num=1cluser_name=cephfshost_name=web01ceph osd create --cluster $cluser_name $osd_uuid $osd_nummkdir /data/ceph/osd/$cluser_name-$osd_nummkdir /data/ceph/osd/$cluser_name-$osd_num/journalecho "bluestore" &gt; /data/ceph/osd/$cluser_name-$osd_num/typeceph-osd --cluster $cluser_name -i $osd_num --mkfs --mkjournal --mkkey --osd-uuid $osd_uuid ceph auth add --cluster $cluser_name osd.$osd_num osd 'allow *' mon 'allow profile osd' -i /data/ceph/osd/$cluser_name-$osd_num/keyringceph --cluster $cluser_name&gt; osd crush add-bucket $host_name host &gt; osd crush move $host_name root=default&gt; osd crush add osd.$osd_num 1.0 host=$host_nameceph osd tree --cluster $cluser_nametouch /data/ceph/osd/$cluser_name-$osd_num/&#123;done,upstart&#125;sudo chown -R ceph.admin:ceph.admin /data/ceph/osdsudo systemctl start ceph-osd@$osd_num 1）产生用于osd 的 uuid， 每个osd都需要一个唯一的uuid uuidgen 270cac2a-359d-4ebd-9713-612f81fb4bb2 2） 调用 ceph osd create 分配OSD编号：ceph osd create {uuid} {osd数字编号} ## ceph osd create [{uuid} [{id}]] ceph osd create 270cac2a-359d-4ebd-9713-612f81fb4bb2 1 --cluster ceph 3） 调用 ceph-osd -i {osd数字编号} --mkfs --mkkey --osd-uuid {uuid} 初始化OSD目录： # 必须先创建对应的目录ceph-osd.1 为{集群名}-{osd.数字编号},这里osd 的id只能用数字不能用字符 mkdir /data/ceph/osd/ceph-1 mkdir /data/ceph/osd/ceph-1/journal ceph-osd -i 1 --mkfs --mkjournal --mkkey --osd-uuid 270cac2a-359d-4ebd-9713-612f81fb4bb2 # 上面的命令会初始化目录，并产生一个授权文件/data/ceph/osd/ceph-osd.1/keyring 4） 添加osd授权 ceph auth add osd.1 osd &apos;allow *&apos; mon &apos;allow profile osd&apos; -i /data/ceph/osd/ceph-1/keyring 到这里，OSD的准备工作就已经做好了，可以启动OSD了，在启动之前，也可以先初始化一下crush map。 osd.1 这是虚拟节点，1是{osd数字编号} 5) 添加一个host节点vm01 #添加一个host节点vm01 ceph osd crush add-bucket vm01 host # 将vm01移到default下 ceph osd crush move vm01 root=default # 将osd.1以1.0的权重加到vm01中 ceph osd crush add osd.1 1.0 host=vm01 # 查看当前OSD Tree ceph osd tree osd.1添加到vm01，osd.2添加到vm02，osd.3添加到vm03。这么做目的是因为Ceph默认分配的策略是至少有一份数据在其他机器上. 6）修改权限 #用systemctl启动必须添加空文件sysvinit,否则只能手工启动 touch /data/ceph/osd/ceph-1/{done,upstart} ##touch /data/ceph/osd/ceph-1/sysvinit chown -R ceph.admin:ceph.admin /data/ceph/osd 7) 启动osd # 启动osd ceph-osd -i 1 #或者如下方式启动 systemctl start ceph-osd@1 或手工启动 /usr/bin/ceph-osd -i 1 --pid-file /var/run/ceph/osd.1.pid -c /etc/ceph/ceph.conf --cluster ceph --osd-data=/data/ceph/osd/ceph-1 --osd-journal=/data/ceph/osd/ceph-1/journal # 查看当前OSD Tree ceph osd tree # 查看集群状态 ceph -s ## 用systemctl 启动不了osd, 需要修改ceph-osd-prestart.sh，此文件在启动文件里有运行 ## 查看 # vi /usr/lib/systemd/system/ceph-osd@.service ExecStartPre=/usr/lib/ceph/ceph-osd-prestart.sh --cluster ${CLUSTER} --id %i ## 修改，自定义的目录路径和运行用户名 vi /usr/lib/ceph/ceph-osd-prestart.sh ...... #data=&quot;/var/lib/ceph/osd/${cluster:-ceph}-$id&quot; data=&quot;/data/ceph/osd/${cluster:-ceph}-$id&quot; ...... if [ $owner != &apos;ceph.admin&apos; -a $owner != &apos;ceph&apos; -a $owner != &apos;root&apos; ]; then 6) 分别在vm02 vm03， 执行上述命令，{osd数字编号}要修改 OSD使用ceph-disk初始化初始化完mon之后，添加OSD只需要几个简单的命令。 使用ceph-disk 初始化硬盘或分区或文件夹： ceph-disk prepare --cluster {cluster-name} --cluster-uuid {uuid} --fs-type {ext4|xfs|btrfs} {data-path} [{journal-path}] 如: sudo ceph-disk prepare --cluster ceph --cluster-uuid a7f64266-0894-4f1e-a635-d0aeaca0e993 --fs-type ext4 /dev/sdb 需要注意的是，这里所说的journal-path，实践中发现其实应该填写的是一个block device或者一个文件名，而不是一个文件夹。如果data-path是文件夹，fs-type选项可以忽略。 激活OSD： ceph-disk activate {data-path} [--activate-key {path}] 其中的参数activate-key是可选的，用来指定/data/ceph/bootstrap-osd/{cluster}.keyring的位置。这个keyring是在ceph-mon mkfs时生成的，所以需要从刚才初始化的mon节点里拷贝过来。 OSD 使用bluestore## 下面的 osd_data_1/bluestore_block_db_1等，表示 osd 1 的分区，确保label系统中唯一 ## 要想使用识别某类盘，需要使用 --typecode= 参数 ## 清除所有的分区信息 # sgdisk --zap-all /dev/sdb ## 创建osd data 分区，用于存放keyring等信息文件 # sgdisk --new=1:0:+1GB --change-name=1:osd_data_1 --partition-guid=1:$(uuidgen) --mbrtogpt -- /dev/sdb ## 创建block db wal # sgdisk --new=2:0:+1GB --change-name=2:bluestore_block_db_1 --partition-guid=2:$(uuidgen) --mbrtogpt -- /dev/sdb # sgdisk --new=3:0:+1GB --change-name=3:bluestore_block_wal_1 --partition-guid=3:$(uuidgen) --mbrtogpt -- /dev/sdb # sgdisk --new=4:0:+15GB --change-name=4:bluestore_block_1 --partition-guid=4:$(uuidgen) --mbrtogpt -- /dev/sdb ## 记得更改磁盘的权限，系统重启会导致权限恢复到默认值，导致无法启动osd chown -R root:ceph.admin /dev/sdb{1,2,3,4} 或者 chown -R ceph.admin:disk /dev/sdb{1,2,3,4} 为防止系统重启权限恢复默认值： 添加udev规则设置分区权限 # vi /etc/udev/rules.d/20-ceph-osd.rules KERNEL==&quot;sdb*&quot;, SUBSYSTEM==&quot;block&quot;, ENV{DEVTYPE}==&quot;partition&quot;, OWNER=&quot;ceph.admin&quot;, GROUP=&quot;ceph.admin&quot;, MODE=&quot;0660&quot; 或者,下面这一条重启不能生效， 必须手动触发udev命令，其中bluestore就是gpt自定义的label KERNEL==&quot;sd*&quot;, SUBSYSTEM==&quot;block&quot;, ENV{DEVTYPE}==&quot;partition&quot;,PROGRAM==&quot;/usr/bin/udevadm info $devnode | grep ID_PART_ENTRY_NAME&quot;, RESULT==&quot;*bluestore*&quot;, OWNER=&quot;ceph.admin&quot;, GROUP=&quot;ceph.admin&quot;, MODE=&quot;0660&quot; # partx /dev/sdb NR START END SECTORS SIZE NAME UUID 1 2048 2099199 2097152 1G osd_data_1 2f568a34-d89c-4c74-a444-602553e35fbf 2 2099200 4196351 2097152 1G bluestore_block_db_1 5023371f-29e6-4d28-ae4d-f84107c1d368 3 4196352 6293503 2097152 1G bluestore_block_wal_1 cc6995ae-77fa-4a05-88a3-88389bb31a07 4 6293504 41943006 35649503 17G bluestore_block_1 ecd23004-d31f-4603-a8dd-b931902c125d # ls -l /dev/disk/by-partlabel/ | grep _1 lrwxrwxrwx. 1 root root 10 Oct 11 08:27 bluestore_block_1 -&gt; ../../sdb4 lrwxrwxrwx. 1 root root 10 Oct 11 08:27 bluestore_block_db_1 -&gt; ../../sdb2 lrwxrwxrwx. 1 root root 10 Oct 11 08:27 bluestore_block_wal_1 -&gt; ../../sdb3 lrwxrwxrwx. 1 root root 10 Oct 11 08:27 osd_data_1 -&gt; ../../sdb1 # mkfs.xfs /dev/sdb1 # mount /dev/sdb1 /data/ceph/osd/ceph-1 ## 注意初始化osd目录前一定要加入此文件，表示初始时使用bluestore # echo &quot;bluestore&quot; &gt; /data/ceph/osd/ceph-1/type 后面的操作和上面osd设置一样 挂载方式有两种： 1） 配置文件指定： [osd] bluestore = true osd data = /data/ceph/osd/$clust-$id bluestore block path = /dev/disk/by-partlabel/bluestore_block_$id bluestore block db path = /dev/disk/by-partlabel/bluestore_block_db_$id bluestore block wal path = /dev/disk/by-partlabel/bluestore_block_wal_$id 2） osd data 目录下指定软连接 # cd /data/ceph/osd/ceph-1 # ln -sf /dev/disk/by-partlabel/bluestore_block_1 block # ln -sf /dev/disk/by-partlabel/bluestore_block_db_1 block.db # ln -sf /dev/disk/by-partlabel/bluestore_block_wal_1 block.wal [osd] bluestore = true osd data = /data/ceph/osd/$clust-$id MDS手动安装## 添加MDS配置123456789101112131415cat &gt;&gt; /etc/ceph.conf &lt;&lt; EOF [mds] mds data = /data/ceph/mds/$cluster-$name keyring = /data/ceph/mds/$cluster-$name/keyring [mds.vm01] host = vm01 [mds.vm02] host = vm02 [mds.vm03] host = vm03EOF ## 添加MDS节点1234567891011121314cluser_name=cephfshost_name=web01mkdir -p /data/ceph/mds/$cluser_name-mds.$host_name/ceph auth get-or-create --cluster $cluser_name mds.$host_name osd 'allow rwx' mds 'allow' mon 'allow profile mds' -o /data/ceph/mds/$cluser_name-mds.$host_name/keyringceph auth list --cluster $cluser_namechown -R ceph.admin:ceph.admin /data/ceph/mdssystemctl restart ceph-mds@$host_name ## 创建cephfs文件系统123456789cluser_name=cephfsceph mds stat --cluster $cluser_nameceph osd lspools --cluster $cluser_nameceph osd pool create metadata 128 128 --cluster $cluser_nameceph osd pool create data 128 128 --cluster $cluser_nameceph fs new webfs metadata data --cluster $cluser_name 若有使用cephfs，则MDS节点是必要的。 首先从mon节点拷贝/etc/ceph/{cluster-name}.conf 配置文件。 # 实例模板，其中$cluster 为集群名(这里是ceph)，$name 为&lt;节点名&gt;.&lt;mds编号&gt;，比如mds.vm01为$name 则 $id 为vm01 [mds] mds data = /data/ceph/mds/$cluster-$name keyring = /data/ceph/mds/$cluster-$name/keyring [mds.vm01] host = vm01 [mds.vm02] host = vm02 [mds.vm03] host = vm03 创建目录 mkdir -p /data/ceph/mds/ceph-mds.vm01/ 创建keyring：ceph auth get-or-create mds.{mds-number} mds &apos;allow &apos; osd &apos;allow *&apos; mon &apos;allow rwx&apos; &gt; /data/ceph/mds/{cluster}-{mds-number}/keyring。 ceph auth get-or-create mds.vm01 osd &apos;allow rwx&apos; mds &apos;allow&apos; mon &apos;allow profile mds&apos; -o /data/ceph/mds/ceph-mds.vm01/keyring 更改权限 chown -R ceph.admin:ceph.admin /data/ceph/mds 开启MDS systemctl start ceph-mds@vm01 查看状态 ceph mds stat # 列出集群池 ceph osd lspools 需要注意的是，此时通过ceph -s是看不到mds相关信息的，ceph mds stat可以看到MDS不是active的状态。需要先创建一个fs，MDS就会被激活。 使用以下命令创建两个pool，一个用来存储fs的文件数据，一个用来存放fs的元数据：ceph osd pool create {pool-name} {pg-number}。 创建fs：ceph fs new {fs-name} {metadata-pool_name} {data-pool_name}。 此时再看ceph mds stat和ceph -s，就能看到mds为active and up的状态了。 # 先创建一个metadata pool，存放元数据，必须多副本，否则元数据丢了，就无法恢复数据 ceph osd pool create metadata 64 64 # 再创建一个data pool，存放实际数据，最好使用低延时的ssd盘 ceph osd pool create data 64 64 格式： ceph osd pool create {pool-name} {pg-num} [{pgp-num}] [replicated] [crush-rule-name] [expected-num-objects] ceph osd pool create {pool-name} {pg-num} {pgp-num} erasure [erasure-code-profile] [crush-rule-name] [expected_num_objects] # 需要ceph命令创建文件系统testfs，后两参数是metadata和 data的pool ceph fs new testfs metadata data # 获取pool 副本数 # ceph osd pool get metadata min_size # ceph osd pool get metadata size # 获取PG 在osd上的分布 # ceph pg dump | grep ^1 | awk &apos;{print $1,$2,$15}&apos; 1.7c 496 [1,3] 1.7d 517 [3,2] 1.7e 496 [2,1] 1.7f 466 [1,2] mgr 手动安装## 添加mgr配置12345678cat &gt;&gt; /etc/ceph.conf &lt;&lt; EOF [mgr] mgr data = /data/ceph/mgr/$cluster-$name mgr initial modules = dashboardEOF ## 添加mgr节点12345678910111213141516cluser_name=cephfshost_name=web01mkdir /data/ceph/mgr/$cluser_name-mgr.$host_name/ -pceph auth get-or-create --cluster $cluser_name mgr.$host_name mon 'allow profile mgr' osd 'allow *' mds 'allow *' -o /data/ceph/mgr/$cluser_name-mgr.$host_name/keyringchown -R ceph.admin:ceph.admin /data/ceph/mgrsystemctl restart ceph-mgr@$host_nameceph mgr module enable dashboard --cluster $cluser_name --forceceph mgr services --cluster $cluser_name 1) 配置文件添加： [mgr] mgr data = /data/ceph/mgr/$cluster-$name mgr initial modules = dashboard 2) 创建mgr用户,这里权限可能需要修改一下 # ceph auth get-or-create mgr.vm01 mon &apos;allow profile mgr&apos; osd &apos;allow *&apos; mds &apos;allow *&apos; -o /data/ceph/mgr/ceph-mgr.vm01/keyring 如果已创建好了的密匙，则可以直接导入密匙 # ceph-authtool --create-keyring /data/ceph/mgr/ceph-mgr.vm01/keyring --gen-key -n mgr.vm01 --cap mon &apos;allow profile mgr&apos; --cap osd &apos;allow *&apos; --cap mds &apos;allow *&apos; # ceph auth import -i /data/ceph/mgr/ceph-mgr.vm01/keyring # 已有的用户修改权限 # ceph auth caps mgr.vm01 mon &apos;allow profile mgr&apos; osd &apos;allow *&apos; mds &apos;allow *&apos; # 删除用户 # ceph auth del mgr.vm01 3) 导出用户密钥 # mkdir /data/ceph/mgr/ceph-mgr.vm01 # ceph auth get mgr.vm01 -o /data/ceph/mgr/ceph-mgr.vm01/keyring # chown -R ceph.admin:ceph.admin /data/ceph/mgr 4) 服务器地址和可选端口必须配置为 config-key ## 服务器地址新版不需要设置，会自动选定一台mgr地址,多余的当备用机，port 默认端口7000,需要可以修改 # ceph config-key put mgr/dashboard/server_addr 200.200.200.221 # ceph config-key put mgr/dashboard/server_port 8888 ## 启用mgr dashboard模块，先要启动mgr服务,再启用dashboard # systemctl start ceph-mgr@vm01 # ceph mgr module enable dashboard 5) 重启ceph-mgr # systemctl restart ceph-mgr@vm01 需要修改默认启动用户 # vi /usr/lib/systemd/system/ceph-mgr@.service ...... ExecStart=/usr/bin/ceph-mgr -f --cluster ${CLUSTER} --id %i --setuser ceph.admin --setgroup ceph.admin ...... 6) 查看模块 # ceph mgr module ls { &quot;enabled_modules&quot;: [ &quot;balancer&quot;, &quot;dashboard&quot;, &quot;restful&quot;, &quot;status&quot; ], &quot;disabled_modules&quot;: [ &quot;influx&quot;, &quot;localpool&quot;, &quot;prometheus&quot;, &quot;selftest&quot;, &quot;zabbix&quot; ] } 7） 查看访问地址 # ceph mgr services { &quot;dashboard&quot;: &quot;http://vm01:7000/&quot; } 8) 帮助 # ceph mgr help # ceph tell mgr help 客户端挂载cephfs# 客户端安装ceph-common yum install ceph-common # 使用其他用户挂载 添加一个用户, osd 后面不能加 pool=testfs，否则没写入权限 如果后面用户权限更改了，需要重新加载 # ceph auth add client.john mon &apos;allow r&apos; osd &apos;allow rwx&apos; mds &apos;allow&apos; 在服务器上，列出授权用户 # ceph auth list client.john key: AQBie8NZNjGQOBAAagXYD3fSrTwX+sTc+aVjYQ== caps: [mds] allow caps: [mon] allow r caps: [osd] allow rwx 把密钥存入文档 # vi /etc/ceph/john.key AQBie8NZNjGQOBAAagXYD3fSrTwX+sTc+aVjYQ== chmod 0600 /etc/ceph/john.key mkdir -p /mnt/cephfs # 强制卸载挂载 # umount -fl /mnt/cephfs # fstab 加载格式： {ipaddress}:{port}:/ {mount}/{mountpoint} {filesystem-name} [name=username,secret=secretkey|secretfile=/path/to/secretfile],[{mount.options}] 10.100.100.4:6789,10.100.100.5:6789,10.100.100.6:6789:/ /mnt/cephfs ceph name=john,secretfile=/etc/ceph/john.key,noatime,_netdev 0 0 # 语法：mount -t ceph mds_node1:6789,mds_node2:6789,mds_node3:6789:/ client_mount_path -o name=admin,secret=Key_value 删除osd123456789101112131415osd_num=1cluser_name=cephfshost_name=web01ceph osd out osd.$osd_num --cluster $cluser_nameceph -w --cluster $cluser_namesystemctl stop ceph-osd@$osd_numceph osd crush remove osd.$osd_num --cluster $cluser_nameceph osd crush remove $host_name --cluster $cluser_nameceph auth del osd.$osd_num --cluster $cluser_nameceph osd rm $osd_num --cluster $cluser_name 多MDS变成单MDS的方法设置最大mds 多活的mds的max_mds会超过1，这里需要先将max_mds设置为1 ceph mds set max_mds 1 deactive mds ceph mds deactivate 1 重设ceph fs, 先要停止左右的ceph-mds实例 ceph mds fail vm01systemctl stop ceph-mds@vm01ceph fs reset datafs –yes-i-really-mean-itceph fs status datafs设置mds期望待机备用数量 ceph fs set datafs standby_count_wanted 1 故障切换的管理¶ 如果一个 MDS 守护进程不再与监视器通讯，监视器把它标记为 laggy （滞后）状态前会等待 mds_beacon_grace 秒（默认是 15 秒）。 为安全起见，每个文件系统都要指定一些灾备守护进程，灾备数量包括处于灾备重放状态、等着接替失效 rank 的（记着，灾备重放守护进程不会被重分配去接管另一个 rank 、或者另一个 CephFS 文件系统内的失效守护进程）。不在重放状态的灾备守护进程会被任意文件系统当作自己的灾备。每个文件系统都可以单独配置期望的灾备守护进程数量，用这个： ceph fs set standby_count_wanted count 设置为 0 表示禁用健康检查。 术语¶ 一个 Ceph 集群内可以没有、或者有多个 CephFS 文件系统。 CephFS 文件系统有一个人类可读的名字（用 fs new 设置）、和一个整数 ID ，这个 ID 称为文件系统集群 ID 或 FSCID 。 每个 CephFS 都有几个 rank ，默认是一个，从 0 起。一个 rank 可看作是一个元数据分片。文件系统 rank 数量的控制在 多活 MDS 守护进程的配置 里详述。 CephFS 的每个 ceph-mds 进程（一个守护进程）刚启动时都没有 rank ，它由监视器集群分配。一个守护进程一次只能占据一个 rank ，只有在 ceph-mds 守护进程停止的时候才会释放 rank 。 如果某个 rank 没有依附一个守护进程，那这个 rank 就失效了（ failed ）。分配给守护进程的 rank 才被当作正常的（ up ）。 首次配置守护进程时，管理员需分配静态的名字，一般配置都会用守护进程所在的主机名作为其守护进程名字。 守护进程每次启动时，还会被分配一个 GID ，对于这个守护进程的特定进程的生命周期来说它是唯一的。 GID 是整数。 Todo 译者注： rank 翻译为“席位”、“座席”？它们共同处理元数据，且动态分配，类似客服中心的座席。MDS 守护进程的引用¶ 针对 MDS 守护进程的大多数管理命令都接受一个灵活的参数格式，它可以包含 rank 、 GID 或名字。 使用 rank 时，它前面可以加文件系统的名字或 ID ，也可以不加。如果某个守护进程是灾备的（即当前还没给它分配 rank ），那就只能通过 GID 或名字引用。 例如，假设我们有一个 MDS 守护进程，名为 myhost ，其 GID 为 5446 ，分配的 rank 是 0 ，它位于名为 myfs 的文件系统内，文件系统的 FSCID 是 3 ，那么，下面的几种形式都适用于 fail 命令： ceph mds fail 5446 # GIDceph mds fail myhost # Daemon nameceph mds fail 0 # Unqualified rankceph mds fail 3:0 # FSCID and rankceph mds fail myfs:0 # Filesystem name and rank 故障切换的管理¶ 如果一个 MDS 守护进程不再与监视器通讯，监视器把它标记为 laggy （滞后）状态前会等待 mds_beacon_grace 秒（默认是 15 秒）。 为安全起见，每个文件系统都要指定一些灾备守护进程，灾备数量包括处于灾备重放状态、等着接替失效 rank 的（记着，灾备重放守护进程不会被重分配去接管另一个 rank 、或者另一个 CephFS 文件系统内的失效守护进程）。不在重放状态的灾备守护进程会被任意文件系统当作自己的灾备。每个文件系统都可以单独配置期望的灾备守护进程数量，用这个： ceph fs set standby_count_wanted count 设置为 0 表示禁用健康检查。灾备守护进程的配置¶ 共有四个选项，用于控制守护进程处于灾备状态时如何工作： mds_standby_for_namemds_standby_for_rankmds_standby_for_fscidmds_standby_replay 这些配置可写入 MDS 守护进程所在主机（而非监视器上）的 ceph.conf 配置文件。守护进程会在启动时加载这些配置，并发送给监视器。 默认情况下，如果这些选项一个也没配置，那么没领到 rank 的所有 MDS 守护进程都会作为任意 rank 的灾备。 这些配置虽说可以把灾备守护进程关联到特定的名字或 rank ，然而并不能保证这个守护进程只用于那个 rank 。也就是说，有好几个灾备可用时，会用关联的守护进程。假如一个 rank 失效了，而且有一个可用的灾备，那么即使此灾备已关联了另外的 rank 或守护进程名，它仍然会被用掉。mds_standby_replay¶ 如果此选项设置为 true ，灾备守护进程就会持续读取某个处于 up 状态的 rank 的元数据日志。这样它就有元数据的热缓存，在负责这个 rank 的守护进程失效时，可加速故障切换。 一个正常运行的 rank 只能有一个灾备重放守护进程（ standby replay daemon ），如果两个守护进程都设置成了灾备重放状态，那么其中任意一个会取胜，另一个会变为普通的、非重放灾备状态。 一旦某个守护进程进入灾备重放状态，它就只能为它那个 rank 提供灾备。如果有另外一个 rank 失效了，即使没有灾备可用，这个灾备重放守护进程也不会去顶替那个失效的。 历史问题：在 v10.2.1 版之前的 Ceph 中，只要设置了 mds_standby_for_* ，这个选项（设置为 false 时）就始终为 true 。mds_standby_for_name¶ 设置此选项可使灾备守护进程只接替与此名字相同的 rank 。mds_standby_for_rank¶ 设置此选项可使灾备守护进程只接替指定的 rank ，如果有其它 rank 失效了，此守护进程不会去顶替它。 你有多个文件系统时，可联合使用 mds_standby_for_fscid 选项来指定想为哪个文件系统的 rank 提供灾备。mds_standby_for_fscid¶ 如果设置了 mds_standby_for_rank ，那么这里可把它限定为是哪个文件系统的 rank 。 如果没设置 mds_standby_for_rank ，那么设置 FSCID 后，这个守护进程可用于此 FSCID 所相关的任意 rank 。当你想让某一守护进程可作任意 rank 的灾备、但仅限于某个特定文件系统时，可用此选项实现。mon_force_standby_active¶ 这些选项用于监视器主机，默认值为 true 。 如果设置为 false ，那么配置为 standby_replay=true 的灾备守护进程只会顶替它们负责的 rank 或指定名字。反之，如果这里设置为 true ，那么配置为 standby_replay=true 的灾备守护进程有可能被分配其它 rank 。实例¶ 这些是 ceph.conf 配置实例。实践中，你可以让所有服务器上的所有守护进程都使用相同的配置文件，也可以让各服务器上的配置文件各不相同，其中只包含它的其守护进程相关的配置。简单的一对¶ 两个 MDS 守护进程 a 和 b 作为一对，其中任意一个没分到 rank 的将作为另一个的灾备重放追随者。 [mds.a]mds standby replay = truemds standby for rank = 0 [mds.b]mds standby replay = truemds standby for rank = 0 浮动灾备¶ 某一文件系统有三个 MDS 守护进程： a 、 b 、 c ，其 max_mds 为 2 。 无须过多配置，没有分到 rank 的守护进程会成为灾备，它会顶替任何一个失效的守护进程。两个 MDS 集群¶ 有两个文件系统、四个 MDS 守护进程，我想让其中两个作为一对服务于一个文件系统，另外两个作为一对服务于另一个文件系统。 [mds.a]mds standby for fscid = 1 [mds.b]mds standby for fscid = 1 [mds.c]mds standby for fscid = 2 [mds.d]mds standby for fscid = 2 客户端配置参考¶ client acl type描述: 设置 ACL 类型。现在还只能设置为 “posix_acl” 表示启用 POSIX ACL ，或者可设置为空字符串。此选项只有在 fuse_default_permissions 被设置为 false 时有效。类型: String默认值: “” (no ACL enforcement) client cache mid描述: 设置客户端缓存中点。此中点把最近用过的列表分割为热列表和暖列表。类型: Float默认值: 0.75 client_cache_size描述: 设置客户端可保留在元数据缓存中的索引节点数量。类型: Integer默认值: 16384 client_caps_release_delay描述: 设置释放能力的延时，单位为秒。这个延时控制着客户端不再需要能力时，再等多少秒就释放，以便其它需要这些能力的用户使用。类型: Integer默认值: 5 (seconds) client_debug_force_sync_read描述: 设置为 true 时，客户端会跳过本地页缓存、直接从 OSD 读取数据。类型: Boolean默认值: false client_dirsize_rbytes描述: 设置为 true 时，就采用目录的递归尺寸（也就是其内所有文件尺寸之和）。类型: Boolean默认值: true client_max_inline_size描述: 控制内联数据的最大尺寸，小于此尺寸就存储到文件的索引节点内，超过则存到单独的 RADOS 对象内。本选项只有设置了 MDS 图的 inline_data 标志时有效。类型: Integer默认值: 4096 client_metadata描述: 客户端向各 MDS 发送元数据时，除了自动生成的版本号、主机名等信息，还可以附加逗号分隔的字符串作为附加元数据。类型: String默认值: “” （没有附加元数据） client_mount_gid描述: 设置 CephFS 挂载后的组 ID 。类型: Integer默认值: -1 client_mount_timeout描述: 设置挂载 CephFS 时的超时时间，单位为秒。类型: Float默认值: 300.0 client_mount_uid描述: 设置 CephFS 挂载后的用户 ID 。类型: Integer默认值: -1 client_mountpoint描述: 指定要挂载的 CephFS 文件系统目录。此选项的作用类似 ceph-fuse 命令的 -r 选项。类型: String默认值: “/“ client_oc描述: Enable object caching.类型: Boolean默认值: true client_oc_max_dirty描述: 设置对象缓存的脏数据上限，单位为字节。类型: Integer默认值: 104857600 (100MB) client_oc_max_dirty_age描述: 设置脏数据在对象缓存中的最大存留时间，单位为秒。类型: Float默认值: 5.0 （秒） client_oc_max_objects描述: 设置对象缓存允许的最大对象数。类型: Integer默认值: 1000 client_oc_size描述: 设置客户端可缓存的数据上限，单位为字节。类型: Integer默认值: 209715200 (200 MB) client_oc_target_dirty描述: 设置认定为脏数据的目标尺寸。我们建议这个数字尽量小些。类型: Integer默认值: 8388608 (8MB) client_permissions描述: 检查所有 I/O 操作的客户端权限。类型: Boolean默认值: true client_quota描述: 设置为 true 表示启用客户端配额。类型: Boolean默认值: true client_quota_df描述: 让 statfs 操作报告根目录的配额。类型: Boolean默认值: true client_readahead_max_bytes描述: 设置内核预读数据的最大尺寸，单位为字节。本选项可被 client_readahead_max_periods 覆盖。类型: Integer默认值: 0 (unlimited) client_readahead_max_periods描述: 设置内核预读的文件布局分片最大数量（对象尺寸 * 条带数量）。本选项会覆盖 client_readahead_max_bytes 选项。类型: Integer默认值: 4 client_readahead_min描述: 设置内核预读的最小尺寸，单位为字节。类型: Integer默认值: 131072 (128KB) client_reconnect_stale描述: 是否自动重连过期的会话。类型: Boolean默认值: false client_snapdir描述: 设置快照目录名。类型: String默认值: “.snap” client_tick_interval描述: 设置更新能力及维持其它信息的间隔时长，单位为秒。类型: Float默认值: 1.0 （秒） client_use_random_mds描述: 为各个请求随机选取 MDS 。类型: Boolean默认值: false fuse_default_permissions描述: 设置为 false 时， ceph-fuse 工具会用自己的权限验证机制，而非依靠 FUSE 的强制权限。启用 POSIX ACL 需把此选项设置为 false 、同时设置 client acl type=posix_acl 。类型: Boolean默认值: true开发者选项¶ Important 以下选项仅供内部测试，只是为了保持文档完整才罗列在这里。 client_debug_getattr_caps描述: 检查 MDS 的响应是否有必要的能力。类型: Boolean默认值: false client_debug_inject_tick_delay描述: 在客户端动作之间人为地加入延时。类型: Integer默认值: 0 client_inject_fixed_oldest_tid描述:类型: Boolean默认值: false client_inject_release_failure描述:类型: Boolean默认值: false client_trace描述: 所有文件操作的追踪文件的路径。其输出可用于 Ceph 的人造客户端。类型: String默认值: “” (disabled) https://drunkard.github.io/cephfs/client-config-ref/ 参考： http://caitianxiong.com/2017/02/25/deploy-ceph-cluster-manually/#more https://lotuslab.org/2017/03/11/Ceph_manual_deploy_guide.html http://docs.ceph.org.cn/install/manual-deployment/ http://www.cnblogs.com/boshen-hzb/p/6927407.html 手动添加ceph的mds 1、在需要安装的目标机器上创建mds目录 mkdir -p /data/ceph/mds/ceph-0 2、生成mds的keyring，并将其写入/data/ceph/mds/ceph-0/keyring文件中 ceph auth get-or-create mds.0 mon ‘allow rwx’ osd ‘allow *’ mds ‘allow’ -o /data/ceph/mds/ceph-0/keyring 上面红色部分不能写成allow *，要不然会报错。 3、 apt-get install ceph-mdsceph-mds –cluster ceph -i 0 -m 10.111.131.125:6789 4、创建文件系统 ceph osd pool create cephfs_data 100ceph osd pool create cephfs_metadata 100ceph fs new cephfs cephfs_metadata cephfs_data How-to quickly deploy a MDS server. Assuming that /data/ceph/mds/mds is the mds data point. Edit ceph.conf and add a MDS section like so: [mds] mds data = /data/ceph/mds/mds.$id keyring = /data/ceph/mds/mds.$id/mds.$id.keyring [mds.0] host = {hostname} Create the authentication key (only if you use cephX): $ sudo mkdir /data/ceph/mds/mds.0$ sudo ceph auth get-or-create mds.0 mds ‘allow ‘ osd ‘allow *’ mon ‘allow rwx’ &gt; /data/ceph/mds/mds.0/mds.0.keyring https://my.oschina.net/itfanr/blog/397044修改/etc/ceph/ceph.conf文件： [global] auth supported = none osd pool default size = 2 osd crush chooseleaf type = 0 objecter_inflight_op_bytes=4294967296 objecter_inflight_ops=1024 #debug filestore = 100 #debug osd = 10 debug journal = 1 filestore blackhole=false filestore queue max ops=1024 filestore queue max bytes=1073741824 filestore max sync interval=5 #osd op num threads per shard=1 #osd op num shards=1 filestore wbthrottle enable=false filestore merge threshold=50 filestore split multiple=10 #osd objectstore=satafilestore [mon][mon.0] host = itfanr-host1 mon addr = 192.168.100.14:6789 [mds][mds.0] host = itfanr-host1 [osd] osd mkfs type = xfs osd mkfs options xfs = -f -i size=2048 osd mount options xfs = inode64,noatime osd crush update on start = 0 [osd.0] host = itfanr-host1 devs = /dev/sdb1 osd journal = /dev/sdb2 [osd.1] host = itfanr-host1 devs = /dev/sdc1 osd journal = /dev/sdc2 [osd.2] host = itfanr-host1 devs = /dev/sdd1 osd journal = /dev/sdd2 [osd.3] host = itfanr-host1 devs = /dev/sde1 osd journal = /dev/sde2]]></content>
      <categories>
        <category>ceph</category>
        <category>install</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx AB测试]]></title>
    <url>%2Fnginx%2Fconfig%2FNginx%20AB%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[split_clients指令语法：split_clients string $variable { ... } 默认值: — 配置段: http 原始字符串的值经过MurmurHash2算法进行了哈希。 使用实例## 配置 http { split_clients &quot;${remote_addr}AAA&quot; $variant { 0.5% .one; 2% .two; * &quot;&quot;; } server { location / { index index${variant}.html; } } } ## 然后新建几个对应页面文件 cd /usr/local/nginx/html/ echo &quot;*&quot; &gt;index.html echo &quot;one&quot; &gt;index.one.html echo &quot;two&quot; &gt;index.two.html 示例中: 哈希值从0到21474835（0.5%）对应于变量$variant的&quot;.one&quot;值， 哈希值从21474836到107374180（2%）对应于值&quot;.two&quot;， 哈希值从107374181到4294967295对应于值&quot;&quot;（一个空字符串）。]]></content>
      <categories>
        <category>nginx</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何用Nginx搬运整个世界]]></title>
    <url>%2Fnginx%2Fconfig%2F%E5%A6%82%E4%BD%95%E7%94%A8Nginx%E6%90%AC%E8%BF%90%E6%95%B4%E4%B8%AA%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[如何用Nginx搬运整个世界 https://dream.ren/proxy_the_whole_world_by_nginx.html 基于http协议的各种反代方法太多太简单了，网上肯定一大把，这里就无需多言了，今天博主来介绍一种更为通用、隐蔽、安全和高效的反代方法，此方法并非完全工作在第七层，通过工作在第四层的代理支持https等多种应用层协议，同时支持TCP、UDP代理，是真的几乎代天代地代空气，反代整个世界。涨姿势的时候到了，请大家撸起。。袖子，准备干他娘的一炮！ 由于在国内使用https协议访问谷歌学术时会受到域名字段检测，导致在国内无法正常使用谷歌学术，即使使用sni代理，依然无法规避这种检测机制导致的连接失败，所以，国内的上网设备，在不使用代理客户端的情况下，使用谷歌学术去检索资料几乎不可能。然而Pure DNS却能支持谷歌学术的访问并且有长期支持的打算，其实现正是得益于Nginx强大到炸裂的代理功能。下面将对四层Nginx反代配置、当前追梦人博客和谷歌学术反代服务器的Nginx配置进行介绍，说到Nginx，真的得夸一夸，在兼顾性能的情况下各种负载均衡、热更新、各种反代、各种骚操作都能搞定，还能有lua加持，点个赞👍。 上面也提到了，通常情况下国内上网设备需要安装代理客户端才能访问谷歌学术，Pure DNS也不能算例外，只不过Pure DNS把客户端也放到了服务器上运行，才实现了用户免装客户端。为了实现谷歌学术的免客户端访问，需要防火墙内、外各一台服务器进行多层代理，防火墙外Nginx服务器反代谷歌学术并同时作为服务端运行，防火墙内服务器Nginx作为客户端与防火墙外服务端加密通信，同时，防火墙内Nginx又作为服务端为用户提供服务，Pure DNS友情劫持谷歌学术的解析结果，使谷歌学术指向防火墙内自建Nginx反代服务器。这时，用户与谷歌学术服务器间的连接路径为：用户→https协议→防火墙内Nginx→ssl加密→防火墙外Nginx→sni反代→谷歌学术服务器，用户端效果就像普通https方式一样即可访问谷歌学术。注意，此处单箭头并不合适，但是我懒得画图了。。。 Nginx过早的版本并不支持下面的配置，可以阅读我的另一篇博文Nginx之stream模块初体验，查看对Nginx的要求，下面的配置仅供参考，实际操作前请备份Nginx配置文件。 下面首先是防火墙外Nginx配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354user nginx; #机器几个核就写几，更通用的方法是auto，Nginx会自动应用合适的值worker_processes auto;error_log /var/log/nginx/error.log error;pid /var/run/nginx.pid; #Nginx允许使用的最大文件描述符数量限制，适当调大可避免”too many open files”错误worker_rlimit_nofile 1048576;events { #设置轮询方法 use epoll; #单个工作进程可以允许同时建立外部连接的数量，低配机器慎加 worker_connections 262144; #尽可能多地接收连接 multi_accept on; } stream { #这里定义一个后端的map，防止直接通过https方式访问IP造成的循环反代 map $ssl_preread_server_name $backend { ~*[0-9]$ unix:/dev/shm/null.sock; default $ssl_preread_server_name:443; } #下面这段就是sni代理+ssl加密服务端的实现 server { listen 4333 ssl; #与防火墙内Nginx服务器使用ssl加密方式进行连接，效果和stunnel等隧道代理类似， #这里主要为了加密流量实现防火墙穿透 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; #服务端加密方式优先 #ssl_prefer_server_ciphers on; #证书文件，可以是自签证书，这里的证书配置主要是服务端验证客户端时要用到， #表示博主随手签了一个丢root目录了，这里也暂时懒得改了，可以用这两条命令自签（记得去掉#号）： #openssl genrsa -out key.pem 2048 #openssl req -new -x509 -key key.pem -out cert.pem -days 3650 ssl_certificate /root/cert.pem; ssl_certificate_key /root/key.pem; #下面三条配置是用来验证客户端的，防止非授权客户端连接，没错，这里博主懒得再签一个了 ssl_client_certificate /root/cert.pem; ssl_trusted_certificate /root/cert.pem; ssl_verify_client on; ssl_session_cache shared:SSL:20m; ssl_session_timeout 10m; #下面是sni代理转发设置 ssl_preread on; #DNS服务器设置，用来解析$ssl_preread_server_name（也就是https中的域名） #注意，下面一定要替换成可用的dns！ #我在此处用来限制被代理域名，不能啥网站都代啊对不，当然你也可以用map去限制域名，一样的效果 #如果允许代理任何https站点，可以设置为resolver 8.8.8.8; resolver 127.0.0.1:5353; #resolver 8.8.8.8; proxy_pass $backend; } }下面是防火墙内Nginx配置，因为此服务器上跑着现在这个博客以及Pure DNS官网，需要与谷歌学术共用443端口，而且博客又要能够知道到访客的真实IP，因此配置多了点，在这里，并没有开放http80端口谷歌学术的访问，因为会被未备案提示拦截…然后刚好省下了80端口的反代，只使用443端口进行反代。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109user nginx;worker_processes auto;error_log /var/log/nginx/error.log error;pid /var/run/nginx.pid;worker_rlimit_nofile 1048576;events { worker_connections 262144; multi_accept on; use epoll;} stream { #代理缓冲区大小 proxy_buffer_size 128k; #代理超时时间 #proxy_connect_timeout 5s; #会话状态存储区域，限制单IP最大连接数的时候会用到 #limit_conn_zone $binary_remote_addr zone=addr:10m; #SNI日志格式，SNI代理并未拆解证书，常规的变量在这里是用不了的 #时间|用户IP|域名|接收字节数|发送字节数|会话用毫秒数 log_format main &apos;$time_iso8601|$remote_addr|$ssl_preread_server_name&apos; &apos;|$bytes_received|$bytes_sent|$session_time&apos;; #后端转发策略 map $ssl_preread_server_name $backend { ~*[0-9]$ unix:/dev/shm/localweb.sock; ~*dream.ren$ unix:/dev/shm/localweb.sock; ~*puredns.cn$ unix:/dev/shm/localweb.sock; default unix:/dev/shm/nginx-sni.sock; } #Nginx加密转发上游配置，也就是防火墙外Nginx，由于经费不足，其中只包含了一台备份机，防止单点故障导致的服务中断 upstream sni_stunnel { zone upstream_sni_stunnel 64k; server **.**.**.**:4333 fail_timeout=120s; server **.**.**.**:4333 backup; } #Nginx加密转发 server { #在内存中监听域套接字（域套接字相比sock套接字具有更好的性能）， #并声明使用proxy_protocol代理协议，这个协议是用来传递客户端真实IP的 listen unix:/dev/shm/nginx-sni.sock proxy_protocol; #并不需要和sni_stunnel配置中的远程服务器使用proxy_protocol协议，要关闭，否则连接会被中断 proxy_protocol off; #与sni_stunnel服务器使用ssl加密方式进行连接 proxy_ssl on; #证书文件，可以是自签证书，为了能与防火墙外服务器连接时通过验证， #若防火墙外Nginx未开启客户端验证可以不用配置证书 proxy_ssl_certificate /root/cert.pem; #证书秘钥文件 proxy_ssl_certificate_key /root/key.pem; #下面2行是用来验证服务端的，好像还有些问题 #proxy_ssl_trusted_certificate /root/cert.pem; #proxy_ssl_verify on; #proxy_ssl_ciphers AES128-SHA:AES256-SHA:RC4-SHA:DES-CBC3-SHA:RC4-MD5; #proxy_connect_timeout 5s; #转发到sni_stunnel中的服务器 proxy_pass sni_stunnel; #开启ssl_preread，用来检测域名的 ssl_preread on; } #监听服务端口 server { listen 443; #声明使用proxy_protocol代理协议，和上面那个server配套使用的 proxy_protocol on; #限制单IP最大连接数 #limit_conn addr 10; #单连接限速 #proxy_download_rate 400k; #proxy_upload_rate 400k; #配置sni使用日志，并给日志加缓冲， #if=$ssl_preread_server_name表示只有当sni域名不为空的时候进行记录 access_log /var/log/nginx/sniproxy.log main buffer=8k flush=5s if=$ssl_preread_server_name; #使用上面的那个转发策略 proxy_pass $backend; #开启ssl_preread，用来检测域名的 ssl_preread on; } } #下面是托管在本机上网站的相关配置，网上应该有很多详细介绍，这里就不多做介绍了; #相信聪明的你配置出一个SSL LAB评分A+的站点应该不是什么难事儿~~http { include /etc/nginx/mime.types; default_type application/octet-stream; charset utf-8; log_format main ‘$time_iso8601|$remote_addr|$host|$request|$request_time|$status’ ‘|$body_bytes_sent|$upstream_addr|$upstream_response_time|$upstream_status’ ‘|”$http_referer”|”$http_user_agent”|”$http_x_forwarded_for”‘; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; client_max_body_size 50m; keepalive_timeout 65; gzip on; gzip_min_length 1k; gzip_buffers 16 16k; #gzip_http_version 1.1; gzip_comp_level 5; gzip_types text/plain application/javascript application/x-javascript text/javascript text/css application/xml application/xml+rss application/json application/vnd.ms-fontobject font/ttf font/otf image/svg+xml; #gzip_vary on; #gzip_proxied expired no-cache no-store private auth; gzip_proxied any; gzip_disable &quot;MSIE [1-6]\.&quot;; include /etc/nginx/vhost/*.conf; }另外，在写本文的时候，发现了另一个好玩的东西：Go Proxy，看起来可玩性很高，感兴趣的童鞋可以去看看：https://github.com/snail007/goproxy/blob/master/README_ZH.md]]></content>
      <categories>
        <category>nginx</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle的高级复制、流复制、备库的区别]]></title>
    <url>%2FOracle%E7%9A%84%E9%AB%98%E7%BA%A7%E5%A4%8D%E5%88%B6%E3%80%81%E6%B5%81%E5%A4%8D%E5%88%B6%E3%80%81%E5%A4%87%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Oracle备份功能包括：高级复制（Advanced Replication） 流复制（Streams Replication） 备库（Dataguard） 一 dataguard：dataguard在高可用及容灾方面一般是dba的首选，毕竟dataguard在这方面 存在压倒性的优势，不管是物理备用库（physical standby database）还是逻辑备用库（logical standby database），它们都具有一些共同的待征。 配置和管理方面的成本：dataguard比stream replication简单方便；安全与稳定方面的成本：dataguard比stream replication稳定可靠。 对对于一个24x7的系统来说，这些是非常重要的，系统宕机时间的增加不仅影响着公司的形象，还会影响公司的效益；采用dataguard，数据的安全性相当有保障，物理备用库可以在最短的时间完成故障切换，逻辑备用库在保障数据安全的同时， 也可以承担大量的报表等业务；由于dataguard的配置与管理比较简单，同理也降低了dba的工作强度； 二 流复制（12c以下版本，12c级12c以上的流复制功能被整合到OGG中） 适用于如下情况： 1、局部复制 stream可以只复制某些表或某些模式 2、异构环境 充分利用现有的设备与技术 3、远程容灾 stream对网络的要求较dataguard低 stream replication有灵活的复制策略，不仅可以配置只复制某些表，还可以配置仅复制某些表上的ddl或dml，相比dataguard必须整个数据库复制而言，可以节省相当的存储投资，毕竟对于某些海量数据而言，有许多是不必要复制的。 如果在异构环境，即不同的操作系统，那dataguard将会束手无策，非stream replication莫属，这样可以充分利用现有的环境，配置高用可方案，在异构环境，stream replication将会是advanced replication的强劲对手。 stream replication传播的是经过logmnr挖掘并包装的逻辑改变记录（LCRs），相比dataguard传送archived redo log、advanced replication的mview log与mview刷新的方式，stream replication对网络的需求降低了很多，在远程异地容灾的过程中，租用网络带宽是一笔较高的费用，stream replication可以适当地降低这笔费用。 三 高级复制：advanced replication相对于dataguard，缺点是：配置与管理较复杂、安全与稳定性不够；优点：局部复制、异构环境等。advanced replication是一种相当成熟的技术，在许多关键系统中得到成功的运用，相对于9iR2推出的stream replication而言，双方适用的环境虽然相当，比如都可以进行局部复制、异构复制、远程容灾等，advanced replication目前在稳定性与安全性方面更经得起考验。 对比stream replication与advanced replication底层的实现技术，stream replication在实时性、稳定性、高效率、低消耗（较少的cpu/network资源）等方面更有优势，但凡一些新推出的功能，都或多或少存在一些不确定的因素。 在10gR1中，oracle针对目前stream replication存在的弱点进行了增强，不仅提供了从advanced replication迁移到stream replication的脚本，还提供了stream replication的配置与监控工具，stream replication在配置与管理方面必将智能化、简单化，担负起与shareplex争夺企业数据复制市场的重任。 四 高级复制与流复制区别高级复制与Streams Replication的原理是完全不同的，Streams Replication可以到表，用户，数据库级别，但高级复制似乎只能到表一级。 Streams Replication不是高级复制的升级版。 异构环境下，oracle的高可用和容灾有高级复制和stream 复制两种，两种的异同点如下： 1.高级复制是基于触发器（trigger）原理，而stream是基于日志挖掘原理，因此stream复制对源数据库的性能影响更小，但实时性不如高级复制。 2.高级复制复制的对象是基于数据库目标（object）的，如表、索引和存储过程，而stream复制可以针对表、方案（schema）和整个数据库，因此如果出于容灾整个数据库的考虑，stream复制的配置相对简单。 3.高级复制是一种相当成熟的技术，在许多关键系统中得到成功的运用，相对于9iR2推出的stream复制，高级复制目前在稳定性与安全性方面更经得起考验。 4.从发展的角度看，流的应用会越来越多，从oracle10g，oracle公司提供了从高级复制向流复制移植的工具，可以看出，oracle公司会更偏重于基于流的新技术。 5.由于高级复制是基于触发器的，因此所有的复制对象结构（ddl）的改变，都必须通过oracle提供的复制包来实施，和应用结合的比较紧，更适合于开发者使用，而流复制则更适合dba来实施。 流复制支持双向数据复制，而高级复制会有冲突； 流复制支持异构数据库复制，而没有资料说明高级复制也有相同功能； 两种实际使用来看，streams复制需要更少的带宽，2m带宽，如果 streams复制不行，高级复制大概更没戏，但是用streams最好别网络断线时间过长，不知道是bug还是oracle没考虑这种情况，如果复制停 顿一段时间，再恢复正常，大概是队列表中消息太多了，入队出队都很慢，非线性增长啊，这样就需要不短的一段时间来同步数据，高级复制就没这种状况。 bug，反正10，2，0，1有一些，看你碰的到碰不到了，严重的能让你删掉队列表重建才行，意味着基本是重建整个复制了，不过想重复一下又不出现了；还有使用negative rule如果站点多了遇到大的更新事务速度就变得极慢，站点多了要先设计好结构；会不停在有apply进程的站点udump目录下生成trc文件，虽然还算不上很成熟，不过streams复制真是好东西，以后必定会取代高级复制，建议打10.2.0.3补丁，据说修正了不少bug. stream对系统的设计与维护方要有相当的对stream技术的把控能力，而大多数系分与 DBA对这个东西都没有经验，所以难以推广；dataguard胜在维护简单可靠，一般dba都可以维护。stream以后会的前景会非常广阔！ 尤其是双向复制，解决了很多实际问题。 五 Data Guard 和Stream 区别Date Guard有两种类型：physical standby 和 logical standby。 这两中standby 都有3个功能模块： 日志传送；日志接收，日志恢复。两种standby在前两个模块中是一样的，都是通过LGWR或者ARCn进程发送日志，通过RFS进程接受日志。 区别在第三个模块： Physical Standby 使用的是Media Recovery技术直接在数据块级别进行恢复， 因此Physical Standby 能够做到两个数据库的完全同步， 没有数据类型限制。 Logical Standby实际是通过Logminer技术，把日志中的记录还原成SQL语句，然后通过Apply Engine 执行这些语句实现数据同步， 因此Logical Standby不能保证数据的完全一致。 比如Logical Standby 不支持某些数据类型，这一点在选择Logical Standby时必须要考虑. Logical Standby 不支持的数据类型可以从DBA_LOGSTDBY_UNSUPPORTED是不里查看. SQL&gt;SELECT * FROM DBA_LOGSTDBY_UNSUPPORTED; Stream 使用的是Logical Standby 第三个模块，也就是在Source Database一端，Capture 进程利用Logminer 技术把日志内容还原成LCR， 然后发送到Target Database， 而在Target database 一端， 也是通过Apply Engine 执行这些LCR。 因此Stream在使用上也有些限制条件。这些可以从视图ALL/DBA_STREAMS_NEWLY_SUPPORTED, ALL/DBA_STREAMS_UNSUPPORTED 查看stream复制不支持的数据类型。 12345SQL&gt;SELECT table_name, reason FROM ALL_STREAMS_NEWLY_SUPPORTED;SQL&gt;SELECT table_name, reason FROM DBA_STREAMS_NEWLY_SUPPORTED; SQL&gt;SELECT table_name, reason FROM DBA_STREAMS_UNSUPPORTED;SQL&gt;SELECT table_name, reason FROM ALL_STREAMS_UNSUPPORTED; 下面以图表的形式列举他们的区别： Streams Data Guard 主要目的是数据共享 主要目的是灾难恢复和高可用性 可以多方向同步 只能是单向，从Primary–&gt; Standby 数据粒度可以是数据库，Schema，Table三个级别 只有数据库级别 支持异种平台的同步(Heterogeneous Platforms) 必须同种平台 (Homogeneous Platforms) 参与复制的每个数据库可以读写 只有Primary可以读写，Standby 只读 支持Oracle 和非Oracle 数据库间的同步 只能是Oracle数据库间 参考Oracle 最高可用性体系结构 — MAA http://www.oracle.com/technetwork/cn/database/maa-088017-zhs.html ORACLE集群概念和原理 http://www.cnblogs.com/baiboy/p/orc2.html?spm=a2c4e.11153940.blogcont604235.13.60885f58gTplbC#_label1 Oracle的高级复制、流复制、备库的区别 http://apps.hi.baidu.com/share/detail/34247695 Oracle Stream Replication技术: https://blog.csdn.net/tianlesoftware/article/details/4759356]]></content>
      <categories>
        <category>oracle</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 模块编译安装配置]]></title>
    <url>%2Fnginx%2Fconfig%2FNginx%20%E6%A8%A1%E5%9D%97%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[动态模块模块加载# 需要配置在nginx.conf文件的最顶端。 1234567891011121314151617181920212223# 存放模块的目录 mkdir /etc/nginx/modules -p# 存放模块配置文件的目录 mkdir /etc/nginx/modules.d -p# 配置文件添加模块导入# 安装模块 yum install nginx-module-geoip# 添加模块配置文件 cat &gt; /etc/nginx/modules.d/ngx_http_geoip_module.conf &lt;&lt; EOF load_module "modules/ngx_http_geoip_module.so"; EOF 模块编译1） 动态编译参数，单独的一个模块文件，需放在/etc/nginx/modules目录下 --add-dynamic-module=PATH 2） 静态编译参数, 模块直接包含在nginx程序文件里，需替换nginx程序文件 --add-module=PATH 3） 编译示例： ## 获取正在运行的nginx编译配置 # nginx -V nginx version: nginx/1.14.0 built by gcc 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC) built with OpenSSL 1.0.2k-fips 26 Jan 2017 TLS SNI support enabled configure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=&apos;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC&apos; --with-ld-opt=&apos;-Wl,-z,relro -Wl,-z,now -pie&apos; ## 下载第三放模块代码 ## 下载nginx源代码 ## 编译配置 # ./configure --add-module=/opt/nginx_upstream_check_module-master --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=&apos;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC&apos; --with-ld-opt=&apos;-Wl,-z,relro -Wl,-z,now -pie&apos; ## 编译 # make ## 编译的程序文件和第三方模块存放路径 nginx源码目录/objs/nginx nginx源码目录/objs/*.so]]></content>
      <categories>
        <category>nginx</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 安装配置]]></title>
    <url>%2Fnginx%2Fconfig%2FNginx%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[yum 安装 nginx http 基本配置cp /etc/nginx/nginx.conf{,.origin} mkdir -p /etc/nginx/{http.d,local.d,modules.d,special.d} http 基本配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495cat &gt; /etc/nginx/nginx.conf &lt;&lt; EOF# include /etc/nginx/modules.d/*.confuser nginx nginx;worker_processes auto;worker_cpu_affinity auto;worker_rlimit_nofile 65535;#worker_priority -10;#working_directory /etc/nginx pid /run/nginx.pid;# nginx发生错误的日志记录，默认error，配置项有debug, info, notice, warn, error, crit, alert, or emerg。# 最好设置为crit，因为403也会记录，太多影响性能。error_log /data/log/nginx/nginx_error.log crit;events &#123; use epoll; multi_accept on; worker_connections 65535;&#125;http &#123; include mime.types; default_type application/octet-stream; log_format main '\$remote_addr - \$remote_user [\$time_local] "\$request" ' '\$status \$body_bytes_sent "\$http_referer" ' '"\$http_user_agent" "\$http_x_forwarded_for"'; access_log off; charset UTF-8; server_tokens off; sendfile on; # 默认为0,没有限制，一个快速连接可能会完全占用整个工作进程。 # NGINX不会尝试一次将整个文件发送出去，而是每次发送大小为1m的块数据。 # 设置太小影响文件下载的速度 #sendfile_max_chunk 1m; tcp_nopush on; tcp_nodelay on; ## 默认为off,可以不需要设置 autoindex off; # 下面一般取值10-60秒 keepalive_timeout 65; client_body_timeout 10; client_header_timeout 10; send_timeout 10; reset_timedout_connection on; keepalive_requests 5000; types_hash_max_size 2048; # 还是采用默认值 #server_names_hash_max_size 512; # 默认值32|64|128，默认值取决于处理器的高速缓存行的大小。 #server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_body_buffer_size 128K; client_max_body_size 20m; # client_body_temp_path path [level1 [level2 [level3]]]; # client_body_temp_path /var/cache/nginx/client_temp 1 2; ## 模块配置 include /etc/nginx/http.d/*.conf; ## 虚拟主机配置 include /etc/nginx/conf.d/*.conf;&#125;EOF gzip 模块配置1234567891011121314151617181920212223cat &gt; /etc/nginx/http.d/20.gzip.conf &lt;&lt; EOF ## 开启gzip gzip on; gzip_min_length 1k; #gzip_proxied any; gzip_proxied expired no-cache no-store private auth; gzip_vary on; ## gzip_buffers 32 4k|16 8k; gzip_buffers 32 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_disable 'MSIE [1-6]\.'; gzip_types text/plain text/css text/xml application/javascript application/json application/xml application/xml+rss application/xhtml+xml application/rss+xml application/atom+xml;EOF fastcgi模块在http中配置12345678910111213141516171819202122232425262728293031mkdir -p /etc/nginx/http.dcat &gt; /etc/nginx/http.d/40.fastcgi.conf &lt;&lt; EOF # fastcgi_bind 200.200.200.10; ## 下面三个超时，前端页面最好不要超过75秒, 后端管理页面可以指定300秒 fastcgi_connect_timeout 65; fastcgi_send_timeout 60; fastcgi_read_timeout 60; fastcgi_buffers 16 64k; fastcgi_buffer_size 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 256k; fastcgi_temp_path /dev/shm/fastcgi_temp 1 2; ## 默认on,所以不需要设置 # fastcgi_buffering on; ## 你必须明确的在error_page中指定处理方法使这个参数有效，否则nginx不会拦截 fastcgi_intercept_errors on; ## fastcgi 页面缓存定义, 如果需要开启 # fastcgi_cache_path /dev/shm/fpm_cache levels=1:2 keys_zone=fpm_cache_key:50m inactive=30m max_size=1g; EOF fastcgi模块在location中配置123456789101112131415161718192021222324252627282930313233343536mkdir -p /etc/nginx/local.dcat &gt; /etc/nginx/local.d/40.fastcgi_location.conf &lt;&lt; EOF ## 最好修改php.in(cgi.fix_pathinfo=0) ## 定义此条可以防上执行上传的php脚本 try_files \$uri =404; fastcgi_split_path_info ^(.+\.php)(.*)\$; fastcgi_param PATH_INFO \$fastcgi_path_info; fastcgi_param SCRIPT_FILENAME \$document_root\$fastcgi_script_name; fastcgi_pass 127.0.0.1:9000; #fastcgi_pass unix:/run/php-fpm.sock; #fastcgi_pass http://upstream_app; include fastcgi_params; fastcgi_index index.php; ## 不在客户端显示php本版 fastcgi_hide_header X-Powered-By; ## fastcgi_next_upstream error | timeout | invalid_header | http_500 | http_503 | http_403 | http_404 | http_429 | non_idempotent | off ...; ## fastcgi_next_upstream_timeout 0; ## fastcgi_next_upstream_tries 0; ## 如果需要开启fastcgi页面缓存 ## fast_cache 缓存参数定义 #include local.d/45.fastcgi_cache_params.conf;EOF fastcgi 缓存参数配置(location)# 缓存目录会自动创建 http里参数配置123456789101112131415mkdir -p /etc/nginx/http.dcat &gt; /etc/nginx/http.d/45.fastcgi_cache.conf &lt;&lt; EOF ## fastcgi 页面缓存定义, 如果需要开启 ## 缓存目录,levels=目录层级(举例:1:2会生成16*256个字目录) ## keys_zone=缓存空间的名字:用多少内存,inactive=默认失效时间(10m),max_size=最多用多少硬盘空间(超过将删除最久没使用的)。 ## use_temp_path=off，表示临时文件存放在缓存目录里。如果为on, 需要添加设置 fastcgi_temp_path path [level1 [level2 [level3]]]; ## 只能定义在http里 fastcgi_cache_path /dev/shm/fpm_cache levels=1:2 keys_zone=fpm_cache_key:50m inactive=30m max_size=1g use_temp_path=off; EOF location里参数配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960mkdir -p /etc/nginx/local.dcat &gt; /etc/nginx/local.d/45.fastcgi_cache_params.conf &lt;&lt; EOF ## fastcgi_cache 缓存配置参数 ## 定义不会从缓存中获取响应的条件。如果字符串参数的至少一个值不为空且不等于"0"，则不会从缓存中获取响应： fastcgi_cache_bypass \$skip_fpm_cache; ## 定义不将响应保存到缓存的条件。 如果字符串参数的至少一个值不为空且不等于"0"，则不会保存响应： fastcgi_no_cache \$skip_fpm_cache; ## fastcgi_cache_bypass \$cookie_nocache \$arg_nocache\$arg_comment; ## fastcgi_cache_bypass \$http_pragma \$http_authorization; ## fastcgi_no_cache \$cookie_nocache \$arg_nocache\$arg_comment; ## fastcgi_no_cache \$http_pragma \$http_authorization; ## 开启FastCGI缓存并指定缓存名称 fastcgi_cache fpm_cache_key; ## 定义fastcgi_cache的key fastcgi_cache_key \$scheme\$request_method\$host\$request_uri; fastcgi_cache_valid 200 301 302 1h; fastcgi_cache_valid 404 500 502 503 504 0s; fastcgi_cache_valid any 1m; ## 经过多少次请求的相同URL将被缓存。 fastcgi_cache_min_uses 2; ## 默认值: off fastcgi_cache_use_stale error timeout invalid_header http_500 http_503 updating; ## 请注意，在更新时必须允许使用陈旧的缓存响应。 fastcgi_cache_background_update on; fastcgi_ignore_headers X-Accel-Expires Cache-Control Expires Set-Cookie; ## x-cache头，用于调试 #add_header X-Cache-Status \$upstream_cache_status; #add_header X-Cache "\$upstream_cache_status - \$upstream_response_time"; fastcgi_cache_lock on; ## 默认值5s fastcgi_cache_lock_age 5s; fastcgi_cache_lock_timeout 5s; ## 默认就是GET HEAD, 所以不需配置，没设置POST，post 页面就不会被缓存 #fastcgi_cache_methods GET HEAD; ## 默认值off # fastcgi_keep_conn on;EOF proxy代理模块配置location里参数配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253cat &gt; /etc/nginx/local.d/30.proxy.conf &lt;&lt; EOF ## 注意参数后面加/ 表示一个绝对的location，用来替换客户请求的url;不加/ 表示会自动添加客户请求的url. proxy_pass \$scheme://images; proxy_redirect off; proxy_set_header Host \$host:\$proxy_port; proxy_set_header X-Real-IP \$remote_addr; proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto \$scheme; proxy_connect_timeout 65; proxy_send_timeout 65; proxy_read_timeout 65; proxy_buffer_size 64k; proxy_buffers 16 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 256k; proxy_temp_path /dev/shm/proxy_temp 1 2; ## 默认已设置 # proxy_buffering on; # proxy_max_temp_file_size 1024m; # proxy_temp_path /var/cache/nginx/proxy_temp 1 2; # proxy_http_version 1.0; ## 启用负载时用 #proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; #proxy_next_upstream_timeout 0; #proxy_next_upstream_tries 0; # proxy_intercept_errors on; # proxy_limit_rate 1024k; # proxy_headers_hash_max_size 512; # proxy_headers_hash_bucket_size 128; ## 设置不传递来自后端服务器响应的head字段给客户端 ## proxy_hide_header field; ## 允许从代理服务器向客户端传递禁用的标头字段。 ## proxy_pass_header field;EOF proxy代理缓存在http中配置http里参数配置123456789101112mkdir -p /etc/nginx/http.dcat &gt; /etc/nginx/http.d/35.proxy_cache.conf &lt;&lt; EOF ## 代理缓存定义 ## proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] ## 只能定义在http里 proxy_cache_path /dev/shm/proxy_cache levels=1:2 keys_zone=proxy_cache_key:250m inactive=1d max_size=1g use_temp_path=off;EOF location里参数配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647cat &gt; /etc/nginx/local.d/35.proxy_cache.conf &lt;&lt; EOF proxy_cache proxy_cache_key; proxy_cache_key \$scheme\$proxy_host\$uri\$is_args\$args; proxy_cache_min_uses 1; ## 确定在与代理服务器通信期间可以在哪些情况下使用过时的缓存响应。 ## proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | off ...; proxy_cache_use_stale error timeout invalid_header updating http_500 http_502; proxy_cache_valid 200 301 302 1h; proxy_cache_valid 404 500 502 503 504 0s; proxy_cache_valid any 1m; proxy_ignore_headers X-Accel-Expires Cache-Control Expires Set-Cookie; ## 允许使用具有"If-Modified-Since"和"If-None-Match"头字段的条件请求重新验证过期缓存项。 ## 默认值off proxy_cache_revalidate on; ## 后面的变量值不为0 或 不是空值("")，则不从缓存取或不缓存 #proxy_cache_bypass \$skip_proxy_cache #proxy_no_cache \$skip_proxy_cache proxy_cache_lock on; #proxy_cache_lock_timeout 5s; #proxy_cache_lock_age 5s; ## X-Proxy-Cache头，用于调试 #add_header X-Proxy-Cache \$upstream_cache_status; #add_header X-Proxy-Cache '$upstream_cache_status from $server_addr'; add_header X-Proxy-Cache "\$upstream_cache_status - \$upstream_response_time"; ## 允许启动后台子请求以更新过期的缓存项，同时将过时的缓存响应返回给客户端。 ## 默认值为off #proxy_cache_background_update on; ## 指定客户端那些方法被缓存，默认为GET|HEAD。基本不需要设置 ## proxy_cache_methods GET| HEAD|POSTEOF 打开文件缓存location里参数配置123456789cat &gt; /etc/nginx/local.d/60.open_file_cache.conf &lt;&lt; EOF open_file_cache max=10000 inactive=5m; open_file_cache_valid 2m; open_file_cache_min_uses 1; #open_file_cache_errors on;EOF server 配置12345678910111213141516server &#123; location ~* ^.+\.(ogg|ogv|svg|svgz|eot|otf|woff|mp4|ttf|rss|atom|jpg|jpeg|gif|png|ico|zip|tgz|gz|rar|bz2|doc|xls|exe|ppt|tar|mid|midi|wav|bmp|rtf)$ &#123; access_log off; log_not_found off; expires max; &#125; location = /robots.txt &#123; access_log off; log_not_found off; &#125; location ~ /\. &#123; deny all; access_log off; log_not_found off; &#125;&#125; nginx http 配置说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320#包含动态模块配置文件# include /etc/modules.d/*.conf# nginx工作进程以那个用户&amp;组权限运行user nginx nginx;# nginx 工作进程数，默认auto 自动检测，一般设置为CPU内核总数，过高也并不起到提高性能的作用worker_processes auto;# 为每一个进程分配cpu,或者将一个进程分配到多个cpu。worker_cpu_affinity auto;## 示例：将8 个进程分配到8 个cpu。当然能够写多个，或者将一个进程分配到多个cpu。##worker_processes 8;##worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;#更改所有worker进程的最大打开最大文件数限制，受系统进程的最大打开文件数量限制（ulimit -n 65535），在 /etc/security/limits.conf 中配置。# fs.file-max：该参数决定了系统中所允许的文件句柄最大数目，文件句柄设置代表linux系统中可以打开的文件的数量。######################################### $ ulimit -n# # 查看linux系统文件描述符# $ sudo sysctl -a | grep fs.file# fs.file-max = 655360# fs.file-nr = 6592 0 655360# fs.xfs.filestream_centisecs = 3000########################################worker_rlimit_nofile 65535;# 相当于nice, 取值-20/20，负数为更高优先级。#worker_priority -10;# nginx工作目录，必须绝对路径，默认--prefix=path#working_directory /etc/nginx#指定pid文件的位置,默认值就可以pid /run/nginx.pid;# nginx发生错误的日志记录，默认error，配置项有debug, info, notice, warn, error, crit, alert, or emerg。最好设置为crit，因为403也会记录，太多影响性能。error_log /data/log/nginx/nginx_error.log crit;events &#123; # 多路复用，Linux 关键配置，允许单个线程处理多个客户端请求。 use epoll; # nginx进程一次同时接收一个还是多个请求连接。需高并发的服务器开启。 # 允许尽可能地处理更多的连接数，如果 worker_connections 配置太低，会产生大量的无效连接请求。 multi_accept on; # 配置单个 Nginx 单个进程可服务的客户端数量，（最大值客户端数 = 单进程连接数 * 进程数 ）,不能超过 worker_rlimit_nofile 值 # 最大客户端数同时也受操作系统 socket 连接数的影响（最大 64K ） worker_connections 65535;&#125; http &#123; #使用的默认的 MIME-type include mime.types; default_type application/octet-stream; #定义日志格式 log_format &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; # 直接关闭http日志。但不影响server 配置里的访问日志记录 access_log off; #设置头文件默认字符集 charset UTF-8; #Nginx打开网页报错时,关闭版本号显示 server_tokens off; # 开启 sendfile 选项，使用内核的 FD 文件传输功能，这个比在用户态用 read() + write() 的方式更加高效。 # sendfile()可以在磁盘和TCP socket之间互相拷贝数据(或任意两个文件描述符)。 sendfile on; # 设置为非零值时，限制可以在单个sendfile（）调用中传输的数据量。 # 默认为0,没有限制，一个快速连接可能会完全占用整个工作进程。 # NGINX不会尝试一次将整个文件发送出去，而是每次发送大小为1m的块数据。 # 可以减少阻塞调用sendfile()所花费的最长时间 # 设置太小影响文件下载的速度 #sendfile_max_chunk 1m; # 打开 tcp_nopush 选项，Nginux 允许将 HTTP 应答首部与数据内容在同一个报文中发出。 # 这个选项使服务器在 sendfile 时可以提前准备 HTTP 首部，能够达到优化吞吐的效果。 # 告诉nginx在一个数据包里发送所有头文件，而不一个接一个的发送。 tcp_nopush on; # 不要缓存 data-sends （关闭 Nagle 算法），这个能够提高高频发送小数据报文的实时性。 # 配置 nginx 不缓存数据，快速发送小数据 tcp_nodelay on; # 值为on, 表示开启目录列表访问，合适下载服务器，默认关闭(off)。 # 网站为了安全，必须关闭 autoindex off; # 下面一般取值10-60秒 # HTTP连接持续时间,值越大无用的线程变的越多,0:关闭此功能,默认为75。客户端不再做任何操作，保持连接的超时时间。 # 在http早期 ，每个http请求都要求打开一个tpc socket连接，并且使用一次之后就断开这个tcp连接。 # 使用keep-alive可以改善这种状态，即在一次TCP连接中可以持续发送多份数据而不会 断开连接。 # 通过使用keep-alive机制，可以减少tcp连接建立次数，也意味着可以减少TIME_WAIT状态连接， # 以此提高性能和提高httpd 服务器的吞吐率(更少的tcp连接意味着更少的系统内核调用,socket的accept()和close()调用)。 # 但是，长时间的tcp连接容易导致系统资源无效占用。 # keepalive_timout时间值意味着：一个http产生的tcp连接在传送完最后一个响应后，还需要hold住 keepalive_timeout秒后，才开始关闭这个连接。 keepalive_timeout 65; # 定义读取客户端请求主体的超时。 # 超时只能在两个连续读操作之间的一段时间内设置，而不是传输整个请求主体。 # 如果客户端在此时间内没有传输任何内容，则408（请求超时）错误将返回给客户端。 client_body_timeout 10; # 定义读取客户端请求标头的超时。 # 如果客户端在此时间内未传输整个报头，则408（请求超时）错误将返回给客户端。 client_header_timeout 10; # 设置向客户端发送响应的超时时间。 # 超时只在两次连续的写入操作之间设置，而不是用于传输整个响应。 # 如果客户端在此时间内没有收到任何内容，则连接关闭。 send_timeout 10; # 允许服务器在客户端停止发送应答之后关闭连接，以便释放连接相应的 socket 内存开销。 # 当有大并发需求时，建议打开。 reset_timedout_connection on; # 单个客户端通过&quot;一个存活长连接&quot;送达的最大请求数（默认是100，建议根据客户端在&quot;keepalive&quot;存活时间内的总请求数来设置） # 当送达的请求数超过该值后，该连接就会被关闭。 keepalive_requests 5000; # types_hash_max_size影响散列表的冲突率。 # types_hash_max_size越大，就会消耗更多的内存，但散列key的冲突率会降低，检索速度就更快。 # types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升。 types_hash_max_size 2048; # 保存服务器名字的hash表是由指令 server_names_hash_max_size 和 server_names_hash_bucket_size所控制的。 # 参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。 # 在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。 # 如果 hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。 # 第一次是确定存储单元的地址，第二次是在存储单元中查找键值。 # 因此，如果Nginx给出需要增大 hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. # 还是采用默认值 #server_names_hash_max_size 512; #server_names_hash_bucket_size 128; # 默认值32|64|128，默认值取决于处理器的高速缓存行的大小。 # 客户请求头缓冲大小。一般一个请求的头部大小不会超过1k, 除非有很大的cookie。 # 这个可以根据你的系统分页大小来设置,系统分页大小的整数倍，$ getconf PAGESIZE。64位系统默认值为16k。 # nginx默认会用client_header_buffer_size这个buffer来读取header值， # 如果header过大，它会使用large_client_header_buffers来读取。 client_header_buffer_size 32k; # 设置用于读取大型客户端请求标头的缓冲区的最大数量和大小。 # 请求行不能超过一个缓冲区的大小，或者414（Request-URI太大）错误返回给客户端。 # 请求头字段也不能超过一个缓冲区的大小，或者400（错误请求）错误返回给客户端。 # 缓冲区仅在需求时分配。 默认情况下，缓冲区大小等于8K字节。 # 如果请求处理结束后连接转换为保持活动状态，则释放这些缓冲区。 # 下面取值表示最多用4组32k的内存缓冲区来存储。 large_client_header_buffers 4 32k; # 此指令设置用于请求主体的缓冲区大小。 # 如果主体超过缓冲区大小，则完整主体或其一部分将写入临时文件。 # 如果NGINX配置为使用文件而不是内存缓冲区，则该指令会被忽略。 # 默认情况下，该指令为32位系统设置一个8k缓冲区，为64位系统设置一个16k缓冲区。 # 该指令在NGINX配置的http，server和location区块使用。 client_body_buffer_size 128K; # 设置&quot;Content-Length&quot;请求标题字段中指定的客户端请求主体的最大允许大小。 # 此指令设置NGINX能处理的最大请求主体大小。 # 如果请求大于指定的大小，则NGINX发回HTTP 413（Request Entity too large）错误。 # 如果服务器处理大文件上传，则该指令非常重要。 # 此参数一般用来限制上传文件的最大值。由于编码的原因，一般设置比实际上传文件大30% client_max_body_size 20m; # 如果缓冲区与请求大小相比较小，则数据将写入磁盘上的文件，因此将涉及I/O操作。 # 指定存储请求正文的临时文件的位置。 # level1,2,3如果有值就代表存在一级，二级，三级子目录。 # 目录名是由数字进行命名的，所以这里的具体的值就是代表目录名的数字位数。 # client_body_temp_path path [level1 [level2 [level3]]]; # client_body_temp_path /var/cache/nginx/client_temp/ 1 2; # 禁用NGINX缓冲区并将请求体存储在临时文件中。文件包含纯文本数据。 # off:该值将禁用文件写入 # clean：请求body将被写入文件。 该文件将在处理请求后删除。 # on: 请求正文将被写入文件。 处理请求后，将不会删除该文件。 # 默认情况下，指令值为关闭。 # 不建议设置 # client_body_in_file_only off # NGINX将完整的请求主体存储在单个缓冲区中。 默认情况下，指令值为off。 # 如果启用(on)，它将优化读取$request_body变量时涉及的I/O操作。 # 不建议设置 # client_body_in_single_buffer off #------------------------------------------------------ #线程池优化,使用--with-threads配置参数编译 #aio threads; #thread_pool default threads=32 max_queue=65536; #aio threads=default; #关于更多线程请点击查看 #响应头 add_header X-Cache $upstream_cache_status; #缓存命中 add_header X-Frame-Options SAMEORIGIN; #是为了减少点击劫持（Clickjacking）而引入的一个响应头 add_header X-Content-Type-Options nosniff; include /usr/local/nginx/conf/vhosts/*.conf; #在当前文件中包含另一个文件内容的指令 #静态文件的缓存性能调优 open_file_cache max=65535 inactive=20s; #这个将为打开文件指定缓存,max 指定缓存数量.建议和打开文件数一致.inactive 是指经过多长时间文件没被请求后删除缓存 open_file_cache_valid 30s; #这个是指多长时间检查一次缓存的有效信息,例如我一直访问这个文件,30秒后检查是否更新,反之更新 open_file_cache_min_uses 2; #定义了open_file_cache中指令参数不活动时间期间里最小的文件数 open_file_cache_errors on; #NGINX可以缓存在文件访问期间发生的错误,这需要设置该值才能有效,如果启用错误缓存.则在访问资源（不查找资源）时.NGINX会报告相同的错误 #资源缓存优化 server &#123; #防盗链设置 location ~* \.(jpg|gif|png|swf|flv|wma|asf|mp3|mmf|zip|rar)$ &#123; #防盗类型 valid_referers none blocked *.renwole.com renwole.com; #none blocked参数可选.允许使用资源文件的域名 if ($invalid_referer) &#123; return 403; #rewrite ^/ https://www.renwole.com #若不符合条件域名,则返回403或404也可以是域名 &#125; &#125; location ~ .*\.(js|css)$ &#123; access_log off; expires 180d; #健康检查或图片.JS.CSS日志.不需要记录日志.在统计PV时是按照页面计算.而且写入频繁会消耗IO. &#125; location ~* \.(ogg|ogv|svg|svgz|eot|otf|woff|mp4|swf|ttf|rss|atom|jpg|jpeg|gif|png|ico|zip|tgz|gz|rar|bz2|doc|xls|exe|ppt|tar|mid|midi|wav|bmp|rtf)$ &#123; access_log off; log_not_found off; expires 180d; #视图&amp;元素很少改变.可将内容缓存到用户本地.再次访问网站时就无需下载.节省流量.加快访问速度.缓存180天 &#125; &#125; server &#123; listen 80 default_server; server_name .renwole.com; rewrite ^ https://www.renwole.com$request_uri?; &#125; server &#123; listen 443 ssl http2 default_server; listen [::]:443 ssl http2; server_name .renwole.com; root /home/web/renwole; index index.html index.php; ssl_certificate /etc/letsencrypt/live/www.renwole.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.renwole.com/privkey.pem; ssl_dhparam /etc/nginx/ssl/dhparam.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers &apos;ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA:ECDHE-ECDSA-DES-CBC3-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:DES-CBC3-SHA:!DSS&apos;; ssl_session_cache shared:SSL:50m; ssl_session_timeout 1d; ssl_session_tickets off; ssl_prefer_server_ciphers on; add_header Strict-Transport-Security max-age=15768000; ssl_stapling on; ssl_stapling_verify on; include /usr/local/nginx/conf/rewrite/wordpress.conf; access_log /usr/local/nginx/logs/renwole.log; location ~ \.php$ &#123; root /home/web/renwole; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; &#125; &#125; fastcgi 配置fastcgi 在 http 模块配置http 模块配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677mkdir -p /etc/nginx/http.dcat &gt; /etc/nginx/http.d/40.fastcgi.conf &lt;&lt; EOF ## 指定从哪个IP地址和端口出去访问FastCGI server ## off 表示取消继承http或server里的配置，可以允许系统自动分配本地IP地址和端口 ## transparent 表示允许从非本地IP地址（例如，来自客户端的真实IP地址）出去访问FastCGI服务器. ## 比如：fastcgi_bind $remote_addr transparent; ## fastcgi_bind address [transparent] | off; ## 下面三个超时，前端页面最好不要超过75秒, 后端页面可以指定300秒 #连接到后端 Fastcgi 的超时时间,单位秒 fastcgi_connect_timeout 65; #与 Fastcgi 建立连接后多久不传送数据,就会被自动断开 fastcgi_send_timeout 60; #接收 Fastcgi 应答超时时间 fastcgi_read_timeout 60; ## 对于单个连接，设置用于从FastCGI服务器读取响应的缓冲区的数量和大小。 ## 默认情况下，缓冲区大小等于一个内存页面。 这是4K或8K，取决于平台。 ## 较大的请求将被缓冲到磁盘 ## fastcgi_buffers 8 4k|8k; fastcgi_buffers 16 64k; ## 指定读取 Fastcgi 应答第一部分需要多大的缓冲区,可以设置gastcgi_buffers选项指定的缓冲区大小 ## 默认一个内存页的大小，一般4k或8k fastcgi_buffer_size 64k; ## 繁忙时的buffer,可以是fastcgi_buffer的两倍 fastcgi_busy_buffers_size 128k; ## 在写入fastcgi_temp_path时将用多大的数据块,默认值是fastcgi_buffers的两倍,该值越小越可能报 502 BadGateway fastcgi_temp_file_write_size 256k; #fastcgi_max_temp_file_size=1024m; #fastcgi_temp_path /var/cache/nginx/fastcgi_temp 1 2; fastcgi_temp_path /dev/shm/fastcgi_temp 1 2; ## 启用或禁用来自FastCGI服务器的响应缓冲。 ## 启用缓冲时，nginx会尽快收到来自FastCGI服务器的响应，并将其保存到由fastcgi_buffer_size和fastcgi_buffers指令设置的缓冲区中。 ## 如果整个响应不适合内存，则其一部分可以保存到磁盘上的临时文件中。 ## 写入临时文件由fastcgi_max_temp_file_size和fastcgi_temp_file_write_size指令控制。 ## 当禁用缓冲时，响应会在收到时立即同步传递给客户端。 nginx不会尝试从FastCGI服务器读取整个响应。 ## nginx一次可以从服务器接收的数据的最大大小由fastcgi_buffer_size指令设置。 ## 通过在"X-Accel-Buffering"响应头域中通过"是"或"否"，也可以启用或禁用缓冲。 可以使用fastcgi_ignore_headers指令禁用此功能。 ## fastcgi_buffering on | off; ## 默认on,所以不需要设置 #fastcgi_buffering on; ## 确定FastCGI服务器对代码大于或等于300的响应是否应传递给客户端。 ## 或者是否被拦截并重定向到nginx以便使用error_page指令进行处理。 ## 你必须明确的在error_page中指定处理方法使这个参数有效，否则nginx不会拦截 ## fastcgi_intercept_errors on | off; fastcgi_intercept_errors on; ## fastcgi 页面缓存定义, 如果需要开启 ## 缓存目录,levels=目录层级(举例:1:2会生成16*256个字目录) ## keys_zone=缓存空间的名字:用多少内存,inactive=默认失效时间(10m),max_size=最多用多少硬盘空间(超过将删除最久没使用的)。 ## use_temp_path=off，表示临时文件存放在缓存目录里。如果为on, 需要添加设置 fastcgi_temp_path path [level1 [level2 [level3]]]; ## 只能定义在http里 # fastcgi_cache_path /dev/shm/fpm_cache levels=1:2 keys_zone=fpm_cache_key:50m inactive=30m max_size=1g use_temp_path=off; EOF fastcgi 在server中配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546server &#123; listen 80; server_name www.test.com; access_log /var/log/nginx/test_access.log; error_log /var/log/nginx/test_error.log; root /var/www/html; index index.php index.html; ## 如果启用fastcgi cache，这里设置过滤掉不需要的进行缓存的页面。 ## 设置默认缓存。当然也可以设置默认不缓存，需要缓存的在通过过滤设置 set $skip_fpm_cache 0; ## 这里以wordpress为例 ## if ($request_uri ~* &quot;/wp-admin/|/xmlrpc.php|wp-.*.php|/feed/|index.php|sitemap(_index)?.xml&quot;) &#123; ## set $skip_fpm_cache 1; ## &#125; location / &#123; &#125; location ~ \.php($|/) &#123; ## fpm 处理 include local.d/40.fastcgi_location.conf ## 导入包含一些传递到FastCGI服务器的参数的文件 include fastcgi_params; ## fast_cache 缓存参数定义 #include local.d/45.fastcgi_cache_params.conf; &#125; location ~* &quot;\.(?:ogg|ogv|svg|svgz|eot|otf|woff|mp4|ttf|rss|atom|jpg|jpeg|gif|png|ico|zip|tgz|gz|rar|bz2|doc|xls|exe|ppt|tar|mid|midi|wav|bmp|rtf)$&quot; &#123; access_log off; log_not_found off; expires max; &#125; location = /robots.txt &#123; access_log off; log_not_found off; &#125; location ~ /\. &#123; deny all; access_log off; log_not_found off; &#125; &#125;&#125; fastcgi 在 location 模块配置location 模块配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657mkdir -p /etc/nginx/local.dvi /etc/nginx/local.d/40.fastcgi_location.conf ## 在PHP开启「cgi.fix_pathinfo」的情况下，PHP可能会把错误的文件类型当作PHP文件来解析。存在安全问题。 ## 最好修改php.in(cgi.fix_pathinfo=0) ## 定义此条可以防上执行上传图片的php脚本 ## 比如http://www.xxx.com/fake.jpg/foo.php, 如果fake.jpg实际是一个php脚本文件，则会执行。 try_files $uri =404; ## fastcgi_split_path_info regex; ## 只能定义在location里 ## 定义捕获$ fastcgi_path_info变量值的正则表达式。 正则表达式应该有两个捕获： ## 第一个变为$ fastcgi_script_name变量的值，第二个变为$ fastcgi_path_info变量的值。 ## 例如，使用这些设置和"/show.php/article/0001"请求， ## SCRIPT_FILENAME参数将等于"/path/to/php/show.php"， ## 并且PATH_INFO参数将等于"/article/0001"。 fastcgi_split_path_info ^(.+\.php)(.*)$; #fastcgi_param SCRIPT_FILENAME /path/to/php$fastcgi_script_name; fastcgi_param SCRIPT_FILENAME $documet_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; ## 只能定义在location里 ## 使用tcp连接 fastcgi_pass 127.0.0.1:9000; ## 使用unix socket连接 #fastcgi_pass unix:/run/php-fpm.sock; ## 导入包含一些传递到FastCGI服务器的参数的文件 #include fastcgi_params; ## 定义/默认页面 fastcgi_index index.php; ## 不会传递的字段给客户端, 不在客户端显示php本版 fastcgi_hide_header X-Powered-By; ################################################### ## 负载均衡有关 ## fastcgi_pass http://upstream_app ## 指定应将请求传递到下一个服务器的情况： ## fastcgi_next_upstream error | timeout | invalid_header | http_500 | http_503 | http_403 | http_404 | http_429 | non_idempotent | off ...; ## 时间限制和尝试next upstream限制，0表示不限制 ## fastcgi_next_upstream_timeout 0; ## fastcgi_next_upstream_tries 0; ################################################### ## 如果需要开启fastcgi页面缓存 ## fast_cache 缓存参数定义 #include local.d/45.fastcgi_cache_params.conf; fastcgi_cache 缓存配置参数fastcgi_cache：缓存fastcgi生成的内容，很多情况是php生成的动态的内容，少了nginx与php的通信的次数，更减轻了php和数据库 location fastcgi_cache 缓存配置参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109mkdir -p /etc/nginx/local.dvi /etc/nginx/local.d/45.fastcgi_cache_params.conf ## fastcgi_cache 缓存配置参数 ## 定义不会从缓存中获取响应的条件。如果字符串参数的至少一个值不为空且不等于"0"，则不会从缓存中获取响应： fastcgi_cache_bypass $skip_fpm_cache; ## 定义不将响应保存到缓存的条件。 如果字符串参数的至少一个值不为空且不等于"0"，则不会保存响应： fastcgi_no_cache $skip_fpm_cache; ## fastcgi_cache_bypass $cookie_nocache $arg_nocache$arg_comment; ## fastcgi_cache_bypass $http_pragma $http_authorization; ## fastcgi_no_cache $cookie_nocache $arg_nocache$arg_comment; ## fastcgi_no_cache $http_pragma $http_authorization; ## 开启FastCGI缓存并指定缓存名称 fastcgi_cache fpm_cache_key; ## 定义fastcgi_cache的key fastcgi_cache_key $scheme$request_method$host$request_uri; ##-------------------------------------------- ## 为指定的http返回代码指定缓存时间。没指定代码，后面直接跟时间，表示缓存返回响应代码为200 301 302的请求的页面 ## any 表示任意返回代码 fastcgi_cache_valid 200 301 302 1h; fastcgi_cache_valid 404 500 502 503 504 0s; fastcgi_cache_valid any 1m; ## 经过多少次请求的相同URL将被缓存。 fastcgi_cache_min_uses 6; ## 定义哪些情况下用过期缓存 ## 如果无法选择要处理请求的FastCGI服务器，则error参数还允许使用过时的缓存响应。 ## updating参数允许使用陈旧的缓存响应，如果它当前正在更新。这样可以在更新缓存数据时最大限度地减少对FastCGI服务器的访问次数。 ## 为了最大限度地减少填充新缓存元素时对FastCGI服务器的访问次数，可以使用fastcgi_cache_lock指令。 ## "Cache-Control"头字段的"reale-revalidate"扩展允许使用陈旧的缓存响应，如果它正在更新。 ## "Cache-Control"头字段的"stale-if-error"扩展允许在发生错误时使用陈旧的缓存响应。 ## 默认值: off fastcgi_cache_use_stale error timeout invalid_header http_500 http_503 updating; ## 当过时的缓存响应则返回给客户端时 ## 允许启动后台子请求来更新过期的缓存项目。 ## 请注意，在更新时必须允许使用陈旧的缓存响应。 fastcgi_cache_background_update on; ## 禁止处理来自FastCGI服务器的某些响应头字段。 ## 如果未禁用，则处理这些头字段具有以下效果： ## "X-Accel-Expires"，"Expires"，"Cache-Control"，"Set-Cookie"和"Vary" 设置响应缓存的参数; ## "X-Accel-Redirect" 执行内部重定向到指定的URI; ## "X-Accel-Limit-Rate" 设置向客户传送回复的速率限制; ## "X-Accel-Buffering" 启用或禁用缓冲响应; ## "X-Accel-Charset" 设置所需的响应字符集。 ## 有一些情况会影响到cache的命中 这里需要特别注意： ## Nginx fastcgi_cache在缓存后端fastcgi响应时，当响应里包含"set-cookie"时，不缓存; ## 当响应头包含Expires时，如果过期时间大于当前服务器时间，则nginx_cache会缓存该响应，否则，则不缓存; ## 当响应头包含Cache-Control时，如果Cache-Control参数值为no-cache、no-store、private中任意一个时，则不缓存， ## 如果Cache-Control参数值为max-age时，会被缓存，且nginx设置的cache的过期时间，就是系统当前时间 + mag-age的值 ## 有些php session设置可能会在请求头里产生不缓存标记,所以需要忽略这些请求头 fastcgi_ignore_headers X-Accel-Expires Cache-Control Expires Set-Cookie; ## x-cache头，用于调试 ## $upstream_response_time为过期时间 ## $upstream_cache_status 变量表示此请求响应来自cache的状态，几种状态分别为： ## •MISS - 在缓存中找不到响应，因此从原始服务器获取响应。然后可以缓存响应。 ## •BYPASS - 响应是从源服务器获取的，而不是从缓存中提供的，因为请求与proxy_cache_bypass指令匹配。 ## •EXPIRED - 缓存中的条目已过期。响应包含来自源服务器的新内容。 ## •STALE - 内容过时，因为源服务器未正确响应，并且已配置proxy_cache_use_stale。 ## •UPDATING - 内容过时，因为当前正在更新条目以响应先前的请求，并且配置了proxy_cache_use_stale更新。 ## •REVALIDATED - 启用了proxy_cache_revalidate指令，NGINX验证当前缓存的内容仍然有效（If-Modified-Since或If-None-Match）。 ## •HIT - 响应包含直接来自缓存的有效，新鲜内容。 #add_header X-Cache-Status $upstream_cache_status; #add_header X-Cache "$upstream_cache_status - $upstream_response_time"; ## 启用后，通过将请求传递给FastCGI服务器，一次只允许一个请求填充根据fastcgi_cache_key指令标识的新缓存元素。 ## 同一缓存元素的其他请求将等待响应出现在缓存中或缓存锁定以释放此元素，直到fastcgi_cache_lock_timeout指令设置的时间。 ## 如何规避大并发时锁的堵塞, 如果对数据实时性要求不太高，可以使用 fastcgi_cache_use_stale updating 设置，这样堵塞时可以使用旧数据应付. fastcgi_cache_lock on; ## 如果传递给FastCGI服务器的最后一个请求在指定时间内没有完成获取数据来更新缓存， ## 则将另一个请求传递给FastCGI服务器。 fastcgi_cache_lock_age 5s; ## 当时间到期时，请求将被传递给FastCGI服务器，但是，响应将不会被缓存。 fastcgi_cache_lock_timeout 5s; ## 默认就是GET HEAD, 所以不需配置，没设置POST，post 页面就不会被缓存 #fastcgi_cache_methods GET HEAD; ## 默认情况下，FastCGI服务器将在发送响应后立即关闭连接。 ## 但是，当此伪指令设置为on时，nginx将指示FastCGI服务器保持连接打开。 ## 特别是，这对于FastCGI服务器的keepalive连接起作用是必要的。比如 upstream 中使用keepalive ## 默认值off # fastcgi_keep_conn on; ## 限制从FastCGI服务器读取响应的速度。 速率以每秒字节数指定。零值禁用速率限制。 ## 根据请求设置限制，因此如果nginx同时打开两个到FastCFI服务器的连接，则总速率将是指定限制的两倍。 ## 仅当启用了对来自FastCGI服务器的响应的缓冲时，该限制才有效。 # fastcgi_limit_rate 0; ## 使用具有"If-Modified-Since"和"If-None-Match"标头字段的条件请求启用过期缓存项的重新验证。 #fastcgi_cache_revalidate on; fastcgi_cache设置多个磁盘缓存1234567891011121314151617## 用到ngx_http_split_clients_module 模块，此模块一般用来做AB测试的。fastcgi_cache_path /path/to/hdd1 levels=1:2 keys_zone=my_cache_hdd1:10m max_size=10g inactive=60m use_temp_path=off;fastcgi_cache_path /path/to/hdd2 levels=1:2 keys_zone=my_cache_hdd2:10m max_size=10g inactive=60m use_temp_path=off;split_clients $request_uri $my_cache &#123; 50% &quot;my_cache_hdd1&quot;; 50% &quot;my_cache_hdd2&quot;;&#125;server &#123; ... location / &#123; fastcgi_cache $my_cache; &#125;&#125; 缓存清理## 方法一：直接删除缓存目录，然后还要运行nginx -s reload，来清理nginx缓存 rm -rf /dev/shm/fpm_cache/* nginx -s reload ## 方法二：编译使用第三方插件，根据访问路径清理缓存 http://labs.frickle.com/files/ngx_cache_purge-2.3.tar.gz https://github.com/FRiCKLE/ngx_cache_purge location 配置12345678location ~ /purge(/.*) &#123; fastcgi_cache_purge fpm_cache_key "$scheme$request_method$host$1"; allow 127.0.0.1; deny all;&#125; proxy代理模块配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157## 设置代理服务器的协议和地址以及应映射位置的可选URI。作为协议，可以指定“ http”或“ https”。该地址可以指定为域名或IP地址，以及可选端口：## proxy_pass URL;## 注意参数后面加/ 表示一个绝对的location，用来替换客户请求的url;不加/ 表示会自动添加客户请求的url.proxy_pass $scheme://images;#Proxy Settings## proxy_redirect [ default|off|redirect replacement ];## 默认：proxy_redirect default;## 当上游服务器返回的响应是重定向或刷新请求（如HTTP响应码是301或者302）时，proxy_redirect可以重设HTTP头部的location或refresh字段给客户端。## 假设后端服务器返回给代理服务器的Location字段为http://localhost:8000/two/uri/ ，而代理服务器需要返回的是http://frontend/one/uri 给客户端。## proxy_redirect http://localhost:8000/two/ http://frontend/one/;## 将Location字段重写为http://frontend/one/uri/。## 在代替的字段中可以不写服务器名：nginx会将host及port部分替换成自身的server_name及listen port，即使它来自非80端口。 ## proxy_redirect http://localhost:8000/two/ /; # 相当于(proxy_redirect http://localhost:8000/two/ http://$host:$server_port/;)## 对于多个域名匹配的server，redirect设置不能写作’/&apos;了，否则会用第一个域名作为redirect域名## 如果使用&quot;default&quot;参数，将根据location和proxy_pass参数的设置来决定。## 例如下列两个配置等效：## location /one/ &#123;## proxy_pass http://upstream:port/two/; ## proxy_redirect default; #此条设置等同于(proxy_redirect http://upstream:port/two/ http://upstream:port/two/one/;)## &#125;## prox_redirect 可以使用变量和正则，可以有用多个prox_redirect，但如果proxy_pass使用了变量，default将禁用。## 示例：proxy_redirect http://localhost:8000/ http://$host:$server_port/;## proxy_redirect http://$proxy_host:8000/ /;## proxy_redirect ~^(http://[^:]+):\d+(/.+)$ $1$2;## proxy_redirect ~*/user/([^/]+)/(.+)$ http://$1.example.com/$2;## 参数off将在这个字段中禁止所有的proxy_redirect指令.## 一般用于后端服务器和转发目的服务器目录一致，或者转发给后端服务器自己，location路径没变。proxy_redirect off;## proxy_set_header field value;## 允许将请求header字段重新定义或附加到传递给后端服务器 。该value可以包含文本，变量，以及它们的组合## value 为空(&quot;&quot;),表示取消传递此header字段给后端服务器proxy_set_header Host $host:$proxy_port;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;## 如果server 里用了ssl，客户端通过https连nginx 代理, nginx与后端服务器的通信还是http，为了让后端程序识别和使用客户端## Most PHP, Python, Rails, Java App can use this header ###proxy_set_header X-Forwarded-Proto https;proxy_set_header X-Forwarded-Proto $scheme;## proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | non_idempotent | off ...;## 指定请求应传递到下一个服务器的情况：## error:在与服务器建立连接，向其传递请求或读取响应标头时发生错误;## timeout:在与服务器建立连接，向其传递请求或读取响应头时发生超时;## invalid_header:服务器返回空响应或无效响应;## non_idempotent:通常，如果请求已经被发送到上游服务器（1.9.13），则具有非幂等方法的请求（POST，LOCK，PATCH）不被传递到下一个服务器;启用此选项明确允许重试此类请求;## off:禁用将请求传递到下一个服务器。proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;## 限制请求可以传递到下一个服务器的时间。 0值关闭此限制。# proxy_next_upstream_timeout 0;## 限制将请求传递到下一个服务器的可能尝试次数。 0值关闭此限制。# proxy_next_upstream_tries 0;proxy_connect_timeout 65;proxy_send_timeout 65;proxy_read_timeout 65;## 启用或禁用来自代理服务器的响应缓冲。## 默认为on#proxy_buffering on;## 设置size用于读取从代理服务器接收到的响应的第一部分的缓冲区。## 默认：proxy_buffer_size 4k | 8k;proxy_buffer_size 32k;## 为单个连接 设置用于从代理服务器读取响应的缓冲区number和size.proxy_buffers 16 32k;proxy_busy_buffers_size 128k;## 如果buffer不够用，就写入临时文件由 proxy_max_temp_file_size和 proxy_temp_file_write_size指令控制。proxy_temp_file_write_size 256k;## 默认最大1024m, 可以不用设置# proxy_max_temp_file_size 1024m;## 定义用于存储临时文件的目录，其中包含从代理服务器接收的数据。## 在指定目录下最多可以使用三级子目录层次结构。## proxy_temp_path path [level1 [level2 [level3]]];# proxy_temp_path /var/cache/nginx/proxy_temp 1 2;proxy_temp_path /dev/shm/proxy_temp 1 2;## 当客户端没等到response就关闭了连接，代理服务器是否关闭与后端的连接## 默认 proxy_ignore_client_abort 是关闭的，## 此时在请求过程中如果客户端端主动关闭请求或者客户端网络断掉，## 那么 Nginx 会记录 499，同时 request_time 是 「后端已经处理」的时间，而 upstream_response_time 为 “-“## 如果使用了 proxy_ignore_client_abort on ;## 那么客户端主动断掉连接之后，Nginx 会等待后端处理完(或者超时)，然后 记录 「后端的返回信息」 到日志。## 所以，如果后端 返回 200， 就记录 200 ；如果后端放回 5XX ，那么就记录 5XX 。## 如果超时(默认60s，可以用 proxy_read_timeout 设置)，Nginx 会主动断开连接，记录 504。# proxy_ignore_client_abort on;## proxy_intercept_errors on | off;## 确定代码大于或等于300的代理响应是应该传递给客户端还是被拦截并重定向到nginx以便使用error_page指令进行处理。## 默认值off# proxy_intercept_errors on;## proxy_limit_rate rate;## 仅当启用了代理服务器的响应缓冲时，此限制才有效 。## 限制从代理服务器读取响应的速度。在rate被以每秒字节数指定。零值禁用速率限制。## 设置proxy_hide_header和proxy_set_header 指令size使用的哈希表的最大值。## 默认：proxy_headers_hash_max_size 512;# proxy_headers_hash_max_size 512;## 设置proxy_hide_header和proxy_set_header 指令size使用的哈希表的存储区。## 默认：proxy_headers_hash_bucket_size 64;# proxy_headers_hash_bucket_size 64;## 设置不传递来自后端服务器响应的head字段给客户端## proxy_hide_header field;## 允许从代理服务器向客户端传递禁用的标头字段。## proxy_pass_header field;## 设置代理的HTTP协议版本。默认情况下，使用版本1.0。建议将1.1版与 keepalive 连接和 NTLM身份验证配合使用。## 默认：proxy_http_version 1.0;## proxy_store on | off | string;## 默认值off## 开启将文件保存到磁盘上的功能。## 如果设置为on，nginx将文件保存在alias指令或root指令设置的路径中。## 如果设置为off，nginx将关闭文件保存的功能。## 此外，保存的文件名也可以使用含变量的string参数来指定：proxy_store /data/www$original_uri;## 保存文件的修改时间根据接收到的“Last-Modified”响应头来设置。响应都是先写到临时文件，然后进行重命名来生成的。## 这条指令可以用于创建静态无更改文件的本地拷贝，比如：## location /images/ &#123;## root /data/www;## open_file_cache_errors off;## error_page 404 = @fetch;## &#125;## location @fetch &#123;## internal;## proxy_pass http://backend/;## proxy_store on;## proxy_store_access user:rw group:rw all:r;## proxy_temp_path /var/cache/nginx/proxy_temp 1 2; # 下面也可写成(root /data/www;)## alias /data/www/; ## &#125; proxy代理缓存配置proxy_cache：缓存后端服务器的内容，可能是任何内容，包括静态的和动态，减少了nginx与后端通信的次数，节省了传输时间和后端宽带 http里配置12345## 代理缓存定义## proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size [inactive=time] ## 只能定义在http里# proxy_cache_path /dev/shm/proxy_cache levels=1:2 keys_zone=proxy_cache_key:250m inactive=1d max_size=1g use_temp_path=off; location里配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576## 定义缓存的键## proxy_cache_key "$host$request_uri$cookie_user";proxy_cache_key $scheme$proxy_host$uri$is_args$args;## 经过多少次请求就缓存proxy_cache_min_uses 1;proxy_cache_revalidate on;## 确定在与代理服务器通信期间可以在哪些情况下使用过时的缓存响应。## proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | off ...;proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;## 设置不同响应代码的缓存时间。## proxy_cache_valid [code ...] time;## 如果后面只跟时间，表示只缓存200,301和302个响应。## any 表示缓存任何响应## 注意，直接在响应头中设置缓存的参数比这里的优先级高。## "X-Accel-Expires"标题字段以秒为单位设置响应的缓存时间。零值禁用响应的缓存。如果值以@前缀开头，则设置自Epoch以来的绝对时间（以秒为单位），响应可以高速缓存。## 如果标题不包括"X-Accel-Expires"字段，则可以在标题字段"Expires"或"Cache-Control"中设置高速缓存的参数。## 如果标头包含"Set-Cookie"字段，则不会缓存此类响应。## 如果标题包含具有特殊值" *" 的"Vary"字段，则不会缓存此类响应（1.7.7）。如果标题包含具有另一个值的"Vary"字段，则将考虑相应的请求标题字段来缓存这样的响应（1.7.7）。proxy_cache_valid 200 301 302 10m;proxy_cache_valid any 1m;## 禁用从代理服务器处理某些响应头字段。## 可以忽略以下字段："X-Accel-Redirect"，"X-Accel-Expires"，"X-Accel-Limit-Rate"（1.1.6），"X-Accel-Buffering"（1.1.6） ，"X-Accel-Charset"（1.1.6），"Expires"，"Cache-Control"，"Set-Cookie"（0.8.44）和"Vary"（1.7.7）。## 如果未禁用，则处理这些标头字段会产生以下影响：## "X-Accel-Expires"，"Expires"，"Cache-Control"，"Set-Cookie"和"Vary"设置响应缓存的参数;## "X-Accel-Redirect"执行 内部重定向到指定的URI;## "X-Accel-Limit-Rate"设置向客户端传输响应的 速率限制 ;## "X-Accel-Buffering"启用或禁用 缓冲响应;## "X-Accel-Charset"设置了所需 的响应字符集。#proxy_ignore_headers X-Accel-Expires Cache-Control Expires Set-Cookie;## 定义在哪些情况下不从cache读取，直接从backend获取资源；配置方式同proxy_no_cache。## 后面的变量值不为0 或 不是空值("")，则不从缓存取或不缓存#proxy_cache_bypass $proxy_skip_cache#proxy_no_cache $proxy_skip_cache## proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment; ## proxy_cache_bypass $http_pragma $http_authorization;## proxy_no_cache $cookie_nocache $arg_nocache $arg_comment; ## proxy_no_cache $http_pragma $http_authorization;## 启用后，如果缓存过期，一次只允许一个请求传递给代理服务器, 获取数据后更新缓存，其它请求要么等待缓存更新，要么使用旧的缓存数据。proxy_cache_lock on; ## 锁定超时，请求将被传递给代理的服务器，但是，响应不会被缓存。proxy_cache_lock_timeout 5s;## 在锁定期间内还未更新缓存，则再让下一个请求去获取更新proxy_cache_lock_age 5s; ## 允许启动后台子请求以更新过期的缓存项，同时将过时的缓存响应返回给客户端。## 默认值为off#proxy_cache_background_update on;## 允许使用具有"If-Modified-Since"和"If-None-Match"头字段的条件请求重新验证过期缓存项。## 默认值off#proxy_cache_revalidate on;## 指定客户端那些方法被缓存，默认为GET|HEAD。基本不需要设置## proxy_cache_methods GET| HEAD|POST## X-Proxy-Cache头，用于调试#add_header X-Proxy-Cache \$upstream_cache_status;#add_header X-Proxy-Cache '$upstream_cache_status from $server_addr';add_header X-Proxy-Cache "\$upstream_cache_status - \$upstream_response_time"; ## 缓存过期标记说明： .Expires: 最原始的配置策略，即设置过期时间，但使用效率低下，目前绝大部分已经被Cache-Control（有兴趣的可以去看下http1.0和http1.1）； .Cache-Control：定义缓存资源属性是private或者是public，并且设置缓存多久后过期，本例中，属性为public，60秒过期； .X-Accel-Expires: 只有nginx能识别的缓存特性header，优先级大于上面两个header，可以设置此header，在nginx侧来重新定义缓存特性； .Etag和Last-Modified是捆绑生成的: 有些场景下，你希望client端的浏览器长时间缓存，而缓存服务器只短时间缓存文件，以至于当后端服务器更新后，缓存服务器会及时同步，我们就可以使用最后两个header，Last-Modified表示最后修改时间，并声明一个ETag(哈希值)，做为缓存内容的标签，具有唯一性;客户端访问请求带有If‑Modified‑Since或者If‑None‑Match header，并申明自己的客户端带有静态缓存文件,以及文件修改日期和ETag值，如果服务器端的版本和Etag值与客户端一致，则服务端会直接返回304 not modified，这个验证流程是非常快的，并且节省网络带宽； .如果Cache-Control设置为public，则客户端不会去验证资源的有效性，将会一直使用直到过期，同时public也代表资源可以被缓存在web proxy中； .如果Cache-Control包含must-revalidate，则客户端每一次访问请求资源都会去验证缓存是否有更新； 打开文件缓存## max：设置缓存中的最大元素数; 在缓存溢出时，删除最近最少使用（LRU）的元素; ## inactive：定义一个时间，如果在此期间未访问该元素，则从该缓存中删除该元素; 默认情况下，它是60秒; open_file_cache max = 1000 inactive = 20s; ## 打开文件缓存的过期时间验证间隔 open_file_cache_valid 60s; ## 在inactive时间内，访问多少次就缓存 open_file_cache_min_uses 2; ## 启用或禁用文件查找错误的缓存，默认值off #open_file_cache_errors on; 参考：http://www.cnblogs.com/cmfwm/p/7659179.html Nginx 的 open_file_cache 相关配置可以缓存静态文件的元信息，在这些静态文件被频繁访问时可以显着提升性能。 注意不会缓存文件内容，只缓存文件元信息。还是慎用此功能。 被缓存的文件元信息包括： fd，文件被打开一次后，fd保留使用 size path last modified time 由于 nginx 还持有原文件的 fd，所以你删除此文件后，文件并不会真正消失， client 还是能通过原路径访问此文件。即便你删除后又新建了一个同名文件，在当前缓存更新周期内能访问到的还是原文件的内容。 文件大小调整，可能导致发给客户端的信息并非是修改后文件内容。 如果你的静态文件内容变化频繁并且对时效性要求较高，一般应该把 open_file_cache_valid 设置的小一些，以便及时检测和更新。 如果变化相当不频繁的话，那就可以设置大一点，在变化后用 reload nginx 的方式来强制更新缓存。 对静态文件访问的 error 和 access log 不关心的话，可以关闭已提升效率。 location 说明1.=开头表示精确匹配，如 A 中只匹配根目录结尾的请求，后面不能带任何字符串。 2.^~ 开头表示uri以某个常规字符串开头，不是正则匹配。 3.~ 开头表示区分大小写的正则匹配; 4.~* 开头表示不区分大小写的正则匹配 5./ 通用匹配, 如果没有其它匹配,任何请求都会匹配到 顺序 no优先级： (location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ,* 正则顺序) &gt; (location 部分起始路径) &gt; (/) 压缩模块http 模块配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859mkdir -p /etc/nginx/http.dcat &gt; /etc/nginx/http.d/50.gzip.conf &lt;&lt; EOF ## 开启gzip gzip on; ## 对数据启用压缩的最少字节数,如:请求小于1K文件,不要压缩,压缩小数据会降低处理此请求的所有进程速度 gzip_min_length 1k; ## Nginx做为反向代理的时候启用,匹配的前提是后端服务器必须要返回包含"Via"的 header头： ## off - 关闭所有的代理结果数据的压缩 ## expired - 启用压缩，如果header头中包含 "Expires" 头信息 ## no-cache - 启用压缩，如果header头中包含 "Cache-Control:no-cache" 头信息 ## no-store - 启用压缩，如果header头中包含 "Cache-Control:no-store" 头信息 ## private - 启用压缩，如果header头中包含 "Cache-Control:private" 头信息 ## no_last_modified - 启用压缩,如果header头中不包含 "Last-Modified" 头信息 ## no_etag - 启用压缩 ,如果header头中不包含 "ETag" 头信息 ## auth - 启用压缩 , 如果header头中包含 "Authorization" 头信息 ## any - 无条件启用压缩 #gzip_proxied any; gzip_proxied expired no-cache no-store private auth; ## 是否在http header中添加Vary: Accept-Encoding，建议开启,让前端的缓存服务器识别压缩后的文件,代理 gzip_vary on; ## 设置用于处理请求压缩的缓冲区数量和大小。 ## 比如32 4K表示按照内存页（one memory page）大小以4K为单位（即一个系统中内存页为4K），申请32倍的内存空间。 ## 此项设置太小，如果需要压缩的文件超过缓存数X缓存大小，会导致数据截断。 ## gzip_buffers 32 4k|16 8k; gzip_buffers 64 16k; ## 设置gzip压缩针对的HTTP协议版本，默认1.1。默认在http/1.0的协议下不开启gzip压缩。 ## nginx和后端的upstream server之间默认是用HTTP/1.0协议通信的 ## 后端的nginx上没有设置gzip_http_version为1.0，那么Cache的url将不会进行gzip压缩。 ## 前端的nginx也要开启gzip gzip_http_version 1.0; ## gzip压缩等级在0-9内,数值越大压缩率越高,CPU消耗也就越大 ## gzip_comp_level 1的压缩能力已经够用了，后面级别越高，压缩的比例其实增长不大，反而很吃处理性能。 gzip_comp_level 2; ## 表明哪些UA头不使用gzip压缩，禁用低版本的IE浏览器启用压缩功能 #gzip_disable "msie6"; gzip_disable "MSIE [1-6]\."; ## 进行压缩的文件类型。javascript有多种形式。其中的值可以在 mime.types 文件中找到。 gzip_types text/plain text/css text/xml application/javascript application/json application/xml application/xml+rss application/xhtml+xml application/rss+xml application/atom+xml;EOF 连接限制http 模块配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950mkdir -p /etc/nginx/http.dcat &gt; /etc/nginx/http.d/50.limit.conf &lt;&lt; EOF## 白名单,代理，特别IP地址或网络geo \$remote_addr \$whiteiplist &#123; default 1; 101.230.0.11 0; 10.250.250.0/24 0; 127.0.0.1 0;&#125;## 返回值为空表示不限制map \$whiteiplist \$limit &#123; 1 \$binary_remote_addr; 0 "";&#125;## 获取客户端的真是IP，会直接映射到remote_addrreal_ip_header X-Forwarded-For;set_real_ip_from 139.219.193.17;#set_real_ip_from 0.0.0.0/0;#real_ip_recursive on;# 状态返回444, 表示Nginx不响应客户端请求，直接丢弃。# log level 设置为info, 这样就不会记录到错误日志里limit_conn_zone \$limit zone=conn:30m;limit_conn_status 444;limit_conn_log_level info;limit_req_zone \$limit zone=perip:30m rate=5r/s;limit_req_status 444;limit_req_log_level info;EOF## 最后编辑 /etc/nginx.conf 文件,在最后用include包含此文件http &#123; ......... include /etc/nginx/http.d/*.conf; include /etc/nginx/conf.d/*.conf;&#125; server 模块配置123456789101112131415161718192021## 在location里添加限制，一般在html php jsp 等页面处理模块添加。## 静态资源文件由于处理速度比较开，除非极端攻击，否则不添加。server&#123; ..... location ~ [^/]\.php(/|$) &#123; ..... ## 限制某时段内保持每ip最多的连接数 limit_conn conn 5; ## 限制某时段内每ip最多的页面并发请求数 limit_req zone=perip burst=5 nodelay; ...... &#125; .....&#125; geoip模块加载# 需要配置在nginx.conf文件的最顶端。 1234567891011121314151617181920212223242526272829303132# 存放模块的目录 mkdir /etc/nginx/modules -p# 存放模块配置文件的目录 mkdir /etc/nginx/modules.d -p# 配置文件添加模块导入# 安装模块 yum install nginx-module-geoip# 添加模块配置文件## nginx.conf 开头添加模块cat &gt; /etc/nginx/modules.d/ngx_http_geoip_module.conf &lt;&lt; EOFload_module "modules/ngx_http_geoip_module.so";EOF## nginx.conf http 里头添加配置cat &gt; /etc/nginx/http.d/http_geoip.conf &lt;&lt; EOFgeoip_country /etc/nginx/geoip/GeoIP.dat;EOF ## location 中应用12345678910111213141516171819202122232425262728293031323334353637383940location /myip &#123; default_type text/plain; return 200 "$remote_addr $geoip_country_name $geoip_country_code $geoip_city"; #return 403 "if you are not a robot,please contact server admin.";&#125;## 使用if判断会出现问题，这里只是一个不完善的示例location ~ [^/]\.php(/|$)&#123; ## 利用cookie检测防范cc攻击，前提客户端浏览器必须支持cookie # if ($cookie_clientip != "ip_$remote_addr")&#123; # add_header Set-Cookie "clientip=ip_$remote_addr"; # return 301 "$scheme://$host$request_uri"; # &#125; set $adminflag 0; if ( $request_uri ~* "/+(?:downloader|admin)" ) &#123; set $adminflag 1; #rewrite ^/(.*)$ $scheme://$host/myip permanent; &#125; if ( $geoip_country_code !~* "CN" ) &#123; set $adminflag "$&#123;adminflag&#125;1"; #rewrite ^/(.*)$ $scheme://$host/myip permanent; &#125; if ( $adminflag = "11" ) &#123; return 403; &#125; ....&#125; 常用的标准模块核心模块： core module 常用的标准模块： HTTP modules： ngx_http_core_modules http核心功能模块（重要） ngx_http_ssl_module http信道加密模块（重要） ngx_http_upstream_module http定义服务器组模块（重要） ngx_http_fastcgi|uWSGI|SCGI_module http web api接口模块（重要） ngx_http_proxy_module http反向代理模块（重要） ngx_http_gzip_module http gzip压缩传输模块（次一级） ngx_http_log_module http日志模块（次一级） ngx_http_referer_modulehttp防盗链模块（次一级） ngx_http_rewrite_module http重定向模块（次一级） ngx_http_access_module http权限控制模块 ngx_http_auth_basic_module http认证模块 ngx_http_stub_status_module http状态模块 ngx_http_headers_module http首部信息模块 Mail modules： 用的少 Stream modules： ngx_stream_core_module http的伪四层负载均衡模块 启用 aio 线程池http://www.infoq.com/cn/articles/thread-pools-boost-performance-9x http、 server，或者location上下文中包含aio threads指令即可： aio threads; 这是线程池的最简配置。实际上的精简版本示例如下： thread_pool default threads=32 max_queue=65536; aio threads=default; 这里定义了一个名为&quot;default&quot;，包含32个线程，任务队列最多支持65536个请求的线程池。 如果任务队列过载，NGINX将输出如下错误日志并拒绝请求： thread pool &quot;NAME&quot; queue overflow: N tasks waiting http { thread_pool one threads=128 max_queue=0; thread_pool two threads=32; server { location /one { aio threads=one; } location /two { aio threads=two; } } … } https://www.cnblogs.com/felixzh/category/882480.html nginx http2 介绍https://blog.csdn.net/zhuyiquan/article/details/52585941]]></content>
      <categories>
        <category>nginx</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[混合云自建V-P-N]]></title>
    <url>%2Flinux%2Fipsec%2F%E6%B7%B7%E5%90%88%E4%BA%91%E8%87%AA%E5%BB%BAV-P-N%2F</url>
    <content type="text"><![CDATA[参考：https://yq.aliyun.com/articles/504348?spm=a2c4e.11153940.blogcont434405.27.300e35b1Inhu7M#4 docker VPN 服务器## 网站： https://github.com/hwdsl2/docker-ipsec-vpn-server 安装docker1234567891011121314cat &gt;/etc/yum.repos.d/docker.repo &lt;&lt;EOF##https://download.docker.com/linux/centos/[docker-ce-stable]name=Docker CE Stable - \$basearchbaseurl=https://download-stage.docker.com/linux/centos/7/\$basearch/stableenabled=1gpgcheck=1gpgkey=https://download-stage.docker.com/linux/centos/gpgEOFyum install docker-ce docker 镜像systemctl start docker ## 预构建的可信任镜像 docker pull hwdsl2/ipsec-vpn-server 运行 IPsec VPN 服务器## 环境变量，可选 12345678910111213141516cat &gt; /etc/vpn.env &lt;&lt;EOF# Define your own values for these variables# - DO NOT put "" or '' around values, or add space around =# - DO NOT use these special characters within values: \ " '# 注： 在你的 env 文件中，不要为变量值添加 "" 或者 ''，或在 = 两边添加空格。不要在值中使用这些字符： \ " '。# IPsec PSK (预共享密钥)VPN_IPSEC_PSK=your_ipsec_pre_shared_key# VPN 用户名和密码VPN_USER=your_vpn_usernameVPN_PASSWORD=your_vpn_passwordEOF 加载 IPsec af_key 内核模块## 重要： 首先需要在 Docker 主机上加载 IPsec af_key 内核模块： modprobe af_key ## 为保证系统启动加载，systemd-modules-load.service会自动加载配置文件 cat &gt; /etc/modules-load.d/af_key.conf &lt;&lt;EOF # Load af_key.ko at boot af_key EOF 使用镜像创建一个新的 Docker 容器（将 ./vpn.env 替换为你自己的 env 文件）： docker run \ --name ipsec-vpn-server \ --env-file /etc/vpn.env \ --restart=always \ -p 500:500/udp \ -p 4500:4500/udp \ -v /lib/modules:/lib/modules:ro \ -d --privileged \ hwdsl2/ipsec-vpn-server 获取 VPN 登录信息docker logs ipsec-vpn-server ## 在命令输出中查找这些行： Connect to your new VPN with these details: Server IP: 你的VPN服务器IP IPsec PSK: 你的IPsec预共享密钥 Username: 你的VPN用户名 Password: 你的VPN密码 （可选步骤） 备份自动生成的 VPN 登录信息（如果有）到当前目录： docker cp ipsec-vpn-server:/opt/src/vpn-gen.env ./ 查看服务器状态## 如需查看你的 IPsec VPN 服务器状态，可以在容器中运行 ipsec status 命令： docker exec -it ipsec-vpn-server ipsec status ## 或者查看当前已建立的 VPN 连接： docker exec -it ipsec-vpn-server ipsec whack --trafficstatus 提示：Windows 用户 在首次连接之前需要修改注册表，以解决 VPN 服务器 和/或 客户端与 NAT（比如家用路由器）的兼容问题。 同一个 VPN 账户可以在你的多个设备上使用。但是由于 IPsec/L2TP 的局限性，如果需要同时连接在同一个 NAT （比如家用路由器）后面的多个设备到 VPN 服务器，你必须仅使用 IPsec/XAuth 模式。 对于有外部防火墙的服务器（比如 EC2/GCE），请为 VPN 打开 UDP 端口 500 和 4500。 在编辑任何 VPN 配置文件之前，你必须首先在正在运行的 Docker 容器中 开始一个 Bash 会话。 如果需要添加，修改或者删除 VPN 用户账户，请参见 管理 VPN 用户。重要： 在编辑完 VPN 配置文件之后，你还必须注释掉脚本 /opt/src/run.sh 中的相应部分，以避免你的更改在容器重启后丢失。 在 VPN 已连接时，客户端配置为使用 Google Public DNS。如果偏好其它的域名解析服务，请编辑 /opt/src/run.sh 并将 8.8.8.8 和 8.8.4.4 替换为你的新服务器。然后重启 Docker 容器。 高级用法1. 从源代码构建 高级用户可以从 GitHub 下载并自行编译源代码： git clone https://github.com/hwdsl2/docker-ipsec-vpn-server.git cd docker-ipsec-vpn-server docker build -t hwdsl2/ipsec-vpn-server . 若不需要改动源码，也可以这样： docker build -t hwdsl2/ipsec-vpn-server github.com/hwdsl2/docker-ipsec-vpn-server.git 2. 在容器中运行 Bash shell 在正在运行的 Docker 容器中开始一个 Bash 会话： docker exec -it ipsec-vpn-server env TERM=xterm bash -l （可选步骤） 安装 vim 编辑器： apt-get update &amp;&amp; apt-get -y install vim 然后在容器中运行你的命令。完成后退出并重启 Docker 容器 （如果需要）： exit docker restart ipsec-vpn-server 3. 启用 Libreswan 日志 为了保持较小的 Docker 镜像，Libreswan (IPsec) 日志默认未开启。如果你是高级用户，并且需要启用它以便进行故障排除，首先在正在运行的 Docker 容器中开始一个 Bash 会话： docker exec -it ipsec-vpn-server env TERM=xterm bash -l 然后运行以下命令： apt-get update &amp;&amp; apt-get -y install rsyslog service rsyslog restart service ipsec restart sed -i &apos;/modprobe/a service rsyslog restart&apos; /opt/src/run.sh exit 完成后你可以这样查看 Libreswan 日志： docker exec -it ipsec-vpn-server grep pluto /var/log/auth.log 技术细节需要运行以下两个服务： Libreswan (pluto) 提供 IPsec VPN， xl2tpd 提供 L2TP 支持。 默认的 IPsec 配置支持以下协议： IKEv1 with PSK and XAuth (&quot;Cisco IPsec&quot;) IPsec/L2TP with PSK 为使 VPN 服务器正常工作，将会打开以下端口： 4500/udp and 500/udp for IPsec 配置 IPsec/XAuth (“Cisco IPsec”) VPN 客户端https://github.com/hwdsl2/setup-ipsec-vpn/blob/master/docs/clients-zh.md#windows-%E9%94%99%E8%AF%AF-809 Windows 注: 你也可以使用 IPsec/L2TP 模式 连接，无需安装额外的软件。 下载并安装免费的 Shrew Soft VPN 客户端。 https://www.shrew.net/download/vpn 注： 该 VPN 客户端支持 Windows 2K/XP/Vista/7/8 系统。 单击开始菜单 -&gt; 所有程序 -&gt; ShrewSoft VPN Client -&gt; VPN Access Manager 单击工具栏中的 Add (+) 按钮。 在 Host Name or IP Address 字段中输入你的 VPN 服务器 IP。 单击 Authentication 选项卡，从 Authentication Method 下拉菜单中选择 Mutual PSK + XAuth。 在 Local Identity 子选项卡中，从 Identification Type 下拉菜单中选择 IP Address。 单击 Credentials 子选项卡，并在 Pre Shared Key 字段中输入你的 VPN IPsec PSK。 单击 Phase 1 选项卡，从 Exchange Type 下拉菜单中选择 main。 单击 Phase 2 选项卡，从 HMAC Algorithm 下拉菜单中选择 sha1。 单击 Save 保存 VPN 连接的详细信息。 选择新添加的 VPN 连接。单击工具栏中的 Connect 按钮。 在 Username 字段中输入你的 VPN 用户名。 在 Password 字段中输入你的 VPN 密码。 单击 Connect。 VPN 连接成功后，你会在 VPN Connect 状态窗口中看到 tunnel enabled 字样。单击 &quot;Network&quot; 选项卡，并确认 Established - 1 显示在 &quot;Security Associations&quot; 下面。最后你可以到 这里 检测你的 IP 地址，应该显示为你的 VPN 服务器 IP。 如果在连接过程中遇到错误，请参见 故障排除。 OS X 打开系统偏好设置并转到网络部分。 在窗口左下角单击 + 按钮。 从 接口 下拉菜单选择 VPN。 从 VPN类型 下拉菜单选择 Cisco IPSec。 在 服务名称 字段中输入任意内容。 单击 创建。 在 服务器地址 字段中输入你的 VPN 服务器 IP。 在 帐户名称 字段中输入你的 VPN 用户名。 在 密码 字段中输入你的 VPN 密码。 单击 鉴定设置 按钮。 在 机器鉴定 部分，选择 共享的密钥 单选按钮，然后输入你的 VPN IPsec PSK。 保持 群组名称 字段空白。 单击 好。 选中 在菜单栏中显示 VPN 状态 复选框。 单击 应用 保存VPN连接信息。 要连接到 VPN： 使用菜单栏中的图标，或者打开系统偏好设置的网络部分，选择 VPN 并单击 连接。最后你可以到 这里 检测你的 IP 地址，应该显示为你的 VPN 服务器 IP。 Android 启动 设置 应用程序。 在 无线和网络 部分单击 更多...。 单击 VPN。 单击 添加VPN配置文件 或窗口右上角的 +。 在 名称 字段中输入任意内容。 在 类型 下拉菜单选择 IPSec Xauth PSK。 在 服务器地址 字段中输入你的 VPN 服务器 IP。 保持 IPSec 标识符 字段空白。 在 IPSec 预共享密钥 字段中输入你的 VPN IPsec PSK。 单击 保存。 单击新的VPN连接。 在 用户名 字段中输入你的 VPN 用户名。 在 密码 字段中输入你的 VPN 密码。 选中 保存帐户信息 复选框。 单击 连接。 VPN 连接成功后，会在通知栏显示图标。最后你可以到 这里 检测你的 IP 地址，应该显示为你的 VPN 服务器 IP。 如果在连接过程中遇到错误，请参见 故障排除。 iOS 进入设置 -&gt; 通用 -&gt; VPN。 单击 添加VPN配置...。 单击 类型 。选择 IPSec 并返回。 在 描述 字段中输入任意内容。 在 服务器 字段中输入你的 VPN 服务器 IP。 在 帐户 字段中输入你的 VPN 用户名。 在 密码 字段中输入你的 VPN 密码。 保持 群组名称 字段空白。 在 密钥 字段中输入你的 VPN IPsec PSK。 单击右上角的 存储。 启用 VPN 连接。 VPN 连接成功后，会在通知栏显示图标。最后你可以到 这里 检测你的 IP 地址，应该显示为你的 VPN 服务器 IP。 故障排除Windows 错误 809 无法建立计算机与 VPN 服务器之间的网络连接，因为远程服务器未响应。 要解决此错误，在首次连接之前需要修改一次注册表，以解决 VPN 服务器 和/或 客户端与 NAT （比如家用路由器）的兼容问题。请下载并导入下面的 .reg 文件，或者打开 提升权限命令提示符 并运行以下命令。完成后必须重启计算机。 适用于 Windows Vista, 7, 8.x 和 10 (下载 .reg 文件) REG ADD HKLM\SYSTEM\CurrentControlSet\Services\PolicyAgent /v AssumeUDPEncapsulationContextOnSendRule /t REG_DWORD /d 0x2 /f 仅适用于 Windows XP (下载 .reg 文件) REG ADD HKLM\SYSTEM\CurrentControlSet\Services\IPSec /v AssumeUDPEncapsulationContextOnSendRule /t REG_DWORD /d 0x2 /f 另外，某些个别的 Windows 系统配置禁用了 IPsec 加密，此时也会导致连接失败。要重新启用它，可以运行以下命令并重启。 适用于 Windows XP, Vista, 7, 8.x 和 10 (下载 .reg 文件) REG ADD HKLM\SYSTEM\CurrentControlSet\Services\RasMan\Parameters /v ProhibitIpSec /t REG_DWORD /d 0x0 /f]]></content>
      <categories>
        <category>linux</category>
        <category>ipsec</category>
      </categories>
      <tags>
        <tag>ipsec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下配置hexo开机启动]]></title>
    <url>%2Fhexo%2Fwindows%E4%B8%8B%E9%85%8D%E7%BD%AEhexo%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[为了更方便的使用，寻找一种可以开机启动hexo server的方法，通过脚本实现。 需要创建2个脚本，一个为vbs脚本，一个为bat脚本。 vbs脚本放到启动文件夹，用于运行bat脚本，而bat脚本用于启动hexo server 创建vbs脚本set ws=WScript.CreateObject(&quot;WScript.Shell&quot;) ws.Run &quot;C://share//hexo//hexo-server.bat /start&quot;,0 创建bat脚本cd C:/share/hexo hexo s -d 将vbs脚本放到启动文件夹win10 启动文件夹目录为 C:\Users\你的用户名\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup 这样就能实现开机启动hexo server了，剩下的一切都可以交给浏览器和hexo-admin了。 如果使用七牛，则可以使用hexo-admin with qiniu]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows 2008R2 浏览器支持MP4播放]]></title>
    <url>%2Fwindows%2Fwindows%202008R2%20%E6%B5%8F%E8%A7%88%E5%99%A8%E6%94%AF%E6%8C%81MP4%E6%92%AD%E6%94%BE%2F</url>
    <content type="text"><![CDATA[安装和kb2483177补丁kb2483177 https://download.microsoft.com/download/7/3/D/73D3721D-17E7-4D7A-9C64-5CCD0DD285B1/Windows6.1-KB2483177-x64.msu kb2454826：可选安装 https://download.microsoft.com/download/D/B/D/DBD62263-2627-49CB-B675-AA1601EBE0BD/Windows6.1-KB2454826-v2-x64.msu 参考：https://blog.csdn.net/linyuejiang/article/details/9945693]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 负载-代理-缓存配置]]></title>
    <url>%2Fnginx%2Fconfig%2FNginx%20Proxy%20%E4%BB%A3%E7%90%86%E5%9B%BE%E7%89%87%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E7%BC%93%E5%AD%98%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[nginx http 里负载配置123456789101112131415mkdir -p /etc/nginx/http.dcat &gt; /etc/nginx/http.d/20.upstream.conf &lt;&lt; EOFupstream images &#123; server 200.200.200.222:99 weight=5 max_fails=3 fail_timeout=60s; server 200.200.200.223:99 weight=5 max_fails=3 fail_timeout=60s; # server 200.200.200.225:99 weight=5 backup; # server unix:/tmp/backend3; #使用unix socket # keepalive 32;&#125;EOF nginx server 代理配置123456789location ~ .*\.(mp4|gif|jpg|jpeg|png|bmp|swf|js|css)$&#123; ## 指定访问后端服务器的IP地址 #proxy_bind 127.0.0.1; proxy_pass $scheme://images; include local.d/proxy.conf; proxy_next_upstream http_404;&#125; 代理参数123456789101112131415161718192021222324252627mkdir -p /etc/nginx/local.dcat &gt; /etc/nginx/local.d/proxy.conf &lt;&lt; EOF#proxy_next_upstream http_404proxy_redirect off;proxy_set_header Host \$host;proxy_set_header X-Real-IP \$remote_addr;proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;proxy_set_header Accept-Encoding 'gzip';client_max_body_size 100m;client_body_buffer_size 256k;proxy_connect_timeout 60;proxy_send_timeout 60;proxy_read_timeout 60;proxy_buffer_size 512k;proxy_buffers 8 512k;proxy_busy_buffers_size 512k;proxy_temp_file_write_size 512k;EOF upstream调度算法默认round robin 随机负载。 1. ip_hash 源地址hash调度方法,可用位置:upstream 指定一个使用负载均衡方法根据客户端 IP 地址将请求分发给一些服务器的群。 客户 IPv4 地址或者 IPv6 地址的前三个位群作为一个散列键。 这个方法可以使同一个客户端的常常被发送给同一台主机，除非这台主机是不可用状态。 在这种情况下(该主机不可用)客户端请求会被传递到另一台主机。大多数情况下，它将被发送给同一台主机。 Nginx 1.3.2 和 1.2.2 之后开始支持 IPv6 地址。 如果服务器中的一台需要临时移除掉，那么它应该使用 down 参数标记以保持客户 IP 地址的当前散列。 在 Nginx 1.3.1 和 1.2.2 版本之前的版本是无法使用 ip_hash 负载均衡方式定义服务器权重的。 2. least_conn 最少连接调度算法，当server拥有不同的权重时其为wlc，当所有后端主机连接数相同时，则使用wrr，适用于长连接 定义一群应该在请求传递给具有最小有效连接的服务器时使用的负载均衡方法，要考虑到服务器的权重。如果有很多这样的服务器，将会使用带权重的 round-robin 方法。 3. hash key [consistent] 基于指定的key的hash表来实现对请求的调度，此处的key可以直接文本、变量或二者组合 可用位置:upstream 作用：将请求分类，同一类请求将发往同一个upstream server，使用consistent参数，将使用ketama一致性hash算法，适用于后端是Cache服务器（如varnish）时使用 hash $request_uri consistent; #根据url hash $remote_addr; #根据请求的主机 server 配置语法：server address [parameters]; 在upstream上下文中server成员，以及相关的参数； 可用位置:upstream address的表示格式： unix:/PATH/TO/SOME_SOCK_FILE IP[:PORT] HOSTNAME[:PORT] parameters： weight=number #权重，默认为1 max_conns #连接后端报务器最大并发活动连接数，1.11.5后支持 max_fails=number #失败尝试最大次数；超出此处指定的次数时，server将被标记为不可用,默认为1 fail_timeout=time #后端服务器标记为不可用状态的连接超时时长，默认10s backup #将服务器标记为“备用”，即所有服务器均不可用时才启用 down #标记为“不可用”，配合ip_hash使用，实现灰度发布 可设置参数为： 1. weight=number ： 默认为1，weight越大，负载的权重就越大。 2. max_fails=number ： 设置由 fail_timeout 定义的时间段内连接该主机的失败次数，以此来断定 fail_timeout 定义的时间段内该主机是否可用。 默认情况下这个数值设置为 1。零值的话禁用这个数量的尝试。 当超过最大次数时，返回proxy_next_upstream模块定义的错误。 由proxy_next_upstream、fastcgi_next_upstream、以及memcached_next_upstream 等指令来判定错误尝试。 如果群里面只有一台主机，那么 max_fails、 fail_timeout 和 slow_start 参数将被忽略，而且这样的主机也永远不会被认为不可用。 3. fail_timeout=time ： 设置 在指定时间内连接到主机的失败次数，超过该次数该主机被认为不可用。 服务器被视为无效的时段。 这个参数默认是 10 秒钟。 fail_timeout 的默认值是 10 秒，配合默认值为 1 的 max_fails 参数，意思是如果在 fail_timeout 期间后端失败了 max_fails 次，那么就将这个后端标识为不可用，在接下来的 fail_timeout 期间， NGINX 不会再将请求分配到这个后端。 如果将 fail_timeout 设置为 0 ，那么无论后端失败了多少次， NGINX 会继续把请求分发到这个后端服务器地址。 在动态应用中，出现偶尔的 500 错误是很正常而且几乎无法避免的。如果后端因为某些更严重的原因一直出现 500 错误，那nginx upstream 的自动剔除该服务器。 fail_timeout 设置为 10 秒或者更长时间，可能对于静态的后端会更有意义。因为静态的后端通常很难出现 500 错误。如果出错了，一般也都是因为一些更麻烦的问题，比如硬盘坏了，或者内存满了之类 1. 假如 upstream 只有一个 server ，那 max_fails 和 fail_timeout 都是没用的。 2. 假如 upstream 有多个 server ，那超过了 max_fails 次错误后，在 fail_timeout 时间内会摘除这个 server。如果全部 server 都失败， nginx 会清空这个状态，轮询所有服务器 4. backup：将当前服务器标记为备份服务器。当主服务器不可用时，向备用服务器传递请求。 5. down： 标记当前服务器为不可用；和 ip_hash 指令一起使用。 6. slow_start=time ： 设置一台不健康的主机变成健康主机，或者当一台主机在被认为不可用变成可用时，将其权重由零恢复到标称值的时间。 默认值为零，也就是说，禁用慢启动。 这个功能仅作为我们的商业订阅的一部分。 keepalive语法：keepalive connections; 激活 upstream 服务器的连接缓存。 connections 参数设置保存在每个工作进程缓存中的 upstream 主机的闲置 keepalive 连接的最大个数。 超出这个数目时，最近很少使用的连接被关闭。 keepalive 指令并没有限制一个 Nginx 工作进程所能承载的连接总量。 connections 应该设置为一个足够小的值以使 upstream 服务器也足以应对新的连接。 用 http 1.1 和 connection keep-alive 可以提高效率。 nginx 默认给 upstream 是 connection: close 12345678910111213141516171819## 带有 keepalive 连接的 memcached upstream 配置例子：upstream memcached_backend &#123; server 127.0.0.1:11211; server 10.0.0.2:11211; keepalive 32;&#125;server &#123; ... location /memcached/ &#123; set $memcached_key $uri; memcached_pass memcached_backend; &#125;&#125; 对于 HTTP，proxy_http_version 指令应该设置为 &quot;1.1&quot;，并且清空 &quot;Connection&quot; 头字段： 1234567891011121314151617upstream http_backend &#123; server 127.0.0.1:8080; keepalive 16;&#125;server &#123; ... location /http/ &#123; proxy_pass http://http_backend; proxy_http_version 1.1; proxy_set_header Connection &quot;&quot;; ... &#125;&#125; 对于 FastCGI 服务器，需要为持久连接设置 fastcgi_keep_conn： 当使用 round-robin 之外的负载均衡方法时，需要在 keepalive 指令之前将他们激活。 SCGI 和 uwsgi 协议没有长连接的概念。 12345678910111213141516upstream fastcgi_backend &#123; server 127.0.0.1:9000; keepalive 8;&#125;server &#123; ... location /fastcgi/ &#123; fastcgi_pass fastcgi_backend; fastcgi_keep_conn on; ... &#125;&#125; Nginx Proxy 代理图片静态文件缓存配置图片服务器使用 Nginx 的 proxy_store 把主服务器的静态内容缓存到本地。 一次访问结束后，以后的访问将直接在本地硬盘上读写。从而分担流量负载 server { include listen.conf; server_name ucenter.gznow.org; location ~ \.php$ { limit_conn one 20; limit_rate 50k; proxy_pass http://s1; include proxy.conf; } location / { expires max; root /data/nginx_cache/ucenter; proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /data/nginx_cache/ucenter; include local.d/proxy.conf; #proxy_bind 127.0.0.1; proxy_next_upstream http_404; if ( !-e $request_filename) { proxy_pass $scheme://images; } } } 缓存模板123456789101112131415161718192021222324http&#123; proxy_cache_path /var/cache/nginx/proxy_cache levels=1:2:2 keys_zone=proxycache:20m inactive=120s max_size=1g; upstream mysqlsrvs&#123; ip_hash; #源地址hash调度方法 写了backup就不可用 server 172.18.99.1:80 weight=2; #weight权重 server 172.18.99.2:80; #标记down，配合ip_hash使用，实现灰度发布 server 172.18.99.3:80 backup; #backup将服务器标记为“备用”，即所有服务器均不可用时才启用 &#125;&#125;server&#123; server_name www.a.com; proxy_cache proxycache; proxy_cache_key $request_uri; proxy_cache_valid 200 302 301 1h; proxy_cache_valid any 1m; location / &#123; proxy_pass http://mysqlsrvs; &#125;&#125; Haproxy做代理,后端nginx获取真实用户IP1）修改haproxy配置文件,添加如下参数: option httpclose option forwardfor 2）修改nginx配置文件,添加如下参数 注意:需要编译模块--with-http_realip_module #haproxy服务器IP set_real_ip_from 192.168.64.128; real_ip_header X-Forwarded-For; real_ip_recursive on; 3）分别重启haproxy和nginx upstreem 第三方check模块cd /opt yum install unzip wget https://github.com/yaoweibin/nginx_upstream_check_module/archive/master.zip wget http://nginx.org/download/nginx-1.14.0.tar.gz tar -zxf nginx-1.14.0.tar.gz unzip master.zip cd /opt/nginx-1.14.0/ ## 给nginx打上补丁 patch -p1 &lt; /opt/nginx_upstream_check_module-master/check_1.12.1+.patch ## 配置 ./configure --add-module=/opt/nginx_upstream_check_module-master --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt=&apos;-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC&apos; --with-ld-opt=&apos;-Wl,-z,relro -Wl,-z,now -pie&apos; make &amp;&amp; make install 配置样本1234567891011121314151617181920212223242526272829303132333435http &#123; upstream cluster &#123; # simple round-robin server 192.168.0.1:80; server 192.168.0.2:80; check interval=5000 rise=1 fall=3 timeout=4000; #check interval=3000 rise=2 fall=5 timeout=1000 type=ssl_hello; #check interval=3000 rise=2 fall=5 timeout=1000 type=http; #check_http_send "HEAD / HTTP/1.0\r\n\r\n"; #check_http_expect_alive http_2xx http_3xx; &#125; server &#123; listen 80; location / &#123; proxy_pass http://cluster; &#125; location /status &#123; check_status; access_log off; allow SOME.IP.ADD.RESS; deny all; &#125; &#125;&#125; 参数： check syntax: *check interval=milliseconds [fall=count] [rise=count] [timeout=milliseconds] [default_down=true|false] [type=tcp|http|ssl_hello|mysql|ajp|fastcgi]* default: *none, if parameters omitted, default parameters are interval=30000 fall=5 rise=2 timeout=1000 default_down=true type=tcp* check_http_send syntax: *check_http_send http_packet* default: *&quot;GET / HTTP/1.0\r\n\r\n&quot;* context: *upstream* description: If you set the check type is http, then the check function will sends this http packet to check the upstream server. check_http_expect_alive syntax: *check_http_expect_alive [ http_2xx | http_3xx | http_4xx | http_5xx ]* default: *http_2xx | http_3xx* context: *upstream* description: These status codes indicate the upstream server&apos;s http response is ok, the backend is alive. check_keepalive_requests syntax: *check_keepalive_requests num* default: *check_keepalive_requests 1* context: *upstream* description: The directive specifies the number of requests sent on a connection, the default vaule 1 indicates that nginx will certainly close the connection after a request. check_fastcgi_param Syntax: *check_fastcgi_params parameter value* default: see below context: *upstream* description: If you set the check type is fastcgi, then the check function will sends this fastcgi headers to check the upstream server. The default directive looks like: check_fastcgi_param &quot;REQUEST_METHOD&quot; &quot;GET&quot;; check_fastcgi_param &quot;REQUEST_URI&quot; &quot;/&quot;; check_fastcgi_param &quot;SCRIPT_FILENAME&quot; &quot;index.php&quot;; check_shm_size syntax: *check_shm_size size* default: *1M* context: *http* description: Default size is one megabytes. If you check thousands of servers, the shared memory for health check may be not enough, you can enlarge it with this directive.]]></content>
      <categories>
        <category>nginx</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[winrar 命令行使用]]></title>
    <url>%2Fwindows%2Fwinrar%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[利用WinRAR命令行压缩文件或文件夹压缩文件夹 winrar.exe a -ag -k -r -s -ibck c:/bak.rar c:/dat/ 压缩多个文件 winrar a -ag -ibck bak.rar filename1 filename2 参数说明 winrar.exe:运行winrar， 如果winrar.exe没在默认路径中则需要指明路径，如c:/Progra~1/winrar/winrar.exe ...； a :备份所有文件； -ag :当创建压缩文件时，以格式“YYYYMMDDHHMMSS”附加当前日期字符串,文件名bakYYYYMMDDHHMMSS.rar； -k :锁定压缩文件； -r:备份目录和子目录； -s :创建固实压缩文件； -ibck :后台运行； c:/bak.rar :备份的路径和基本名称(-ag参数会自动在bak后加上系统当前时间)， 也可不用-ag参数，通过“%date:~0,4%%date:~5,2%%date:~8,2%”取得时间字串， 也可写作c:/bak.zip； c:/dat/ :要备份的文件目录。 filename1：要压缩的文件名，可以多个，也可用通配符file* &quot;C:/Program Files/WinRAR/WinRAR.exe&quot; a -k -r -s -ibck C:/share/app/database.rar C:/share/app/databaseA/]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>zip</tag>
        <tag>winrar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lsyncd 同步文件]]></title>
    <url>%2Fsync%2Flsyncd%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[前言lsyncd基于rsync，且要求rsync &gt;= 3.1，可输入rsync --version查看当前版本 CentOS自带的软件或yum安装的软件太古老 官方网址：http://axkibe.github.io/lsyncd/ 服务器端需要安装配置好rsyncd yum 安装 lsyncdyum --enablerepo=epel -y install lsyncd ## 查看lsyncd版本 lsyncd --version 配置文件settings { logfile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.log&quot;, statusFile =&quot;/usr/local/lsyncd-2.1.5/var/lsyncd.status&quot;, inotifyMode = &quot;CloseWrite&quot;, maxProcesses = 8, } -- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大 sync { default.direct, source = &quot;/tmp/src&quot;, target = &quot;/tmp/dest&quot;, delay = 1 maxProcesses = 1 } -- II. 本地目录同步，rsync模式：rsync sync { default.rsync, source = &quot;/tmp/src&quot;, target = &quot;/tmp/dest1&quot;, excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;, rsync = { binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, bwlimit = 2000 } } -- III. 远程目录同步，rsync模式 + rsyncd daemon sync { default.rsync, source = &quot;/tmp/src&quot;, target = &quot;syncuser@172.29.88.223::module1&quot;, delete=&quot;running&quot;, exclude = { &quot;.*&quot;, &quot;.tmp&quot; }, delay = 30, init = false, rsync = { binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, verbose = true, password_file = &quot;/etc/rsyncd.d/rsync.pwd&quot;, _extra = {&quot;--bwlimit=200&quot;} } } -- IV. 远程目录同步，rsync模式 + ssh shell sync { default.rsync, source = &quot;/tmp/src&quot;, target = &quot;172.29.88.223:/tmp/dest&quot;, -- target = &quot;root@172.29.88.223:/remote/dest&quot;, -- 上面target，注意如果是普通用户，必须拥有写权限 maxDelays = 5, delay = 30, -- init = true, rsync = { binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, bwlimit = 2000 -- rsh = &quot;/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no&quot; -- 如果要指定其它端口，请用上面的rsh } } -- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同 sync { default.rsyncssh, source = &quot;/tmp/src2&quot;, host = &quot;172.29.88.223&quot;, targetdir = &quot;/remote/dir&quot;, excludeFrom = &quot;/etc/rsyncd.d/rsync_exclude.lst&quot;, -- maxDelays = 5, delay = 0, -- init = false, rsync = { binary = &quot;/usr/bin/rsync&quot;, archive = true, compress = true, verbose = true, _extra = {&quot;--bwlimit=2000&quot;}, }, ssh = { port = 1234 } } lsyncd.conf配置选项说明settings 里面是全局设置，--开头表示注释，下面是几个常用选项说明： • logfile 定义日志文件 • stausFile 定义状态文件 • nodaemon=true 表示不启用守护模式，默认 • statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒 • inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify • maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而maxProcesses = 8，则最大能看到有8个rysnc进程 • maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到 sync 里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式： • default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程； default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份； default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证 • source 同步的源目录，使用绝对路径。 • target 定义目的地址.对应不同的模式有几种写法： /tmp/dest ：本地目录同步，可用于direct和rsync模式 172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd --delete --include-from=- --exclude=* SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步 172.29.88.223::module ：同步到远程服务器目录，用于rsync模式 三种模式的示例会在后面给出。 • init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true • delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件） • excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = &quot;/etc/lsyncd.exclude&quot;，如果是简单的排除，可以使用exclude = LIST。 这里的排除规则写法与原生rsync有点不同，更为简单： o 监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo o 如果规则以斜线/开头，则从头开始要匹配全部 o 如果规则以/结尾，则要匹配监控路径的末尾 o ?匹配任何字符，但不包括/ o *匹配0或多个字符，但不包括/ o **匹配0或多个字符，可以是/ • delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值，请参考 Lsyncd 2.1.x ‖ Layer 4 Config ‖ Default Behavior。 rsync （提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销） • bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出） • compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false • perms 默认保留文件权限。 • 其它rsync的选项 其它还有rsyncssh模式独有的配置项，如host、targetdir、rsync_path、password_file，见后文示例。rsyncOps={&quot;-avz&quot;,&quot;--delete&quot;}这样的写法在2.1.*版本已经不支持。 lsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。]]></content>
      <categories>
        <category>sync</category>
      </categories>
      <tags>
        <tag>sync</tag>
        <tag>lsyncd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 服务搭建和hexo发布]]></title>
    <url>%2Fgit%2Fgit%20%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA%E5%92%8Chexo%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[git中文文档https://git-scm.com/book/zh/v2 安装yum install -y git 服务器上添加git连接用户## 添加用户，设置密钥连接1234567891011121314151617181920## 创建用户, 必须设置-s /bin/git-shell，防止用户远程登陆系统useradd -s /bin/git-shell s_git## 最好设置一个复杂的密码passwd s_git## 设置密钥登陆，ssh需要设置密钥登陆mkdir /home/s_git/.sshchmod 700 /home/s_git/.sshtouch 700 /home/s_git/.ssh/authorized_keyschmod 600 /home/s_git/.ssh/authorized_keyschown -R s_git:s_git /home/s_git/.ssh## 把公钥输入进去cat &gt; /home/s_git/.ssh/authorized_keys &lt;&lt; EOFssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDeVoDwGgk0XZVEOxoIwCmwR2YD+Om/zsGWMLpwOkTTC2fPtDOk6rO3LA15FfNY6FKhGER2zoZaTUKltUgPYB3IDcC3L9bazc3TnI5SW6/AUWXeFjYTMweZkhCCx9+XHscvIZ21hnvEfP5cmU1sPRegOTxI6Lv7itCcg6kGS2P8wqjQeNEgLs7xcfo4+5Jk0Hq3Ke77gYIlBg37+XuiMg2g8UR8KkRuzK/ZCFK5kPXmSg/yGETieUyflPHiaCFEQcQJdNblO0pFoZSOLAgtjXoIdnwkzCt7A6w3KumSFzlOUc+2S6N7k+NfvPa/iW/1NG7m5fiwdt3X0ZnIXRnC05GHEOF 服务器上添加 git repositorymkdir /data/git -p ## 创建一个空的Git仓库，服务器上的Git仓库通常都以.git结尾 git init --bare /data/git/hexo.git ## 设置目录权限 chown -R s_git:s_git /data/git 客户端密钥登陆设置1. windows: 在用户的home个人目录下添加.ssh目录，比如用户Lion (C:\Users\lion\.ssh)，添加密钥文件id_rsa, id_rsa.pub 需要安装git客户端，见文尾 2. linux 在用户home目录下添加.ssh目录，如/home/lion/.ssh，添加密钥文件id_rsa, id_rsa.pub git客户端初次使用## 需要全局设置一下用户信息 git config --global user.name &quot;John Doe&quot; git config --global user.email johndoe@example.com ## 查看git配置信息 git config --list git配置文件地址Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置： /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。 ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。 每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。 在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\Users\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置 测试客户端推送cd test git init git remote add origin ssh://s_git@wall.suroot.com:55555/data/git/hexo.git touch test.txt git add test.txt git commit -m &quot;init commit&quot; ## 上传 git push origin master ## 下载 git pull origin master ## 删除 git -rm ## 查看所有分支 git branch -v 测试客户端克隆mkdir test cd test git clone ssh://s_git@wall.suroot.com:55555/data/git/hexo.git 客户端hexo推送到nginx网站hexo 修改配置文件## Deployment ## Docs: https://hexo.io/docs/deployment.html ## repo: git@github.com:xxx/xxx.github.io.git deploy: type: git repo: ssh://s_git@wall.suroot.com:55555/data/git/hexo.git branch: master hexo 发布推送## 生成hexo静态页面内容，并推送到git repository hexo clean &amp;&amp; hexo generate --deploy ## 指定额外配置文件，如果想推送到不同的git hexo --config github.yml clean hexo --config nginx_server.yml generate --deploy nginx 服务配置server { listen 80; charset utf-8; root /data/www/blog; index index.htm index.html index.jsp; } ## 从git repository中克隆出hexo静态网站 mkdir /data/www/blog git clone /data/git/hexo.git /data/www/blog ## 注意这里需要修改网站的文件夹为git用户，否则没权限更新 chown -R s_git:s_git /data/www/blog git自动同步nginx网站## git hooks 参考： https://git-scm.com/book/zh/v2/%E8%87%AA%E5%AE%9A%E4%B9%89-Git-Git-%E9%92%A9%E5%AD%90 ## 每当开发者将网站更新推送到git repository时，git就自动同步到网站目录 ## 配置git服务器hooks12345678910111213141516171819202122cat &gt; /data/git/hexo.git/hooks/post-receive &lt;&lt; EOF#!/bin/sh## 把部署目录更新到博客的最新生成状态#git --work-tree=/data/www/blog --git-dir=/data/git/hexo.git checkout -f## 还原环境变量，否则会拉不到代码unset GIT_DIRcd /data/www/blog## git add . -A &amp;&amp; git stash#拉取最新代码git pull origin masterEOFchown s_git:s_git /data/git/hexo.git/hooks/post-receivechmod a+x /data/git/hexo.git/hooks/post-receive windows下git客户端安装下载安装 githttps://git-scm.com/download/win https://github.com/git-for-windows/git/releases/download/v2.17.1.windows.2/Git-2.17.1.2-64-bit.exe https://github.com/git-for-windows/git/releases/download/v2.17.1.windows.2/PortableGit-2.17.1.2-64-bit.7z.exe portable 版本，只需解压，在window环境变量里添加 解压路径\Git\cmd 12345678910111213141516171819202122232425262728293031安装版，只需命令行的，安装步骤如下：选择安装组件：可以全不选，或只选 桌面浏览（Windows Explorer integration） 使用Git Bash方式，shell方式是否创建开始菜单快捷方式目录:否设置环境，选择使用什么样儿的命令行工具，一般情况我们使用默认配置，使用Git Bash Git自带：使用Git自带的Git Bash命令行工具设置HTTPS 传输加密方式，点击【Next &gt;】 使用OpenSSL库选择换行格式，点击【Next &gt;】：下面选第一个 让Git能够自动转换文件中的换行符：签出到本地时转换为Windows下的换行符，提交到服务器时转换为Unix下的换行符 让Git在签出到本地时不做转换，保留原始文件的换行符；提交到服务器时转换为Unix下的换行符 让Git在签出到本地时和提交到服务器时都不做转换配置Git bash终端仿真器，点击【Next &gt;】：最好选第二个 使用MinTTY终端 使用windows默认的命令行性能配置，是否启用文件系统缓存，点击【Next &gt;】开始安装 git 环境变量配置安装成功后需要配置Git环境变量 「注意该步骤为Git在windows cmd命令中配置，如果不配置，直接使用Git Bash即可」 在Path变量中增加：C:\Program Files\Git\cmd 验证是否配置成功，打开windows命令行，输入git version命令，出现下列信息表示配置成功。 git config --global user.name dolphincn git config --global user.email share2030cn@126.com 下面三行可以不操作 git config --global push.default matching git config --global core.quotepath false git config --global core.editor &quot;vim&quot; 添加ssh 密钥添加github ssh 登陆密钥， 打开cmd，运行mkdir .ssh， 在当前用户的home目录下创建.ssh目录，把密钥复制进去. 密钥可以用ssh-key 或 GitHub上生成，私钥和公钥名字分别为：id_rsa id_rsa.pub 检验是否能连上了github，windows 命令行下运行，前提配置了git环境变量 $ ssh git@github.com 参考Hexo+Git服务器搭建blog http://yelog.org/2016/10/23/hexo-git-server-blog/]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rsync 同步文件]]></title>
    <url>%2Fsync%2FRsync%2F</url>
    <content type="text"><![CDATA[Rsync是linux/Unix文件同步和传送工具。用于替代rcp的一个工具，rsync可以通过rsh或ssh使用，也能以daemon模式去运行，在以daemon方式运行时rsync server会开一个873端口，等待客户端去连接。连接时rsync server会检查口令是否相符，若通过口令查核，则可以通过进行文件传输，第一次连通完成时，会把整份文件传输一次，以后则就只需进行增量备份。 yum 安装epel源安装1234567891011 cat &gt; /etc/yum.repos.d/epel.repo &lt;&lt; EOF[epel]name=Extra Packages for Enterprise Linux 7 - \$basearchbaseurl=http://dl.fedoraproject.org/pub/epel/7Server/x86_64/failovermethod=priorityenabled=1gpgcheck=1gpgkey=http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7ServerEOF 安装## centos 7.5 已经安装了3.1.2 版本 yum install rsync ## 查看当前rsync版本 rsync --version 编译安装：下载rsync源码 # wget https://download.samba.org/pub/rsync/rsync-3.1.3.tar.gz 解压 # tar -zxvf rsync-3.1.3.tar.gz 进入目录 # cd rsync-3.1.3 查看编译配置参数 # ./configure --help 编译安装, 安装时同步保存日志，这种编译 # ./configure --prefix=/usr 编译好二进制rsync程序会放在/usr/bin目录下,即/usr/bin/rsync 编译可以带如下参数 --with-rsyncd-conf=/etc/rsyncd.conf # 默认/etc/rsyncd.conf --without-included-zlib # 此开关使用系统安装的zlib库进行编译。 # make # make install | tee make_install.log 出于安全原因，鼓励将rsync服务器作为非特权用户和组运行。 如果您打算将rsync作为后台进程运行，请使用root用户颁发的以下命令创建rsyncd用户和组： # groupadd -g 80 rsyncd # useradd -c &quot;rsyncd Daemon&quot; -d /home/rsync -g rsyncd -s /sbin/nologin -u 80 rsyncd 最后需要手动添加配置文件: rsyncd服务器配置rsyncd systemd配置文件123456789101112131415161718cat &gt;&gt; /usr/lib/systemd/system/rsyncd.service &lt;&lt; EOF[Unit]Description=fast remote file copy program daemonConditionPathExists=/etc/rsyncd.conf[Service]EnvironmentFile=/etc/sysconfig/rsyncdExecStart=/usr/bin/rsync --port=555873 --daemon --no-detach "\$OPTIONS"[Install]WantedBy=multi-user.targetEOFcat /etc/sysconfig/rsyncdOPTIONS="" rsyncd 启动配置文件rsyncd 启动配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465cat &gt;&gt; /etc/rsyncd.conf &lt;&lt; EOF## 如果要修改文件的权限就用root用户，否则最好创建一个普通用户来运行rsyncport = 55873 # 默认端口号为873,防火墙需要同时开启tcp/udp对应的端口号uid = root # rsyncd 启动运行的用户,必须有对同步目录有读写权限gid = root # rsyncd 启动运行的用户组use chroot = no # 是否启用chroot监狱max connections = 200 # 最大连接数timeout 600 # 连接超时pid file=/var/run/rsyncd.pid # 指定PID文件lock file=/var/run/rsyncd.lock # 指定支持max connection的锁文件，默认为/var/run/rsyncd.locklog file=/var/log/rsyncd.log # rsyncd 服务器的日志transfer logging = yes # 记录所有文件传输日志log format = %t %a %m %f %bmotd file = /etc/rsyncd.d/rsync.motd # 定义服务器信息的，自己写 rsyncd.motd 文件内容strict modes=yes # 指定是否检查口令文件的权限auth users = rsync_backup # 连接用户名，和linux系统用户名无关系secrets file = /etc/rsyncd.d/rsync.auth # 验证密码文件，文本格式 用户名:密码，一行一个账户# 多个用逗号隔开#允许网段或ip地址hosts allow=200.200.200.0/24#拒绝其他网段hosts deny=*# 设置no 或 false，客户端可以上传文件，yes 或 true是只读# 允许上传read only = false# 设置no 或 false，客户端可以下载文件，yes 或 true是不能下载#不允许下载#write only = true#不显示rsync服务端资源列表list = false# ignore nonreadable = yesdont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.iso *.bz2 *.tbz#可以忽略一些IO错误ignore errors = true# MODULE OPTIONS[wwwroot]path = /data/wwwroot/[sweet]path = /data/wwwroot/sweet.com.cn[module_test]path = /data/rsync_bak2comment = rsync test logs## 该用户系统中存在且对后面指定的备份目录拥有权限auth users = seanuid = seangid = seansecrets file = /etc/rsyncd.d/rsyncd.secretsread only = falselist = falsehosts allow=172.29.88.204hosts deny=0.0.0.0/32EOF [conf] #自定义模块 path = /usr/local/nginx/conf #用来指定要备份的目录 comment = Nginx conf ignore errors #可以忽略一些IO错误 read only = no #设置no，客户端可以上传文件，yes是只读 write only = no #no为客户端可以下载，yes不能下载 hosts allow = 192.168.2.0/24 #可以连接的IP hosts deny = * #禁止连接的IP list = false #客户请求时，使用模块列表 uid = root gid = root auth users = backup #连接用户名，和linux系统用户名无关系 secrets file = /etc/rsyncd.pass #验证密码文件 rsyncd 密匙文件和提示文件rsyncd 密匙文件和启动用户12345678## 创建认证用户密码文件并进行授权600mkdir /etc/rsyncd.decho "rsync_backup:rsync_9391" &gt;&gt;/etc/rsyncd.d/rsync.authchmod 600 /etc/rsyncd.d/rsync.authecho "Waring, this is private server." &gt; /etc/rsyncd.d/rsync.motd rsyncd 启动用户1234567## 创建rsync管理用户，如果不用root启动rsyncdgroupadd -g 80 rsyncduseradd -c "rsyncd Daemon" -M -g rsyncd -s /sbin/nologin -u 80 rsyncd## useradd -s /sbin/nologin -M rsyncd rsyncd 文件目录rsyncd 存放同步文件目录12345## 创建数据备份储存目录,目录修改属主mkdir /data/wwwroot/chown -R rsyncd:rsyncd /data/wwwroot/ 客户端部署## 确认rsync 安装 rpm -qa |grep rsync yum install rsync 添加密码文件，不需要用户名mkdir /etc/rsyncd.d echo &quot;rsync_9391&quot; &gt;&gt;/etc/rsyncd.d/rsync.password chmod 600 /etc/rsyncd.d/rsync.password 测试数据传输rsync -azHAX --port=55873 /data/test rsync_backup@200.200.200.222::wwwroot --password-file=/etc/rsyncd.d/rsync.password rsync -azHAX --delete --port=55873 --bwlimit=10240 /data/test rsync_backup@200.200.200.222::wwwroot --password-file=/etc/rsyncd.d/rsync.password ## 注意同步目录(/data/test/), 后面加/表示同步目录下的文件及子文件夹, 与目标服务器的目录下的所有文件和文件夹一致，多余的会被删除。 不加/表示同步/data/test目录，目标服务器的目录下会创建对应的test目录。而且只有test目录下的文件和文件夹一致，不会理会test目录外的文件或文件夹 客户端直接通过ssh同步两个目录,不经服务端## 注意源目录后面加了/, 下面/data/test和/data/wwwroot 目录下的内容将会保持一致，/data/wwwroot下面多余内容将删除 sudo rsync -azHAX --delete -e &quot;ssh &quot; /data/test/ root@200.200.200.222:/data/wwwroot rsync 选项-V : --verbose 传输时显示详细信息和进度. -z : --compress 传输进行压缩以提高传输效率, --compress-leve=NUM 可按级别压缩 -n : 执行空运行，模拟执行，显示更改。执行rsync操作前先执行空运行，以确保重要的文件不会被覆盖或删除. -a : --archive 代表存档模式，相当于使用了-rlptgoD这一坨选项,默认已同步符号连接，但硬连接除外。同时不会同步高级文件全限(ACL 和 SELinux上下文),同步ACL需要启用-A 选项，同步SElinux上下文启用-X(大写)选项. -r : --recursive 递归同步整个目录树 -l : --links 同步符号连接 -p : --perms 保留权限 -t : --time,保留时间信息 -g : --group 保留组所有权 -o : --owner 保留文件所有者 -D : --devices 同步设备文件, 保留设备文件信息 -P : --progress 大写的P,显示同步的过程以及传输时的进度等信息 -H : 保留硬连接。 -A, --acls preserve ACLs (implies --perms) -X, --xattrs preserve extended attributes,保留selinux特性 -S : 对稀疏文件进行特殊处理以节省DST的空间 -e : --rsh=COMMAND 使用ssh信道协议 --bwlimit=KBPS : 限制传输速度,用于传输大文件时,单位kb/s rsync六种不同的工作模式：1.拷贝本地文件，将/home/coremail目录下的文件拷贝到/cmbak目录下。 rsync -avSH /home/coremail/ /cmbak/ 2.拷贝本地机器的内容到远程机器。 rsync -av /home/coremail/ 192.168.11.12:/home/coremail/ 3.拷贝远程机器的内容到本地机器。 rsync -av 192.168.11.11:/home/coremail/ /home/coremail/ 4.拷贝远程rsync服务器(daemon形式运行rsync)的文件到本地机。 rsync -av root@172.16.78.192::www /databack 5.拷贝本地机器文件到远程rsync服务器(daemon形式运行rsync)中。当DST路径信息包含”::”分隔符时启动该模式。 rsync -av /databack root@172.16.78.192::www 6.显示远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。 rsync -v rsync://192.168.11.11/data]]></content>
      <categories>
        <category>sync</category>
      </categories>
      <tags>
        <tag>sync</tag>
        <tag>Rsync</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[syncthing 同步文件]]></title>
    <url>%2Fsync%2Fsyncthing%20%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[syncthing 安装配置 使用总结：一分钟内能同步变更，可以同步权限，但不能同步所有者和所属组，以及ACL等属性。 共享的文件夹没权读取或写入，会导致同步问题，同时导致自动选用端口，而不用指定端口。 同步的文件所有者和所有组，改为syncthing运行的用户名和组 同步间隔内(一分钟内)，多个服务器同一个文件变更，按时间优先原则选择，有冲突的文件会自动重命名。 支持无登陆权限的用户启动,保存syncthing运行配置文件的目录必须有读写权限，同步目录也必须有读写权限 The following are not synchronized; File or Directory Owners and Groups (not preserved) Directory Modification Times (not preserved) Hard Links (followed, not preserved) Extended Attributes, Resource Forks (not preserved) Windows, POSIX or NFS ACLs (not preserved) Devices, FIFOs, and Other Specials (ignored) Sparse file sparseness (will become sparse, when supported by the OS &amp; filesystem) 配置参考：https://docs.syncthing.net/users/config.html 需要安装配置时间同步yum install chrony systemctl start chronyd systemctl enable chronyd 防火墙开放端口，还需要关闭selinuxfirewall-cmd --add-port={22000/tcp,8888/tcp} firewall-cmd --add-port={22000/tcp,8888/tcp} --permanent 如果文件夹很多，需要调整echo &quot;fs.inotify.max_user_watches=204800&quot; | sudo tee -a /etc/sysctl.conf sudo sh -c &apos;echo 204800 &gt; /proc/sys/fs/inotify/max_user_watches&apos; 设置时区cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime 安装配置## 官网：https://syncthing.net/ ## 安装 syncthing 1234567891011121314151617181920212223242526272829303132wget https://github.com/syncthing/syncthing/releases/download/v0.14.48/syncthing-linux-amd64-v0.14.48.tar.gztar -zxf syncthing-linux-amd64-v0.14.48.tar.gz -C /usr/localmv /usr/local/syncthing-linux-amd64-v0.14.48 /usr/local/syncthingcp /usr/local/syncthing/etc/linux-systemd/system/syncthing@.service /usr/lib/systemd/system/vi /usr/lib/systemd/system/syncthing@.service[Unit]Description=Syncthing - Open Source Continuous File Synchronization for %IDocumentation=man:syncthing(1)After=network.target#Wants=syncthing-inotify@.service## 地址不能用引号[Service]User=%iExecStart=/usr/local/syncthing/syncthing -no-browser -no-restart -logflags=1 -home=/web/syncthing/%iRestart=on-failureSuccessExitStatus=3 4RestartForceExitStatus=3 4[Install]WantedBy=multi-user.target## 下面两参数不需要，centos运行不了#environment = STNORESTART="1", HOME="/web/syncthing/%i"#directory = /web/syncthing/%i 启动# 创建同步账户 groupadd -g 2222 g_sync useradd -u 2222 -g 2222 -M -s /sbin/nologin u_sync mkdir /web/syncthing/u_sync -p chown -R u_sync:g_sync /web/syncthing/u_sync systemctl start syncthing@&lt;启动用户名&gt; ## 启动时如果没配置-home 参数，将会自动在运行用户home目录下创建运行配置目录，如： ~/.config/syncthing webui 访问# 编辑配置文件 vi /data/syncthing/&lt;user_name_folder&gt;/.config.xml &lt;gui enabled=&quot;true&quot; tls=&quot;false&quot;&gt; &lt;address&gt;0.0.0.0:8384&lt;/address&gt; 改为(user:test.admin,pwd:test.admin!9595) &lt;gui enabled=&quot;true&quot; tls=&quot;true&quot;&gt; &lt;address&gt;200.200.200.221:8888&lt;/address&gt; &lt;user&gt;test.admin&lt;/user&gt; &lt;password&gt;$2a$10$ddH.7NbCZPrBzvn95dANT.bpFBKW/9anJ8a6xq44CZbcGJcE3kJGG&lt;/password&gt; 两台服务器数据同步基本必须的配置actions--&gt;settings--&gt;general: Device Name: vm01 Automatic upgrades: No upgrades Default Folder Path: /sync/www actions--&gt;settings--&gt;GUI: GUI Listen Address: 200.200.200.221:8888 GUI Authentication User: test GUI Authentication Password: test Use HTTPS for GUI： checked Start Browser ：checked ## 本机连接配置, 局域网用并手动配置同步服务器地址，所以不启用NAT端口转换，局域网搜索服务器，英特网搜索服务器，中继服务服务器 actions--&gt;settings--&gt;Connection: Sync Protocol Listen Addresses: tcp://200.200.200.221:22000 Enable NAT traversal: unchecked Local Discovery: unchecked Global Discovery: unchecked Enable Relaying: unchecked Incoming Rate Limit (KiB/s) ：0 Outgoing Rate Limit (KiB/s) : 0 actions--&gt;settings--&gt;advanced: Device &quot;vm03&quot; : Addresses: tcp://200.200.200.221:22000 Allowed Networks: 200.200.200.0/24 服务器连接配置,局域网用，所有服务器都手动添加对方服务器连接信息主界面--&gt;Remote Devices--&gt;Add remote Device： ## 对方的id，在actions--&gt;show id Device ID：FOYBGA7-CMD2C6O-5JFBWNW-5D34HJ4-TXTEY6C-UZ7E7EE-X4ZR3DR-S6BCQA2 ## 对方的设备名 Device Name：vm02 ## 对方的连接地址，actions--&gt;settings--&gt;Connection--&gt;Sync Protocol Listen Addresses Addresses：tcp://200.200.200.222:22000 # 自动在默认的共享文件夹下创建和共享目录，这个最好取消，最好手动配置共享和同步目录 Auto Accept：unchecked # 对方不是中继服务就不需要选 Introducer: uncehcked 同步共享文件夹,同步的服务器配置最好都一致，folder id 必须一致主界面--&gt;Folders--&gt;add folder Folders--&gt;add folder--&gt; General： ## 显示名可以和folder id 一样 Folder Label : wwwroot ## 唯一标记用于同步和共享文件夹，同步的同一个文件夹，所有的服务器上都要一致 Folder ID : wwwroot ## 在服务上要共享同步的目录 Folder Path : /sync/wwwroot ## 勾选同步和共享给哪些设备或服务器，没有列出需要添加服务器或设备 Share With Devices： Folders--&gt;add folder--&gt; File Versioning： ## 这里不启用文件本版管理，相当于github功能 File Versioning：no File Versioning Folders--&gt;add folder--&gt; ignore patterns： ## 忽略哪些文件同步或共享，采用模式匹配 Folders--&gt;add folder--&gt; Advance: Scanning: ## 监控变更 Watch for Changes : checked ## 完整扫描间隔，单位秒 Full Rescan Interval (s)： 3600 ## 如果选Send only, 则表示作为master不会自动同步其它设备的文件最新的变更，也不会去覆盖其它设备的最新变更. Folder Type： Send &amp; Receive File Pull Order ：Newest First Minimum Free Disk Space: 5 % Permissions： Ignore： unchecked 提升同步速度和限制共享网络# 添加同步服务器和设置好同步文件夹后，分别需要在高级里面设置各个设备的连接地址，地址栏里不要有dynamic，否则同步速度很慢 actions--&gt;settings--&gt;advanced: Addresses: tcp://200.200.200.222:22000 Allowed Networks: 200.200.200.0/24 # 可能需要重启syncthing 如果无法及时更新文件变更，请安装inotify-toolsyum install inotify-tools #添加以下代码 vi /etc/sysctl.conf fs.inotify.max_queued_events=99999999 fs.inotify.max_user_watches=99999999 fs.inotify.max_user_instances=65535 完整配置文件## 只需把自动生成的配置文件里对应的 &lt;device id=&quot;DER7MDE-ACFAHGP-U5NMSCL-FEY7NJK-KKQYAHP-7LBSOHD-7WFW76J-IPCGMQM&quot; &lt;address&gt;tcp://10.100.100.5:22000&lt;/address&gt; &lt;urUniqueID&gt;cfxLXRKZ&lt;/urUniqueID&gt; &lt;listenAddress&gt;tcp://10.100.100.5:22000&lt;/listenAddress&gt; &lt;localAnnounceMCAddr&gt;[ff12::8384]:22000&lt;/localAnnounceMCAddr&gt; ## 密码和apikey需要重新生成 &lt;password&gt;$2a$10$ddH.7NbCZPrBzvn95dANT.bpFBKW/9anJ8a6xq44CZbcGJcE3kJGG&lt;/password&gt; &lt;apikey&gt;KgfbYLfLVjf7LJhh4vuYrHbmEXdZhix7&lt;/apikey&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;configuration version=&quot;28&quot;&gt; &lt;folder id=&quot;sweet&quot; label=&quot;sweet&quot; path=&quot;/data/wwwroot/sweet&quot; type=&quot;readwrite&quot; rescanIntervalS=&quot;3600&quot; fsWatcherEnabled=&quot;true&quot; fsWatcherDelayS=&quot;10&quot; ignorePerms=&quot;false&quot; autoNormalize=&quot;true&quot;&gt; &lt;filesystemType&gt;basic&lt;/filesystemType&gt; &lt;device id=&quot;DER7MDE-ACFAHGP-U5NMSCL-FEY7NJK-KKQYAHP-7LBSOHD-7WFW76J-IPCGMQM&quot; introducedBy=&quot;&quot;&gt;&lt;/device&gt; &lt;device id=&quot;2Y75F2E-66PD3UW-EJZZOTD-67VNT2R-6RBGWXX-GAGWSMX-KO73YJK-NSLFSQU&quot; introducedBy=&quot;&quot;&gt;&lt;/device&gt; &lt;minDiskFree unit=&quot;%&quot;&gt;10&lt;/minDiskFree&gt; &lt;versioning&gt;&lt;/versioning&gt; &lt;copiers&gt;0&lt;/copiers&gt; &lt;pullerMaxPendingKiB&gt;0&lt;/pullerMaxPendingKiB&gt; &lt;hashers&gt;0&lt;/hashers&gt; &lt;order&gt;newestFirst&lt;/order&gt; &lt;ignoreDelete&gt;false&lt;/ignoreDelete&gt; &lt;scanProgressIntervalS&gt;0&lt;/scanProgressIntervalS&gt; &lt;pullerPauseS&gt;0&lt;/pullerPauseS&gt; &lt;maxConflicts&gt;10&lt;/maxConflicts&gt; &lt;disableSparseFiles&gt;false&lt;/disableSparseFiles&gt; &lt;disableTempIndexes&gt;false&lt;/disableTempIndexes&gt; &lt;paused&gt;false&lt;/paused&gt; &lt;weakHashThresholdPct&gt;25&lt;/weakHashThresholdPct&gt; &lt;markerName&gt;.stfolder&lt;/markerName&gt; &lt;useLargeBlocks&gt;false&lt;/useLargeBlocks&gt; &lt;/folder&gt; &lt;device id=&quot;DER7MDE-ACFAHGP-U5NMSCL-FEY7NJK-KKQYAHP-7LBSOHD-7WFW76J-IPCGMQM&quot; name=&quot;web02&quot; compression=&quot;metadata&quot; introducer=&quot;false&quot; skipIntroductionRemovals=&quot;false&quot; introducedBy=&quot;&quot;&gt; &lt;address&gt;tcp://10.100.100.5:22000&lt;/address&gt; &lt;paused&gt;false&lt;/paused&gt; &lt;allowedNetwork&gt;10.100.100.0/24&lt;/allowedNetwork&gt; &lt;autoAcceptFolders&gt;false&lt;/autoAcceptFolders&gt; &lt;maxSendKbps&gt;0&lt;/maxSendKbps&gt; &lt;maxRecvKbps&gt;0&lt;/maxRecvKbps&gt; &lt;/device&gt; &lt;device id=&quot;2Y75F2E-66PD3UW-EJZZOTD-67VNT2R-6RBGWXX-GAGWSMX-KO73YJK-NSLFSQU&quot; name=&quot;web03&quot; compression=&quot;metadata&quot; introducer=&quot;false&quot; skipIntroductionRemovals=&quot;false&quot; introducedBy=&quot;&quot;&gt; &lt;address&gt;tcp://10.100.100.6:22000&lt;/address&gt; &lt;paused&gt;false&lt;/paused&gt; &lt;allowedNetwork&gt;10.100.100.0/24&lt;/allowedNetwork&gt; &lt;autoAcceptFolders&gt;false&lt;/autoAcceptFolders&gt; &lt;maxSendKbps&gt;0&lt;/maxSendKbps&gt; &lt;maxRecvKbps&gt;0&lt;/maxRecvKbps&gt; &lt;/device&gt; &lt;gui enabled=&quot;true&quot; tls=&quot;true&quot; debugging=&quot;false&quot;&gt; &lt;address&gt;10.100.100.5:8888&lt;/address&gt; &lt;user&gt;test.admin&lt;/user&gt; &lt;password&gt;$2a$10$ddH.7NbCZPrBzvn95dANT.bpFBKW/9anJ8a6xq44CZbcGJcE3kJGG&lt;/password&gt; &lt;apikey&gt;KgfbYLfLVjf7LJhh4vuYrHbmEXdZhix7&lt;/apikey&gt; &lt;theme&gt;default&lt;/theme&gt; &lt;/gui&gt; &lt;options&gt; &lt;listenAddress&gt;tcp://10.100.100.5:22000&lt;/listenAddress&gt; &lt;globalAnnounceServer&gt;default&lt;/globalAnnounceServer&gt; &lt;globalAnnounceEnabled&gt;false&lt;/globalAnnounceEnabled&gt; &lt;localAnnounceEnabled&gt;false&lt;/localAnnounceEnabled&gt; &lt;localAnnouncePort&gt;21027&lt;/localAnnouncePort&gt; &lt;localAnnounceMCAddr&gt;[ff12::8384]:21027&lt;/localAnnounceMCAddr&gt; &lt;maxSendKbps&gt;0&lt;/maxSendKbps&gt; &lt;maxRecvKbps&gt;0&lt;/maxRecvKbps&gt; &lt;reconnectionIntervalS&gt;60&lt;/reconnectionIntervalS&gt; &lt;relaysEnabled&gt;false&lt;/relaysEnabled&gt; &lt;relayReconnectIntervalM&gt;10&lt;/relayReconnectIntervalM&gt; &lt;startBrowser&gt;false&lt;/startBrowser&gt; &lt;natEnabled&gt;false&lt;/natEnabled&gt; &lt;natLeaseMinutes&gt;60&lt;/natLeaseMinutes&gt; &lt;natRenewalMinutes&gt;30&lt;/natRenewalMinutes&gt; &lt;natTimeoutSeconds&gt;10&lt;/natTimeoutSeconds&gt; &lt;urAccepted&gt;-1&lt;/urAccepted&gt; &lt;urSeen&gt;3&lt;/urSeen&gt; &lt;urUniqueID&gt;cfxLXRKZ&lt;/urUniqueID&gt; &lt;urURL&gt;&lt;/urURL&gt; &lt;urPostInsecurely&gt;false&lt;/urPostInsecurely&gt; &lt;urInitialDelayS&gt;1800&lt;/urInitialDelayS&gt; &lt;restartOnWakeup&gt;true&lt;/restartOnWakeup&gt; &lt;autoUpgradeIntervalH&gt;0&lt;/autoUpgradeIntervalH&gt; &lt;upgradeToPreReleases&gt;false&lt;/upgradeToPreReleases&gt; &lt;keepTemporariesH&gt;24&lt;/keepTemporariesH&gt; &lt;cacheIgnoredFiles&gt;false&lt;/cacheIgnoredFiles&gt; &lt;progressUpdateIntervalS&gt;5&lt;/progressUpdateIntervalS&gt; &lt;limitBandwidthInLan&gt;false&lt;/limitBandwidthInLan&gt; &lt;minHomeDiskFree unit=&quot;%&quot;&gt;10&lt;/minHomeDiskFree&gt; &lt;releasesURL&gt;&lt;/releasesURL&gt; &lt;alwaysLocalNet&gt;10.100.100.0/24&lt;/alwaysLocalNet&gt; &lt;overwriteRemoteDeviceNamesOnConnect&gt;false&lt;/overwriteRemoteDeviceNamesOnConnect&gt; &lt;tempIndexMinBlocks&gt;10&lt;/tempIndexMinBlocks&gt; &lt;trafficClass&gt;0&lt;/trafficClass&gt; &lt;defaultFolderPath&gt;/data/wwwroot&lt;/defaultFolderPath&gt; &lt;setLowPriority&gt;true&lt;/setLowPriority&gt; &lt;minHomeDiskFreePct&gt;0&lt;/minHomeDiskFreePct&gt; &lt;/options&gt;&lt;/configuration&gt;]]></content>
      <categories>
        <category>sync</category>
      </categories>
      <tags>
        <tag>sync</tag>
        <tag>syncthing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Magento 文件夹及文件权限]]></title>
    <url>%2Fnginx%2Fmagento%2FMagento%20%E6%96%87%E4%BB%B6%E5%A4%B9%E5%8F%8A%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[#for magento 1.5+find . -type f -exec chmod 644 {} \;find . -type d -exec chmod 755 {} \;chmod o+w var var/.htaccess app/etcchmod 550 magechmod -R o+w media Folder permissions: 755File permissions 644Mage permissions: 550]]></content>
      <categories>
        <category>nginx</category>
        <category>magento</category>
      </categories>
      <tags>
        <tag>magento</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Next 创建分类和标签页]]></title>
    <url>%2Fhexo%2FHexo%20Next%20%E5%88%9B%E5%BB%BA%E5%88%86%E7%B1%BB%E5%92%8C%E6%A0%87%E7%AD%BE%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[创建分类页面新建一个页面，命名为 categories 。命令如下： hexo new page categories 编辑刚新建的页面，在source/categories目录下的index.md， 将页面的类型设置为 categories ，主题将自动为这个页面显示所有分类。 title: 分类 date: 2014-12-22 12:39:04 type: &quot;categories&quot; ## 如果在主题layout自定义了分类显示页面，可以设置对应的layout的页面 #layout: &quot;custom_layout&quot; --- 注意：如果有启用多说 或者 Disqus 评论，默认页面也会带有评论。 需要关闭的话，请添加字段 comments 并将值设置为 false，如： title: 分类 date: 2014-12-22 12:39:04 type: &quot;categories&quot; comments: false --- 在菜单中添加链接。编辑主题的 _config.yml ， 将 menu 中的 categories: /categories 注释去掉，如下: menu: home: / || home #about: /about/ || user #tags: /tags/ || tags categories: /categories/ || th 创建标签云页面添加一个标签云页面，并在菜单中显示页面链接。 新建一个页面，命名为 tags 。命令如下： hexo new page &quot;tags&quot; 编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。 title: All tags date: 2014-12-22 12:39:04 type: &quot;tags&quot; --- 注意：如果有启用多说 或者 Disqus 评论，默认页面也会带有评论。 需要关闭的话，请添加字段 comments 并将值设置为 false，如： title: All tags date: 2014-12-22 12:39:04 type: &quot;tags&quot; comments: false --- 在菜单中添加链接。编辑主题的 _config.yml ，添加 tags 到 menu 中，如下: menu: home: / || home #about: /about/ || user tags: /tags/ || tags]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx mp4 伪流支持]]></title>
    <url>%2Fnginx%2Fconfig%2Fnginx%20mp4%20%E4%BC%AA%E6%B5%81%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[基本配置location ~ .*\.(mp4)$ mp4; mp4_buffer_size 1m; mp4_max_buffer_size 5m; } ngx_http_mp4_module模块: 对具有.mp4, .m4v, and .m4a.扩展名的H.264/AAC格式文件提供服务器端的伪流支持。 请求连接后面允许添加?start=秒数.毫秒数，表示从某时刻开始播放，如： http://example.com/elephants_dream.mp4?start=238.88]]></content>
      <categories>
        <category>nginx</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker CE 安装]]></title>
    <url>%2Fdocker%2Fdocker%20CE%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[$ sudo yum install docker-ce 配置yum 源1234567891011121314151617181920212223 $ sudo yum install -y yum-utils $ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 或者 cat &gt; /etc/yum.repo.d/docker.repo &lt;&lt; EOF [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge] name=Docker CE Edge - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpgEOF 删除旧版如果原来装有旧版，删除可能装有的版本 $ sudo yum remove docker docker-common docker-selinux docker-engine-selinux docker-engine docker-ce 安装12345678# 安装需要的依赖包$ sudo yum install -y device-mapper-persistent-data lvm2# 安装docker ce$ sudo yum install docker-ce docker 服务管理操作123456$ sudo systemctl enable docker.service$ sudo systemctl start docker.service$ sudo systemctl stop docker.service$ sudo systemctl restart docker.service$ sudo systemctl status docker.service 查找docker 网桥和IP地址12345docker 默认网桥名为docker0，并分配了一个IP 地址$ ip a$ ip a list docker0 docker 操作命令格式1234docker commanddocker command argdocker [options] command arg 查看docker 信息和帮助12345678docker infodocker help | more# 查找ps cp 命令帮助docker ps --helpdocker cp --help docker 基本操作命令# 运行docker容器 docker container run hello-world # 查找docker 镜像 docker search nginx # 下载docker镜像 docker pull nginx # 查看已有的镜像 docker images # 通过下载nginx镜像启动一个容器 docker container run --name my-nginx-c1 --detach nginx # 将本地目录/home/vivek/html/挂载到nginx 容器的nginx默认的网站目录 docker container run --name my-nginx-c2 -p 80:80 -v /home/vivek/html/:/usr/share/nginx/html:ro -d nginx --name my-nginx-c1 : 给容器命名, 简写 -n --detach : 后台运行容器，并打印出容器ID，简写 -d -v /home/vivek/html:/usr/share/nginx/html:ro : 将物理机上的文件夹挂载到容器上，注意目录后面都没/，容器会自动创建没有的挂载目录 -p 80:80 : 将容器端口映射到物理机的端口 -e：设置环境变量 # 显示正在运行的容器 # 加-a, 只显示正在运行的容器 docker container ls -a # 列出的结果是按列显示的。每一列的值分别为： * Container ID ：一开始的几个字符对应你的容器的唯一 ID * Image ：你运行容器的镜像名 * Command ：容器启动后运行的命令 * Created ：创建时间 * Status ：容器当前状态 * Ports ：与宿主端口相连接的端口信息 * Names ：容器名（如果你没有命名你的容器，那么会随机创建） # 对应Docker 旧版本命令，旧版不需要加container, 其它命令类似 docker ps docker ps -a # 通过容器id或容器名，在容器上运行命令 docker container exec fe0cdbc0225a ls /etc/nginx docker container exec my-nginx-c1 ls /etc/nginx # 获取容器bash ，并保存修改 docker container exec -i -t fe0cdbc0225a bash docker container exec -i -t my-nginx-c1 bash # 通过容器ID或容器名停止容器 docker container stop my-nginx-c1 docker container stop fe0cdbc0225a # 启动已停止的容器 # 一个已经停止并保存了当时运行状态的容器。启动后，它将以停止时的状态重新开始运行。 docker container start my-nginx-c1 # 删除容器 # 容器删除之前必须是先停止 docker container rm my-nginx-c1 docker container ls # 查看 Docker 容器的历史纪录 docker container logs my-nginx-c1 # 查看 Docker 容器的进程 docker container top my-nginx-c1]]></content>
      <categories>
        <category>docker</category>
        <category>install</category>
      </categories>
      <tags>
        <tag>install</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 系统入侵检查]]></title>
    <url>%2Flinux%2Flinux%20%E7%B3%BB%E7%BB%9F%E5%85%A5%E4%BE%B5%E6%A3%80%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[查看登陆日志# wtmp日志记录每个用户登录、注销及系统的启动、停机的事件 last last -f /var/log/wtmp who /var/log/wtmp # last命令往回搜索wtmp来显示自从文件第一次创建以来登录过的用户. # who命令查询utmp文件并报告当前登录的每个用户。 # who的默认输出包括用户名、终端类型、登录日期及远程主机。 查看security日志more /var/log/secure # /var/log/secure：记录登录系统存取数据的文件; # 例如:pop3，ssh，telnet，ftp等都会记录在此. 记录登陆后的IP地址和某用户名所操作的历史记录通过在/etc/profile里面加入以下代码就可以实现： PS1=&quot;`whoami`@`hostname`:&quot;&apos;[$PWD]&apos; history USER_IP=`who -u am i 2&gt;/dev/null| awk &apos;{print $NF}&apos;|sed -e &apos;s/[()]//g&apos;` if [ &quot;$USER_IP&quot; = &quot;&quot; ] then USER_IP=`hostname` fi if [ ! -d /tmp/dbasky ] then mkdir /tmp/dbasky chmod 777 /tmp/dbasky fi if [ ! -d /tmp/dbasky/${LOGNAME} ] then mkdir /tmp/dbasky/${LOGNAME} chmod 300 /tmp/dbasky/${LOGNAME} fi export HISTSIZE=4096 DT=`date &quot;+%Y-%m-%d_%H:%M:%S&quot;` export HISTFILE=&quot;/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT&quot; chmod 600 /tmp/dbasky/${LOGNAME}/*dbasky* 2&gt;/dev/null source /etc/profile 使用脚本生效 退出用户，重新登录 查看文件修改属性find /data/wwwroot -name &quot;*.php&quot; -mtime -10 | xargs ls -l stat filename #查看指定文件的信息 查找webshell 关键字find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;eval&quot; |more find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;shell_exec&quot; |more find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;passthru&quot; |more find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;fsockopen&quot; |more 常用日志文件系统日志是由一个名为syslog的服务管理的，如以下日志文件都是由syslog日志服务驱动的： /var/log/boot.log：录了系统在引导过程中发生的事件，就是Linux系统开机自检过程显示的信息 /var/log/lastlog ：记录最后一次用户成功登陆的时间、登陆IP等信息 /var/log/messages ：记录Linux操作系统常见的系统和服务错误信息 /var/log/secure ：Linux系统安全日志，记录用户和工作组变坏情况、用户登陆认证情况 /var/log/btmp ：记录Linux登陆失败的用户、时间以及远程IP地址 /var/log/syslog：只记录警告信息，常常是系统出问题的信息，使用lastlog查看 /var/log/wtmp：该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件，使用last命令查看 /var/run/utmp：该日志文件记录有关当前登录的每个用户的信息。如 who、w、users、finger等就需要访问这个文件 wtmp和utmp文件都是二进制文件，它们不能被诸如tail之类的命令剪贴或合并（使用cat命令）。用户需要使用who、w、users、last和ac等命令来使用这两个文件包含的信息。 lastlog 文件在每次有用户登录时被查询。 可以使用lastlog命令检查某特 定用户上次登录的时间，并格式化输出上次登录日志 /var/log/lastlog的内容。 它根据UID排序显示登录名、端口号（tty）和上次登录时间。 如果一个用户从未登录过，lastlog显示 **Never logged**。注意需要以root身份运行该命令. &quot;last -u 102&quot;命令将报告UID为102的用户；&quot;last -t 7&quot;命令表示限制为上一周的报告。 sshd 加固配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 # 仅允许SSH协议版本2 # SSH协议版本1有安全问题，包括中间人攻击(man-in-the-middle)和注入(insertion)攻击 Protocol 2 # 修改端口，密码尝试3次以上断开，超过30秒还未登陆成功端开 # 修改selinux: semanage port -a -t ssh_port_t -p tcp 55555 Port 55555 LoginGraceTime 30 MaxAuthTries 3 # 禁止root用户和空密码登陆 PermitRootLogin no PermitEmptyPasswords no # 如果需要 ChallengeResponseAuthentication no UsePAM no # 禁用密码验证，开启密钥验证 PasswordAuthentication no PubkeyAuthentication yes AuthenticationMethods publickey # 仅允许特定的用户通过SSH登陆 AllowUsers ceph.admin mysql.admin # 配置空闲超时注销时长，以秒为单位设置一个空闲超时时间（300秒 = 5分钟）。 # 一旦空闲时间超过这个值，空闲用户就会被踢出会话。 ClientAliveInterval 300 ClientAliveCountMax 0 # 禁用基于主机的授权（需核实） HostbasedAuthentication no # 允许特定用户用特定IP或域名通过SSH登陆，域名需要开启DNS UseDNS yes AllowUsers ceph.admin@189.12.1.4 mysql.admin@xyz.com``` bash 使用rsa 或 ed25519 加密密匙 $ ssh-keygen -t ed25519 -C "Login to production cluster at xyz corp" 或 $ ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa_aws_$(date +%Y-%m-%d) -C "AWS key for abc corp clients" 随机产生用户密码1234567891011121314151617$ vi genpasswd#!/bin/bashgenpasswd() &#123; local l=$1 [ "$l" == "" ] &amp;&amp; l=20 tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c $&#123;l&#125; | xargs&#125;# genpasswd 16genpasswd $1$ bash genpasswd 32 # 在默认配置文件 /etc/ssh/sshd_config 追加如下内容（ 将arcfour cipher 停用） Ciphers aes128-ctr,aes192-ctr,aes256-ctr # 禁用弱MAC算法，在默认配置文件 /etc/ssh/sshd_config追加如下内容 MACs hmac-sha1,umac-64@openssh.com,hmac-ripemd160,hmac-md5-96, hmac-sha2-256,hmac-sha2-512,hmac-ripemd160@openssh.com # 使用以下命令获取 OpenSSH 支持的加密方法： $ ssh -Q cipher $ ssh -Q cipher-auth $ ssh -Q mac $ ssh -Q kex $ ssh -Q key # 在重启 sshd 前检查配置文件的有效性和密匙的完整性，运行： $ sudo sshd -t # 扩展测试模式： $ sudo sshd -T # 限制登录设置主要是对hosts.allow与hosts.deny就行改动 # 首先限制所有IP都无法连接，我们顺便将FTP的限制也加入其中。 # 注意要想FTP限制起作用，需要修改配置中的tcp_wrappers=YES。 vi /etc/hosts.deny sshd:ALL vsftpd:ALL 设定允许指定的IP地址连接： vi /etc/hosts.allow # xxx.xxx.xxx.表示网段 sshd:192.168.1. vsftpd:192.168.1. 参考：https://linux.cn/article-9394-1.html 保护 SSH 的三把锁https://www.ibm.com/developerworks/cn/aix/library/au-sshlocks/ 增加黑客入侵的难度http://www.ibm.com/developerworks/i/p-fkereki.jpgFederico Kereki2010 年 11 月 30 日发布 WeiboGoogle+用电子邮件发送本页面Comments1简介 如果需要远程访问计算机并启用了 Secure Shell (SSH) 连接，黑客就会尝试突破您的防线并控制您的计算机，您必须接受这个事实。尽管不能保证计算机不会被 “黑客” 占领，但是一些简单的解决方案有助于保护 SSH，可以让攻击困难一些。本文讨论三种技术：常用缩写词 API: 应用程序编程接口 DNS: 域名系统 IETF: Internet 工程工作小组 LDAP: 轻量级目录访问协议 RFC: 请求注解 TCP: 传输控制协议 UDP: 用户数据报协议 把 SSH 的标准端口改为不常用的值并增强 SSH 配置，从而挡住最简单的攻击。 定义有限的用户列表，只允许这些用户登录。 完全隐藏允许 SSH 访问的事实，要求根据特殊的 “敲门” 序列识别有效用户。 要想应用这些技术，需要能够访问根账户。另外，可能必须安装一些包，需要配置防火墙和路由器（如果有路由器的话），打开和关闭特定的端口并把数据包转发到您的计算机。加强保护 “隐匿产生安全” 这个概念尽人皆知而且受到大家的嘲笑，因为采用隐匿的方式，希望没人了解您的方法，这只是一厢情愿的想法。但是，在某些场景中，隐匿一点儿会有帮助。尽管简单的措施无法阻止下定决心的黑客，但是至少能够挡住那些 “脚本小子”，他们的脚本往往水平很一般。 人人都知道 SSH 连接的标准端口是 22。因此，为了让计算机更安全，应该采取的第一个措施是把端口改为另一个不常用的非标准端口号，比如 22960。1024 以上的号码通常都可以使用，但是应该查阅参考资料以避免导致问题。这一修改对您的影响仅仅是必须使用下面的命令连接计算机：1 ssh -p 22960 your.machine.url 为了实现这个小措施，只需在 /etc/ssh/sshd_config 文件中做简单的修改。编辑此文件（必须作为根用户），寻找 Port 22 行，把端口号改为您选择的号码（如果这一行以镑符 [#] 开头，表示它被注释掉了，那么应该取消注释标志）。保存文件，用 /etc/init.d/sshd restart 命令重新启动 SSH。应该在防火墙上打开您选择的端口并关闭端口 22。 但是，还可以更进一步。编辑配置文件，在其中包含 清单 1 所示的行。注意，其中一些行可能已经存在，但是可以把它们注释掉。清单 1. 通过修改 SSH 配置文件简便地增强安全性12345 Port 22960LoginGraceTime 30MaxAuthTries 3Protocol 2PermitRootLogin no LoginGraceTime 允许一次登录花费 30 秒；如果用户花费的时间超过 30 秒，就不允许他访问，必须重新登录。MaxAuthTries 把错误尝试的次数限制为 3 次，3 次之后拒绝登录尝试。上面的 Protocol 2 行禁止使用比较弱的协议。最后一行不允许任何人作为根用户登录，这会让黑客攻击更困难。还可以使用 DenyUsers、AllowUsers、DenyGroups 和 AllowGroups 选项实现其他限制。这些修改不会显著增强计算机的安全性，但是只尝试强力攻击标准端口 22 的一般脚本会失败，不会造成损害。无论如何，这是向正确的方向迈出了第一步。在本文后面，我们将使用更安全的方法，不仅修改端口号，而且完全隐藏它。谁可以进入？ 对于大多数人，PAM 是一种罐装的烹调油。但是作为 Linux® 安全术语，PAM 代表可插入身份验证模块（Pluggable Authentication Modules）。这些模块提供额外的身份验证规则，保护对计算机的访问。 首先讨论一个基本问题：究竟为什么要使用 PAM？如果每个程序不得不定义自己的身份验证逻辑，就会很混乱。如何确定所有应用程序都实现了相同的测试和检查？如果需要额外的控制手段，那么怎么办？难道要重新编写所有程序吗？在计算机科学领域，有时候可以用额外的一层解决所有问题，至少在安全方面是这样。如果一个程序需要验证用户的身份，它可以调用 PAM API。这个 API 负责执行在 PAM 配置文件中指定的所有检查。这种方法还允许方便地修改身份验证规则，所有感知 PAM 的程序都会自动地应用新规则，不需要修改它们的代码。如果希望使用某种生物学检查（比如虹膜扫描器或指纹采集器），而且生产商提供了 PAM，就可以方便地设置它。在配置文件中包含模块调用，所有应用程序就可以使用这个设备了。配置 PAM PAM 提供四个安全领域的特性，但是应用程序不太可能同时需要所有这些方面。例如，passwd 命令只需要下面列表中的第三组： account 处理账户限制。对于有效的用户，允许他做什么？ auth 处理用户识别 — 例如，通过输入用户名和密码。 password 只处理与密码相关的问题，比如设置新密码。 session 处理连接管理，包括日志记录。 在 /etc/pam.d 目录中为将使用 PAM 的每个应用程序创建一个配置文件，文件名与应用程序名相同。例如，login 命令的配置文件是 /etc/pam.d/login。 必须定义将应用哪些模块，创建一个动作 “堆”。PAM 运行堆中的所有模块，根据它们的结果允许或拒绝用户的请求。还必须定义检查是否是必需的。最后，other 文件为没有特殊规则的所有应用程序提供默认规则。 optional 模块可以成功，也可以失败；PAM 根据模块是否最终成功返回 success 或 failure。 required 模块必须成功。如果失败，PAM 返回 failure，但是会在运行堆中的其他模块之后返回。 requisite 模块也必须成功。但是，如果失败，PAM 立即返回 failure，不再运行其他模块。 sufficient 模块在成功时导致 PAM 立即返回 success，不再运行其他模块。 配置文件的结构很简单。可以包含注释，注释以散列符 (#) 开头；通过在换行处加上反斜杠 ()，可以把长的行分为多行。行有三个字段：领域 (account、auth、password 或 session）、控制标志（optional、required、requisite 或 sufficient）、将运行的模块的路径和参数。注意，第二个字段可以更复杂；更多信息见 参考资料。另外，可以使用 include 规则以包含其他文件中的规则，比如 auth include common-account。 特殊的 /etc/pam.d/other 文件是 “默认的” 配置文件（见 清单 2），其中的规则自动地应用于没有自己的配置文件的所有应用程序。为了确保安全，应该快速检查 /etc/pam.d 目录，把您不使用的所有配置文件改为其他名称（这样就会使用 other 配置）。如果认为确实需要某个应用程序，那么只需把配置文件改回原来的名称。默认配置通常拒绝所有请求（通过使用 pam_deny.so 模块）并警告管理员（通过 pam_warn.so 模块），让管理员解决问题。 标准的 “other” 配置文件为没有自己的配置文件的所有应用程序提供安全的默认规则（拒绝所有请求）。清单 2. 标准的 “other” 配置文件123456 account required pam_deny.soauth required pam_deny.soauth required pam_warn.sopassword required pam_deny.sopassword required pam_warn.sosession required pam_deny.so 如果把 pam_deny.so 替换为 pam_unix.so，就应用标准的身份验证方法（输入用户名和密码）。如果您不关心安全性，那么使用 pam_permit.so，这会允许任何请求！一些可用方法 尽管没有标准的模块列表，但是所有发行版都包含以下模块中的大多数。请检查驻留模块的 /lib/security 或 /usr/lib/security 目录。对于 64 位操作系统，用 lib64 替换 lib。如果需要更多信息，可以尝试执行 man the.name.of.the.module，而不要直接执行它；PAM 不是可执行的二进制代码。 pam_access 根据 /etc/security/access.conf 文件允许或拒绝访问。稍后将使用此模块决定允许哪些用户登录。 pam_cracklib 和 pam_pwcheck 检查新密码的强度。 pam_deny 和 pam_permit 是基本模块，分别拒绝或允许访问。 pam_echo 向用户显示指定文件的内容。 pam_lastlog 向用户显示他上一次登录的日期和时间。 pam_ldap.so 让用户根据 LDAP 服务器进行身份验证，提供跨网络的集中式身份验证。 pam_limits 模块允许指定系统资源限制，限制在 /etc/security/limits.conf 文件中定义。 pam_listfile 提供根据一个文件的内容允许或拒绝服务的另一种方法。 pam_mail 检查用户是否有未处理的邮件。 pam_motd 向用户显示 “message of the day” 文件。 如果 /etc/nologin 文件存在，pam_nologin 阻止所有登录。 pam_rootok 允许根用户访问，不执行进一步检查。/etc/pam.d/su 中常常包含这个模块；必需的行是 auth sufficient pam_rootok.so。根用户可以作为任何用户操作，不需要提供密码。 pam_succeed_if 检查账户的特定属性，比如是否是某个组的成员。 pam_time 可以根据 /etc/security/time.conf 中的规则限制对服务的访问。 pam_unix（或 pam_unix2）提供基于 /etc/passwd 和 /etc/shadow 文件的传统 UNIX® 身份验证。 pam_userdb 根据一个 Berkeley 数据库执行身份验证。 pam_warn 在系统日志中记录信息。 pam_wheel 只向 wheel 组的成员提供根访问权；必需的行是 auth required pam_wheel.so。 关于其他模块和编写自己的模块的信息，请查阅 参考资料。现在，使用 PAM 决定谁可以登录您的计算机。用 PAM 限制访问 现在，我们来使用 PAM 限制谁可以连接您的服务器。必须编辑 /etc/pam.d/sshd 文件，让它像清单 3 这样。清单 3. 在 sshd PAM 文件中添加 pam_access.so1234567 #%PAM-1.0account include common-accountaccount required pam_access.soauth include common-authauth required pam_nologin.sopassword include common-passwordsession include common-session 在 sshd PAM 文件中添加 pam_access.so，就可以轻松地定义谁可以使用 SSH 连接您的计算机。pam_access.so 模块实现基于 /etc/security/access.conf 文件的安全控制，见清单 4。清单 4. 通过使用 pam_access.so，定义谁可以或不可以使用 SSH1234 : ALL : 192.168.1. : jack : ALL : jill : ALL : ALL : ALL 第一行允许任何用户 (ALL) 从内部网络登录。后两行允许用户 jack 和 jill 从任何地方访问服务器。最后一行拒绝其他任何用户从其他任何地方访问。允许多个用户访问的另一种方法是使用 pam_listfile.so，这需要创建一个允许访问的用户列表（例如 /etc/ssh_users）。在 /etc/pam.d/sshd 文件中添加以下行：12 auth required pam_listfile.so item=user sense=allow file=/etc/ssh_users onerr=fail 这还没有完。必须修改 /etc/ssh/sshd_config 文件，让它使用 PAM。在此文件中添加 UsePAM yes 行，重新启动 sshd 守护进程，这样就行了！究竟是否有门？ 即使应用了前两节中的方法，无论您怎么预防，黑客仍然会尝试穿越您系统中任何开放的门户。改变 SSH 端口号对于经验丰富的黑客只能造成小小的麻烦。限制允许访问的用户会有帮助，但前提是没有用户落入黑客或社会工程攻击的圈套而泄露密码。无论如何，只要您的系统中有门，就会吸引黑客。 增强计算机安全性的最后一种方案是最激进的：关闭打开的端口，这会让任何攻击都无法攻破您的计算机。只向能够提供 “秘密敲门暗号” 的用户开放所需的端口，让用户能够输入密码并访问计算机。 这种技术称为端口敲门，适用于需要访问不向公众开放的服务器的用户。服务器可以关闭所有端口，直到用户提供一个秘密的敲门序列 （序列很容易实现，而且需要的资源不多）。 打开秘密端口之后，应用常用的安全机制（比如密码或证书）。只需在防火墙级上提供一个额外的安全层，需要秘密端口的所有服务就会正常工作。 这种方法的要点在于关闭所有端口并监视外部连接尝试。当识别出预定义的尝试序列（称为敲门序列 ）时，可以执行打开端口等操作，让外部的用户能够进来。敲门序列的复杂程度由您决定，从简单的列表（比如依次尝试 TCP 端口 7000、UDP 端口 7100 和 TCP 端口 7200）到一次性序列集合都可以。（按密码学术语来说，一次性序列与 “一次一密” 相似，这是已知最安全的加密方法。）外面的用户必须知道使用 SSH 所需的端口号和密码，还必须知道打开端口并启用密码所需的敲门序列。如果没有这个序列，连接尝试就会静悄悄地失败。 这为什么是非常安全的方案？因为有 65,535 个端口（见 参考资料）。即使考虑到已经分配的端口，仍然有超过 60,000 个可用端口。如果敲门序列只包含四次 “敲门”，黑客要想通过强力攻击猜出序列，就必须测试大约 13,000,000,000,000,000,000 个序列（13 后面 18 个零）。这样的攻击显然不太可能奏效！当然，强力攻击或胡乱猜测并不是猜出正确序列的惟一方法。因此，不要只使用单一安全方法；而是使用一系列安全层来增加攻击的难度。 必须安装敲门守护进程 knockd；它监视敲门序列，当发现有效的序列时执行相应的操作。如果愿意，可以从头构建它，但是大多数（如果不是所有的话）发行版中都有这个包。最好使用包管理工具安装它。例如，在 OpenSUSE 中，可以使用 Yast2 或通过执行 sudo zypper install knockd 安装它。在 Ubuntu 中可以使用 sudo apt-get install knockd，在 Debian 中使用 sudo aptitude install knockd。用发行版的软件安装工具搜索 knockd 往往能够找到它。 安装这个包之后，必须编辑 /etc/knockd.conf 文件以指定端口敲门规则，然后启动守护进程。为了完成所需的设置，必须了解您的防火墙的工作方式。例如，在 OpenSUSE 中，可以使用 清单 5 这样的设置。清单 5. 针对 OpenSUSE 防火墙设计的示例配置文件1234567 [opencloseSSH] sequence= 7000,8000,9000 tcpflags= syn seq_timeout= 15 cmd_timeout= 30 start_command= /usr/sbin/iptables -s %IP% -I input_ext 1 -p tcp –dport 22960 -j ACCEPT stop_command= /usr/sbin/iptables -s %IP% -D input_ext -p tcp –dport 22960 -j ACCEPT 这个示例在用户依次在端口 7000、8000 和 9000 上敲门之后启用 SSH 访问。 在启动 knockd 之前，关闭端口 22960 并尝试远程登录。这个尝试应该会失败，见清单 6。清单 6. 如果禁用 SSH 访问而且不启动敲门守护进程，登录尝试会失败12 ssh the.url.for.your.site -p 22960 -o ConnectTimeout=15ssh: connect to host the.url.for.your.site port 22960: Connection timed out 现在，使用 sudo /etc/init.d/knockd start 或 sudo knockd -d 启动端口敲门守护进程（这两个命令是等效的），然后再试一下；端口敲门序列要求在端口 7000、8000 和 9000 上敲门。必须在 15 秒内完成这个序列。识别出序列之后端口打开，必须在 30 秒内登录。否则，端口再次关闭。 为了检验这个过程，回到您的远程机器上并登录。这一次提供所需的敲门序列，见 清单 7。注意，在安装 knockd 时通常也会安装 knock 命令。如果不是这样，只需用发行版的包管理工具搜索它。清单 7. 提供所需的敲门序列之后登录成功12345 knock the.url.for.your.site 7000knock the.url.for.your.site 8000knock the.url.for.your.site 9000ssh the.url.for.your.site -p 22960 -o ConnectTimeout=10Password: 如果提供了错误的敲门序列（或根本没有敲门），会收到 “Connection timed out” 消息，SSH 端口仍然完全关闭，看不出它是存在的。如果您处于路由器后面 如果您的服务器通过路由器连接 Internet，就必须修改它的配置。具体细节因路由器和防火墙类型而异，但是一般来说应该： 打开敲门端口并把数据包转发到您的计算机，让 knockd 能够识别并处理它们。 把端口 22960（SSH 连接使用的端口）上的数据包转发到您计算机上的端口 22960。 配置您计算机的防火墙，让它拒绝对端口 22960 和敲门端口的连接。 尽管路由器会打开一些端口，但是对它们的所有访问都会到达您计算机的防火墙。访问会被阻止，除非探测到正确的端口敲门序列。敲门配置 /etc/knockd.conf 文件有一个一般选项小节 options，希望使用的每个敲门序列各有一个小节。选项可以是大写、小写或大小写混合形式。 在默认情况下，knockd 监视 eth0 接口。要想使用另一个接口（例如 eth1），可以包含 Interface=eth1 行。注意，只使用设备名而不是设备的完整路径。 如果希望启用日志记录，可以通过包含 useSyslog 行使用标准的 Linux 日志文件，也可以通过包含 LogFile=/the/full/path/to/your/file 使用自己的文件。但是，应该认识到日志记录是一个漏洞；如果黑客获得了日志，入侵者就会掌握端口敲门序列。 如果希望能够检查 knockd 是否仍然在运行，那么包含 PidFile=/the/full/path/to/a/PID/file。这个守护进程的进程 ID (PID) 将存储在这个文件中。应该通过一个 cron 任务定期检查 knockd 是否仍然在运行并在需要时重新启动它。注意，当这个守护进程停止运行时，系统是安全的；所有端口关闭，不可访问。在守护进程重新启动之前，用户无法登录。 可以让 knockd 监听多个序列并以不同方式响应各个序列。在前面的示例中，让 knockd 打开 SSH 端口；可以简单地启用 HTTP 端口，让用户能够访问 web 服务器，也可以运行特定的进程。在配置文件中，每个序列都有相应的小节。 使用 sequence 定义敲门序列，比如 7000,8000,9000。在默认情况下，敲门使用 TCP，但是可以添加 UDP 以增加复杂性，比如 7000,8000:udp,9000。 除了使用固定的序列之外，还可以指定一个包含 “一次性序列” 的文件，这些序列在使用之后就会删除，不能再次使用。指定这种序列的方法如下： 1 one_time_sequences=/the/full/path/to/a/sequences/file 使用任何文本编辑器创建此文件；其中每行包含一个序列（按照上面所示的格式）。应该在远程计算机上保存此文件的拷贝以便记住如何登录。 可以指定应该扫描哪些到达的 TCP 数据包，丢弃不与 ACK、FIN、PSH、RST、SYN 或 URG 标志匹配的数据包。对于 SSH 连接，应该使用 TCPFlags=SYN。 可以用 Seq_Timeout=seconds.to.wait 指定完成一个序列的最大时间。如果在此时间内没有输入完整的序列，就不会识别出它，访问被拒绝。 可以用 Cmd_Timeout=seconds.to.wait 指定在识别出序列之后用户执行第二个命令的最大时间。如果提供了敲门序列的用户没有快速地输入下一个命令（例如登录），端口会再次关闭。 最重要的参数是 Start_command=some.command.to.execute，它指定成功地识别出敲门序列之后要执行的命令或脚本。如果需要引用敲门者的 IP 地址（例如为了允许从他的计算机连接您的计算机），可以使用 %IP%。在运行时，它会替换为正确的值。在上面的示例中指定： 1 /usr/sbin/iptables -s %IP% -I input_ext 1 -p tcp --dport 22960 -j ACCEPT iptables 向提供敲门序列的 IP 地址上的用户开放端口 22960。 另一个重要的参数是 Stop_command=some.command.to.execute；当超过 Cmd_timeout 时间之后，执行它指定的命令或脚本。 在这里，因为只希望打开或关闭端口 22960，所以使用单一命令就够了。如果需要更复杂的操作，可以通过调用脚本执行所需的任何操作 — 操作甚至可以完全不涉及打开端口。可以触发任何操作，比如运行进程或执行备份。当然，了解要使用的命令可能有点儿难度。例如，因为我运行 OpenSUSE，它提供自己的防火墙前端，所以我不得不通过查看 iptables -l 的输出了解应该执行哪个命令来打开或关闭端口 22960。 对于 knockd 本身，有几个选项需要考虑： -c：允许指定默认配置文件 /etc/knockd.conf 之外的另一个配置文件 -d：让 knockd 作为后台守护进程运行，这是标准运行方式 -D：提供输出调试消息 -h：提供关于语法和选项的帮助 -i：允许指定默认的 eth0 接口之外的其他接口 -l：为日志项启用 DNS 查找 — 这是一种不好的做法，因为这强迫计算机使用 DNS 通信流，会产生漏洞 -v：提供更详细的消息和解释 -V：提供程序的版本号 最后，可以使用多种方法产生敲门序列本身，编写 knock 命令是最简单的方法。 以下命令在 TCP 端口 7000 上敲门：1 knock the.url.for.your.site 7000 以下命令在 UDP 端口 8000 上敲门：1 knock the.url.for.your.site -u 8000 或1 knock the.url.for.your.site 8000:udp -h 参数提供这个命令的帮助。结束语 您看到了三种保护 SSH 访问的方法：修改 sshd 的配置参数，通过 PAM 限制可以登录的用户，以及使用端口敲门序列隐藏存在 SSH 访问的事实。尽管没有任何方法能够完全保护任何计算机，但是采取这三个措施会让您的服务器安全一些。]]></content>
      <categories>
        <category>linux</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WordPress Nginx 安全配置 – 禁用某些目录执行PHP]]></title>
    <url>%2Fnginx%2Fwordpress%2FWordPress%20Nginx%20%E5%AE%89%E5%85%A8%E9%85%8D%E7%BD%AE%20%E2%80%93%20%E7%A6%81%E7%94%A8%E6%9F%90%E4%BA%9B%E7%9B%AE%E5%BD%95%E6%89%A7%E8%A1%8CPHP%2F</url>
    <content type="text"><![CDATA[以下我们将介绍Wordpress Nginx 安全配置：禁用某些目录执行PHP，详细说明查看如下配置信息： server { listen 80; server_name website.com; # Redirect non-www to www (website.com -&gt; www.website.com) return 301 http://www.$server_name$request_uri; } server { listen 80; server_name www.website.com; access_log /var/www/website.com/logs/access.log main; error_log /var/www/website.com/logs/error.log warn; root /var/www/website.com/public/htdocs; index index.html index.htm index.php; # 日志不记录 robots.txt location = /robots.txt { log_not_found off; access_log off; } # 如果没有 favicon 文件则退出并返回 204 (没有错误内容) location ~* /favicon\.ico$ { try_files $uri =204; expires max; log_not_found off; access_log off; } # 以下格式文件日志不需要记录 location ~* \.(js|css|png|jpg|jpeg|bmp|gif|ico)$ { expires max; log_not_found off; access_log off; # Send the all shebang in one fell swoop tcp_nodelay off; # Set the OS file cache open_file_cache max=1000 inactive=120s; open_file_cache_valid 45s; open_file_cache_min_uses 2; open_file_cache_errors off; } # http://wiki.nginx.org/WordPress # 设置静态地址必须要添加的配置 # 如果你后台添加了固定链接，则需要添加以下配置 location / { try_files $uri $uri/ /index.php?$args; } # 禁止访问 htaccess 文件 location ~ /\. { deny all; } # nocgi cgi等可执行的，不允许 location ~* \.(pl|cgi|py|sh|lua)\$ { return 444; } #禁止访问 wp-config.php install.php 文件 location = /wp-config.php { deny all; } location = /wp-admin/install.php { deny all; } # 禁止访问 /wp-content/ 目录的 php 格式文件 (包含子目录) location ~* ^/wp-content/.*.(php|phps)$ { deny all; } # 允许内部分 wp-includes 目录的 .php 文件 location ~* ^/wp-includes/.*\.(php|phps)$ { internal; } # 禁止访问 /wp-content/ 目录的以下文件格式 (包含子目录) location ~* ^/wp-content/.*.(txt|md|exe)$ { deny all; } # 禁止uploads、images目录下面的所有php、jsp访问 location ~ ^/(uploads|images)/.*\.(php|php5|jsp)$ { deny all; #return 403; } # 禁止访问目录 /conf/* location ^~ /conf/ { deny all; } # 注意：上述/conf/后面的斜杠不能少，否则所有以conf开头的目录或文件都将禁止访问。 ## 禁止访问任何目录下的.sql文件，禁止浏览器访问 location ~.*\.sql { deny all; } # 这样，任一目录的sql文件都不会被用户访问到了。 # 处理 .php 文件 location ~ \.php$ { try_files $uri =404; fastcgi_split_path_info ^(.+\.php)(/.+)$; include /etc/nginx/fastcgi_params; fastcgi_connect_timeout 180s; fastcgi_send_timeout 180s; fastcgi_read_timeout 180s; fastcgi_intercept_errors on; fastcgi_max_temp_file_size 0; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_index index.php; } # 限制登陆和管理IP地址 location ~ ^/(wp-admin|wp-login\.php) { allow 1.2.3.4; deny all; ## 下面是fastcgi 方式 index index.php index.html index.htm; fastcgi_index index.php; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; ## 下面是代理方式的设置 proxy_pass http://apachebackend; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # wordpress 重写规则 rewrite ^/sitemap_index\.xml$ /index.php?sitemap=1 last; rewrite ^/([^/]+?)-sitemap([0-9]+)?\.xml$ /index.php?sitemap=$1&amp;sitemap_n=$2 last; # Add trailing slash to */wp-admin requests rewrite /wp-admin$ $scheme://$host$uri/ permanent; # 403页面配置 error_page 403 http://cdn-home.mimvp.com/404.html; # 指定CDN页面 error_page 403 404.html; # 指定当前项目根目录下的404.html文件 }]]></content>
      <categories>
        <category>nginx</category>
        <category>wordpress</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx设置连接限制和限制白名单]]></title>
    <url>%2Fnginx%2Fsecurity%2Fnginx%E8%AE%BE%E7%BD%AE%E8%BF%9E%E6%8E%A5%E9%99%90%E5%88%B6%E5%92%8C%E9%99%90%E5%88%B6%E7%99%BD%E5%90%8D%E5%8D%95%2F</url>
    <content type="text"><![CDATA[要求设置ip白名单，需用到nginx geo 与 nginx map nginx默认加载了ngx-http-geo-module和ngx-http-map-module相关内容； ngx-http-geo-module可以用来创建变量，变量值依赖于客户端 ip 地址; ngx-http-map-module可以基于其他变量及变量值进行变量创建，其允许分类，或者映射多个变量到不同值并存储在一个变量中； Nginx geo 格式说明 Syntax ( 语法格式 ): geo [$address] $variable { ... } Default ( 默认 ): - Content ( 配置段位 ): http Nginx map 格式说明 Syntax ( 语法格式 ): map String $variable { ... } Default ( 默认 )：- Content ( 配置段位 ): http 开启nginx连接限制对指定请求路径不设置限制，如对请求路径为api目录下的请求不做限制，则可写为 server{ location /app { proxy_pass http://192.168.1.111:8095/app; limit_conn conn 50; limit_rate 500k; limit_req zone=foo burst=5 nodelay; } location /app/api { proxy_pass http://192.168.1.111:8095/app/api } } # 因nginx会优先进行精准匹配，所以以上写法即接触了对api目录下属路径的限制 白名单配置示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657http&#123; # ... 其他配置内容 ################################## ## /etc/nginx/http.d/map.conf #定义白名单ip列表变量 geo $whiteiplist &#123; default 1; 10.250.250.0/24 0; 127.0.0.1 0; &#125; #使用map指令映射将白名单列表中客户端请求ip为空串 map $whiteiplist $limit&#123; 1 $binary_remote_addr ; 0 ""; &#125; ################################## ## /etc/nginx/http.d/limit.conf ## 配置前端代理，获取客户端真实IP real_ip_header X-Forwarded-For; set_real_ip_from 139.219.193.17; #set_real_ip_from 0.0.0.0/0; #real_ip_recursive on; # $limit defined in /etc/nginx/http.d/map limit_conn_zone $limit zone=conn:30m; limit_conn_status 444; limit_conn_log_level info; limit_req_zone $limit zone=perip:30m rate=5r/s; limit_req_status 444; limit_req_log_level info; ################################## server&#123; location /app &#123; ## 单IP同时连接数限制 limit_conn conn 5; ## 单IP单位时间内请求数限制 limit_req zone=perip burst=5 nodelay; ##每个请求最大传输速率 limit_rate 500k; proxy_pass http://192.168.1.111:8095/app; &#125; &#125;&#125; 白名单配置可用于对合作客户，搜索引擎等请求过滤限制 特殊情况处理1234567891011121314151617181920212223242526272829303132333435363738394041#如果想仅限制指定的请求，如：只限制Post请求，则：http&#123; # 其他请求.. #请求地址map映射 map $request_method $limit &#123; default ""; POST $binary_remote_addr; &#125; #限制定义 limit_req_zone $limit zone=perip:20m rate=10r/s; server&#123; ... #与普通限制一致 limit_req zone=perip burst=5 nodelay; &#125;&#125;#在此基础上，想进行指定方法的白名单限制处理，则：http&#123; #... #定义白名单列表 map $whiteiplist $limitips&#123; 1 $binary_remote_addr; 0 ""; &#125; #基于白名单列表，定义指定方法请求限制 map $request_method $limit &#123; default ""; # POST $binary_remote_addr; POST $limitips; &#125; #限制定义 limit_req_zone $limit zone=perip:20m rate=10r/s; #在server中进行引用 server&#123; #... 与普通限制相同 limit_req zone=perip burst=5 nodelay; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用NGINX的GeoIp库做国外ip屏蔽]]></title>
    <url>%2Fnginx%2Fsecurity%2F%E7%94%A8NGINX%E7%9A%84GeoIp%E5%BA%93%E5%81%9A%E5%9B%BD%E5%A4%96ip%E5%B1%8F%E8%94%BD%2F</url>
    <content type="text"><![CDATA[安装GeoIp模块12345678910111213141516171819## 安装模块，nginx也是通过yum安装yum install nginx-module-geoip## 安装对应nginx 版本的 模块yum --showduplicate list nginx-module-geoipnginx-module-geoip.x86_64 1:1.12.0-1.el7.ngx nginxnginx-module-geoip.x86_64 1:1.12.1-1.el7.ngx nginxnginx-module-geoip.x86_64 1:1.12.2-1.el7_4.ngx nginxnginx-module-geoip.x86_64 1:1.14.0-1.el7_4.ngx nginxyum install nginx-module-geoip-1:1.12.2-1.el7_4.ngx.x86_64ls /usr/lib64/nginx/modules/ngx_http_geoip_module-debug.so ngx_http_geoip_module.so ngx_stream_geoip_module-debug.so ngx_stream_geoip_module.so 下载ip库本地下载GeoIP库 123456789101112131415## 下载ip库信息文件并放在/etc/nginx/geoip/目录mkdir -p /etc/nginx/geoip/## 旧版本库，官网将在201902停止提供下载wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz -O /etc/nginx/geoip/GeoIP.dat.gzwget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz -O /etc/nginx/geoip/GeoLiteCity.dat.gz## 新版数据库不支持，第三方插件地址: https://github.com/leev/ngx_http_geoip2_modulewget http://geolite.maxmind.com/download/geoip/database/GeoLite2-Country.tar.gz -O /etc/nginx/geoip/GeoLite2-Country.tar.gzwget http://geolite.maxmind.com/download/geoip/database/GeoLite2-City.tar.gz -O /etc/nginx/geoip/GeoLite2-City.tar.gzgunzip /etc/nginx/geoip/GeoIP.dat.gz gunzip /etc/nginx/geoip/GeoLiteCity.dat.gz 修改nginx配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061vi /etc/nginx/nginx.conf## 模块加载最好放在顶部，必须放在event配置项前面，否则报错load_module modules/ngx_http_geoip_module.so;#load_module modules/ngx_stream_geoip_module.so;......http&#123; geoip_country /etc/nginx/geoip/GeoIP.dat; #不按城市划分，就不需要加载 #geoip_city /etc/nginx/geoip/GeoLiteCity.dat; ## 如果前端有反向代理的话 #geoip_proxy 192.168.100.0/24; #geoip_proxy 2001:0db8::/32; #geoip_proxy_recursive on; ## 用于php-fpm fastcgi_param GEOIP_COUNTRY_CODE $geoip_country_code; fastcgi_param GEOIP_COUNTRY_CODE3 $geoip_country_code3; fastcgi_param GEOIP_COUNTRY_NAME $geoip_country_name; server &#123; listen 80; server_name localhost; location / &#123; set $adminflag 0; if ( $request_uri ~* "/+(downloader|admin)" ) &#123; set $adminflag 1; #rewrite ^/(.*)$ $scheme://$host/myip permanent; &#125; if ( $geoip_country_code != CN ) &#123; set $adminflag "$&#123;adminflag&#125;1"; #return 301 $scheme://$host/myip; &#125; if ( $adminflag = "11" ) &#123; return 403; &#125; root /usr/share/nginx/html; index index.html index.htm; &#125; location /myip &#123; default_type text/plain; return 200 "$remote_addr $geoip_country_name $geoip_country_code $geoip_city"; &#125; &#125;&#125; GeoIP参数http://nginx.org/en/docs/http/ngx_http_geoip_module.html Syntax: geoip_country file; Default: — Context: http Specifies a database used to determine the country depending on the client IP address. The following variables are available when using this database: $geoip_country_code two-letter country code, for example, “RU”, “US”. $geoip_country_code3 three-letter country code, for example, “RUS”, “USA”. $geoip_country_name country name, for example, “Russian Federation”, “United States”. Syntax: geoip_city file; Default: — Context: http Specifies a database used to determine the country, region, and city depending on the client IP address. The following variables are available when using this database: $geoip_area_code telephone area code (US only). This variable may contain outdated information since the corresponding database field is deprecated. $geoip_city_continent_code two-letter continent code, for example, “EU”, “NA”. $geoip_city_country_code two-letter country code, for example, “RU”, “US”. $geoip_city_country_code3 three-letter country code, for example, “RUS”, “USA”. $geoip_city_country_name country name, for example, “Russian Federation”, “United States”. $geoip_dma_code DMA region code in US (also known as “metro code”), according to the geotargeting in Google AdWords API. $geoip_latitude latitude. $geoip_longitude longitude. $geoip_region two-symbol country region code (region, territory, state, province, federal land and the like), for example, “48”, “DC”. $geoip_region_name country region name (region, territory, state, province, federal land and the like), for example, “Moscow City”, “District of Columbia”. $geoip_city city name, for example, “Moscow”, “Washington”. $geoip_postal_code postal code.]]></content>
      <categories>
        <category>nginx</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 日志记录]]></title>
    <url>%2Fnginx%2Flog%2Fnginx%20%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[日志语法参考: http://nginx.org/en/docs/http/ngx_http_log_module.html Syntax: access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; Default: access_log logs/access.log combined; Context: http, server, location, if in location, limit_except 使用geo不记录特定IP请求的日志ngx_http_geo_module模块可以用来创建变量，其值依赖于客户端IP地址。 geo指令使用ngx_http_geo_module模块提供的。 默认情况下，nginx有加载这个模块，除非人为的 --without-http_geo_module。 ngx_http_geo_module模块可以用来创建变量，其值依赖于客户端IP地址。 geo指令语法: geo [$address] $variable { ... } 默认值: — 配置段: http 定义从指定的变量获取客户端的IP地址。 默认情况下，nginx从$remote_addr变量取得客户端IP地址，但也可以从其他变量获得。如$realip_remote_addr. geo $realip_remote_addr $loggable{ default 1; 10.250.250.0/24 0; 139.219.188.72 0; 139.219.187.55 0; 127.0.0.1 0; } access_log /data/wwwlogs/nginx_access.log main buffer=32k flush=5 if=$loggable; access_log on; 如果该变量([$address])的值不能代表一个合法的IP地址，那么nginx将使用地址“255.255.255.255”。 nginx通过CIDR或者地址段来描述地址，支持下面几个参数： delete：删除指定的网络 default：如果客户端地址不能匹配任意一个定义的地址，nginx将使用此值。 如果使用CIDR，可以用“0.0.0.0/0”代替default。没指定default，默认值将为空字符串。 include： 包含一个定义地址和值的文件，可以包含多个。 proxy：定义可信地址。 如果请求来自可信地址，nginx将使用其“X-Forwarded-For”头来获得地址。 相对于普通地址，可信地址是顺序检测的。 proxy_recursive：开启递归查找地址。 如果关闭递归查找，在客户端地址与某个可信地址匹配时，nginx将使用“X-Forwarded-For”中的最后一个地址来代替原始客户端地址。如果开启递归查找，在客户端地址与某个可信地址匹配时，nginx将使用“X-Forwarded-For”中最后一个与所有可信地址都不匹配的地址来代替原始客户端地址。 ranges：使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。 示例： geo $country { default ZZ; include conf/geo.conf; delete 127.0.0.0/16; proxy 192.168.100.0/24; proxy 2001:0db8::/32; 127.0.0.0/24 US; 127.0.0.1/32 RU; 10.1.0.0/16 RU; 192.168.1.0/24 UK; } vim conf/geo.conf 10.2.0.0/16 RU; 192.168.2.0/24 RU; 地址段例子： geo $country { ranges; default ZZ; 127.0.0.0-127.0.0.0 US; 127.0.0.1-127.0.0.1 RU; 127.0.0.1-127.0.0.255 US; 10.1.0.0-10.1.255.255 RU; 192.168.1.0-192.168.1.255 UK; } geo指令主要是根据IP来对变量进行赋值的。因此geo块下只能定义IP或网络段，否则会报错。 使用map来过滤日志记录Nginx map 格式说明 Syntax ( 语法格式 ): map String $variable { ... } Default ( 默认 )：- Content ( 配置段位 ): http map $status $loggable { ~^[23] 0; default 1; } access_log /path/to/access.log combined if=$loggable; 一个简单的geo区域负载示例http { ..... geo $geo { default default; 192.168.6.189/32 uk; 192.168.6.8/32 us; # 192.168.0.0/24 tw } upstream uk.server { server 192.168.6.101; } upstream us.server { server 192.168.6.102; } upstream default.server { server 192.168.6.121:8080; } sendfile on; keepalive_timeout 65; server { listen 80; server_name 192.168.6.121; index index.html index.htm; root html; location / { proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://$geo.server$request_uri; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 8080; server_name 192.168.6.121; location / { root html; index index.html index.htm; } } }]]></content>
      <categories>
        <category>nginx</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 多下级目录配置]]></title>
    <url>%2Fhexo%2FHexo%20%E8%99%9A%E6%8B%9F%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[使用注意# 发布和预览运行时都需要先清空，不然会文章融合在一起, 搜索也会不能用 # 下级目录一定要添加参数: --config &lt;下级配置文件&gt; # 主目录运行 hexo clean hexo server -d # 下级目录运行 hexo --config life.yml clean hexo --config life.yml server -d 发布流程# 先编译 hexo clean &amp;&amp; hexo generate hexo --config life.yml clean &amp;&amp; hexo --config life.yml generate # 再将下级目录编译的静态文件夹移到主目录，这里将public 下的 life 移到 work 下 # 最后发部主目录 hexo deploy 根目录设置根目录./work 配置文件_config.yml1234567891011121314151617181920# Sitetitle: 克隆人战争subtitle: 为了生存, 为了利益,&lt;br/&gt;争斗才是人类历史的主旋律！description: 现实是强者理想的实现keywords:author: dolphinlanguage: zh-CNtimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://dolphincn.github.ioroot: /permalink: :title/permalink_defaults:# Directorysource_dir: workpublic_dir: public/work 子目录设置子目录./life 配置文件life.yml123456789101112131415161718192021# Sitetitle: 克隆人战争subtitle: 为了生存, 为了利益,&lt;br/&gt;争斗才是人类历史的主旋律！description: 现实是强者理想的实现keywords:author: dolphinlanguage: zh-CNtimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://dolphincn.github.io/liferoot: /life/permalink: :title/permalink_defaults:# Directorysource_dir: lifepublic_dir: public/life]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xcopy 备份文件夹]]></title>
    <url>%2Fwindows%2Fbackup%2Fxcopy%20%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[基本使用创建 backup.bat文件，文件编码格式为ANSI，内容如下 @echo off echo 正在复制&quot;C:\a&quot;文件夹的内容至&quot;D:\b&quot;文件夹下...... xcopy &quot;C:\c&quot; &quot;D:\d&quot; /e/I/d/h/r/y exit 参数说明： /e：拷贝所有子目录，包括空子目录； /I： 如果目标文件或目录不存在且拷贝的文件数多于一，则假设目标为目录； /d：只拷贝文件日期与在目标文件后的文件（即修改过的源文件） /h：同时拷贝隐藏文件和系统文件 /r：拷贝并覆盖只读文件 /y： 复制文件审核设置（不显示已有文件覆盖确认） Xcopy命令详解为了节省时间，可以使用Copy、Xcopy、Xcopy32等命令把数据备份到其他硬盘或分区。 其中用的最多的是“Xcopy”，它的功能非常强大，使用这个命令可以拷贝一个目录中的所有文件，包括该目录中所有子目录中的全部文件（DOS7.0以后的Xcopy甚至可以拷贝隐藏文件）。 其语法为：XCOPY source [destination] [/Y][/-Y] [/A | /M] [/D[:date]] [/P] [/S [/E]] [/W][/C] [/I] [/Q] [/F] [/L] [/H] [/R] [/T] [/U][/K] [/N] 参数介绍： /A 拷贝文件，但不改变文件的存档属性。 /M 拷贝文件，同时关闭文件的存档属性。 /D: 拷贝指定日期以后文件。如果没有给出指定日期，仅拷贝比目标文件更新的文件。 /P 在建立每一目标文件时进行提醒。 /S 拷贝当前目录和所有子目录下的所有文件，但不包括空目录。 /E 拷贝当前目录和所有子目录下的所有文件，同时也包括空目录。 /W 在拷贝文件前提示你按任意键确认。 /C 即使有错误发生也继续拷贝。 /Q 在拷贝文件时不显示文件名。 /F 在拷贝时显示所有源文件和目标文件名。 /L 显示被拷贝的文件。 /H 拷贝隐含文件和系统文件。 /R 覆盖只读文件。 /T 建立目录，但不拷贝文件，但不包括空目录和空的子目录。 /T /E 命令包括空的目录和子目录。 /U 更新已经存在的目标文件。 /K 拷贝文件属性。一般来说XCOPY命令将重置只读文件属性。 /Y 不给出提示信息直接覆盖已经存在的文件。 /-Y 在覆盖已经存在的文件时给出提示信息。 /N 拷贝短文件名，即8.3格式的文件。 比如要将d:\xly下所有文件备份到e:\xly1，可以使用如下命令： xcopy d:\xly*.*/s/h e:\xly1 又比如，要恢复e:\xly1下2006年6月1日以后的文件至D:\xly，就可使用如下命令： xcopy e:\xly1*.*/s/h/d:2006-06-01 d:\xly]]></content>
      <categories>
        <category>windows</category>
        <category>backup</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>backup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo渲染时排除部分文件或目录]]></title>
    <url>%2Fhexo%2FHexo%E6%B8%B2%E6%9F%93%E6%97%B6%E6%8E%92%E9%99%A4%E9%83%A8%E5%88%86%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[skip_render: - &apos;baidu.html&apos; - &apos;google.html&apos; - &apos;demo/other/3.html&apos; 只有source目录下的文件才会发布到public（能够在网络上访问到），因此Hexo只渲染source目录下的文件。 设置排除项skip_render参数设置的路径是相对于source目录的路径。 假设source目录下的文件如以下目录树所示 12345678910111213├─ demo| ├─ js-view-size| | ├─ 1.html| | └┈ 2.html| ├─ other| | ├─ 3.html| | ├─ 4.html| | └┈ 5.md| ├─ 6.html| └┈ 7.md├─ baidu.html└┈ google.html 排除单个文件排除baidu.html skip_render: &apos;baidu.html&apos; 排除3.html skip_render: &apos;demo/other/3.html&apos; 排除多个文件排除baidu.html和google.html skip_render: - &apos;baidu.html&apos; - &apos;google.html&apos; 或者 skip_render: &apos;*.html&apos; 后者会排除source目录下所有后缀为html的文件，但是不会排除子目录如demo及其子目录中的html文件。 排除baidu.html和google.html以及3.html skip_render: - &apos;baidu.html&apos; - &apos;google.html&apos; - &apos;demo/other/3.html&apos; 或者 skip_render: - &apos;*.html&apos; - &apos;demo/other/3.html&apos; 排除source/demo/other目录中的所有html文件 skip_render: &apos;demo/other/*.html&apos; 这不会排除5.md文件 排除source/demo/other目录中的所有文件 skip_render: &apos;demo/other/**&apos; 排除baidu.html和google.html以及整个source/demo目录 skip_render: - &apos;*.html&apos; - &apos;demo/**&apos;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 写作]]></title>
    <url>%2Fhexo%2FHexo%20%E5%86%99%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Front-matter文本开头都需要有下面类式格式标记1234567891011121314151617181920---title: ##文章标题date: ##时间，格式为 YYYY-MM-DD HH:mm:sscategories: ##分类tags: ##标签，多标签格式为 [tag1,tag2,...]keywords: ##文章关键词，多关键词格式为 keyword1,keywords2,...description: ##文章描述---正文示例：---title: Hexo 写作urlname: hexo_writingdate: 2018-06-18 10:44:15categories: hexotags: hexo--- 语法简明概述1234567891011121314151617分段 两个回车换行 两个空格 + 回车标题 # ~ ######，#号的个数表示几级标题，即表示一级标题到六级标题强调 **文字** ， __文字__ ， _文字_ ， *文字* ， 文字引用 &gt; 注意后面紧跟个空格表格 - 和 | 分割行和列 ， : 控制对其方式代码块 四个空格 开头或， 使用``` 代码内容 ```链接 [文字](链接地址)图片 ![图片说明](图片地址) ，地址可以是本地路劲，也可以是网络地址列表 * ， + ， - ， 1. ，选其中之一，注意后面紧跟个空格列表 ‘+’ 、 ‘-’ 用于无序列表，1.2.3.有序列表删除 ~~XXXXX~~分割线 三个以上的星号、减号、底线。（星号或是减号中间可以插入空格）兼容html，完全可以用html语言来书写如果需要在文档中显示一下Markdown语法相关的字符，可以在前面增加一个反斜杠 Read More 标记在首页里，文章自动截断，作为文章的简述，并添加read more. &lt;!-- more --&gt; 标题格式： # 欢迎使用Markdown编辑器写博客 //一级标题 对应 &lt;h1&gt; &lt;/h1&gt; ## 标题输入 //二级标题 对应 &lt;h2&gt; &lt;/h2&gt; ### 三级标题 //三级标题 对应 &lt;h3&gt; &lt;/h3&gt; #### 四级标题 //四级标题 对应 &lt;h4&gt; &lt;/h4&gt; ##### 五级标题 //五级标题 对应 &lt;h5&gt; &lt;/h5&gt; ###### 六级标题 //六级标题 对应 &lt;h6&gt; &lt;/h6&gt; ####### 七级标题 //抱歉，木有了（但是他会影响生成的目录，目录行多出一行空行） 另一种是在文字的下面加”=”（等号）或”-“（减号），分别表示一级和二级标题。 语法参考如下： 一级标题 ======== 二级标题 -------- 加粗、斜体斜体, 前后各加一个 *（星号）或 _（下划线）表示 粗体, 前后各加两个 *（星号）或 _（下划线）表示。 格式： *斜体* **加粗** ***加粗并斜体*** 删除线格式： ~~删除一段文本~~ 高亮格式： &lt;code&gt;高亮文字&lt;/code&gt; 引用显示格式： &gt; 每行开始都使用 &apos;&gt;&apos;； &gt; 引用**开始**； &gt; 引用**换行**； &gt; 引用**结束**。 &gt; 还在引用中！ 两个回车结束引用！ 省略使用格式： &gt; 仅第一行加应用； 引用**开始**； 引用**换行**； 引用**结束**； 两个回车结束引用,不在引用范围内了！ 嵌套使用格式： &gt; 动物 &gt;&gt; 水生动物 &gt;&gt; 陆生动物 &gt;&gt;&gt; 猴子 &gt;&gt;&gt; 人 &gt;&gt;&gt;&gt; 程序猿 &gt;&gt;&gt;&gt; 攻城狮 &gt;&gt;产品狗 //这里需要注意，没有空行间隔，忽略降级引用标记 射鸡虱 //这里需要注意，没有空行间隔，忽略降级引用标记 &gt;&gt; 两栖类动物 &gt;&gt;&gt; 大鳄鱼 唐老鸭 两个回车结束引用,不在引用范围内了！ 表格Markdown使用管线图的方式实现表格，如下表示一个简单的表格，注意表格的开头要空一行。 可以使用冒号来定义对齐方式： | 左对齐 | 右对齐 | 居中 | | :-------- | -------:| :--: | | Computer | 5000 元 | 1台 | | Phone | 1999 元 | 1部 | 代码块123456789使用 ``` 开始，后跟代码语言名，比如Python ， ``` 结束 例如：```Python#!/usr/bin/env python# -*- coding: utf-8 -*-print &apos;Hello World! ```如果需要包含```，那就需要用四个反引号(`) 分隔线在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西，中间可以插入空格 语法参考如下： *** * * * ********* - - - _________ 复选框学习内容： - [x] Markdown使用方法 - [x] Python3.4.x编程 - [x] Git使用方法 - [ ] Github使用方法 - [ ] shell编程 学习内容： Markdown使用方法 Python3.4.x编程 Git使用方法 Github使用方法 shell编程 超链接[首页](http://zhuzhuyule.xyz) [我的信息](/about/) [纪念册](https://love.zhuzhuyule.xyz/) 自动链接首页:http://zhuzhuyule.xyz 我的信息:http://zhuzhuyule.xyz/about/ 纪念册:https://love.zhuzhuyule.xyz/ 包括在一对尖括号里的地址或邮箱，也会被Markdown自动处理为链接。 语法参考如下： 访问&lt;https://github.com/&gt; mailto: &lt;address@example.com&gt; 添加本地图片连接首先需在hexo根目录下创建source/images文件夹。 images前面必须加/,表示相对网站的根目录 格式： ![&quot;图片描述&quot;](/images/图片文件夹/图片文件名.jpg) 添加视频 注意：书写代码前面不能有空格或tab键，否则只显示文本。 html5 &lt;video&gt;标签，能自动适应长宽： &lt;video src=&apos;&apos; type=&apos;video/mp4&apos; controls=&apos;controls&apos; width=&apos;100%&apos; height=&apos;100%&apos; autoplay=&quot;autoplay&quot;&gt;&lt;/video&gt; 其中type 可以不填，参考： https://developer.mozilla.org/en-US/docs/Web/HTML/Supported_media_formats参考： https://developer.mozilla.org/en-US/docs/Web/HTML/Supported_media_formats iframe标签： &lt;iframe src=&quot;/images/video/Faded.mp4&quot; height=498 width=510 frameborder=0 allowfullscreen &gt;&lt;/iframe&gt; 视频插件： hexo-tag-dplayer： https://github.com/MoePlayer/hexo-tag-dplayer 添加音频 注意：书写代码前面不能有空格或tab键，否则只显示文本。 html5 &lt;audio&gt;标签 &lt;audio src=&apos;/images/hexo/hexo_writing/see_you_again.mp3&apos; controls=&apos;controls&apos;&gt;&lt;/audio&gt; iframe标签： &lt;iframe src=&quot; frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 &gt;&lt;/iframe&gt; 或者使用插件： hexo-tag-aplayer：https://github.com/grzhan/hexo-tag-aplayer HTML 5 video 标签属性现在如果要在页面中使用video标签，需要考虑三种情况， 支持Ogg Theora或者VP8（如果这玩意儿没出事的话）的（Opera、Mozilla、Chrome）， 支持H.264的（Safari、IE 9、Chrome） 都不支持的（IE6、7、8）。 Video标签的使用 Video标签含有src、poster、preload、autoplay、loop、controls、type、width、height等几个属性， 以及一个内部使用的标签&lt;source&gt;。 1) src属性和poster属性 src属性是用于指定视频的地址。 poster属性用于指定一张图片，在当前视频数据无效时显示（预览图）。视频数据无效可能是视频正在加载，可能是视频地址错误等等。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; poster=&quot;http://www.youname.com/images/first.png&quot; autoplay=&quot;autoplay&quot;&gt;&lt;/video&gt; 2) preload属性 此属性用于定义视频是否预加载。属性有三个可选择的值：none、metadata、auto。如果不使用此属性，默认为auto。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot;&gt;&lt;/video&gt; None：不进行预加载。使用此属性值，可能是页面制作者认为用户不期望此视频，或者减少HTTP请求。 Metadata：部分预加载。使用此属性值，代表页面制作者认为用户不期望此视频，但为用户提供一些元数据（包括尺寸，第一帧，曲目列表，持续时间等等）。 Auto：全部预加载。 3) autoplay属性 Autoplay属性用于设置视频是否自动播放，是一个布尔属性。当出现时，表示自动播放，去掉是表示不自动播放。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot;&gt;&lt;/video&gt; 注意： HTML中布尔属性的值不是true和false。 正确的用法是，在标签中使用此属性表示true，此时属性要么没有值，要么其值恒等于他的名字 （此处，自动播放为&lt;video autoplay /&gt;或者&lt;video autoplay=”autoplay” /&gt;）； 而在标签中不使用此属性表示false（此处不进行自动播放为&lt;video /&gt;）。 4) loop属性 loop属性用于指定视频是否循环播放，同样是一个布尔属性。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; loop=&quot;loop&quot;&gt;&lt;/video&gt; 5) controls属性 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot; controls=&quot;controls&quot;&gt;&lt;/video&gt; Controls属性用于向浏览器指明页面制作者没有使用脚本生成播放控制器，需要浏览器启用本身的播放控制栏。 控制栏须包括播放暂停控制，播放进度控制，音量控制等等。 每个浏览器默认的播放控制栏在界面上不一样。 6) width属性和height属性 值最好都用100%，自动适应长宽 7) source标签 &lt;video width=&quot;658&quot; height=&quot;444&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot; controls=&quot;controls&quot;&gt; &lt;source src=&quot;http://www.youname.com/images/first.ogv&quot; /&gt; &lt;source src=&quot;http://www.youname.com/images/first.ogg&quot; /&gt; &lt;/video&gt; Source标签用于给媒体（因为audio标签同样可以包含此标签，所以这儿用媒体，而不是视频）指定多个可选择的（浏览器最终只能选一个）文件地址，且只能在媒体标签没有使用src属性时使用。 浏览器按source标签的顺序检测标签指定的视频是否能够播放（可能是视频格式不支持，视频不存在等等），如果不能播放，换下一个。此方法多用于兼容不同的浏览器。Source标签本身不代表任何含义，不能单独出现。 此标签包含src、type、media三个属性。 src属性：用于指定媒体的地址，和video标签的一样。 Type属性：用于说明src属性指定媒体的类型，帮助浏览器在获取媒体前判断是否支持此类别的媒体格式。 video/MP4 = 带有 H.264 视频编码和 AAC 音频编码的 MPEG 4 文件 video/WebM = 带有 VP8 视频编码和 Vorbis 音频编码的 WebM 文件 video/Ogg = 带有 Theora 视频编码和 Vorbis 音频编码的 Ogg 文件 参考： https://developer.mozilla.org/en-US/docs/Web/HTML/Supported_media_formats Media属性：用于说明媒体在何种媒介中使用，不设置时默认值为all，表示支持所有媒介。你想到&lt;style&gt;标签的media属性了么？一样一样一样的。 8) 一个完整的例子 &lt;video width=&quot;658&quot; height=&quot;444&quot; poster=&quot;http://www.youname.com/images/first.png&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot; controls=&quot;controls&quot;&gt;&lt;source src=&quot;http://www.youname.com/images/first.ogv&quot; /&gt;&lt;source src=&quot;http://www.youname.com/images/first.ogg&quot; /&gt;&lt;/video&gt; 这段代码在页面中定义了一个视频，此视频的预览图为poster的属性值，显示浏览器的默认媒体控制栏，预加载视频的元数据，循环播放，宽度为900像素，高度为240像素。 第一选择视频地址为第一个source标签的src属性值，视频类别为Ogg视频，视频编码译码器为Theora，音频编码译码器为Vorbis，播放媒 介为显示器；第二选择视频地址不再累述。如果你还要兼容IE的话，可以在最后一个source标签后再加上Flash播放器的标签集，或者使用一点 JavaScript代码。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode git hexo 配合使用]]></title>
    <url>%2Fhexo%2Fvscode%20git%20hexo%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概况安装vscode 安装git客户端 安装nodejs v8 添加nodejs环境变量 通过npm 安装 hexo 下载安装 vscodehttps://code.visualstudio.com 下载安装 githttps://git-scm.com/download/win https://github.com/git-for-windows/git/releases/download/v2.17.1.windows.2/Git-2.17.1.2-64-bit.exe https://github.com/git-for-windows/git/releases/download/v2.17.1.windows.2/PortableGit-2.17.1.2-64-bit.7z.exe portable 版本，只需解压，在window环境变量里添加 解压路径\Git\cmd 12345678910111213141516171819202122232425262728293031安装版，只需命令行的，安装步骤如下：选择安装组件：可以全不选，或只选 桌面浏览（Windows Explorer integration） 使用Git Bash方式，shell方式是否创建开始菜单快捷方式目录:否设置环境，选择使用什么样儿的命令行工具，一般情况我们使用默认配置，使用Git Bash Git自带：使用Git自带的Git Bash命令行工具设置HTTPS 传输加密方式，点击【Next &gt;】 使用OpenSSL库选择换行格式，点击【Next &gt;】：下面选第一个 让Git能够自动转换文件中的换行符：签出到本地时转换为Windows下的换行符，提交到服务器时转换为Unix下的换行符 让Git在签出到本地时不做转换，保留原始文件的换行符；提交到服务器时转换为Unix下的换行符 让Git在签出到本地时和提交到服务器时都不做转换配置Git bash终端仿真器，点击【Next &gt;】：最好选第二个 使用MinTTY终端 使用windows默认的命令行性能配置，是否启用文件系统缓存，点击【Next &gt;】开始安装 git 环境变量配置安装成功后需要配置Git环境变量 「注意该步骤为Git在windows cmd命令中配置，如果不配置，直接使用Git Bash即可」 在Path变量中增加：C:\Program Files\Git\cmd 验证是否配置成功，打开windows命令行，输入git version命令，出现下列信息表示配置成功。 git config --global user.name dolphincn git config --global user.email share2030cn@126.com 下面三行可以不操作 git config --global push.default matching git config --global core.quotepath false git config --global core.editor &quot;vim&quot; 添加ssh 密钥添加github ssh 登陆密钥， 打开cmd，运行mkdir .ssh， 在当前用户的home目录下创建.ssh目录，把密钥复制进去. 密钥可以用ssh-key 或 GitHub上生成，私钥和公钥名字分别为：id_rsa id_rsa.pub 检验是否能连上了github，windows 命令行下运行，前提配置了git环境变量 $ ssh git@github.com 初始化git目录$ mkdir tmp //创建推送目录 $ cd tmp //进入推送目录 $ git init //设置该目录为推送 $ touch README //生成readme $ git add . //加入修改的文件 $ git commit -m &apos;first commit&apos; //递交修改声明 $ git remote add local git@github.com:abcd/tmp.git //将本地local 和github关联 $ git push local master //将本地文件推送到github $ git pull master local //将github拉到本地 参考：https://www.yiibai.com/git/ 下载安装nodejs:https://nodejs.org/dist/v8.11.3/node-v8.11.3-x64.msi hexo 在windows 上安装安装hexo之前必须先安装git nodejs 在本地新建一个Blog文件夹，文件右键，选择Git Bash 创建hexo blog 目录 $ mkdir c:/hexo 打开git命令行输入： 全局安装hexo-cli $ npm install -g hexo-cli $ cd c:/hexo hexo 初始化目录 $ hexo init 在目录中安装 node_modules $ npm install 部署到github配置 按装本地搜索插件 $ npm install hexo-generator-searchdb --save 打开Hexo 站点的_config.yml,添加配置 search: path: search.xml field: all format: html limit: 10000 打开themes/next下的_config.yml,搜索关键字local_search,设置为true local_search: enable: true 安装hexo-deployer-git插件 $ npm install hexo-deployer-git --save 修改hexo本地网站配置文件 _config.yml # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git #部署环境，基于hexo+githubpage,所以这里使用git。注意：不同版本的hexo，type有可能不同，3.x以后应使用git,具体参看官方文档 repository: git@github.com:dolphincn/dolphincn.github.io.git #git仓库地址，替换成你的username即可，其他保持不变，后面会提到如何创建git仓库 branch: master 主题安装 安装主题和渲染器： $ cd /data/hexo_blog/ $ git clone --depth 1 https://github.com/theme-next/hexo-theme-next themes/next 编辑Hexo目录下的 _config.yml，将theme的值改为next 安装图片浏览器 $ rm -rf themes/next/source/lib/fancybox $ git clone --depth 1 https://github.com/theme-next/theme-next-fancybox3 themes/next/source/lib/fancybox 编辑next 主题配置文件 _config.yml: fancybox: true 安装书签保存插件 $ rm -rf themes/next/source/lib/bookmark $ git clone --depth 1 https://github.com/theme-next/theme-next-bookmark.git themes/next/source/lib/bookmark 编辑next 主题配置文件 _config.yml: bookmark: true 其它插件，如果需要可以安装 # npm install hexo-generator-feed --save # npm install hexo-generator-sitemap --save $ npm install hexo-generator-json-content --save Hexo 常用命令Hexo 安装升级 npm install hexo -g #安装 npm update hexo -g #升级 hexo init #初始化 常用简写 hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 启动本地服务 hexo server #Hexo #会监视文件变动并自动更新，您无须重启服务器。 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP 监视文件变动 hexo generate #使用 Hexo 生成静态文件快速而且简单 hexo generate --watch #监视文件变动 hexo clean #清除缓存 网页正常情况下可以忽略此条命令 部署 #两个命令的作用是相同的 hexo generate --deploy hexo deploy --generate hexo deploy -g hexo server -g 草稿 # 新建草稿 hexo new draft &lt;title&gt; # 发布草稿为post hexo publish draft &lt;title&gt; 模板 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server） hexo deploy #将.deploy目录部署到GitHub hexo new [layout] &lt;title&gt; hexo new photo &quot;My Gallery&quot; hexo new &quot;Hello World&quot; --lang tw 写作时间 变量 描述 :title 标题 :year 建立的年份（4 位数） :month 建立的月份（2 位数） :i_month 建立的月份（去掉开头的零） :day 建立的日期（2 位数） :i_day 建立的日期（去掉开头的零） 自定义配置文件的路径 $ hexo --config custom.yml 安全模式,在安全模式下，不会载入插件和脚本。 $ hexo --safe 渲染文件 render $ hexo render &lt;file1&gt; [file2] ... 参数 描述 -o, --output 设置输出路径 hexo基本命令总结：每次部署的步骤，可按以下三步来进行： hexo clean hexo generate hexo deploy 命令总结 常用命令： hexo new &quot;postName&quot; #新建文章 hexo new mylayout &quot;postName&quot; #使用指定的layout模板新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server） hexo server -p 80 -i 192.168.100.1 # 指定服务器端口和ip hexo deploy #将.deploy目录部署到GitHub hexo help #查看帮助 hexo version #查看Hexo的版本 复合命令： hexo deploy -g #生成加部署 hexo server -g #生成加预览 hexo server -s #使用已生成的静态文件预览 命令的简写为： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 备份source源文件windwos 10 下更新备份重要的文件到 icloud 目录下123456# 注意：是按时间来更新备份，所以需要系统时间正常xcopy "C:\share\hexo\source" "C:\Users\lion\iCloudDrive\hexo_blog\source" /e/c/I/d/r/yxcopy "C:\share\hexo\scaffolds" "C:\Users\lion\iCloudDrive\hexo_blog\scaffolds" /e/c/I/d/r/yxcopy "C:\share\hexo\*.yml" "C:\Users\lion\iCloudDrive\hexo_blog" /c/I/d/r/y 参考https://blog.csdn.net/dietime1943/article/details/71751007]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo nexT 主题安装配置]]></title>
    <url>%2Fhexo%2Fhexo%20nexT%20%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装更新hexo： npm update hexo 下载next主题 git clone --depth 1 https://github.com/theme-next/hexo-theme-next /data/hexo_blog/themes/next ## 升级 cd /data/hexo_blog/themes/next git pull ## 修改hexo 配置文件中的主题 /data/hexo_blog/_config.yml theme: next 创建菜单项对应文件目录,以分类、标签、关于为例 hexo new page categories hexo new page tags hexo new page about 选择 Scheme更改 NexT 主题配置文件 文件 /data/hexo_blog/themes/next/_config.yml 选择的 Scheme 主题前去掉 # (没有注释掉的就是当前选择主题) # Schemes #scheme: Muse #scheme: Mist #scheme: Pisces scheme: Gemini 配置搜索在你站点的根目录下 $ npm install hexo-generator-searchdb --save 打开Hexo 站点的_config.yml,添加配置 search: path: search.xml field: post format: html limit: 10000 打开themes/next下的_config.yml,搜索关键字local_search,设置为true local_search: enable: true 说明： path - file path. By default is search.xml . If the file extension is .json, the output format will be JSON. Otherwise XML format file will be exported. field - the search scope you want to search, you can chose: post (Default) - will only covers all the posts of your blog. page - will only covers all the pages of your blog. all - will covers all the posts and pages of your blog. format - the form of the page contents, works with xml mode, options are: html (Default) - original html string being minified. raw - markdown text of each posts or pages. excerpt - only collect excerpt. more - act as you think. limit - define the maximum number of posts being indexed, always prefer the newest. 分页插件在hexo根目录下的_config.yml配置文件末尾添加以下内容以设置分页参数 # Plugins index_generator: path: &apos;&apos; per_page: 10 ##首页默认10篇文章标题，如果值为0不分页 order_by: -date archive_generator: per_page: 10 ##归档页面默认10篇文章标题，如果值为0不分页 yearly: true ##生成年视图 monthly: true ##生成月视图 tag_generator: per_page: 10 ##标签页面默认10篇文章，如果值为0不分页 category_generator: per_page: 10 ##分类页面默认10篇文章，如果值为0不分页 如何在首页隐藏指定的文章文章里添加hide元素变量 --- title: { { title } } hide: true --- 修改next主题文件夹下的layout中的index.swig文件 themes/next/layout/index.swig 定位修改 post_template.render(post, true) {% if ! post.hide %} 或 {% if post.hide == true %} 123456789&#123;% block content %&#125; &lt;section id=&quot;posts&quot; class=&quot;posts-expand&quot;&gt; &#123;% for post in page.posts %&#125; &#123;% if ! post.hide %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endif %&#125; &#123;% endfor %&#125; &lt;/section&gt; Front-matter 定制位于scaffolds目录下的md文件。 Front-matter 是 md 文件最上方以 — 分隔的区域，用于指定个别文件的变量，包括 title ， date ，tag 等信息。 文件的开头是属性，采用统一的 yaml 格式，用三条短横线分隔。下面是文章正文。 title 和 date 可以设置成自动，english_title 最好自己写一个清晰的，这个是网址中的真实名称。 --- title: { { title } } english_title: urlname: top: 5 date: { { date } } categories: [Blog,Hexo] tag: [Hexo,NexT] --- RSS 设置更改 主题配置文件 ，设定 rss 字段的值： false：禁用 RSS，不在页面上显示 RSS 连接。 留空：使用 Hexo 生成的 Feed 链接。 你需要先安装 hexo-generator-feed 插件。 具体的链接地址：适用于已经烧制过 Feed 的情形。 修改文章底部的那个带#号的标签打开themes/next/layout/_macro/下的post.swig文件,搜索rel=&quot;tag&quot;&gt;#,将 # 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; &lt;div class=&quot;post-tags&quot;&gt; {% for tag in post.tags %} {{ tag.name }} {% endfor %} &lt;/div&gt; 隐藏网页底部Hexo 强力驱动打开主题配置文件,搜索关键字copyright，如下: copyright: false powered: enable: false version: false theme: enable: false version: false 添加顶部加载条打开themes/next下的_config.yml，搜索关键字pace,设置为true,可以更换加载样式 开启版权声明主题配置文件下,搜索关键字post_copyright,enable改为true post_copyright: enable: true license: &lt;a href=&quot;https://creativecommons.org/licenses/by-nc-sa/4.0/&quot; rel=&quot;external nofollow&quot; target=&quot;_blank&quot;&gt;CC BY-NC-SA 4.0&lt;/a&gt; 添加文章封面文章封面的意思就是：在博客首页的时候会显示文章的封面图片，进入这篇文章的详细页面后，将不显示这张图片。 如果想添加文章封面的话，需要添加一个字段属性：summary_img，summary_img 的值是图片的路径。 123456789---title: CSS 各种Hack手段date: 2017-06-25 03:25:24categories: 前端tags: [CSS]comments: falsesummary_img: /images/css-hack-1.png--- 修改 \themes\next\layout\_macro\post.swing 文件。 12345678910&#123;% if is_index %&#125; &lt;!-- 自定义,用于添加文章摘要图片，文章中不显示 --&gt; &#123;% if post.summary_img %&#125; &lt;div class=&quot;out-img-topic&quot;&gt; &lt;img src=&#123;&#123; post.summary_img &#125;&#125; class=&quot;img-topic&quot;&gt; &lt;/div&gt; &#123;% endif %&#125; &lt;!-- 自定义结束 --&gt; &#123;% if post.description and theme.excerpt_description %&#125; &#123;&#123; post.description &#125;&#125; 开启了文章封面的文章，我建议将 &lt;!-- more --&gt; 放在文章内容的开头 内容自动截断在index页面，，如果文章内容没有添加&lt;!-- more --&gt;, 就自动截断，不全部显示。 自动截断，显示格式不友好，最好还是手动添加&lt;!-- more --&gt; auto_excerpt: enable: true length: 150 添加头像打开themes/next下的_config.yml文件，搜索 Sidebar Avatar关键字，去掉avatar前面的# # Sidebar Avatar avatar: url: #/images/avatar.gif rounded: false opacity: 1 rotated: false 设置头像边框为圆形框 打开位于themes/next/source/css/_common/components/sidebar/下的sidebar-author.syl文件,修改如下 .site-author-image { display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; // 修改头像边框 border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; } 网站logo设置favicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml 文章加密访问**方法一：简单加密,效果不好** 打开themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,在meta下位置插入这样一段代码： 12345678910&lt;script&gt; (function()&#123; if(&apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; if (prompt(&apos;请输入文章密码&apos;) !== &apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; alert(&apos;密码错误！&apos;); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 然后在文章上写成类似这样： --- title: {{ title }} date: {{ date }} categories: tags: password: password --- **方法二：真正意义的加密** # 插件地址: https://github.com/edolphin-ydf/hexo-encrypt # 安装： npm install hexo-encrypt --save # 配置 # hexo 的根目录下，编辑package.json, 在 dependencies 下添加&quot;hexo-encrypt&quot;: &quot;^0.2.0&quot;, { &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: { &quot;version&quot;: &quot;3.7.1&quot; }, &quot;dependencies&quot;: { ..... &quot;hexo-encrypt&quot;: &quot;^0.2.0&quot;, ..... } } # 功能 用AES加密一篇文章内容 使用qiniu私人空间作为你的img仓库（如果你想使用这个功能，你应该首先得到一个qiniu帐户，搜索谷歌寻求帮助） 将本地img编码为base64类型，然后将其内联到html中 # 缺点 章节不会显示 首页显示不加密，所以需要配合隐藏功能 # 编辑hexo配置文件_config.yml，启用加密 # encrypt encrypt: password: 123456 # 密码 #pwdfile: encrypt_password # 密码存放在一个文档里 # 编辑博客文件md,在front-format 添加 --- encrypt: true enc_pwd: 123456 #不采用默认密码，指定特定密码 --- 自动按照source 目录下的文件夹生成categories# 安装 $ npm install hexo-auto-category --save # 配置 # 在站点根目录下的_config.yml添加： # Generate categories from directory-tree # Dependencies: https://github.com/xu-song/hexo-auto-category # depth: the depth of directory-tree you want to generate, should &gt; 0 auto_category: enable: true depth: # 编译 &amp; 部署 $ hexo clean &amp;&amp; hexo g &amp;&amp; hexo d # 高级配置 # 如果只想生成第一级目录分类，可以设置depth属性，比如： auto_category: enable: true depth: 1 # 缺点： 不支持加密文档 只适合生成静态文件，动态服务，会不断重新创建 修改字体大小打开\themes\next\source\css\ _variables\base.styl文件，将$font-size-base改成16px，如下所示： $font-size-base =16px 如何更改内容区域的宽度？NexT 对于内容的宽度的设定如下： 700px，当屏幕宽度 &lt; 1600px 900px，当屏幕宽度 &gt;= 1600px 移动设备下，宽度自适应 如果你需要修改内容的宽度，同样需要编辑样式文件。 编辑主题的 source/css/_variables/custom.styl 文件，新增变量： // 修改成你期望的宽度 $content-desktop = 700px // 当视窗超过 1600px 后的宽度 $content-desktop-large = 900px 侧边栏推荐阅读打开主题配置文件修改成这样就行了(links里面写你想要的链接): # Blogrolls links_title: 推荐阅读 #links_layout: block links_layout: inline links: 优设: http://www.uisdc.com/ 张鑫旭: http://www.zhangxinxu.com/ Web前端导航: http://www.alloyteam.com/nav/ 前端书籍资料: http://www.36zhen.com/t?id=3448 百度前端技术学院: http://ife.baidu.com/ google前端开发基础: http://wf.uisdc.com/cn/ 文章压缩在站点的根目录下执行以下命令： 123456789101112131415161718192021222324252627282930313233343536373839$ npm install gulp -g$ npm install gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp --save新建 gulpfile.js ，并填入以下内容：var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');// 压缩 public 目录 cssgulp.task('minify-css', function() &#123; return gulp.src('./public/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public'));&#125;);// 压缩 public 目录 htmlgulp.task('minify-html', function() &#123;return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public'))&#125;);// 压缩 public/js 目录 jsgulp.task('minify-js', function() &#123; return gulp.src('./public/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public'));&#125;);// 执行 gulp 命令时执行的任务gulp.task('default', [ 'minify-html','minify-css','minify-js']); 生成博文是执行 hexo g &amp;&amp; gulp 就会根据 gulpfile.js 中的配置，对 public 目录中的静态资源文件进行压缩。 其它高亮代码显示插件https://github.com/ele828/hexo-prism-plugin Hexo-Prism-Plugin NPM Since highlight.js didn&apos;t support JSX syntax properly, I wrote this plugin to replace Hexo&apos;s default code highlight plugin. Install npm i -S hexo-prism-plugin Usage Firstly, you should edit your _config.yml by adding following configuration. prism_plugin: mode: &apos;preprocess&apos; # realtime/preprocess theme: &apos;default&apos; line_number: false # default false custom_css: &apos;path/to/your/custom.css&apos; # optional After that, check highlight option in _config.yml. Make sure that default code highlight plugin is disabled. highlight: enable: false Finally, clean and re-generate your project by running following commands: hexo clean hexo generate pdf 插件https://github.com/superalsrk/hexo-pdf hexo-pdf MIT VERSION Hexo tag for embeded pdf Install $ npm install --save hexo-pdf Usage Normal PDF {% pdf http://7xov2f.com1.z0.glb.clouddn.com/bash_freshman.pdf %} or {% pdf ./bash_freshman.pdf %} Google drive {% pdf https://drive.google.com/file/d/0B6qSwdwPxPRdTEliX0dhQ2JfUEU/preview %} Slideshare {% pdf http://www.slideshare.net/slideshow/embed_code/key/8Jl0hUt2OKUOOE %} 参考：https://segmentfault.com/a/1190000009544924 https://www.jianshu.com/p/3ff20be8574c]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install hexo on centos 7]]></title>
    <url>%2Fhexo%2Finstall%20hexo%20on%20centos%207%2F</url>
    <content type="text"><![CDATA[hexo 官网https://hexo.io/zh-cn/docs/index.html 安装gityum install git 配置git全局信息git config --global user.email &quot;share2030cn@126.com&quot; git config --global user.name &quot;dolphincn&quot; 安装Nodejs123456789101112131415161718192021222324## 安装Nodejs 8, 自动安装npm## 配置 nodejs yum 源# vi /etc/yum.repos.d/nodejs.repo[nodesource]name=Node.js Packages for Enterprise Linux 7 - $basearchbaseurl=https://rpm.nodesource.com/pub_8.x/el/7/$basearchfailovermethod=priorityenabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/NODESOURCE-GPG-SIGNING-KEY-EL[nodesource-source]name=Node.js for Enterprise Linux 7 - $basearch - Sourcebaseurl=https://rpm.nodesource.com/pub_8.x/el/7/SRPMSfailovermethod=priorityenabled=0gpgkey=file:///etc/pki/rpm-gpg/NODESOURCE-GPG-SIGNING-KEY-ELgpgcheck=1## 安装# yum install nodejs 通过二进制包安装nodejs123456789101112131415wget https://nodejs.org/dist/v8.11.2/node-v8.11.2-linux-x64.tar.gztar -zxf node-v8.11.2-linux-x64.tar.gz -C /usr/local/mv /usr/local/node-v8.11.2-linux-x64 /usr/local/nodejsvi /etc/profile.d/nodejs.shexport NODE_HOME=/usr/local/nodejsexport PATH=$NODE_HOME/bin:$PATHsource /etc/profile.d/nodejs.sh## 检查版本node -vnpm -v 安装hexo12345678910111213141516171819202122232425262728293031## npm 全局安装hexo-cli，这个在系统安装一次就可以了npm install -g hexo-cli/usr/bin/hexo -&gt; /usr/lib/node_modules/hexo-cli/bin/hexo## 安装hexo 服务及大部分常用插件## 此命令安装绝大部分常用插件，属于局部安装，会在当前目录下创建node_modules文件夹npm install## 常用插件，大部分已安装npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked --savenpm install hexo-renderer-stylus --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-json-content --save 安装配置blog步骤1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586## 全局安装hexo-clinpm install -g hexo-cli## 创建blog目录 mkdir -p /data/hexo_blog## 初始化blog目录, 并建立blog站点hexo init /data/hexo_blogcd /data/hexo_blog## 安装hexo 服务及大部分常用插件npm install## 新建完成后，指定文件夹的目录如下：.├── _config.yml ## 网站的 配置 信息，您可以在此配置大部分的参数。├── package.json ## 应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。├── scaffolds ## 模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。├── source ## 资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。| ├── _drafts| └── _posts└── themes ## 主题 文件夹。Hexo 会根据主题来生成静态页面。## 下载next主题和安装插件git clone --depth 1 https://github.com/theme-next/hexo-theme-next /data/hexo_blog/themes/nextnpm install hexo-generator-searchdb --save## 配置支持 githubnpm install hexo-deployer-git --save## 修改## repo: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git## 注意，如果用github拥有者的名字建立仓库，如[&lt;username&gt;.github.io]，则可以通过互联网直接访问username.github.io网站内容vi ./_config.....# Deployment## Docs: https://hexo.io/docs/deployment.html deploy:type: gitrepo: git@github.com:dolphincn/dolphincn.github.io.gitbranch: mastermaster message: 'site update: &#123;&#123;now("YYYY-MM-DD HH/mm/ss")&#125;&#125;'## 配置搜索# 在你站点的根目录下npm install hexo-generator-searchdb --save# 打开Hexo 站点的_config.yml,添加配置search: path: search.xml field: all format: html limit: 10000# 打开themes/next下的_config.yml,搜索关键字local_search,设置为truelocal_search: enable: true## 安装图片浏览器$ rm -rf themes/next/source/lib/fancybox$ git clone --depth 1 https://github.com/theme-next/theme-next-fancybox3 themes/next/source/lib/fancybox# 编辑next 主题配置文件 _config.yml: fancybox: true## 安装书签保存插件$ rm -rf themes/next/source/lib/bookmark$ git clone --depth 1 https://github.com/theme-next/theme-next-bookmark.git themes/next/source/lib/bookmark# 编辑next 主题配置文件 _config.yml: bookmark: true 其它主题## 下载bluelake主题和插件 git clone --depth 1 https://github.com/chaooo/hexo-theme-BlueLake.git /data/hexo_blog/themes/bluelake cd /data/hexo_blog npm install hexo-renderer-jade@0.3.0 --save npm install hexo-renderer-stylus --save npm install hexo-generator-json-content@2.2.0 --save ## hexo 管理命令1234567891011121314151617181920212223242526## 启动本地hexo blog服务hexo server# 或者hexo server -i 192.168.100.10 -p 80## 清空hexo clean## 生成静态页面hexo generate## 发布blog 到 githubhexo deploy## 创建一个页面hexo new "a new post"## 将草稿从_drafts移到_posts目录下hexo publish articlename 设置支持txt渲染为html# 如果markdown 文件扩展名保存为txt # 编辑 hexo 配置文件_config.yml,修改 new_post_name: :title.md 改为 new_post_name: :title.txt # 修改内容渲染模块, 照葫芦画瓢，添加一行txt文件的渲染 vi ./node_modules/hexo-renderer-marked/index.js ........ hexo.extend.renderer.register(&apos;txt&apos;, &apos;html&apos;, renderer, true); hexo.extend.renderer.register(&apos;md&apos;, &apos;html&apos;, renderer, true); 配置nginx反向代理123456789101112131415161718192021222324252627282930313233343536 cat &gt; /etc/yum.repos.d/nginx.repo &lt;&lt; EOF# nginx.repo[nginx]name="nginx repo"baseurl=http://nginx.org/packages/rhel/7/x86_64/gpgcheck=1gpgkey=http://nginx.org/packages/keys/nginx_signing.keyenabled=1EOFyum install nginx cat &gt; /etc/nginx/conf.d/hexoblog.conf &lt;&lt; EOFserver &#123; listen 80; server_name blog.com; error_page 404 /404/; location / &#123; root /data/hexo_blog; index index.html; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; &#125;&#125;EOF hexo 命令说明指令 init $ hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new $ hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 generate $ hexo generate 生成静态文件。 选项 描述 -d, --deploy 文件生成后立即部署网站 -w, --watch 监视文件变动 该命令可以简写为 $ hexo g publish $ hexo publish [layout] &lt;filename&gt; 发表草稿。 server $ hexo server -i 200.200.200.221 -p 80 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 选项 描述 -p, --port 重设端口 -s, --static 只使用静态文件 -l, --log 启动日记记录，使用覆盖记录格式 deploy $ hexo deploy 部署网站。 参数 描述 -g, --generate 部署之前预先生成静态文件 该命令可以简写为： $ hexo d render $ hexo render &lt;file1&gt; [file2] ... 渲染文件。 参数 描述 -o, --output 设置输出路径 migrate $ hexo migrate &lt;type&gt; 从其他博客系统 迁移内容。 clean $ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 list $ hexo list &lt;type&gt; 列出网站资料。 version $ hexo version 显示 Hexo 版本。 选项 安全模式 $ hexo --safe 在安全模式下，不会载入插件和脚本。当您在安装新插件遭遇问题时，可以尝试以安全模式重新执行。 调试模式 $ hexo --debug 在终端中显示调试信息并记录到 debug.log。当您碰到问题时，可以尝试用调试模式重新执行一次，并 提交调试信息到 GitHub。 简洁模式 $ hexo --silent 隐藏终端信息。 自定义配置文件的路径 $ hexo --config custom.yml 自定义配置文件的路径，执行后将不再使用 _config.yml。 显示草稿 $ hexo --draft 显示 source/_drafts 文件夹中的草稿文章。 自定义 CWD $ hexo --cwd /path/to/cwd 自定义当前工作目录（Current working directory）的路径。 站点配置文件说明站点配置文件的配置 .\hexo\_config.yml 。 # Hexo Configuration ## Docs: https://hexo.io/docs/configuration.html ## Source: https://github.com/hexojs/hexo/ # Site 网站 title: 为学 #网站标题 subtitle: 天下事有难易乎？为之，则难者亦易矣；不为，则易者亦难矣。 #网站副标题 description: 天下事有难易乎？为之，则难者亦易矣；不为，则易者亦难矣。 #网站描述 author: willxue #您的名字 language: zh-CN #网站使用的语言 timezone: #网站时区。Hexo 默认使用您电脑的时区 # URL 网址 ## 如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/。 url: http://willxue.top permalink: :year/:month/:day/:title/ #生成文件名字的格式我改成blog/:title:year:month:day/ permalink_defaults: # Directory 目录配置 source_dir: source #源文件夹，这个文件夹用来存放内容。 public_dir: public #公共文件夹，这个文件夹用于存放生成的站点文件。 tag_dir: tags #标签文件夹 archive_dir: archives #归档文件夹 category_dir: categories #分类文件夹 code_dir: downloads/code #nclude code 文件夹 i18n_dir: :lang #国际化（i18n）文件夹 skip_render: #跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。 # Writing 文章 new_post_name: :title.md # 新建文章默认文件名 default_layout: post # 默认布局 titlecase: false # Transform title into titlecase external_link: true # 在新标签中打开一个外部链接，默认为true filename_case: 0 #转换文件名，1代表小写；2代表大写；默认为0，意思就是创建文章的时候，是否自动帮你转换文件名，默认就行，意义不大。 render_drafts: false #是否渲染_drafts目录下的文章，默认为false post_asset_folder: false #启动 Asset 文件夹 relative_link: false #把链接改为与根目录的相对位址，默认false future: true #显示未来的文章，默认false highlight: #代码块的设置 enable: true line_number: true auto_detect: false tab_replace: # Category &amp; Tag 分类和标签的设置 default_category: uncategorized #默认分类 category_map: #分类别名 tag_map: #标签别名 # Date / Time format ## Hexo uses Moment.js to parse and display date ## You can customize the date format as defined in ## http://momentjs.com/docs/#/displaying/format/ date_format: YYYY-MM-DD time_format: HH:mm:ss # Pagination 分页 ## Set per_page to 0 to disable pagination per_page: 10 #每页显示的文章量 (0 = 关闭分页功能) pagination_dir: page #分页目录 # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: next feed: type: atom #feed 类型 (atom/rss2) path: atom.xml #rss 路径 limit: 20 #在 rss 中最多生成的文章数(0显示所有) # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: https://github.com/imwillxue/imwillxue.github.com.git branch: master]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB 10.2 galera 集群安装]]></title>
    <url>%2Fmariadb%2FMariaDB%2010.2%20galera%20%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[环境:每台服务器安装CentOS 7.2 Minimal 版本，安装后使用yum update更新一下最新的系统内核和相关配置参数。 MariaDB galera集群建议最少3台服务器，2台无法保证数据完整性。 几台虚拟机ip设置如下： 节点名称 IP地址 cluster1 192.168.56.21 cluster2 192.168.56.22 cluster3 192.168.56.23 删除CentOS自带的老版本mariadb lib文件 查找安装的mariadb sudo rpm -qa | grep mariadb 删除查找到的lib文件 sudo rpm -e --nodeps (这里是查找到的mariadb lib 文件) 安全设置1) firewall 因为安装mariadb galera 需要打开 3306、4444、4567、4568四个端口，而且要降低安全审核级别。 使用以下命令设置防火墙开放这几个端口： 3306是MariaDB/mysql的服务端口，这个都不开那就不用跑MariaDB/MySQL服务了，需要开TCP端口； 4567是Galera做数据复制的通讯和数据传输端口，需要在防火墙放开TCP和UDP； 4568是Galera做增量数据传输使用的端口（Incremental State Transfer, IST），需要防火墙放开TCP； 4444是Galera做快照状态传输使用的端口（State Snapshot Transfer, SST），需要防火墙放开TCP。） sudo firewall-cmd --permanent --zone=public --add-port={3306,4567,4568,4444}/tcp sudo firewall-cmd --permanent --zone=public --add-port=4567/udp sudo firewall-cmd --reload （重新加载防火墙使修改生效） 2) selinux 在CentOS的SELinux配置文件中降低SELinux的安全审核级别，让mysqld可以正常运行，否则SELinux会限制集群数据传输 (setenforce 0 命令只能设置运行时的安全级别，想要完全设置安全级别，需要在SELinux的配置文件中进行配置更改) 使用vi 打开/etc/selinux/config配置文件，设置SELINUX=permissive sudo vi /etc/selinux/config 或者键入命令 semanage permissive -a mysqld_t 使用reboot命令重启服务器使SELinux安全级别更改生效 配置 yum源1) 配置 mariadb 10.2 yum源 官网地址 https://downloads.mariadb.org/ 选择最新稳定版本 MariaDB Galera Cluster 10.2 Series (原有下载地址太慢，需要换成国内的镜像地址) 1234567891011121314151617 cat &gt; /etc/yum.repos.d/mariadb.repo &lt;&lt; EOF[mariadb]name = MariaDB-10.2baseurl = http://yum.mariadb.org/10.2/centos7-amd64/gpgkey = https://yum.mariadb.org/RPM-GPG-KEY-MariaDB#baseurl = http://mirrors.ustc.edu.cn/mariadb/yum/10.2/centos7-amd64/#gpgkey = https://mirrors.ustc.edu.cn/mariadb/yum/RPM-GPG-KEY-MariaDBenabled = 1gpgcheck = 1EOF 2) 配置 percona yum源 1234567891011121314151617181920212223242526 cat &gt; /etc/yum.repos.d/percona.repo &lt;&lt; EOF[percona-release-$basearch]name = Percona-Release YUM repository - $basearchbaseurl = http://repo.percona.com/release/7Server/RPMS/$basearchenabled = 1gpgcheck = 1gpgkey = https://www.percona.com/downloads/RPM-GPG-KEY-percona[percona-release-noarch]name = Percona-Release YUM repository - noarchbaseurl = http://repo.percona.com/release/7Server/RPMS/noarchenabled = 1gpgcheck = 1gpgkey = https://www.percona.com/downloads/RPM-GPG-KEY-percona[percona-release-source]name = Percona-Release YUM repository - Source packagesbaseurl = http://repo.percona.com/release/7Server/SRPMSenabled = 0gpgcheck = 1gpgkey = https://www.percona.com/downloads/RPM-GPG-KEY-perconaEOF 3） 配置 epel 源 123456789101112 cat &gt; /etc/yum.repos.d/epel.repo &lt;&lt; EOF[epel]name=Extra Packages for Enterprise Linux 7 - $basearchbaseurl=http://dl.fedoraproject.org/pub/epel/7Server/x86_64/failovermethod=priorityenabled=1gpgcheck=1gpgkey=http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7ServerEOF 4）配置 centos base 源 12345678910111213141516171819202122232425262728293031323334353637383940 cat &gt; /etc/yum.repos.d/base.repo &lt;&lt; EOF[base]name=CentOS-$releasever - Basebaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#released updates[updates]name=CentOS-$releasever - Updatesbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/updates/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-$releasever - Extrasbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/extras/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plusbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#contrib - packages by Centos Users[contrib]name=CentOS-$releasever - Contribbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/contrib/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7EOF 安装1) 安装 mariadb yum install -y MariaDB-server MariaDB-client galera rsync 因为从10.1开始galera默认依赖，并且包含在mariadb源中，因此安装server和client就可以了。 rsync mariadb默认使用的集群同步工具，centos 7.3 默认已经安装。 2) 安装jemalloc, google 研发的高效内存管理模块，默认系统已安装 yum install jemalloc jemalloc-devel 3）安装Percona XtraBackup mariadb默认使用rsync进行节点间数据同步. 单rsync同步的时候会锁住节点，没有Percona提供的XtraBackup顺畅. 因此这里使用推荐的XtraBackup，需要下载安装 安装Percona XtraBackup 的yum安装源 yum install -y http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm 或者手动配置yum源 yum install percona-xtrabackup-24 在yum中查找最新版本进行安装 yum list | grep percona-xtrabackup yum install -y percona-xtrabackup-24 4）安装socat，否则xtrabackup备份同步方式在单节点故障后重启后在.err错误日志中会报类似以下错误 WSREP_SST: [ERROR] socat not found in path: /usr/sbin:/sbin.... yum install -y socat 5) 配置NTP（chrony） $ yum install chrony $ systemctl enable chronyd.service $ systemctl start chronyd.service $ systemctl status chronyd.service 6) 启动时，在run里自动创建mysql目录 vi /usr/lib/systemd/system/mariadb.service [Service] ...... #PermissionsStartOnly=true RuntimeDirectory=mysql RuntimeDirectoryMode=0755 User=mysql Group=mysql ...... 修改root用户默认密码本文中选择IP为192.168.56.21的虚机作为演示节点进行配置，mariadb安装后默认服务是启动的 1) 修改root用户默认密码 mysqladmin -u root password &quot;root的登录密码&quot; 或者 mysql_secure_installation (这种方式初学者可能会选错，所以建议用前一种方式) 2) 本文使用sst_user用户作为集群的数据同步用户，授予所有权限 进入mysql管理命令 mysql -uroot -p MariaDB&gt; CREATE USER &apos;sst_user&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sst_pass&apos;; MariaDB&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;sst_user&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sst_pass&apos;; # (如果想让用户拥有授有权限，在语句最后加WITH GRANT OPTION) MariaDB&gt; FLUSH PRIVILEGES; 关闭mysql服务，为后续配置做准备systemctl stop mariadb 数据目录准备：1) 安装 semanage 管理工具 yum -y install policycoreutils-python 2) 准备pid socket 目录，防止内存里 mkdir /var/run/mysql chown -R mysql:mysql /var/run/mysql mkdir -p /data/{mysql,tmp/mysql,log/mysql} 3) 数据目录权限和selinux上下文 chown -R mysql:mysql /data/mysql chmod -R 0755 /data/mysql semanage fcontext -a -t mysqld_db_t &quot;/data/mysql(/.*)?&quot; restorecon -RFv /data/mysql 4) 临时目录权限和selinux上下文 chown -R mysql:mysql /data/tmp/mysql chmod -R 0755 /data/tmp/mysql semanage fcontext -a -t mysqld_db_t &quot;/data/tmp/mysql(/.*)?&quot; restorecon -RFv /data/tmp/mysql 5） 日志目录权限和selinux上下文 chown -R mysql:mysql /data/log/mysql chmod -R 0755 /data/log/mysql semanage fcontext -a -t var_log_t &quot;/data/log/mysql(/.*)?&quot; restorecon -RFv /data/log/mysql 6) socket selinux设置 semanage fcontext -a -t mysqld_var_run_t &quot;${DB_datadir}/{mysql.sock，mysql.pid}&quot; restorecon -RFv ${DB_datadir}/{mysql.sock，mysql.pid} 7) 设置 端口 selinux semanage port -a -t mysqld_port_t -p tcp 3306 修改配置文件配置文件路径： /etc/my.cnf.d/server.cnf mariadb的配置文件很多，安装之后有 /etc/my.cnf /etc/my.cnf.d/mysql-clients.cnf /etc/my.cnf.d/server.cnf 其中/etc/my.cnf文件中包含了后两者 /etc/my.cnf.d/mysql-client.cnf中存放客户端连接时的配置信息， 例如[client]和[mysql]，/etc/my.cnf.d/server.cnf中存放服务器的配置信息 可以将所有信息添加到server.cnf，也可以分为client和server配置文件 查找配置文件所在位置以及配置信息的命令,按空格键下翻 mysqld –help –verbose | more 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226 vi /etc/my.cnf.d/server.cnf### 客户端连接配置 #####################################[client]port = 3306socket = /var/run/mysql/mysql.sock # 设置客户端连接socket文件路径，如果mariadb采用socket连接，且更改了默认socket路径配置，客户端就必须设置default-character-set = utf8 # 设置客户端连接默认连接字符类型[mysqld]### 默认或基本配置 #####################################bind-address = 0.0.0.0port = 3306socket = /run/mysql/mysql.sockbasedir = /usr # mysqld二进制文件存放的目录，或者说mysql安装目录datadir = /data/mysql # 数据库文件存放目录tmpdir = /data/tmp/mysqlpid_file = /run/mysql/mysql.pid # 存放数据库进程ID文件log_error = /data/log/mysql/mariadb.error.log # 错误日志文件#log_output = FILE # 参数log_output指定了慢查询输出的格式，默认为FILE，你可以将它设为TABLE，然后就可以查询mysql架构下的slow_log表了 #log-warnings = 1 # 将警告信息也记入到日志中 sync_binlog = 0 # 默认为0 ,就是由文件系统自己控制它的缓存的刷新，系统crash会丢失很多没刷新的事务日志；sync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据刷入磁盘。。此值可以设为100.open_files_limit = 65535 # 该参数用于控制MySQL实例能够同时打开使用的文件句柄数目。max_connections = 4096 # 最大连接数back_log = 500 #接受队列，对于没建立tcp连接的请求队列放入缓存中，队列大小为back_log，受限制与OS参数max_connect_errors = 10000 # 如果某个用户发起的连接error超过该数值，则该用户的下次连接将被阻塞，直到管理员执行flush hosts ; 命令；防止黑客 collation-server = utf8_general_ci # 查询比较不区分大小写character-set-server = utf8 # 数据库采用UTF8字符集#default-time-zone = system #服务器时区 # skip options skip-name-resolve # 取消域名解析，服务器连接等相关设置只能用IP不能用域名，这样加快访问速度 skip-symbolic-links # 不能使用连接文件 skip-external-locking # 不使用系统锁定，要使用myisamchk,必须关闭服务器 #skip-slave-start # 启动mysql时,不自动启动从复制 ### innodb引擎配置 #####################################default-storage-engine = innodb # 数据库默认引擎采用innodbinnodb_file_per_table = 1 # 采用innodb引擎是，每表存放一个文件innodb_buffer_pool_size = 1Ginnodb_open_files = 6000 # innodb 打开文件的最大数量，受限于系统文件打开的数量innodb_data_home_dir = /data/mysql # innodb数据文件存放路径innodb_data_file_path = ibdata1:100M:autoextend # 一般一个文件对一应一个磁盘innodb_log_group_home_dir = /data/mysql # innodb事物日志文件存放路径innodb_log_files_in_group = 2 # 两组事物日志 innodb_log_file_size = 128M # innodb事物日志大小，越大，恢复时间越长。innodb_log_buffer_size = 8M # innodb事物日志缓存，此值默认8M，对系统提升不高innodb_flush_log_at_trx_commit = 2 # 2 为1秒内刷新日志，适合于游戏之类的服务器；1 为每事务刷新一次，适合对数据要求极高的；0 适合数据不太重要，追求效率的innodb_lock_wait_timeout = 50 # InnoDB事务在被回滚之前可以等待一个锁定的超时秒数。InnoDB在它自己的 锁定表中自动检测事务死锁并且回滚事务。InnoDB用LOCK TABLES语句注意到锁定设置。默认值是50秒innodb_autoinc_lock_mode = 2 # 用于控制自增主键的锁机制，该参数可以设置的值为0/1/2。# 建议将参数设置改为2，则表示所有情况插入都使用轻量级别的mutex锁(只针对row模式)，这样就可以避免auto_inc的死锁，同时在INSERT … SELECT 的场景下会提升很大的性能（注意该参数设置为2，binlog的格式需要设置为row）。# 参数设置为1，表示InnoDB使用轻量级别的mutex锁来获取自增锁，替代最原始的表级锁，但是在load data（包括：INSERT … SELECT, REPLACE … SELECT）场景下会使用自增表锁，这样会则可能导致应用在并发导入数据出现死锁。innodb_flush_method = O_DSYNC innodb_max_dirty_pages_pct = 90 # innodb主线程刷新缓存池中的数据，使脏数据比例小于90% #innodb_doublewrite = 1 # 集群默认必须设置为1#innodb_thread_concurrency = 16#innodb-read-io-threads=4#innodb-write-io-threads=4### 数据二进制日志 #####################################binlog_format = ROW # 集群和主从复制需要设置expire_logs_days = 10 #binlog_cache_size = 1M# 下面只有主从设置时才需要#server_id = 10#log-bin = mysql-bin #这些路径相对于datadir #log-bin-index = mysql-bin.index#relayrelay-log = relay-log#relayrelay_log_index = relay-log.index#expire_logs_days = 10 # 日志保存几天，超时自动删除#binlog-do-db = bitnami_magento # 主从同步的库，一般设置在从服务，同步那个数据库#binlog-do-db = test_magento#binlog_ignore_db = mysql#binlog_ignore_db = performance_schema # 不同步哪个数据库#binlog_ignore_db = information_schema#log-slave-updates = 1 # A-B-C， 如果三级主从，B就需要开启，用于将从主读取的日志写入自己的log-bin中用于自己的从服务器同步#slave-skip-errors = 1### 超时设置 ##################################wait-timeout = 28800 #等待关闭连接的时间 #interactive-timeout = 28800 #关闭连接之前，允许interactive_timeout（取代了wait_timeout）秒的不活动时间。客户端的会话wait_timeout变量被设为会话interactive_timeout变量的值。 #connect-timeout = 10 #连接超时之前的最大秒数,在Linux平台上，该超时也用作等待服务器首次回应的时间 #slave-net-timeout = 600 #从服务器也能够处理网络连接中断。但是，只有从服务器超过slave_net_timeout秒没有从主服务器收到数据才通知网络中断 #net_read_timeout = 30 #从服务器读取信息的超时 #net_write_timeout = 60 #从服务器写入信息的超时 #net_retry_count = 10 #如果某个通信端口的读操作中断了，在放弃前重试多次 #net_buffer_length = 16384 #包消息缓冲区初始化为net_buffer_length字节，但需要时可以增长到max_allowed_packet字节### 缓存 ######################################tmp_table_size = 512M #临时表大小，如果超过该值，则结果放到磁盘中 #max_heap_table_size = 512M #该变量设置MEMORY (HEAP)表可以增长到的最大空间大小,参数目的是防止建立超大的内存临时表max_allowed_packet = 16Mread_buffer_size = 2Msort_buffer_size = 2Mjoin_buffer_size = 2Mread_rnd_buffer_size = 4Mtable_cache = 512 # 所有线程打开的表的数目。增大该值可以增加mysqld需要的文件描述符的数量 table_open_cache = 256thread_stack = 192K # 每个线程的堆栈大小 thread_cache_size = 8 # 线程缓存 #thread_concurrency = 8 # 同时运行的线程的数据 此处最好为CPU个数两倍。本机配置为CPU的个数 query_cache_size =0#query_cache_size = 256M #查询缓存大小 query_cache_limit = 4M #不缓存查询大于该值的结果 query_cache_min_res_unit = 2K #查询缓存分配的最小块大小 key_buffer_size = 256M### 慢查询 #####################################slow_query_log = 1 long-query-time = 5 #慢查询时间 超过1秒则为慢查询 slow_query_log_file = /data/log/mysql/slow.log #log-queries-not-using-indexes #log-slow-slave-statements ### 集群配置 ###################################### 集群相关配置，注意集群服务器必须设置default_storage_engine=InnoDB, binlog_format=ROW, innodb_autoinc_lock_mode=2[galera]wsrep_on = ON #(决定是否启动节点间同步,该配置项从10.1.1版本增加的，必须配置ON选项。)wsrep_provider = /usr/lib64/galera/libgalera_smm.so #(指定Galera的库,galera 的同步c++库位置)wsrep_provider_options = "gcache.size=2G; gcache.page_size=1G"wsrep_cluster_name = "db_cluster" #(整个集群的名称，所有节点一致,字符开头，可以包含数字和下划线)#wsrep_cluster_address = "gcomm://" # 当整个集群都停机后，第一台启动时设置为空，注意此机必须是最后一台关机的服务器wsrep_cluster_address = "gcomm://10.100.120.4,10.100.120.5,10.100.120.6" #(集群中所有节点的地址列表，在Percona中第一个启动的节点必须是空值才能启动，MariaDB已无此限制)wsrep_node_name = db01 #(节点名称，其它两个节点需要修改)wsrep_node_address = 10.100.120.4 #(节点地址，其它两个节点需要修改)wsrep_sst_method = rsync#wsrep_sst_method = xtrabackup-v2 #默认是rsync全量拷贝，但是需要在donor节点上执行全局读锁(flushtables with read lock)，建议采用xtrabackup热备份方式，只有在备份.frm表结构文件才会锁表# SST authentication string. This will be used to send SST to joining nodes.#wsrep_sst_auth = sst_user:sst_pass #集群间的身份验证 # enable "strictly synchronous" semantics for read operations# deprecated#wsrep_causal_reads=ON #节点应用完事务才返回查询请求， 避免脏读#--wsrep-sync-wait=0# 二进制日志的格式必须为ROW格式。binlog_format = ROW#指定默认存储引擎为innodb。集群只支持innodb和xtradbdefault_storage_engine = InnoDBinnodb_autoinc_lock_mode=2# How many threads will process writesets from other nodeswsrep_slave_threads=1 #可以指定wsrep的线程数，提高复制效率。# to enable debug level logging, set this to 1wsrep_debug=0wsrep_convert_LOCK_to_trx=0# how many times to retry deadlocked autocommitswsrep_retry_autocommit=1# replicate myisamwsrep_replicate_myisam=1# retry autoinc insert, which failed for duplicate key errorwsrep_drupal_282555_workaround=0# Generate fake primary keys for non-PK tables (required for multi-master# and parallel applying operation)#为没有显式申明主键的表生成一个用于certificationtest的主键，默认为ON wsrep_certify_nonPK=1 # change auto_increment_increment and auto_increment_offset automaticallywsrep_auto_increment_control=1# Maximum number of rows in write setwsrep_max_ws_rows=131072# Maximum size of write setwsrep_max_ws_size=1073741824# Address for incoming client connections. Autodetect by default.#wsrep_node_incoming_address=10.100.120.4# Address on THIS node to receive SST at. DON'T SET IT TO DONOR ADDRESS!!!# (SST method dependent. Defaults to the first IP of the first interface)#wsrep_sst_receive_address=10.100.120.4### 其它配置 #####################################[mysqld_safe]# 使用jemalloc作为内存管理，需要安装jemalloc jemalloc-develmalloc-lib=/usr/lib64/libjemalloc.sobasedir = /usr # mysqld二进制文件存放的目录，或者说mysql安装目录datadir = /data/mysql # 数据库文件存放目录pid_file = /var/run/mysql/mysql.pid # 存放数据库进程ID文件log_error = /data/log/mysql/mariadb.error.log # 错误日志文件[mysqldump]quickmax_allowed_packet = 16M[mysql]no-auto-rehashdefault-character-set = utf8socket = /run/mysql/mysql.sock[myisamchk]key_buffer_size = 128Msort_buffer_size = 128Mread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout 启动初始化及注意事项1) 在其它两个节点上复制配置文件，注意其中的wsrep_node_name和wsrep_node_address需要根据节点实际情况修改 2) 初始化所有节点的数据库 mkdir /var/run/mysql chown -R mysql:mysql /var/run/mysql rm -rf /var/lib/mysql/* rm -rf /data/mysql/* mysql_install_db --basedir=/usr --datadir=/data/mysql --user=mysql 测试结果，所有节点配置一样，如果第一个节点有数据，运行galera_new_cluster启动cluster，后面的加入的节点数据目录可以为空。 临时关闭安全 setenforce 0 systemctl stop firewalld 12345678910111213141516171819202122 # 集群最简单配置，如果复杂配置启动不了，可以先用最简单配置，然后重做初始数据库 cat &gt; /etc/my.cnf.d/server.cnf &lt;&lt; EOF[galera]wsrep_on=ONwsrep_provider=/usr/lib64/galera/libgalera_smm.sowsrep_cluster_address="gcomm://10.100.120.4,10.100.120.5,10.100.120.6"wsrep_provider_options = "gcache.size=2G; gcache.page_size=1G"wsrep_cluster_name="db_cluster"wsrep_node_address="10.100.120.5"wsrep_node_name="db05"wsrep_sst_method=rsyncwsrep_sst_auth=sst_user:sst_passbinlog_format=rowdefault_storage_engine=InnoDBinnodb_autoinc_lock_mode=2bind-address=0.0.0.0EOF 3) 使用专有命令启动第一个节点 galera_new_cluster 该命令暗示现在没有已存在的集群，启动的这台服务器是这个集群中的第一个，会产生新的集群UUID. 如果集群已经存在还使用该命令会导致启动的服务器和已存在的集群不在一个集群体系中，因为产生了不一样的集群UUID 3) 在保证第一个节点启动后逐个启动其它节点，不要并行启动，可能会出预料不到的问题，如果第一个节点没启动，其它节点无法正常启动。 systemctl start mariadb # 查看集群大小 mysql -u root -p -e &quot;SHOW STATUS LIKE &apos;wsrep_cluster_size&apos;&quot; mysql -uroot -p -e &quot;CREATE DATABASE IF NOT EXISTS tocloud DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;&quot; mysql -uroot -p -e &quot;GRANT ALL ON tocloud.* TO test@&apos;%&apos; IDENTIFIED BY &apos;test.9898&apos;;&quot; 如果使用xtrabackup-v2作为同步组件，创建后续在集群同步中拥有同步权限的用户并赋予最基本权限 mysql&gt; GRANT RELOAD, LOCK TABLES, PROCESS, REPLICATION CLIENT ON *.* TO &apos;sst_user&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sst_pass&apos;; mysql&gt; FLUSH PRIVILEGES; 或者 mysql -uroot -p -e &quot;grant all privileges on *.* to &apos;sst_user&apos;@&apos;%&apos; identified by &apos;sst_pass&apos;;FLUSH PRIVILEGES;&quot; 4) 一定注意集群中最后关闭的服务器应该是下次启动的第一个服务器，因为集群判断这台服务器最后关闭所以具有最完整的数据，所以会设置在这台服务器之前关闭的服务器无法正常手动启动，如果强制启动需要手动将grastate.dat文件中的safe_to_boostrap设置为1后强行启动。 重启集群需要修改，最后一个关闭的服务器配置文件下面这个参数为： wsrep_cluster_address=&quot;gcomm://“ 然后重启最后关闭的服务器，再重启其它服务器，最后改回第一台的配置重新启动 最后用此命令查看配置id 集群id 及状态是否一致 mysql -u root -p -e &quot;SHOW STATUS LIKE &apos;wsrep_cluster%&apos;&quot; Restarting the cluster If you shut down all nodes, you effectively terminated the cluster (not the data of course, but the running cluster), hence the right way is to start the all the nodes with gcomm://&lt;node1 address&gt;,&lt;node2 address&gt;,...?pc.wait_prim=no again. On one of the nodes set global wsrep_provider_options=&quot;pc.bootstrap=true&quot;;. Bootstrapping a new cluster: $ mysqld --wsrep-new-cluster Adding another node to a cluster: $ mysqld --wsrep_cluster_address=gcomm://192.168.0.1 # DNS names work as well 5) 初始化 # mysql_secure_installation # 添加超级用户： grant all on *.* to suroot@&apos;127.0.0.1&apos; identified by &apos;lion.net&apos; with grant option; grant all on *.* to suroot@&apos;::1&apos; identified by &apos;lion.net&apos; with grant option; grant all on *.* to suroot@&apos;localhost&apos; identified by &apos;lion.net&apos; with grant option; # 删除空用户和默认用户： drop user root@&apos;127.0.0.1&apos;; drop user root@&apos;::1&apos;; drop user root@&apos;localhost&apos;; drop user &apos;root&apos;@&apos;test-db-vm01&apos;; drop user &apos;&apos;@&apos;test-db-vm01&apos;; drop user &apos;&apos;@localhost; # 删除测试数据库 drop database test; MariaDB负载均衡当MariaDB Galera Cluster集群搭建完成后，通过任意一个节点都可以连接进行数据操作。 当然我们可以借助于haproxy或lvs来实现MySQL数据库集群之间的负载均衡 使用mysql-router代理最好在每个应用的的服务器上安装mysqlrouter 应用最好使用socket连接mysqlrouter 1234567891011121314151617181920212223242526272829303132333435363738 # yum 安装命令 yum install mysqlrouter # 配置 mysqlrouter yum 源 cat &gt; /etc/yum.repos.d/mysql.repo &lt;&lt; EOF[mysql-connectors-community]name=MySQL Connectors Communitybaseurl=http://repo.mysql.com/yum/mysql-connectors-community/el/7/\$basearch/enabled=1gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysql[mysql-tools-community]name=MySQL Tools Communitybaseurl=http://repo.mysql.com/yum/mysql-tools-community/el/7/\$basearch/enabled=1gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysql[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/\$basearch/enabled=0gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysql[mysql80-community]name=MySQL 8.0 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-8.0-community/el/7/\$basearch/enabled=1gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysqlEOF 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 # mysqlrouter 配置 cat &gt; /etc/mysqlrouter/mysqlrouter.conf &lt;&lt; EOF[DEFAULT]logging_folder = /var/log/mysqlrouter/plugin_folder = /usr/lib64/mysqlrouterruntime_folder = /var/run/mysqlrouterconfig_folder = /etc/mysqlrouter[logger]## INFO (default), DEBUG, WARNING, ERROR, and FATALlevel = WARNING[keepalive]interval = 60## 主数据库，用于写[routing:primary]bind_address = 0.0.0.0bind_port=7001socket = /run/mysqlrouter/mysqlrouter.sockdestinations = 200.200.200.221:3306,200.200.200.222:3306,200.200.200.223:3306## first-available适用于cluster写集群；next-available适用于主从互备，主挂了将永远移除，除非重启mysqlrouter；round-robin适用于只读模式routing_strategy = first-available# 连接到 MySQL Router 的最大连接数, 类似 MySQL Server 中的 max_connections 选项, 有效的值为 1 ~ 65535;max_connections = 512## 有效的值为 1 ~ 65535;# 工具连接后端 MySQL Server 的超时时间,单位秒, 默认为 1s, 有效的值为 1 ~ 65535;connect_timeout = 1## 从数据库，用于读[routing:secondary]bind_address = 0.0.0.0bind_port = 7002destinations = 200.200.200.221:3307,200.200.200.222:3307,200.200.200.223:3307routing_strategy = round-robin## 1-4294967296max_connect_errors = 100## 2 and 31536000client_connect_timeout = 9EOF 123456789101112131415161718192021# vi /usr/lib/systemd/system/mysqlrouter.service [Unit] Description=MySQL Router After=syslog.target After=network.target [Service] Type=simple User=mysqlrouter Group=mysqlrouter PIDFile=/var/run/mysqlrouter/mysqlrouter.pid ExecStart=/usr/bin/mysqlrouter -c /etc/mysqlrouter/mysqlrouter.conf PrivateTmp=true [Install] WantedBy=multi-user.target 安装设置haproxy1) 安装 yum install -y haproxy 2) 设置日志，编辑rsyslog # 取消下面两项注释，并添加一行： vi /etc/rsyslog.conf # Provides UDP syslog reception $ModLoad imudp $UDPServerRun 514 # 设置rsyslog系统日志配置 echo &apos;local2.* /var/log/haproxy.log&apos; &gt; /etc/rsyslog.d/haproxy.conf 3) 编辑配置文件 cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bk 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 cat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOFglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats mode 600 level admindefaults mode tcp log global option dontlognull option redispatch retries 3 timeout queue 45s timeout connect 5s timeout client 1m timeout server 1m timeout check 10s maxconn 1020#---------------------------------------------------------------------# HAProxy statistics backend#---------------------------------------------------------------------listen haproxy-monitoring *:9000 mode http stats enable stats show-legends stats refresh 5s stats uri /stats stats realm Haproxy\ Statistics stats auth test_user:test_pass stats admin if TRUE stats hide-versionfrontend mariadb # change on 2nd HAProxy bind *:3030 default_backend mariadb_clusterbackend mariadb_cluster balance leastconn ##default-server port 9200 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxconn 64 maxqueue 128 weight 100 server nodeA 10.100.120.4:3306 maxconn 151 check port 3306 inter 3s fastinter 1s downinter 5s rise 3 fall 3 server nodeB 10.100.120.5:3306 maxconn 151 check port 3306 inter 3s fastinter 1s downinter 5s rise 3 fall 3 server nodeC 10.100.120.6:3306 maxconn 151 backup check port 3306 inter 3s fastinter 1s downinter 5s rise 3 fall 3EOF 4) 配置haproxy的防护墙 firewall-cmd --permanent --add-port=9000/tcp firewall-cmd --permanent --add-port=3030/tcp firewall-cmd --reload 5) 客户端访问测试 mysql -u root -p -h 192.168.210.252 -P 3030 -e &quot;select Host, User, Password from mysql.user&quot; 错误排查1）xtrabackup方式的备份同步在单节点故障后重启会查找配置文件中的这个文件夹，否则会报类似以下错误 .err日志文件错误如下： rm: cannot remove ‘/var/lib/mysql//innobackup.prepare.log’: No such file or directory rm: cannot remove ‘/var/lib/mysql//innobackup.move.log’: No such file or directory WSREP_SST: [INFO] Moving the backup to /var/lib/mysql/ (20170725 11:10:34.925) WSREP_SST: [INFO] Evaluating innobackupex –no-version-check –move-back –force-non-empty-directories ${DATA} &amp;&gt;${DATA}/innobackup.move.log (20170725 11:10:34.928) WSREP_SST: [ERROR] Cleanup after exit with status:1 (20170725 11:10:34.937) 2017-07-25 11:10:34 140292539795200 [ERROR] WSREP: Process completed with error: wsrep_sst_xtrabackup-v2 –role ‘joiner’ –address ‘192.168.56.12’ –datadir ‘/var/lib/mysql/’ –parent ‘3212’ ” : 1 (Operation not permitted) 2017-07-25 11:10:34 140292539795200 [ERROR] WSREP: Failed to read uuid:seqno and wsrep_gtid_domain_id from joiner script. 2017-07-25 11:10:34 140292899555456 [ERROR] WSREP: SST failed: 1 (Operation not permitted) 2017-07-25 11:10:34 140292899555456 [ERROR] Aborting innobackup.move.log 日志文件错误如下： Error: datadir must be specified 2）脑裂问题： 执行下面命令，通过这个命令来强制恢复出现脑裂的节点。 set global wsrep_provider_options=&quot;pc.bootstrap=true&quot;; 3）避免脏读 Galera Cluster不是真正意义上的全同步复制，存在延迟。 wsrep_causal_reads=ON; 4） 启动不了mairadb setenforce 0 mkdir /run/mysql chown mysql:mysql /run/mysql systemctl restart mariadb 检查集群是否构建成功# mysql -e &quot;show status like &apos;wsrep_%&apos;&quot; +------------------------------+----------------------------------------------------------+ | Variable_name | Value | +------------------------------+----------------------------------------------------------+ | wsrep_apply_oooe | 0.000000 | | wsrep_apply_oool | 0.000000 | | wsrep_apply_window | 0.000000 | | wsrep_causal_reads | 0 | | wsrep_cert_deps_distance | 0.000000 | | wsrep_cert_index_size | 0 | | wsrep_cert_interval | 0.000000 | | wsrep_cluster_conf_id | 5 | | wsrep_cluster_size | 3 | | wsrep_cluster_state_uuid | 963cd314-7072-11e6-ac31-16d397a77e7e | | wsrep_cluster_status | Primary | | wsrep_commit_oooe | 0.000000 | | wsrep_commit_oool | 0.000000 | | wsrep_commit_window | 0.000000 | | wsrep_connected | ON | | wsrep_flow_control_paused | 0.000000 | | wsrep_flow_control_paused_ns | 0 | | wsrep_flow_control_recv | 0 | | wsrep_flow_control_sent | 0 | | wsrep_incoming_addresses | 172.29.32.200:3306,172.29.32.201:3306,172.29.32.202:3306 | | wsrep_last_committed | 0 | | wsrep_local_bf_aborts | 0 | | wsrep_local_cached_downto | 18446744073709551615 | | wsrep_local_cert_failures | 0 | | wsrep_local_commits | 0 | | wsrep_local_index | 0 | | wsrep_local_recv_queue | 0 | | wsrep_local_recv_queue_avg | 0.083333 | | wsrep_local_replays | 0 | | wsrep_local_send_queue | 0 | | wsrep_local_send_queue_avg | 0.000000 | | wsrep_local_state | 4 | | wsrep_local_state_comment | Synced | | wsrep_local_state_uuid | 963cd314-7072-11e6-ac31-16d397a77e7e | | wsrep_protocol_version | 5 | | wsrep_provider_name | Galera | | wsrep_provider_vendor | Codership Oy &lt;info@codership.com&gt; | | wsrep_provider_version | 3.5(rXXXX) | | wsrep_ready | ON | | wsrep_received | 12 | | wsrep_received_bytes | 1360 | | wsrep_repl_data_bytes | 0 | | wsrep_repl_keys | 0 | | wsrep_repl_keys_bytes | 0 | | wsrep_repl_other_bytes | 0 | | wsrep_replicated | 0 | | wsrep_replicated_bytes | 0 | | wsrep_thread_count | 2 | +------------------------------+----------------------------------------------------------+ 具体参数含义解释: 以下参数能对整个集群的做集群完整性检查、节点状态检查、复制健康状态检查、网络瓶颈检查、冲突或死锁检测等，具体参数如下： wsrep_cluster_state_uuid #此参数的值是集群的UUID，每个节点应该一致，可以由此看出节点是否还是集群的一员。 wsrep_cluster_status #集群节点的状态， 正常应该返回primary，其他状态异常，说明出现”分区”或是”split-brain”状况。 wsrep_cluster_conf_id #显示集群变更次数，所有节点应该一致， 反之说明有节点与集群断开了。 wsrep_cluster_size #集群中节点的数量。 wsrep_incoming_addresses #集群中成员的IP地址和端口。 wsrep_connected #当前是否连接中，如果该值为Off，且wsrep_ready的值也为Off，则说明该节点没有连接到集群。 wsrep_flow_control_paused #表示复制停止了多长时间，即表明集群因为Slave延迟而慢的程度，值为0~1，越靠近0越好。值为1表示复制完全停止，可优化wsrep_slave_threads的值来改善。 wsrep_flow_control_sent wsrep_flow_control_sent #表示该节点已经停止复制了多少次。 wsrep_last_committed #最新提交事物的记录。 wsrep_local_commits #本地SQL提交记录。 wsrep_local_cert_failures #本地事物提交失败记录。 wsrep_local_bf_aborts #本地事物回滚的次数。 wsrep_local_send_queue wsrep_local_recv_queue #本地发送和接收的队列。 wsrep_local_send_queue_avg wsrep_local_recv_queue_avg #表示slave事务队列的平均长度，slave瓶颈的预兆。 wsrep_local_state_comment #是否在同步中，如果wsrep_connected为On，但wsrep_ready为OFF，则可以从该项查看原因。 wsrep_ready #插件是否应用中。 wsrep_replicated #随着复制发出的次数。 wsrep_replicated_bytes #随着复制发出的字节数。 动态增加节点关于动态增加节点，只需要在/etc/my.cnf.d/server.conf 修改 wsrep_cluster_address=”gcomm://192.168.1.200″ 地址为cluster其中一个节点即可， 然后通过service mysql start 启动服务，会自动增加到集群节点中 注意点:集群是乐观的并发控制，如果有两个事务同时向集群中不同的节点同一行写入并提交，失败的节点将中止,会造成死锁问题 通过设置单点写入多点读取的方式可以解决此问题。下面链接是其中一种解决方案 http://www.severalnines.com/blog/avoiding-deadlocks-galera-set-haproxy-single-node-writes-and-multi-node-reads 目前存在的一些问题可以参考 https://mariadb.com/kb/en/mariadb/documentation/replication-cluster-multi-master/galera/mariadb-galera-cluster-known-limitations/ wsrep_provider_optionhttps://severalnines.com/blog/understanding-gcache-galera 1） 查看: mysql&gt; SHOW VARIABLES LIKE &apos;wsrep_provider_options&apos;\G ... base_port=4567;gcache.mem_size = 0; gcache.name = /var/lib/mysql/galera.cache; gcache.size = 128M; gcache.page_size = 128M; ... 2) 相关设置 gcache.name 可单独设置缓存文件到另外一个磁盘，提高IO并发 gcache.size 此参数定义作为‘IST增量同步’的内容源的galera.cache文件的大小。此文件设置的大些以便节点重新加入集群式更有可能采用IST而非SST。(默认128M) base_port 同步的专用端口 偏移量 auto_increment当更多的 MariaDB 加入到集群之后，集群中的数据库会自动进行协调，并且自动定义偏移量， 这个比较人性化，自动化，如下描述 MariaDB [tocloud]&gt; show variables like &apos;auto_increment%&apos;; +--------------------------+-------+ | Variable_name | Value | +--------------------------+-------+ | auto_increment_increment | 3 | | auto_increment_offset | 2 | +--------------------------+-------+ 配置haproxy实现功能： 1）健康检查，down机的mysql自动从业务去除 2）负载均衡，配置专用的mysql读，写集群ip，程序通过该IP处理业务 下面haproxy配置使用自带的mysql检测功能，只能检测mysql是否存活。 如果要检测数据库一致性，需要配置xinetd服务写检测脚本通过option httpchk实现（略） 1）安装haproxy wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.23.tar.gz tar xvzfhaproxy-1.4.23.tar.gz cd haproxy-1.4.23 make TARGET=generic make install 2)添加mysql用户，在集群任何一台操作即可，会自动同步 添加权限，用于haproxy检测，不需要任何权限，haproxy只检测是否能正常连接关闭mysql mysql -uroot -p GRANT USAGE ON test.* to gaojinbo@’10.10.10.1′; 3)建立haproxy配置文件 vi /etc/haproxy.cfg global maxconn 40000 #debug daemon #quiet user haproxy group haproxy nbproc 1 log 127.0.0.1 local3 spread-checks 2 defaults timeout server 5m timeout connect 5m timeout client 5m timeout http-request 30s timeout queue 5m frontend db_haproxy_status bind :80 default_backend db_status frontend db_write bind 10.10.10.21:3306 default_backend cluster_db_write frontend db_read bind 10.10.10.22:3306 default_backend cluster_db_read backend cluster_db_write mode tcp option tcpka balance roundrobin option mysql-check user gaojinbo server mdb1 10.10.10.11:3306 weight 1 check port 3306 server mdb2 10.10.10.12:3306 weight 1 check port 3306 server mdb3 10.10.10.13:3306 weight 1 check port 3306 backend cluster_db_read mode tcp option tcpka balance roundrobin option mysql-check user gaojinbo server mdb1 10.10.10.11:3306 weight 1 check port 3306 server mdb2 10.10.10.12:3306 weight 1 check port 3306 server mdb3 10.10.10.13:3306 weight 1 check port 3306 backend db_status mode http stats enable #stats scope #stats hide-version stats refresh 5s stats uri /status stats realm Haproxy statistics stats auth gaojinbo:gaojinbo.com 说明： haproxy配置的5分钟超时，如果需要mysql长连接的话，修改超时设置即可 4)启动haproxy haproxy -f /etc/haproxy.cfg 总结通过上面的一系列测试，最后总结一下： 1. 在生产环境下应该避免使用大事务，不建议在高并发写入场景下使用Galera Cluster架构，会导致集群限流，从而引起整个集群hang住，出现生产故障。针对这种情况可以考虑主从，实现读写分离等手段。 2. 对数据一致性要求较高，并且数据写入不频繁，数据库容量也不大（50GB左右），网络状况良好的情况下，可以考虑使用Galera方案 3. MyISAM存储的表，Galera不支持同步。它仅支持XtraDB/ InnoDB存储引擎（虽然有对MyISAM实验支持，具体看wsrep_replicate_myisam系统变量）。 参考：https://my.oschina.net/ioooi/blog/1476604 http://blog.csdn.net/jiangshouzhuang/article/details/62468778 http://www.cnblogs.com/sweetchildomine/p/7884960.html]]></content>
      <categories>
        <category>mariadb</category>
        <category>install</category>
      </categories>
      <tags>
        <tag>mariadb</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongoDB常用命令]]></title>
    <url>%2Fmongdb%2FmongoDB%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[安装mongoDB官网下载安装（Windows安装方法） 基础知识集合——对应关系数据库中的表 文档——对应关系数据库中的行 启动数据库服务定位到安装目录下的bin文件夹里后 &gt; mongod --dbpath ../data/db 如没有data/db文件夹，需先创建，dbpath用于指定数据存放位置 开启一个客户端访问数据库同样的bin文件夹下执行 &gt; mongo 默认连接至test数据库 显示帮助&gt; help 显示所有数据库名称&gt; show dbs 切换数据库&gt; use test 显示当前连接的数据库名称&gt; db 显示当前数据库所有集合&gt; show collections 显示数据库支持的方法&gt; db.help() 显示集合支持的方法&gt; db.users.help() 创建集合&gt; db.createCollection(&quot;users&quot;) 插入操作insert&gt; db.users.insert({&quot;name&quot;:&quot;kiinlam&quot;,&quot;age&quot;:28}) 查询操作find查找所有文档&gt; db.users.find() 查找指定文档&gt; db.users.find({&quot;name&quot;:&quot;kiinlam&quot;}) 查询一条&gt; db.users.findOne({&quot;name&quot;:&quot;kiinlam&quot;}) 大于$gt&gt; db.users.find({&quot;age&quot;:{$gt:22}}) 大于等于$gte&gt; db.users.find({&quot;age&quot;:{$gte:22}}) 小于$lt&gt; db.users.find({&quot;age&quot;:{$lt:22}}) 小于等于$gte&gt; db.users.find({&quot;age&quot;:{$lte:22}}) 不等于$ne&gt; db.users.find(&quot;age&quot;:{$ne:22}) 或$or&gt; db.users.find({$or:[{&quot;name&quot;:&quot;kiinlam&quot;},{&quot;name&quot;:&quot;cheungkiinlam&quot;}]}) 在集合中$in&gt; db.users.find(&quot;name&quot;:{$in:[&quot;kiinlam&quot;,&quot;cheungkiinlam&quot;]}) 不在集合中$nin&gt; db.users.find(&quot;name&quot;:{$nin:[&quot;kiinlam&quot;,&quot;cheungkiinlam&quot;]}) 正则查询&gt; db.users.find({&quot;name&quot;:/^k/,&quot;name&quot;:/m$/}) 筛选查询$where// 使用js function作为筛选条件 &gt; db.users.find({$where: function(){return this.name==&apos;kiinlam&apos;}}) 限制查询数量limit&gt; db.users.find({&quot;age&quot;:22}).limit(10) 更新操作update指定文档全部更新，等于覆盖&gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {&quot;name&quot;:&quot;cheungkiinlam&quot;,&quot;age&quot;:27}) 局部更新一：增量更新$inc// age增加2，其他不变 &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$inc:{&quot;age&quot;:2}}) 局部更新二：字段修改$set// age改为20 &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$set:{&quot;age&quot;:20}}) 新增更新：如果不存在，就新增一条// 第三个参数为true &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$set:{&quot;age&quot;:18}}, true) 批量更新// 如果匹配多条，默认只改第一条，将第四个参数设为true可全部更新 &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$set:{&quot;age&quot;:18}}, true, true) 保存操作save// 插入新文档，如果不提供&quot;_id&quot;字段 &gt; db.users.save({&quot;name&quot;:&quot;kiinlam&quot;, &quot;age&quot;:28}) // 更新已存在的文档 &gt; db.users.save({&quot;_id&quot;:&quot;xxx&quot;,&quot;name&quot;:&quot;kiinlam&quot;, &quot;age&quot;:28}) 删除操作remove删除操作不可恢复 删除所有，但不删除索引&gt; db.users.remove({}) 删除指定文档&gt; db.users.remove({&quot;name&quot;:&quot;kiinlam&quot;}) 删除一条指定文档，如果有多条结果&gt; db.users.remove({&quot;name&quot;:&quot;kiinlam&quot;}, true) 完全删除集合，包括索引，应当使用drop 大量删除时，采用复制需要保留的文档到新集合，再用drop删除集合。 删除数据库&gt; db.dropDatabase() 删除集合&gt; db.users.drop() 计数操作count&gt; db.users.count() &gt; db.users.count({&quot;age&quot;:29}) 唯一值查询distinct指定字段有多个相同时，只取一个，返回指定字段的值组合成的数组&gt; db.users.distinct(&quot;age&quot;) 分组操作group按照age进行分组操作，分组结果存放在user中，值为对应age的name值的数组 key：分组依据 initial：初始化函数，每个不同的age组共享同一个函数 $reduce： 第一个参数为当前文档，第二参数为前一次函数操作的累计对象，第一次为initial对应的对象 &gt; db.users.group({ &quot;key&quot;: {&quot;age&quot;: true}, &quot;initial&quot;: {&quot;user&quot;: []}, &quot;$reduce&quot;: function(cur,prev){ prev.user.push(cur.name); } }) 假设有数据如下： { &quot;_id&quot; : ObjectId(&quot;55910457607379845607d9e2&quot;), &quot;name&quot; : &quot;kiinlam&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55910468607379845607d9e3&quot;), &quot;name&quot; : &quot;shadow&quot;, &quot;age&quot; : 26 } { &quot;_id&quot; : ObjectId(&quot;55910992607379845607d9e5&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55911fca607379845607d9e6&quot;), &quot;name&quot; : &quot;dd&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fd3607379845607d9e7&quot;), &quot;name&quot; : &quot;mm&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fdf607379845607d9e8&quot;), &quot;name&quot; : &quot;gg&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911feb607379845607d9e9&quot;), &quot;name&quot; : &quot;jj&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55920545ff40738c1fd0a839&quot;), &quot;name&quot; : &quot;zz&quot;, &quot;age&quot; : 1 } 分组结果为： [ { &quot;age&quot; : 29, &quot;user&quot; : [ &quot;kiinlam&quot;, &quot;foo&quot; ] }, { &quot;age&quot; : 26, &quot;user&quot; : [ &quot;shadow&quot; ] }, { &quot;age&quot; : 22, &quot;user&quot; : [ &quot;dd&quot;, &quot;mm&quot;, &quot;gg&quot;, &quot;jj&quot; ] }, { &quot;age&quot; : 1, &quot;user&quot; : [ &quot;zz&quot; ] } ] 更多分组功能可选参数: condition 和 finalize。 `condition` —— 过滤条件 `finalize` —— 函数，分组完成后执行 过滤掉age大于22的文档，增加属性标明分组中文档的数量 &gt; db.users.group({ &quot;key&quot;: {&quot;age&quot;: true}, &quot;initial&quot;: {&quot;user&quot;: []}, &quot;$reduce&quot;: function(cur,prev){ prev.user.push(cur.name); }, &quot;condition&quot;: {&quot;age&quot;:{$lte:22}}, &quot;finalize&quot;: function(out){ out.count = out.user.length; } }) 分组结果为： [ { &quot;age&quot; : 22, &quot;user&quot; : [ &quot;dd&quot;, &quot;mm&quot;, &quot;gg&quot;, &quot;jj&quot; ], &quot;count&quot; : 4 }, { &quot;age&quot; : 1, &quot;user&quot; : [ &quot;zz&quot; ], &quot;count&quot; : 1 } ] mapReducemap：映射函数，内部调用emit(key,value)，集合按照key进行映射分组。 reduce：简化函数，对map分组后的数据进行分组简化，reduce(key,value)中的key是emit中的key，而value则是emit分组结果的集合。 mapReduce：最后执行的函数，参数为map、reduce和一些可选参数。 &gt; db.users.mapReduce function ( map , reduce , optionsOrOutString ){ var c = { mapreduce : this._shortName , map : map , reduce : reduce }; assert( optionsOrOutString , &quot;need to supply an optionsOrOutString&quot; ) if ( typeof( optionsOrOutString ) == &quot;string&quot; ) c[&quot;out&quot;] = optionsOrOutString; else Object.extend( c , optionsOrOutString ); var raw = this._db.runCommand( c ); if ( ! raw.ok ){ __mrerror__ = raw; throw Error( &quot;map reduce failed:&quot; + tojson(raw) ); } return new MapReduceResult( this._db , raw ); } 创建map函数 function (){ emit(this.name,{count:1}); } 创建reduce函数 function (key,value){ var result = {count:0}; for(var i = 0; i &lt; value.length; i++){ result.count += value[i].count; } return result; } 执行mapReduce操作 &gt; db.users.mapReduce(map,reduce,{&quot;out&quot;:&quot;collection&quot;}) 假设有数据如下 { &quot;_id&quot; : ObjectId(&quot;55910457607379845607d9e2&quot;), &quot;name&quot; : &quot;kiinlam&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55910468607379845607d9e3&quot;), &quot;name&quot; : &quot;shadow&quot;, &quot;age&quot; : 26 } { &quot;_id&quot; : ObjectId(&quot;55910992607379845607d9e5&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55920545ff40738c1fd0a839&quot;), &quot;name&quot; : &quot;zz&quot;, &quot;age&quot; : 1 } { &quot;_id&quot; : ObjectId(&quot;55911fca607379845607d9e6&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fd3607379845607d9e7&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fdf607379845607d9e8&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911feb607379845607d9e9&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } 输出结果 { &quot;result&quot; : &quot;collection&quot;, // 存放最终结果的集合名 &quot;timeMillis&quot; : 28, &quot;counts&quot; : { &quot;input&quot; : 8, // 传入文档的次数 &quot;emit&quot; : 8, // emit函数被调用次数 &quot;reduce&quot; : 1, // reduce函数被调用次数 &quot;output&quot; : 4 // 最后返回文档的个数 }, &quot;ok&quot; : 1 } 查看集合collection中的结果 &gt; db.collection.find() 输出结果 { &quot;_id&quot; : &quot;foo&quot;, &quot;value&quot; : { &quot;count&quot; : 5 } } { &quot;_id&quot; : &quot;kiinlam&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } { &quot;_id&quot; : &quot;shadow&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } { &quot;_id&quot; : &quot;zz&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } 游标游标只表示一个引用，并不是真正的执行，在需要的时候，通过for循环或next()方法进行遍历读取，枚举结束后，游标销毁，不再返回数据。 申明一个游标 &gt; var list = db.collection.find() 通过forEach遍历游标 &gt; list.forEach(function(i){ print(i._id); }) 输出结果 foo kiinlam shadow zz 或者通过next遍历集合 &gt; var list = db.collection.find() &gt; list.next() { &quot;_id&quot; : &quot;foo&quot;, &quot;value&quot; : { &quot;count&quot; : 5 } } &gt; list.next() { &quot;_id&quot; : &quot;kiinlam&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } &gt; list.next() { &quot;_id&quot; : &quot;shadow&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } &gt; list.next() { &quot;_id&quot; : &quot;zz&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } &gt; list.next() 2015-07-01T11:27:38.186+0800 E QUERY Error: error hasNext: false at Error (&lt;anonymous&gt;) at DBQuery.next (src/mongo/shell/query.js:255:15) at (shell):1:6 at src/mongo/shell/query.js:255 &gt; list &gt; 索引ensureIndex建立索引// 1为升序，-1为降序 &gt; db.users.ensureIndex({&quot;name&quot;:1}) 唯一索引&gt; db.users.ensureIndex({&quot;name&quot;:1},{&quot;unique&quot;:true}) 组合索引&gt; db.users.ensureIndex({&quot;name&quot;:1, &quot;age&quot;:-1}) 查看索引&gt; db.users.getIndexes() 按指定索引查询&gt; db.users.find({&quot;name&quot;:&quot;kiinlam&quot;}).hint({&quot;name&quot;:1,&quot;age&quot;:1}) 删除索引// 删除所有自定义索引 &gt; db.users.dropIndexes() // 删除指定索引 &gt; db.users.dropIndex(&quot;name_1&quot;) 性能分析函数explain&gt; db.users.find().explain(&quot;executionStats&quot;) 主从数据库部署创建主数据库master&gt; mongod --dbpath=XXX --master 创建从数据库slave// 指定从数据库端口--port // 指定主数据库源--source &gt; mongod --dbpath=XXX --port=8888 --slave --source=127.0.0.1:27017 后期指定主数据库源&gt; mongod --dbpath=XXX --port=8888 --slave // 后期添加源 // 切换到local数据库 &gt; use local // 在sources中加入源地址 &gt; db.sources.insert({&quot;host&quot;:&quot;127.0.0.1:27017&quot;}) 副本集replSet该架构没有特定的主数据库，一个数据库宕机了，另一个数据库会顶上 创建第一个数据库服务器// 需要指定集群名及下一个数据库地址 &gt; mongod --dbpath=XXX --port 2222 --replSet mySet/127.0.0.1:3333 创建第二个数据库服务器&gt; mongod --dbpath=XXX --port 3333 --replSet mySet/127.0.0.1:2222 初始化副本集// 进入任一数据库的admin集合 &gt; mongo 127.0.0.1:2222/admin // 执行初始化操作 &gt; db.runCommand({ &quot;replSetInitiate&quot;:{ &quot;_id&quot;:&quot;mySet&quot;, &quot;members&quot;:[ { &quot;_id&quot;:1, &quot;host&quot;:&quot;127.0.0.1:2222&quot; }, { &quot;_id&quot;:2, &quot;host&quot;:&quot;127.0.0.1:3333&quot; } ] } }) 仲裁服务器// 启动仲裁服务器 &gt; mongod --dbpath=XXX --port 4444 --replSet mySet/127.0.0.1:2222 // 回到admin集合中添加仲裁服务器 &gt; mongo 127.0.0.1:2222/admin &gt; rs.addArb(&quot;127.0.0.1:4444&quot;) // 查看服务器集群状态 &gt; rs.status() 分片技术将集合进行拆分，将拆分的数据均摊到几个分片上。 主要参与者： 客户端 路由服务器mongos 配置服务器 分片数据库实例 开启配置服务器config&gt; mongod --dbpath=XXX --port 2222 开启路由服务器mongos// 指定配置服务器 &gt; mongos --port 3333 --configdb=127.0.0.1:2222 开启分片数据库服务器mongod&gt; mongod --dbpath=XXX --port 4444 &gt; mongod --dbpath=XXX --port 5555 服务配置// 进入mongos数据库admin集合 &gt; mongo 127.0.0.1:3333/admin // 添加分片服务器addshard &gt; db.runCommand({ &quot;addshard&quot;:&quot;127.0.0.1:4444&quot;, &quot;allowLocal&quot;:true }) &gt; db.runCommand({ &quot;addshard&quot;:&quot;127.0.0.1:5555&quot;, &quot;allowLocal&quot;:true }) // 开启数据库test的分片功能enablesharding &gt; db.runCommand({&quot;enablesharding&quot;:&quot;test&quot;}) // 指定集合中分片的片键users.name &gt; db.runCommand({&quot;shardcollection&quot;:&quot;test.users&quot;,&quot;key&quot;:{&quot;name&quot;:1}}) // 在mongos中查看数据分片情况 &gt; use test &gt; db.printShardingStatus() 运维运维通常会涉及到以下4个方面 安装部署 状态监控 安全认证 备份和恢复 安装部署为windows服务// 指定日志路径，添加install参数 &gt; mongod --dbpath=XXX --logpath=XXX --port=2222 --install // 启动服务 &gt; net start MongoDB 状态监控静态统计db.stats() // 查看单个数据库状态 &gt; db.stats() stats比较简单，可以参考db.stats()一文 db.serverStatus() // 查看整个mongodb的状态 // 进入admin集合 &gt; mongo 127.0.0.1:2222/admin // 查看状态 &gt; db.serverStatus() serverStatus的参数很多，可以参考db.serverStatus()一文 实时统计&gt; mongostat --port 2222 安全认证TODO 有点复杂，偷懒了，参考安全认证 备份和恢复// 备份test数据库到D:\mongodb\backup &gt; mongodump --port 2222 -d test -o D:\mongodb\backup // 恢复数据，drop表示恢复前删除原有数据 &gt; mongorestore --port 2222 -d test --drop D:\mongodb\backup 参考资料 mongoDB MongoDB文档 install-mongodb-on-windows 8天学通MongoDB系列]]></content>
      <categories>
        <category>mongoDB</category>
      </categories>
      <tags>
        <tag>mongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy 12345678910111213POST /task?id=1 HTTP/1.1Host: example.orgContent-Type: application/json; charset=utf-8Content-Length: 137&#123; "status": "ok", "extended": true, "results": [ &#123;"value": 0, "type": "int64"&#125;, &#123;"value": 1.0e+3, "type": "decimal"&#125; ]&#125; More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[categories]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
