<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hexo Next 创建分类和标签页]]></title>
    <url>%2Fhexo%2FHexo%20Next%20%E5%88%9B%E5%BB%BA%E5%88%86%E7%B1%BB%E5%92%8C%E6%A0%87%E7%AD%BE%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[创建分类页面新建一个页面，命名为 categories 。命令如下： hexo new page categories 编辑刚新建的页面，在source/categories目录下的index.md， 将页面的类型设置为 categories ，主题将自动为这个页面显示所有分类。 title: 分类 date: 2014-12-22 12:39:04 type: &quot;categories&quot; ## 如果在主题layout自定义了分类显示页面，可以设置对应的layout的页面 #layout: &quot;custom_layout&quot; --- 注意：如果有启用多说 或者 Disqus 评论，默认页面也会带有评论。 需要关闭的话，请添加字段 comments 并将值设置为 false，如： title: 分类 date: 2014-12-22 12:39:04 type: &quot;categories&quot; comments: false --- 在菜单中添加链接。编辑主题的 _config.yml ， 将 menu 中的 categories: /categories 注释去掉，如下: menu: home: / || home #about: /about/ || user #tags: /tags/ || tags categories: /categories/ || th 创建标签云页面添加一个标签云页面，并在菜单中显示页面链接。 新建一个页面，命名为 tags 。命令如下： hexo new page &quot;tags&quot; 编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。 title: All tags date: 2014-12-22 12:39:04 type: &quot;tags&quot; --- 注意：如果有启用多说 或者 Disqus 评论，默认页面也会带有评论。 需要关闭的话，请添加字段 comments 并将值设置为 false，如： title: All tags date: 2014-12-22 12:39:04 type: &quot;tags&quot; comments: false --- 在菜单中添加链接。编辑主题的 _config.yml ，添加 tags 到 menu 中，如下: menu: home: / || home #about: /about/ || user tags: /tags/ || tags]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx mp4 伪流支持]]></title>
    <url>%2Fnginx%2Fconfig%2Fnginx%20mp4%20%E4%BC%AA%E6%B5%81%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[基本配置location ~ .*\.(mp4)$ mp4; mp4_buffer_size 1m; mp4_max_buffer_size 5m; } ngx_http_mp4_module模块: 对具有.mp4, .m4v, and .m4a.扩展名的H.264/AAC格式文件提供服务器端的伪流支持。 请求连接后面允许添加?start=秒数.毫秒数，表示从某时刻开始播放，如： http://example.com/elephants_dream.mp4?start=238.88]]></content>
      <categories>
        <category>nginx</category>
        <category>config</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker CE 安装]]></title>
    <url>%2Fdocker%2Fdocker%20CE%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[$ sudo yum install docker-ce 配置yum 源1234567891011121314151617181920212223 $ sudo yum install -y yum-utils $ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo # 或者 cat &gt; /etc/yum.repo.d/docker.repo &lt;&lt; EOF [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge] name=Docker CE Edge - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpgEOF 删除旧版如果原来装有旧版，删除可能装有的版本 $ sudo yum remove docker docker-common docker-selinux docker-engine-selinux docker-engine docker-ce 安装12345678# 安装需要的依赖包$ sudo yum install -y device-mapper-persistent-data lvm2# 安装docker ce$ sudo yum install docker-ce docker 服务管理操作123456$ sudo systemctl enable docker.service$ sudo systemctl start docker.service$ sudo systemctl stop docker.service$ sudo systemctl restart docker.service$ sudo systemctl status docker.service 查找docker 网桥和IP地址12345docker 默认网桥名为docker0，并分配了一个IP 地址$ ip a$ ip a list docker0 docker 操作命令格式1234docker commanddocker command argdocker [options] command arg 查看docker 信息和帮助12345678docker infodocker help | more# 查找ps cp 命令帮助docker ps --helpdocker cp --help docker 基本操作命令# 运行docker容器 docker container run hello-world # 查找docker 镜像 docker search nginx # 下载docker镜像 docker pull nginx # 查看已有的镜像 docker images # 通过下载nginx镜像启动一个容器 docker container run --name my-nginx-c1 --detach nginx # 将本地目录/home/vivek/html/挂载到nginx 容器的nginx默认的网站目录 docker container run --name my-nginx-c2 -p 80:80 -v /home/vivek/html/:/usr/share/nginx/html:ro -d nginx --name my-nginx-c1 : 给容器命名, 简写 -n --detach : 后台运行容器，并打印出容器ID，简写 -d -v /home/vivek/html:/usr/share/nginx/html:ro : 将物理机上的文件夹挂载到容器上，注意目录后面都没/，容器会自动创建没有的挂载目录 -p 80:80 : 将容器端口映射到物理机的端口 -e：设置环境变量 # 显示正在运行的容器 # 加-a, 只显示正在运行的容器 docker container ls -a # 列出的结果是按列显示的。每一列的值分别为： * Container ID ：一开始的几个字符对应你的容器的唯一 ID * Image ：你运行容器的镜像名 * Command ：容器启动后运行的命令 * Created ：创建时间 * Status ：容器当前状态 * Ports ：与宿主端口相连接的端口信息 * Names ：容器名（如果你没有命名你的容器，那么会随机创建） # 对应Docker 旧版本命令，旧版不需要加container, 其它命令类似 docker ps docker ps -a # 通过容器id或容器名，在容器上运行命令 docker container exec fe0cdbc0225a ls /etc/nginx docker container exec my-nginx-c1 ls /etc/nginx # 获取容器bash ，并保存修改 docker container exec -i -t fe0cdbc0225a bash docker container exec -i -t my-nginx-c1 bash # 通过容器ID或容器名停止容器 docker container stop my-nginx-c1 docker container stop fe0cdbc0225a # 启动已停止的容器 # 一个已经停止并保存了当时运行状态的容器。启动后，它将以停止时的状态重新开始运行。 docker container start my-nginx-c1 # 删除容器 # 容器删除之前必须是先停止 docker container rm my-nginx-c1 docker container ls # 查看 Docker 容器的历史纪录 docker container logs my-nginx-c1 # 查看 Docker 容器的进程 docker container top my-nginx-c1]]></content>
      <categories>
        <category>docker</category>
        <category>install</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>install</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 系统入侵检查]]></title>
    <url>%2Flinux%2Flinux%20%E7%B3%BB%E7%BB%9F%E5%85%A5%E4%BE%B5%E6%A3%80%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[查看登陆日志# wtmp日志记录每个用户登录、注销及系统的启动、停机的事件 last last -f /var/log/wtmp who /var/log/wtmp # last命令往回搜索wtmp来显示自从文件第一次创建以来登录过的用户. # who命令查询utmp文件并报告当前登录的每个用户。 # who的默认输出包括用户名、终端类型、登录日期及远程主机。 查看security日志more /var/log/secure # /var/log/secure：记录登录系统存取数据的文件; # 例如:pop3，ssh，telnet，ftp等都会记录在此. 记录登陆后的IP地址和某用户名所操作的历史记录通过在/etc/profile里面加入以下代码就可以实现： PS1=&quot;`whoami`@`hostname`:&quot;&apos;[$PWD]&apos; history USER_IP=`who -u am i 2&gt;/dev/null| awk &apos;{print $NF}&apos;|sed -e &apos;s/[()]//g&apos;` if [ &quot;$USER_IP&quot; = &quot;&quot; ] then USER_IP=`hostname` fi if [ ! -d /tmp/dbasky ] then mkdir /tmp/dbasky chmod 777 /tmp/dbasky fi if [ ! -d /tmp/dbasky/${LOGNAME} ] then mkdir /tmp/dbasky/${LOGNAME} chmod 300 /tmp/dbasky/${LOGNAME} fi export HISTSIZE=4096 DT=`date &quot;+%Y-%m-%d_%H:%M:%S&quot;` export HISTFILE=&quot;/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT&quot; chmod 600 /tmp/dbasky/${LOGNAME}/*dbasky* 2&gt;/dev/null source /etc/profile 使用脚本生效 退出用户，重新登录 查看文件修改属性find /data/wwwroot -name &quot;*.php&quot; -mtime -10 | xargs ls -l stat filename #查看指定文件的信息 查找webshell 关键字find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;eval&quot; |more find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;shell_exec&quot; |more find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;passthru&quot; |more find /data/wwwroot -name &quot;*.php&quot; |xargs grep &quot;fsockopen&quot; |more 常用日志文件系统日志是由一个名为syslog的服务管理的，如以下日志文件都是由syslog日志服务驱动的： /var/log/boot.log：录了系统在引导过程中发生的事件，就是Linux系统开机自检过程显示的信息 /var/log/lastlog ：记录最后一次用户成功登陆的时间、登陆IP等信息 /var/log/messages ：记录Linux操作系统常见的系统和服务错误信息 /var/log/secure ：Linux系统安全日志，记录用户和工作组变坏情况、用户登陆认证情况 /var/log/btmp ：记录Linux登陆失败的用户、时间以及远程IP地址 /var/log/syslog：只记录警告信息，常常是系统出问题的信息，使用lastlog查看 /var/log/wtmp：该日志文件永久记录每个用户登录、注销及系统的启动、停机的事件，使用last命令查看 /var/run/utmp：该日志文件记录有关当前登录的每个用户的信息。如 who、w、users、finger等就需要访问这个文件 wtmp和utmp文件都是二进制文件，它们不能被诸如tail之类的命令剪贴或合并（使用cat命令）。用户需要使用who、w、users、last和ac等命令来使用这两个文件包含的信息。 lastlog 文件在每次有用户登录时被查询。 可以使用lastlog命令检查某特 定用户上次登录的时间，并格式化输出上次登录日志 /var/log/lastlog的内容。 它根据UID排序显示登录名、端口号（tty）和上次登录时间。 如果一个用户从未登录过，lastlog显示 **Never logged**。注意需要以root身份运行该命令. &quot;last -u 102&quot;命令将报告UID为102的用户；&quot;last -t 7&quot;命令表示限制为上一周的报告。 sshd 加固配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 # 仅允许SSH协议版本2 # SSH协议版本1有安全问题，包括中间人攻击(man-in-the-middle)和注入(insertion)攻击 Protocol 2 # 修改端口，密码尝试3次以上断开，超过30秒还未登陆成功端开 # 修改selinux: semanage port -a -t ssh_port_t -p tcp 55555 Port 55555 LoginGraceTime 30 MaxAuthTries 3 # 禁止root用户和空密码登陆 PermitRootLogin no PermitEmptyPasswords no # 如果需要 ChallengeResponseAuthentication no UsePAM no # 禁用密码验证，开启密钥验证 PasswordAuthentication no PubkeyAuthentication yes AuthenticationMethods publickey # 仅允许特定的用户通过SSH登陆 AllowUsers ceph.admin mysql.admin # 配置空闲超时注销时长，以秒为单位设置一个空闲超时时间（300秒 = 5分钟）。 # 一旦空闲时间超过这个值，空闲用户就会被踢出会话。 ClientAliveInterval 300 ClientAliveCountMax 0 # 禁用基于主机的授权（需核实） HostbasedAuthentication no # 允许特定用户用特定IP或域名通过SSH登陆，域名需要开启DNS UseDNS yes AllowUsers ceph.admin@189.12.1.4 mysql.admin@xyz.com``` bash 使用rsa 或 ed25519 加密密匙 $ ssh-keygen -t ed25519 -C "Login to production cluster at xyz corp" 或 $ ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa_aws_$(date +%Y-%m-%d) -C "AWS key for abc corp clients" 随机产生用户密码1234567891011121314151617$ vi genpasswd#!/bin/bashgenpasswd() &#123; local l=$1 [ "$l" == "" ] &amp;&amp; l=20 tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c $&#123;l&#125; | xargs&#125;# genpasswd 16genpasswd $1$ bash genpasswd 32 # 在默认配置文件 /etc/ssh/sshd_config 追加如下内容（ 将arcfour cipher 停用） Ciphers aes128-ctr,aes192-ctr,aes256-ctr # 禁用弱MAC算法，在默认配置文件 /etc/ssh/sshd_config追加如下内容 MACs hmac-sha1,umac-64@openssh.com,hmac-ripemd160,hmac-md5-96, hmac-sha2-256,hmac-sha2-512,hmac-ripemd160@openssh.com # 使用以下命令获取 OpenSSH 支持的加密方法： $ ssh -Q cipher $ ssh -Q cipher-auth $ ssh -Q mac $ ssh -Q kex $ ssh -Q key # 在重启 sshd 前检查配置文件的有效性和密匙的完整性，运行： $ sudo sshd -t # 扩展测试模式： $ sudo sshd -T # 限制登录设置主要是对hosts.allow与hosts.deny就行改动 # 首先限制所有IP都无法连接，我们顺便将FTP的限制也加入其中。 # 注意要想FTP限制起作用，需要修改配置中的tcp_wrappers=YES。 vi /etc/hosts.deny sshd:ALL vsftpd:ALL 设定允许指定的IP地址连接： vi /etc/hosts.allow # xxx.xxx.xxx.表示网段 sshd:192.168.1. vsftpd:192.168.1. 参考：https://linux.cn/article-9394-1.html 保护 SSH 的三把锁https://www.ibm.com/developerworks/cn/aix/library/au-sshlocks/ 增加黑客入侵的难度http://www.ibm.com/developerworks/i/p-fkereki.jpgFederico Kereki2010 年 11 月 30 日发布 WeiboGoogle+用电子邮件发送本页面Comments1简介 如果需要远程访问计算机并启用了 Secure Shell (SSH) 连接，黑客就会尝试突破您的防线并控制您的计算机，您必须接受这个事实。尽管不能保证计算机不会被 “黑客” 占领，但是一些简单的解决方案有助于保护 SSH，可以让攻击困难一些。本文讨论三种技术：常用缩写词 API: 应用程序编程接口 DNS: 域名系统 IETF: Internet 工程工作小组 LDAP: 轻量级目录访问协议 RFC: 请求注解 TCP: 传输控制协议 UDP: 用户数据报协议 把 SSH 的标准端口改为不常用的值并增强 SSH 配置，从而挡住最简单的攻击。 定义有限的用户列表，只允许这些用户登录。 完全隐藏允许 SSH 访问的事实，要求根据特殊的 “敲门” 序列识别有效用户。 要想应用这些技术，需要能够访问根账户。另外，可能必须安装一些包，需要配置防火墙和路由器（如果有路由器的话），打开和关闭特定的端口并把数据包转发到您的计算机。加强保护 “隐匿产生安全” 这个概念尽人皆知而且受到大家的嘲笑，因为采用隐匿的方式，希望没人了解您的方法，这只是一厢情愿的想法。但是，在某些场景中，隐匿一点儿会有帮助。尽管简单的措施无法阻止下定决心的黑客，但是至少能够挡住那些 “脚本小子”，他们的脚本往往水平很一般。 人人都知道 SSH 连接的标准端口是 22。因此，为了让计算机更安全，应该采取的第一个措施是把端口改为另一个不常用的非标准端口号，比如 22960。1024 以上的号码通常都可以使用，但是应该查阅参考资料以避免导致问题。这一修改对您的影响仅仅是必须使用下面的命令连接计算机：1 ssh -p 22960 your.machine.url 为了实现这个小措施，只需在 /etc/ssh/sshd_config 文件中做简单的修改。编辑此文件（必须作为根用户），寻找 Port 22 行，把端口号改为您选择的号码（如果这一行以镑符 [#] 开头，表示它被注释掉了，那么应该取消注释标志）。保存文件，用 /etc/init.d/sshd restart 命令重新启动 SSH。应该在防火墙上打开您选择的端口并关闭端口 22。 但是，还可以更进一步。编辑配置文件，在其中包含 清单 1 所示的行。注意，其中一些行可能已经存在，但是可以把它们注释掉。清单 1. 通过修改 SSH 配置文件简便地增强安全性12345 Port 22960LoginGraceTime 30MaxAuthTries 3Protocol 2PermitRootLogin no LoginGraceTime 允许一次登录花费 30 秒；如果用户花费的时间超过 30 秒，就不允许他访问，必须重新登录。MaxAuthTries 把错误尝试的次数限制为 3 次，3 次之后拒绝登录尝试。上面的 Protocol 2 行禁止使用比较弱的协议。最后一行不允许任何人作为根用户登录，这会让黑客攻击更困难。还可以使用 DenyUsers、AllowUsers、DenyGroups 和 AllowGroups 选项实现其他限制。这些修改不会显著增强计算机的安全性，但是只尝试强力攻击标准端口 22 的一般脚本会失败，不会造成损害。无论如何，这是向正确的方向迈出了第一步。在本文后面，我们将使用更安全的方法，不仅修改端口号，而且完全隐藏它。谁可以进入？ 对于大多数人，PAM 是一种罐装的烹调油。但是作为 Linux® 安全术语，PAM 代表可插入身份验证模块（Pluggable Authentication Modules）。这些模块提供额外的身份验证规则，保护对计算机的访问。 首先讨论一个基本问题：究竟为什么要使用 PAM？如果每个程序不得不定义自己的身份验证逻辑，就会很混乱。如何确定所有应用程序都实现了相同的测试和检查？如果需要额外的控制手段，那么怎么办？难道要重新编写所有程序吗？在计算机科学领域，有时候可以用额外的一层解决所有问题，至少在安全方面是这样。如果一个程序需要验证用户的身份，它可以调用 PAM API。这个 API 负责执行在 PAM 配置文件中指定的所有检查。这种方法还允许方便地修改身份验证规则，所有感知 PAM 的程序都会自动地应用新规则，不需要修改它们的代码。如果希望使用某种生物学检查（比如虹膜扫描器或指纹采集器），而且生产商提供了 PAM，就可以方便地设置它。在配置文件中包含模块调用，所有应用程序就可以使用这个设备了。配置 PAM PAM 提供四个安全领域的特性，但是应用程序不太可能同时需要所有这些方面。例如，passwd 命令只需要下面列表中的第三组： account 处理账户限制。对于有效的用户，允许他做什么？ auth 处理用户识别 — 例如，通过输入用户名和密码。 password 只处理与密码相关的问题，比如设置新密码。 session 处理连接管理，包括日志记录。 在 /etc/pam.d 目录中为将使用 PAM 的每个应用程序创建一个配置文件，文件名与应用程序名相同。例如，login 命令的配置文件是 /etc/pam.d/login。 必须定义将应用哪些模块，创建一个动作 “堆”。PAM 运行堆中的所有模块，根据它们的结果允许或拒绝用户的请求。还必须定义检查是否是必需的。最后，other 文件为没有特殊规则的所有应用程序提供默认规则。 optional 模块可以成功，也可以失败；PAM 根据模块是否最终成功返回 success 或 failure。 required 模块必须成功。如果失败，PAM 返回 failure，但是会在运行堆中的其他模块之后返回。 requisite 模块也必须成功。但是，如果失败，PAM 立即返回 failure，不再运行其他模块。 sufficient 模块在成功时导致 PAM 立即返回 success，不再运行其他模块。 配置文件的结构很简单。可以包含注释，注释以散列符 (#) 开头；通过在换行处加上反斜杠 ()，可以把长的行分为多行。行有三个字段：领域 (account、auth、password 或 session）、控制标志（optional、required、requisite 或 sufficient）、将运行的模块的路径和参数。注意，第二个字段可以更复杂；更多信息见 参考资料。另外，可以使用 include 规则以包含其他文件中的规则，比如 auth include common-account。 特殊的 /etc/pam.d/other 文件是 “默认的” 配置文件（见 清单 2），其中的规则自动地应用于没有自己的配置文件的所有应用程序。为了确保安全，应该快速检查 /etc/pam.d 目录，把您不使用的所有配置文件改为其他名称（这样就会使用 other 配置）。如果认为确实需要某个应用程序，那么只需把配置文件改回原来的名称。默认配置通常拒绝所有请求（通过使用 pam_deny.so 模块）并警告管理员（通过 pam_warn.so 模块），让管理员解决问题。 标准的 “other” 配置文件为没有自己的配置文件的所有应用程序提供安全的默认规则（拒绝所有请求）。清单 2. 标准的 “other” 配置文件123456 account required pam_deny.soauth required pam_deny.soauth required pam_warn.sopassword required pam_deny.sopassword required pam_warn.sosession required pam_deny.so 如果把 pam_deny.so 替换为 pam_unix.so，就应用标准的身份验证方法（输入用户名和密码）。如果您不关心安全性，那么使用 pam_permit.so，这会允许任何请求！一些可用方法 尽管没有标准的模块列表，但是所有发行版都包含以下模块中的大多数。请检查驻留模块的 /lib/security 或 /usr/lib/security 目录。对于 64 位操作系统，用 lib64 替换 lib。如果需要更多信息，可以尝试执行 man the.name.of.the.module，而不要直接执行它；PAM 不是可执行的二进制代码。 pam_access 根据 /etc/security/access.conf 文件允许或拒绝访问。稍后将使用此模块决定允许哪些用户登录。 pam_cracklib 和 pam_pwcheck 检查新密码的强度。 pam_deny 和 pam_permit 是基本模块，分别拒绝或允许访问。 pam_echo 向用户显示指定文件的内容。 pam_lastlog 向用户显示他上一次登录的日期和时间。 pam_ldap.so 让用户根据 LDAP 服务器进行身份验证，提供跨网络的集中式身份验证。 pam_limits 模块允许指定系统资源限制，限制在 /etc/security/limits.conf 文件中定义。 pam_listfile 提供根据一个文件的内容允许或拒绝服务的另一种方法。 pam_mail 检查用户是否有未处理的邮件。 pam_motd 向用户显示 “message of the day” 文件。 如果 /etc/nologin 文件存在，pam_nologin 阻止所有登录。 pam_rootok 允许根用户访问，不执行进一步检查。/etc/pam.d/su 中常常包含这个模块；必需的行是 auth sufficient pam_rootok.so。根用户可以作为任何用户操作，不需要提供密码。 pam_succeed_if 检查账户的特定属性，比如是否是某个组的成员。 pam_time 可以根据 /etc/security/time.conf 中的规则限制对服务的访问。 pam_unix（或 pam_unix2）提供基于 /etc/passwd 和 /etc/shadow 文件的传统 UNIX® 身份验证。 pam_userdb 根据一个 Berkeley 数据库执行身份验证。 pam_warn 在系统日志中记录信息。 pam_wheel 只向 wheel 组的成员提供根访问权；必需的行是 auth required pam_wheel.so。 关于其他模块和编写自己的模块的信息，请查阅 参考资料。现在，使用 PAM 决定谁可以登录您的计算机。用 PAM 限制访问 现在，我们来使用 PAM 限制谁可以连接您的服务器。必须编辑 /etc/pam.d/sshd 文件，让它像清单 3 这样。清单 3. 在 sshd PAM 文件中添加 pam_access.so1234567 #%PAM-1.0account include common-accountaccount required pam_access.soauth include common-authauth required pam_nologin.sopassword include common-passwordsession include common-session 在 sshd PAM 文件中添加 pam_access.so，就可以轻松地定义谁可以使用 SSH 连接您的计算机。pam_access.so 模块实现基于 /etc/security/access.conf 文件的安全控制，见清单 4。清单 4. 通过使用 pam_access.so，定义谁可以或不可以使用 SSH1234 : ALL : 192.168.1. : jack : ALL : jill : ALL : ALL : ALL 第一行允许任何用户 (ALL) 从内部网络登录。后两行允许用户 jack 和 jill 从任何地方访问服务器。最后一行拒绝其他任何用户从其他任何地方访问。允许多个用户访问的另一种方法是使用 pam_listfile.so，这需要创建一个允许访问的用户列表（例如 /etc/ssh_users）。在 /etc/pam.d/sshd 文件中添加以下行：12 auth required pam_listfile.so item=user sense=allow file=/etc/ssh_users onerr=fail 这还没有完。必须修改 /etc/ssh/sshd_config 文件，让它使用 PAM。在此文件中添加 UsePAM yes 行，重新启动 sshd 守护进程，这样就行了！究竟是否有门？ 即使应用了前两节中的方法，无论您怎么预防，黑客仍然会尝试穿越您系统中任何开放的门户。改变 SSH 端口号对于经验丰富的黑客只能造成小小的麻烦。限制允许访问的用户会有帮助，但前提是没有用户落入黑客或社会工程攻击的圈套而泄露密码。无论如何，只要您的系统中有门，就会吸引黑客。 增强计算机安全性的最后一种方案是最激进的：关闭打开的端口，这会让任何攻击都无法攻破您的计算机。只向能够提供 “秘密敲门暗号” 的用户开放所需的端口，让用户能够输入密码并访问计算机。 这种技术称为端口敲门，适用于需要访问不向公众开放的服务器的用户。服务器可以关闭所有端口，直到用户提供一个秘密的敲门序列 （序列很容易实现，而且需要的资源不多）。 打开秘密端口之后，应用常用的安全机制（比如密码或证书）。只需在防火墙级上提供一个额外的安全层，需要秘密端口的所有服务就会正常工作。 这种方法的要点在于关闭所有端口并监视外部连接尝试。当识别出预定义的尝试序列（称为敲门序列 ）时，可以执行打开端口等操作，让外部的用户能够进来。敲门序列的复杂程度由您决定，从简单的列表（比如依次尝试 TCP 端口 7000、UDP 端口 7100 和 TCP 端口 7200）到一次性序列集合都可以。（按密码学术语来说，一次性序列与 “一次一密” 相似，这是已知最安全的加密方法。）外面的用户必须知道使用 SSH 所需的端口号和密码，还必须知道打开端口并启用密码所需的敲门序列。如果没有这个序列，连接尝试就会静悄悄地失败。 这为什么是非常安全的方案？因为有 65,535 个端口（见 参考资料）。即使考虑到已经分配的端口，仍然有超过 60,000 个可用端口。如果敲门序列只包含四次 “敲门”，黑客要想通过强力攻击猜出序列，就必须测试大约 13,000,000,000,000,000,000 个序列（13 后面 18 个零）。这样的攻击显然不太可能奏效！当然，强力攻击或胡乱猜测并不是猜出正确序列的惟一方法。因此，不要只使用单一安全方法；而是使用一系列安全层来增加攻击的难度。 必须安装敲门守护进程 knockd；它监视敲门序列，当发现有效的序列时执行相应的操作。如果愿意，可以从头构建它，但是大多数（如果不是所有的话）发行版中都有这个包。最好使用包管理工具安装它。例如，在 OpenSUSE 中，可以使用 Yast2 或通过执行 sudo zypper install knockd 安装它。在 Ubuntu 中可以使用 sudo apt-get install knockd，在 Debian 中使用 sudo aptitude install knockd。用发行版的软件安装工具搜索 knockd 往往能够找到它。 安装这个包之后，必须编辑 /etc/knockd.conf 文件以指定端口敲门规则，然后启动守护进程。为了完成所需的设置，必须了解您的防火墙的工作方式。例如，在 OpenSUSE 中，可以使用 清单 5 这样的设置。清单 5. 针对 OpenSUSE 防火墙设计的示例配置文件1234567 [opencloseSSH] sequence= 7000,8000,9000 tcpflags= syn seq_timeout= 15 cmd_timeout= 30 start_command= /usr/sbin/iptables -s %IP% -I input_ext 1 -p tcp –dport 22960 -j ACCEPT stop_command= /usr/sbin/iptables -s %IP% -D input_ext -p tcp –dport 22960 -j ACCEPT 这个示例在用户依次在端口 7000、8000 和 9000 上敲门之后启用 SSH 访问。 在启动 knockd 之前，关闭端口 22960 并尝试远程登录。这个尝试应该会失败，见清单 6。清单 6. 如果禁用 SSH 访问而且不启动敲门守护进程，登录尝试会失败12 ssh the.url.for.your.site -p 22960 -o ConnectTimeout=15ssh: connect to host the.url.for.your.site port 22960: Connection timed out 现在，使用 sudo /etc/init.d/knockd start 或 sudo knockd -d 启动端口敲门守护进程（这两个命令是等效的），然后再试一下；端口敲门序列要求在端口 7000、8000 和 9000 上敲门。必须在 15 秒内完成这个序列。识别出序列之后端口打开，必须在 30 秒内登录。否则，端口再次关闭。 为了检验这个过程，回到您的远程机器上并登录。这一次提供所需的敲门序列，见 清单 7。注意，在安装 knockd 时通常也会安装 knock 命令。如果不是这样，只需用发行版的包管理工具搜索它。清单 7. 提供所需的敲门序列之后登录成功12345 knock the.url.for.your.site 7000knock the.url.for.your.site 8000knock the.url.for.your.site 9000ssh the.url.for.your.site -p 22960 -o ConnectTimeout=10Password: 如果提供了错误的敲门序列（或根本没有敲门），会收到 “Connection timed out” 消息，SSH 端口仍然完全关闭，看不出它是存在的。如果您处于路由器后面 如果您的服务器通过路由器连接 Internet，就必须修改它的配置。具体细节因路由器和防火墙类型而异，但是一般来说应该： 打开敲门端口并把数据包转发到您的计算机，让 knockd 能够识别并处理它们。 把端口 22960（SSH 连接使用的端口）上的数据包转发到您计算机上的端口 22960。 配置您计算机的防火墙，让它拒绝对端口 22960 和敲门端口的连接。 尽管路由器会打开一些端口，但是对它们的所有访问都会到达您计算机的防火墙。访问会被阻止，除非探测到正确的端口敲门序列。敲门配置 /etc/knockd.conf 文件有一个一般选项小节 options，希望使用的每个敲门序列各有一个小节。选项可以是大写、小写或大小写混合形式。 在默认情况下，knockd 监视 eth0 接口。要想使用另一个接口（例如 eth1），可以包含 Interface=eth1 行。注意，只使用设备名而不是设备的完整路径。 如果希望启用日志记录，可以通过包含 useSyslog 行使用标准的 Linux 日志文件，也可以通过包含 LogFile=/the/full/path/to/your/file 使用自己的文件。但是，应该认识到日志记录是一个漏洞；如果黑客获得了日志，入侵者就会掌握端口敲门序列。 如果希望能够检查 knockd 是否仍然在运行，那么包含 PidFile=/the/full/path/to/a/PID/file。这个守护进程的进程 ID (PID) 将存储在这个文件中。应该通过一个 cron 任务定期检查 knockd 是否仍然在运行并在需要时重新启动它。注意，当这个守护进程停止运行时，系统是安全的；所有端口关闭，不可访问。在守护进程重新启动之前，用户无法登录。 可以让 knockd 监听多个序列并以不同方式响应各个序列。在前面的示例中，让 knockd 打开 SSH 端口；可以简单地启用 HTTP 端口，让用户能够访问 web 服务器，也可以运行特定的进程。在配置文件中，每个序列都有相应的小节。 使用 sequence 定义敲门序列，比如 7000,8000,9000。在默认情况下，敲门使用 TCP，但是可以添加 UDP 以增加复杂性，比如 7000,8000:udp,9000。 除了使用固定的序列之外，还可以指定一个包含 “一次性序列” 的文件，这些序列在使用之后就会删除，不能再次使用。指定这种序列的方法如下： 1 one_time_sequences=/the/full/path/to/a/sequences/file 使用任何文本编辑器创建此文件；其中每行包含一个序列（按照上面所示的格式）。应该在远程计算机上保存此文件的拷贝以便记住如何登录。 可以指定应该扫描哪些到达的 TCP 数据包，丢弃不与 ACK、FIN、PSH、RST、SYN 或 URG 标志匹配的数据包。对于 SSH 连接，应该使用 TCPFlags=SYN。 可以用 Seq_Timeout=seconds.to.wait 指定完成一个序列的最大时间。如果在此时间内没有输入完整的序列，就不会识别出它，访问被拒绝。 可以用 Cmd_Timeout=seconds.to.wait 指定在识别出序列之后用户执行第二个命令的最大时间。如果提供了敲门序列的用户没有快速地输入下一个命令（例如登录），端口会再次关闭。 最重要的参数是 Start_command=some.command.to.execute，它指定成功地识别出敲门序列之后要执行的命令或脚本。如果需要引用敲门者的 IP 地址（例如为了允许从他的计算机连接您的计算机），可以使用 %IP%。在运行时，它会替换为正确的值。在上面的示例中指定： 1 /usr/sbin/iptables -s %IP% -I input_ext 1 -p tcp --dport 22960 -j ACCEPT iptables 向提供敲门序列的 IP 地址上的用户开放端口 22960。 另一个重要的参数是 Stop_command=some.command.to.execute；当超过 Cmd_timeout 时间之后，执行它指定的命令或脚本。 在这里，因为只希望打开或关闭端口 22960，所以使用单一命令就够了。如果需要更复杂的操作，可以通过调用脚本执行所需的任何操作 — 操作甚至可以完全不涉及打开端口。可以触发任何操作，比如运行进程或执行备份。当然，了解要使用的命令可能有点儿难度。例如，因为我运行 OpenSUSE，它提供自己的防火墙前端，所以我不得不通过查看 iptables -l 的输出了解应该执行哪个命令来打开或关闭端口 22960。 对于 knockd 本身，有几个选项需要考虑： -c：允许指定默认配置文件 /etc/knockd.conf 之外的另一个配置文件 -d：让 knockd 作为后台守护进程运行，这是标准运行方式 -D：提供输出调试消息 -h：提供关于语法和选项的帮助 -i：允许指定默认的 eth0 接口之外的其他接口 -l：为日志项启用 DNS 查找 — 这是一种不好的做法，因为这强迫计算机使用 DNS 通信流，会产生漏洞 -v：提供更详细的消息和解释 -V：提供程序的版本号 最后，可以使用多种方法产生敲门序列本身，编写 knock 命令是最简单的方法。 以下命令在 TCP 端口 7000 上敲门：1 knock the.url.for.your.site 7000 以下命令在 UDP 端口 8000 上敲门：1 knock the.url.for.your.site -u 8000 或1 knock the.url.for.your.site 8000:udp -h 参数提供这个命令的帮助。结束语 您看到了三种保护 SSH 访问的方法：修改 sshd 的配置参数，通过 PAM 限制可以登录的用户，以及使用端口敲门序列隐藏存在 SSH 访问的事实。尽管没有任何方法能够完全保护任何计算机，但是采取这三个措施会让您的服务器安全一些。]]></content>
      <categories>
        <category>linux</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WordPress Nginx 安全配置 – 禁用某些目录执行PHP]]></title>
    <url>%2Fnginx%2Fwordpress%2FWordPress%20Nginx%20%E5%AE%89%E5%85%A8%E9%85%8D%E7%BD%AE%20%E2%80%93%20%E7%A6%81%E7%94%A8%E6%9F%90%E4%BA%9B%E7%9B%AE%E5%BD%95%E6%89%A7%E8%A1%8CPHP%2F</url>
    <content type="text"><![CDATA[以下我们将介绍Wordpress Nginx 安全配置：禁用某些目录执行PHP，详细说明查看如下配置信息： server { listen 80; server_name website.com; # Redirect non-www to www (website.com -&gt; www.website.com) return 301 http://www.$server_name$request_uri; } server { listen 80; server_name www.website.com; access_log /var/www/website.com/logs/access.log main; error_log /var/www/website.com/logs/error.log warn; root /var/www/website.com/public/htdocs; index index.html index.htm index.php; # 日志不记录 robots.txt location = /robots.txt { log_not_found off; access_log off; } # 如果没有 favicon 文件则退出并返回 204 (没有错误内容) location ~* /favicon\.ico$ { try_files $uri =204; expires max; log_not_found off; access_log off; } # 以下格式文件日志不需要记录 location ~* \.(js|css|png|jpg|jpeg|bmp|gif|ico)$ { expires max; log_not_found off; access_log off; # Send the all shebang in one fell swoop tcp_nodelay off; # Set the OS file cache open_file_cache max=1000 inactive=120s; open_file_cache_valid 45s; open_file_cache_min_uses 2; open_file_cache_errors off; } # http://wiki.nginx.org/WordPress # 设置静态地址必须要添加的配置 # 如果你后台添加了固定链接，则需要添加以下配置 location / { try_files $uri $uri/ /index.php?$args; } # 禁止访问 htaccess 文件 location ~ /\. { deny all; } # nocgi cgi等可执行的，不允许 location ~* \.(pl|cgi|py|sh|lua)\$ { return 444; } #禁止访问 wp-config.php install.php 文件 location = /wp-config.php { deny all; } location = /wp-admin/install.php { deny all; } # 禁止访问 /wp-content/ 目录的 php 格式文件 (包含子目录) location ~* ^/wp-content/.*.(php|phps)$ { deny all; } # 允许内部分 wp-includes 目录的 .php 文件 location ~* ^/wp-includes/.*\.(php|phps)$ { internal; } # 禁止访问 /wp-content/ 目录的以下文件格式 (包含子目录) location ~* ^/wp-content/.*.(txt|md|exe)$ { deny all; } # 禁止uploads、images目录下面的所有php、jsp访问 location ~ ^/(uploads|images)/.*\.(php|php5|jsp)$ { deny all; #return 403; } # 禁止访问目录 /conf/* location ^~ /conf/ { deny all; } # 注意：上述/conf/后面的斜杠不能少，否则所有以conf开头的目录或文件都将禁止访问。 ## 禁止访问任何目录下的.sql文件，禁止浏览器访问 location ~.*\.sql { deny all; } # 这样，任一目录的sql文件都不会被用户访问到了。 # 处理 .php 文件 location ~ \.php$ { try_files $uri =404; fastcgi_split_path_info ^(.+\.php)(/.+)$; include /etc/nginx/fastcgi_params; fastcgi_connect_timeout 180s; fastcgi_send_timeout 180s; fastcgi_read_timeout 180s; fastcgi_intercept_errors on; fastcgi_max_temp_file_size 0; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_index index.php; } # 限制登陆和管理IP地址 location ~ ^/(wp-admin|wp-login\.php) { allow 1.2.3.4; deny all; ## 下面是fastcgi 方式 index index.php index.html index.htm; fastcgi_index index.php; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; ## 下面是代理方式的设置 proxy_pass http://apachebackend; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # wordpress 重写规则 rewrite ^/sitemap_index\.xml$ /index.php?sitemap=1 last; rewrite ^/([^/]+?)-sitemap([0-9]+)?\.xml$ /index.php?sitemap=$1&amp;sitemap_n=$2 last; # Add trailing slash to */wp-admin requests rewrite /wp-admin$ $scheme://$host$uri/ permanent; # 403页面配置 error_page 403 http://cdn-home.mimvp.com/404.html; # 指定CDN页面 error_page 403 404.html; # 指定当前项目根目录下的404.html文件 }]]></content>
      <categories>
        <category>nginx</category>
        <category>wordpress</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx设置连接限制和限制白名单]]></title>
    <url>%2Fnginx%2Fsecurity%2Fnginx%E8%AE%BE%E7%BD%AE%E8%BF%9E%E6%8E%A5%E9%99%90%E5%88%B6%E5%92%8C%E9%99%90%E5%88%B6%E7%99%BD%E5%90%8D%E5%8D%95%2F</url>
    <content type="text"><![CDATA[要求设置ip白名单，需用到nginx geo 与 nginx map nginx默认加载了ngx-http-geo-module和ngx-http-map-module相关内容； ngx-http-geo-module可以用来创建变量，变量值依赖于客户端 ip 地址; ngx-http-map-module可以基于其他变量及变量值进行变量创建，其允许分类，或者映射多个变量到不同值并存储在一个变量中； Nginx geo 格式说明 Syntax ( 语法格式 ): geo [$address] $variable { ... } Default ( 默认 ): - Content ( 配置段位 ): http Nginx map 格式说明 Syntax ( 语法格式 ): map String $variable { ... } Default ( 默认 )：- Content ( 配置段位 ): http 开启nginx连接限制对指定请求路径不设置限制，如对请求路径为api目录下的请求不做限制，则可写为 server{ location /app { proxy_pass http://192.168.1.111:8095/app; limit_conn conn 50; limit_rate 500k; limit_req zone=foo burst=5 nodelay; } location /app/api { proxy_pass http://192.168.1.111:8095/app/api } } # 因nginx会优先进行精准匹配，所以以上写法即接触了对api目录下属路径的限制 白名单配置示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657http&#123; # ... 其他配置内容 ################################## ## /etc/nginx/http.d/map.conf #定义白名单ip列表变量 geo $whiteiplist &#123; default 1; 10.250.250.0/24 0; 127.0.0.1 0; &#125; #使用map指令映射将白名单列表中客户端请求ip为空串 map $whiteiplist $limit&#123; 1 $binary_remote_addr ; 0 ""; &#125; ################################## ## /etc/nginx/http.d/limit.conf ## 配置前端代理，获取客户端真实IP real_ip_header X-Forwarded-For; set_real_ip_from 139.219.193.17; #set_real_ip_from 0.0.0.0/0; #real_ip_recursive on; # $limit defined in /etc/nginx/http.d/map limit_conn_zone $limit zone=conn:30m; limit_conn_status 444; limit_conn_log_level info; limit_req_zone $limit zone=perip:30m rate=5r/s; limit_req_status 444; limit_req_log_level info; ################################## server&#123; location /app &#123; ## 单IP同时连接数限制 limit_conn conn 5; ## 单IP单位时间内请求数限制 limit_req zone=perip burst=5 nodelay; ##每个请求最大传输速率 limit_rate 500k; proxy_pass http://192.168.1.111:8095/app; &#125; &#125;&#125; 白名单配置可用于对合作客户，搜索引擎等请求过滤限制 特殊情况处理1234567891011121314151617181920212223242526272829303132333435363738394041#如果想仅限制指定的请求，如：只限制Post请求，则：http&#123; # 其他请求.. #请求地址map映射 map $request_method $limit &#123; default ""; POST $binary_remote_addr; &#125; #限制定义 limit_req_zone $limit zone=perip:20m rate=10r/s; server&#123; ... #与普通限制一致 limit_req zone=perip burst=5 nodelay; &#125;&#125;#在此基础上，想进行指定方法的白名单限制处理，则：http&#123; #... #定义白名单列表 map $whiteiplist $limitips&#123; 1 $binary_remote_addr; 0 ""; &#125; #基于白名单列表，定义指定方法请求限制 map $request_method $limit &#123; default ""; # POST $binary_remote_addr; POST $limitips; &#125; #限制定义 limit_req_zone $limit zone=perip:20m rate=10r/s; #在server中进行引用 server&#123; #... 与普通限制相同 limit_req zone=perip burst=5 nodelay; &#125;&#125;]]></content>
      <categories>
        <category>nginx</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用NGINX的GeoIp库做国外ip屏蔽]]></title>
    <url>%2Fnginx%2Fsecurity%2F%E7%94%A8NGINX%E7%9A%84GeoIp%E5%BA%93%E5%81%9A%E5%9B%BD%E5%A4%96ip%E5%B1%8F%E8%94%BD%2F</url>
    <content type="text"><![CDATA[安装GeoIp模块12345678910111213141516171819## 安装模块，nginx也是通过yum安装yum install nginx-module-geoip## 安装对应nginx 版本的 模块yum --showduplicate list nginx-module-geoipnginx-module-geoip.x86_64 1:1.12.0-1.el7.ngx nginxnginx-module-geoip.x86_64 1:1.12.1-1.el7.ngx nginxnginx-module-geoip.x86_64 1:1.12.2-1.el7_4.ngx nginxnginx-module-geoip.x86_64 1:1.14.0-1.el7_4.ngx nginxyum install nginx-module-geoip-1:1.12.2-1.el7_4.ngx.x86_64ls /usr/lib64/nginx/modules/ngx_http_geoip_module-debug.so ngx_http_geoip_module.so ngx_stream_geoip_module-debug.so ngx_stream_geoip_module.so 下载ip库本地下载GeoIP库 123456789101112131415## 下载ip库信息文件并放在/etc/nginx/geoip/目录mkdir -p /etc/nginx/geoip/## 旧版本库，官网将在201902停止提供下载wget http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz -O /etc/nginx/geoip/GeoIP.dat.gzwget http://geolite.maxmind.com/download/geoip/database/GeoLiteCity.dat.gz -O /etc/nginx/geoip/GeoLiteCity.dat.gz## 新版数据库不支持，第三方插件地址: https://github.com/leev/ngx_http_geoip2_modulewget http://geolite.maxmind.com/download/geoip/database/GeoLite2-Country.tar.gz -O /etc/nginx/geoip/GeoLite2-Country.tar.gzwget http://geolite.maxmind.com/download/geoip/database/GeoLite2-City.tar.gz -O /etc/nginx/geoip/GeoLite2-City.tar.gzgunzip /etc/nginx/geoip/GeoIP.dat.gz gunzip /etc/nginx/geoip/GeoLiteCity.dat.gz 修改nginx配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061vi /etc/nginx/nginx.conf## 模块加载最好放在顶部，必须放在event配置项前面，否则报错load_module modules/ngx_http_geoip_module.so;#load_module modules/ngx_stream_geoip_module.so;......http&#123; geoip_country /etc/nginx/geoip/GeoIP.dat; #不按城市划分，就不需要加载 #geoip_city /etc/nginx/geoip/GeoLiteCity.dat; ## 如果前端有反向代理的话 #geoip_proxy 192.168.100.0/24; #geoip_proxy 2001:0db8::/32; #geoip_proxy_recursive on; ## 用于php-fpm fastcgi_param GEOIP_COUNTRY_CODE $geoip_country_code; fastcgi_param GEOIP_COUNTRY_CODE3 $geoip_country_code3; fastcgi_param GEOIP_COUNTRY_NAME $geoip_country_name; server &#123; listen 80; server_name localhost; location / &#123; set $adminflag 0; if ( $request_uri ~* "/+(downloader|admin)" ) &#123; set $adminflag 1; #rewrite ^/(.*)$ $scheme://$host/myip permanent; &#125; if ( $geoip_country_code != CN ) &#123; set $adminflag "$&#123;adminflag&#125;1"; #return 301 $scheme://$host/myip; &#125; if ( $adminflag = "11" ) &#123; return 403; &#125; root /usr/share/nginx/html; index index.html index.htm; &#125; location /myip &#123; default_type text/plain; return 200 "$remote_addr $geoip_country_name $geoip_country_code $geoip_city"; &#125; &#125;&#125; GeoIP参数http://nginx.org/en/docs/http/ngx_http_geoip_module.html Syntax: geoip_country file; Default: — Context: http Specifies a database used to determine the country depending on the client IP address. The following variables are available when using this database: $geoip_country_code two-letter country code, for example, “RU”, “US”. $geoip_country_code3 three-letter country code, for example, “RUS”, “USA”. $geoip_country_name country name, for example, “Russian Federation”, “United States”. Syntax: geoip_city file; Default: — Context: http Specifies a database used to determine the country, region, and city depending on the client IP address. The following variables are available when using this database: $geoip_area_code telephone area code (US only). This variable may contain outdated information since the corresponding database field is deprecated. $geoip_city_continent_code two-letter continent code, for example, “EU”, “NA”. $geoip_city_country_code two-letter country code, for example, “RU”, “US”. $geoip_city_country_code3 three-letter country code, for example, “RUS”, “USA”. $geoip_city_country_name country name, for example, “Russian Federation”, “United States”. $geoip_dma_code DMA region code in US (also known as “metro code”), according to the geotargeting in Google AdWords API. $geoip_latitude latitude. $geoip_longitude longitude. $geoip_region two-symbol country region code (region, territory, state, province, federal land and the like), for example, “48”, “DC”. $geoip_region_name country region name (region, territory, state, province, federal land and the like), for example, “Moscow City”, “District of Columbia”. $geoip_city city name, for example, “Moscow”, “Washington”. $geoip_postal_code postal code.]]></content>
      <categories>
        <category>nginx</category>
        <category>security</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx 日志记录]]></title>
    <url>%2Fnginx%2Flog%2Fnginx%20%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[日志语法参考: http://nginx.org/en/docs/http/ngx_http_log_module.html Syntax: access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; access_log off; Default: access_log logs/access.log combined; Context: http, server, location, if in location, limit_except 使用geo不记录特定IP请求的日志ngx_http_geo_module模块可以用来创建变量，其值依赖于客户端IP地址。 geo指令使用ngx_http_geo_module模块提供的。 默认情况下，nginx有加载这个模块，除非人为的 --without-http_geo_module。 ngx_http_geo_module模块可以用来创建变量，其值依赖于客户端IP地址。 geo指令语法: geo [$address] $variable { ... } 默认值: — 配置段: http 定义从指定的变量获取客户端的IP地址。 默认情况下，nginx从$remote_addr变量取得客户端IP地址，但也可以从其他变量获得。如$realip_remote_addr. geo $realip_remote_addr $loggable{ default 1; 10.250.250.0/24 0; 139.219.188.72 0; 139.219.187.55 0; 127.0.0.1 0; } access_log /data/wwwlogs/nginx_access.log main buffer=32k flush=5 if=$loggable; access_log on; 如果该变量([$address])的值不能代表一个合法的IP地址，那么nginx将使用地址“255.255.255.255”。 nginx通过CIDR或者地址段来描述地址，支持下面几个参数： delete：删除指定的网络 default：如果客户端地址不能匹配任意一个定义的地址，nginx将使用此值。 如果使用CIDR，可以用“0.0.0.0/0”代替default。没指定default，默认值将为空字符串。 include： 包含一个定义地址和值的文件，可以包含多个。 proxy：定义可信地址。 如果请求来自可信地址，nginx将使用其“X-Forwarded-For”头来获得地址。 相对于普通地址，可信地址是顺序检测的。 proxy_recursive：开启递归查找地址。 如果关闭递归查找，在客户端地址与某个可信地址匹配时，nginx将使用“X-Forwarded-For”中的最后一个地址来代替原始客户端地址。如果开启递归查找，在客户端地址与某个可信地址匹配时，nginx将使用“X-Forwarded-For”中最后一个与所有可信地址都不匹配的地址来代替原始客户端地址。 ranges：使用以地址段的形式定义地址，这个参数必须放在首位。为了加速装载地址库，地址应按升序定义。 示例： geo $country { default ZZ; include conf/geo.conf; delete 127.0.0.0/16; proxy 192.168.100.0/24; proxy 2001:0db8::/32; 127.0.0.0/24 US; 127.0.0.1/32 RU; 10.1.0.0/16 RU; 192.168.1.0/24 UK; } vim conf/geo.conf 10.2.0.0/16 RU; 192.168.2.0/24 RU; 地址段例子： geo $country { ranges; default ZZ; 127.0.0.0-127.0.0.0 US; 127.0.0.1-127.0.0.1 RU; 127.0.0.1-127.0.0.255 US; 10.1.0.0-10.1.255.255 RU; 192.168.1.0-192.168.1.255 UK; } geo指令主要是根据IP来对变量进行赋值的。因此geo块下只能定义IP或网络段，否则会报错。 使用map来过滤日志记录Nginx map 格式说明 Syntax ( 语法格式 ): map String $variable { ... } Default ( 默认 )：- Content ( 配置段位 ): http map $status $loggable { ~^[23] 0; default 1; } access_log /path/to/access.log combined if=$loggable; 一个简单的geo区域负载示例http { ..... geo $geo { default default; 192.168.6.189/32 uk; 192.168.6.8/32 us; # 192.168.0.0/24 tw } upstream uk.server { server 192.168.6.101; } upstream us.server { server 192.168.6.102; } upstream default.server { server 192.168.6.121:8080; } sendfile on; keepalive_timeout 65; server { listen 80; server_name 192.168.6.121; index index.html index.htm; root html; location / { proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://$geo.server$request_uri; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 8080; server_name 192.168.6.121; location / { root html; index index.html index.htm; } } }]]></content>
      <categories>
        <category>nginx</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 多下级目录配置]]></title>
    <url>%2Fhexo%2FHexo%20%E8%99%9A%E6%8B%9F%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[使用注意# 发布和预览运行时都需要先清空，不然会文章融合在一起, 搜索也会不能用 # 下级目录一定要添加参数: --config &lt;下级配置文件&gt; # 主目录运行 hexo clean hexo server -d # 下级目录运行 hexo --config life.yml clean hexo --config life.yml server -d 发布流程# 先编译 hexo clean &amp;&amp; hexo generate hexo --config life.yml clean &amp;&amp; hexo --config life.yml generate # 再将下级目录编译的静态文件夹移到主目录，这里将public 下的 life 移到 work 下 # 最后发部主目录 hexo deploy 根目录设置根目录./work 配置文件_config.yml1234567891011121314151617181920# Sitetitle: 克隆人战争subtitle: 为了生存, 为了利益,&lt;br/&gt;争斗才是人类历史的主旋律！description: 现实是强者理想的实现keywords:author: dolphinlanguage: zh-CNtimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://dolphincn.github.ioroot: /permalink: :title/permalink_defaults:# Directorysource_dir: workpublic_dir: public/work 子目录设置子目录./life 配置文件life.yml123456789101112131415161718192021# Sitetitle: 克隆人战争subtitle: 为了生存, 为了利益,&lt;br/&gt;争斗才是人类历史的主旋律！description: 现实是强者理想的实现keywords:author: dolphinlanguage: zh-CNtimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: http://dolphincn.github.io/liferoot: /life/permalink: :title/permalink_defaults:# Directorysource_dir: lifepublic_dir: public/life]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xcopy 备份文件夹]]></title>
    <url>%2Fwindows%2Fbackup%2Fxcopy%20%E5%A4%87%E4%BB%BD%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[基本使用创建 backup.bat文件，文件编码格式为ANSI，内容如下 @echo off echo 正在复制&quot;C:\a&quot;文件夹的内容至&quot;D:\b&quot;文件夹下...... xcopy &quot;C:\c&quot; &quot;D:\d&quot; /e/I/d/h/r/y exit 参数说明： /e：拷贝所有子目录，包括空子目录； /I： 如果目标文件或目录不存在且拷贝的文件数多于一，则假设目标为目录； /d：只拷贝文件日期与在目标文件后的文件（即修改过的源文件） /h：同时拷贝隐藏文件和系统文件 /r：拷贝并覆盖只读文件 /y： 复制文件审核设置（不显示已有文件覆盖确认） Xcopy命令详解为了节省时间，可以使用Copy、Xcopy、Xcopy32等命令把数据备份到其他硬盘或分区。 其中用的最多的是“Xcopy”，它的功能非常强大，使用这个命令可以拷贝一个目录中的所有文件，包括该目录中所有子目录中的全部文件（DOS7.0以后的Xcopy甚至可以拷贝隐藏文件）。 其语法为：XCOPY source [destination] [/Y][/-Y] [/A | /M] [/D[:date]] [/P] [/S [/E]] [/W][/C] [/I] [/Q] [/F] [/L] [/H] [/R] [/T] [/U][/K] [/N] 参数介绍： /A 拷贝文件，但不改变文件的存档属性。 /M 拷贝文件，同时关闭文件的存档属性。 /D: 拷贝指定日期以后文件。如果没有给出指定日期，仅拷贝比目标文件更新的文件。 /P 在建立每一目标文件时进行提醒。 /S 拷贝当前目录和所有子目录下的所有文件，但不包括空目录。 /E 拷贝当前目录和所有子目录下的所有文件，同时也包括空目录。 /W 在拷贝文件前提示你按任意键确认。 /C 即使有错误发生也继续拷贝。 /Q 在拷贝文件时不显示文件名。 /F 在拷贝时显示所有源文件和目标文件名。 /L 显示被拷贝的文件。 /H 拷贝隐含文件和系统文件。 /R 覆盖只读文件。 /T 建立目录，但不拷贝文件，但不包括空目录和空的子目录。 /T /E 命令包括空的目录和子目录。 /U 更新已经存在的目标文件。 /K 拷贝文件属性。一般来说XCOPY命令将重置只读文件属性。 /Y 不给出提示信息直接覆盖已经存在的文件。 /-Y 在覆盖已经存在的文件时给出提示信息。 /N 拷贝短文件名，即8.3格式的文件。 比如要将d:\xly下所有文件备份到e:\xly1，可以使用如下命令： xcopy d:\xly*.*/s/h e:\xly1 又比如，要恢复e:\xly1下2006年6月1日以后的文件至D:\xly，就可使用如下命令： xcopy e:\xly1*.*/s/h/d:2006-06-01 d:\xly]]></content>
      <categories>
        <category>windows</category>
        <category>backup</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>backup</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode git hexo 配合使用]]></title>
    <url>%2Fhexo%2Fvscode%20git%20hexo%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概况安装vscode 安装git客户端 安装nodejs v8 添加nodejs环境变量 通过npm 安装 hexo 下载安装 vscodehttps://code.visualstudio.com 下载安装 githttps://git-scm.com/download/win https://github.com/git-for-windows/git/releases/download/v2.17.1.windows.2/Git-2.17.1.2-64-bit.exe https://github.com/git-for-windows/git/releases/download/v2.17.1.windows.2/PortableGit-2.17.1.2-64-bit.7z.exe portable 版本，只需解压，在window环境变量里添加 解压路径\Git\cmd 12345678910111213141516171819202122232425262728293031安装版，只需命令行的，安装步骤如下：选择安装组件：可以全不选，或只选 桌面浏览（Windows Explorer integration） 使用Git Bash方式，shell方式是否创建开始菜单快捷方式目录:否设置环境，选择使用什么样儿的命令行工具，一般情况我们使用默认配置，使用Git Bash Git自带：使用Git自带的Git Bash命令行工具设置HTTPS 传输加密方式，点击【Next &gt;】 使用OpenSSL库选择换行格式，点击【Next &gt;】：下面选第一个 让Git能够自动转换文件中的换行符：签出到本地时转换为Windows下的换行符，提交到服务器时转换为Unix下的换行符 让Git在签出到本地时不做转换，保留原始文件的换行符；提交到服务器时转换为Unix下的换行符 让Git在签出到本地时和提交到服务器时都不做转换配置Git bash终端仿真器，点击【Next &gt;】：最好选第二个 使用MinTTY终端 使用windows默认的命令行性能配置，是否启用文件系统缓存，点击【Next &gt;】开始安装 git 环境变量配置安装成功后需要配置Git环境变量 「注意该步骤为Git在windows cmd命令中配置，如果不配置，直接使用Git Bash即可」 在Path变量中增加：C:\Program Files\Git\cmd 验证是否配置成功，打开windows命令行，输入git version命令，出现下列信息表示配置成功。 git config --global user.name dolphincn git config --global user.email share2030cn@126.com 下面三行可以不操作 git config --global push.default matching git config --global core.quotepath false git config --global core.editor &quot;vim&quot; 添加ssh 密钥添加github ssh 登陆密钥， 打开cmd，运行mkdir .ssh， 在当前用户的home目录下创建.ssh目录，把密钥复制进去. 密钥可以用ssh-key 或 GitHub上生成，私钥和公钥名字分别为：id_rsa id_rsa.pub 检验是否能连上了github，windows 命令行下运行，前提配置了git环境变量 $ ssh git@github.com 初始化git目录$ mkdir tmp //创建推送目录 $ cd tmp //进入推送目录 $ git init //设置该目录为推送 $ touch README //生成readme $ git add . //加入修改的文件 $ git commit -m &apos;first commit&apos; //递交修改声明 $ git remote add local git@github.com:abcd/tmp.git //将本地local 和github关联 $ git push local master //将本地文件推送到github $ git pull master local //将github拉到本地 参考：https://www.yiibai.com/git/ 下载安装nodejs:https://nodejs.org/dist/v8.11.3/node-v8.11.3-x64.msi hexo 在windows 上安装安装hexo之前必须先安装git nodejs 在本地新建一个Blog文件夹，文件右键，选择Git Bash 创建hexo blog 目录 $ mkdir c:/hexo 打开git命令行输入： 全局安装hexo-cli $ npm install -g hexo-cli $ cd c:/hexo hexo 初始化目录 $ hexo init 在目录中安装 node_modules $ npm install 部署到github配置 按装本地搜索插件 $ npm install hexo-generator-searchdb --save 打开Hexo 站点的_config.yml,添加配置 search: path: search.xml field: all format: html limit: 10000 打开themes/next下的_config.yml,搜索关键字local_search,设置为true local_search: enable: true 安装hexo-deployer-git插件 $ npm install hexo-deployer-git --save 修改hexo本地网站配置文件 _config.yml # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git #部署环境，基于hexo+githubpage,所以这里使用git。注意：不同版本的hexo，type有可能不同，3.x以后应使用git,具体参看官方文档 repository: git@github.com:dolphincn/dolphincn.github.io.git #git仓库地址，替换成你的username即可，其他保持不变，后面会提到如何创建git仓库 branch: master 主题安装 安装主题和渲染器： $ cd /data/hexo_blog/ $ git clone --depth 1 https://github.com/theme-next/hexo-theme-next themes/next 编辑Hexo目录下的 _config.yml，将theme的值改为next 安装图片浏览器 $ rm -rf themes/next/source/lib/fancybox $ git clone --depth 1 https://github.com/theme-next/theme-next-fancybox3 themes/next/source/lib/fancybox 编辑next 主题配置文件 _config.yml: fancybox: true 安装书签保存插件 $ rm -rf themes/next/source/lib/bookmark $ git clone --depth 1 https://github.com/theme-next/theme-next-bookmark.git themes/next/source/lib/bookmark 编辑next 主题配置文件 _config.yml: bookmark: true 其它插件，如果需要可以安装 # npm install hexo-generator-feed --save # npm install hexo-generator-sitemap --save $ npm install hexo-generator-json-content --save Hexo 常用命令Hexo 安装升级 npm install hexo -g #安装 npm update hexo -g #升级 hexo init #初始化 常用简写 hexo n &quot;我的博客&quot; == hexo new &quot;我的博客&quot; #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 启动本地服务 hexo server #Hexo #会监视文件变动并自动更新，您无须重启服务器。 hexo server -s #静态模式 hexo server -p 5000 #更改端口 hexo server -i 192.168.1.1 #自定义 IP 监视文件变动 hexo generate #使用 Hexo 生成静态文件快速而且简单 hexo generate --watch #监视文件变动 hexo clean #清除缓存 网页正常情况下可以忽略此条命令 部署 #两个命令的作用是相同的 hexo generate --deploy hexo deploy --generate hexo deploy -g hexo server -g 草稿 # 新建草稿 hexo new draft &lt;title&gt; # 发布草稿为post hexo publish draft &lt;title&gt; 模板 hexo new &quot;postName&quot; #新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server） hexo deploy #将.deploy目录部署到GitHub hexo new [layout] &lt;title&gt; hexo new photo &quot;My Gallery&quot; hexo new &quot;Hello World&quot; --lang tw 写作时间 变量 描述 :title 标题 :year 建立的年份（4 位数） :month 建立的月份（2 位数） :i_month 建立的月份（去掉开头的零） :day 建立的日期（2 位数） :i_day 建立的日期（去掉开头的零） 自定义配置文件的路径 $ hexo --config custom.yml 安全模式,在安全模式下，不会载入插件和脚本。 $ hexo --safe 渲染文件 render $ hexo render &lt;file1&gt; [file2] ... 参数 描述 -o, --output 设置输出路径 hexo基本命令总结：每次部署的步骤，可按以下三步来进行： hexo clean hexo generate hexo deploy 命令总结 常用命令： hexo new &quot;postName&quot; #新建文章 hexo new mylayout &quot;postName&quot; #使用指定的layout模板新建文章 hexo new page &quot;pageName&quot; #新建页面 hexo generate #生成静态页面至public目录 hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭server） hexo server -p 80 -i 192.168.100.1 # 指定服务器端口和ip hexo deploy #将.deploy目录部署到GitHub hexo help #查看帮助 hexo version #查看Hexo的版本 复合命令： hexo deploy -g #生成加部署 hexo server -g #生成加预览 hexo server -s #使用已生成的静态文件预览 命令的简写为： hexo n == hexo new hexo g == hexo generate hexo s == hexo server hexo d == hexo deploy 备份source源文件windwos 10 下更新备份重要的文件到 icloud 目录下123456# 注意：是按时间来更新备份，所以需要系统时间正常xcopy "C:\share\hexo\source" "C:\Users\lion\iCloudDrive\hexo_blog\source" /e/c/I/d/r/yxcopy "C:\share\hexo\scaffolds" "C:\Users\lion\iCloudDrive\hexo_blog\scaffolds" /e/c/I/d/r/yxcopy "C:\share\hexo\*.yml" "C:\Users\lion\iCloudDrive\hexo_blog" /c/I/d/r/y 参考https://blog.csdn.net/dietime1943/article/details/71751007]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo渲染时排除部分文件或目录]]></title>
    <url>%2Fhexo%2FHexo%E6%B8%B2%E6%9F%93%E6%97%B6%E6%8E%92%E9%99%A4%E9%83%A8%E5%88%86%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[skip_render: - &apos;baidu.html&apos; - &apos;google.html&apos; - &apos;demo/other/3.html&apos; 只有source目录下的文件才会发布到public（能够在网络上访问到），因此Hexo只渲染source目录下的文件。 设置排除项skip_render参数设置的路径是相对于source目录的路径。 假设source目录下的文件如以下目录树所示 12345678910111213├─ demo| ├─ js-view-size| | ├─ 1.html| | └┈ 2.html| ├─ other| | ├─ 3.html| | ├─ 4.html| | └┈ 5.md| ├─ 6.html| └┈ 7.md├─ baidu.html└┈ google.html 排除单个文件排除baidu.html skip_render: &apos;baidu.html&apos; 排除3.html skip_render: &apos;demo/other/3.html&apos; 排除多个文件排除baidu.html和google.html skip_render: - &apos;baidu.html&apos; - &apos;google.html&apos; 或者 skip_render: &apos;*.html&apos; 后者会排除source目录下所有后缀为html的文件，但是不会排除子目录如demo及其子目录中的html文件。 排除baidu.html和google.html以及3.html skip_render: - &apos;baidu.html&apos; - &apos;google.html&apos; - &apos;demo/other/3.html&apos; 或者 skip_render: - &apos;*.html&apos; - &apos;demo/other/3.html&apos; 排除source/demo/other目录中的所有html文件 skip_render: &apos;demo/other/*.html&apos; 这不会排除5.md文件 排除source/demo/other目录中的所有文件 skip_render: &apos;demo/other/**&apos; 排除baidu.html和google.html以及整个source/demo目录 skip_render: - &apos;*.html&apos; - &apos;demo/**&apos;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 写作]]></title>
    <url>%2Fhexo%2FHexo%20%E5%86%99%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Front-matter文本开头都需要有下面类式格式标记1234567891011121314151617181920---title: ##文章标题date: ##时间，格式为 YYYY-MM-DD HH:mm:sscategories: ##分类tags: ##标签，多标签格式为 [tag1,tag2,...]keywords: ##文章关键词，多关键词格式为 keyword1,keywords2,...description: ##文章描述---正文示例：---title: Hexo 写作urlname: hexo_writingdate: 2018-06-18 10:44:15categories: hexotags: hexo--- 语法简明概述1234567891011121314151617分段 两个回车换行 两个空格 + 回车标题 # ~ ######，#号的个数表示几级标题，即表示一级标题到六级标题强调 **文字** ， __文字__ ， _文字_ ， *文字* ， 文字引用 &gt; 注意后面紧跟个空格表格 - 和 | 分割行和列 ， : 控制对其方式代码块 四个空格 开头或， 使用``` 代码内容 ```链接 [文字](链接地址)图片 ![图片说明](图片地址) ，地址可以是本地路劲，也可以是网络地址列表 * ， + ， - ， 1. ，选其中之一，注意后面紧跟个空格列表 ‘+’ 、 ‘-’ 用于无序列表，1.2.3.有序列表删除 ~~XXXXX~~分割线 三个以上的星号、减号、底线。（星号或是减号中间可以插入空格）兼容html，完全可以用html语言来书写如果需要在文档中显示一下Markdown语法相关的字符，可以在前面增加一个反斜杠 Read More 标记在首页里，文章自动截断，作为文章的简述，并添加read more. &lt;!-- more --&gt; 标题格式： # 欢迎使用Markdown编辑器写博客 //一级标题 对应 &lt;h1&gt; &lt;/h1&gt; ## 标题输入 //二级标题 对应 &lt;h2&gt; &lt;/h2&gt; ### 三级标题 //三级标题 对应 &lt;h3&gt; &lt;/h3&gt; #### 四级标题 //四级标题 对应 &lt;h4&gt; &lt;/h4&gt; ##### 五级标题 //五级标题 对应 &lt;h5&gt; &lt;/h5&gt; ###### 六级标题 //六级标题 对应 &lt;h6&gt; &lt;/h6&gt; ####### 七级标题 //抱歉，木有了（但是他会影响生成的目录，目录行多出一行空行） 另一种是在文字的下面加”=”（等号）或”-“（减号），分别表示一级和二级标题。 语法参考如下： 一级标题 ======== 二级标题 -------- 加粗、斜体斜体, 前后各加一个 *（星号）或 _（下划线）表示 粗体, 前后各加两个 *（星号）或 _（下划线）表示。 格式： *斜体* **加粗** ***加粗并斜体*** 删除线格式： ~~删除一段文本~~ 高亮格式： &lt;code&gt;高亮文字&lt;/code&gt; 引用显示格式： &gt; 每行开始都使用 &apos;&gt;&apos;； &gt; 引用**开始**； &gt; 引用**换行**； &gt; 引用**结束**。 &gt; 还在引用中！ 两个回车结束引用！ 省略使用格式： &gt; 仅第一行加应用； 引用**开始**； 引用**换行**； 引用**结束**； 两个回车结束引用,不在引用范围内了！ 嵌套使用格式： &gt; 动物 &gt;&gt; 水生动物 &gt;&gt; 陆生动物 &gt;&gt;&gt; 猴子 &gt;&gt;&gt; 人 &gt;&gt;&gt;&gt; 程序猿 &gt;&gt;&gt;&gt; 攻城狮 &gt;&gt;产品狗 //这里需要注意，没有空行间隔，忽略降级引用标记 射鸡虱 //这里需要注意，没有空行间隔，忽略降级引用标记 &gt;&gt; 两栖类动物 &gt;&gt;&gt; 大鳄鱼 唐老鸭 两个回车结束引用,不在引用范围内了！ 表格Markdown使用管线图的方式实现表格，如下表示一个简单的表格，注意表格的开头要空一行。 可以使用冒号来定义对齐方式： | 左对齐 | 右对齐 | 居中 | | :-------- | -------:| :--: | | Computer | 5000 元 | 1台 | | Phone | 1999 元 | 1部 | 代码块123456789使用 ``` 开始，后跟代码语言名，比如Python ， ``` 结束 例如：```Python#!/usr/bin/env python# -*- coding: utf-8 -*-print &apos;Hello World! ```如果需要包含```，那就需要用四个反引号(`) 分隔线在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西，中间可以插入空格 语法参考如下： *** * * * ********* - - - _________ 超链接[首页](http://zhuzhuyule.xyz) [我的信息](/about/) [纪念册](https://love.zhuzhuyule.xyz/) 自动链接首页:http://zhuzhuyule.xyz 我的信息:http://zhuzhuyule.xyz/about/ 纪念册:https://love.zhuzhuyule.xyz/ 包括在一对尖括号里的地址或邮箱，也会被Markdown自动处理为链接。 语法参考如下： 访问&lt;https://github.com/&gt; mailto: &lt;address@example.com&gt; 添加本地图片连接首先需在hexo根目录下创建source/images文件夹。 images前面必须加/,表示相对网站的根目录 格式： ![&quot;图片描述&quot;](/images/图片文件夹/图片文件名.jpg) 添加视频 注意：书写代码前面不能有空格或tab键，否则只显示文本。 html5 &lt;video&gt;标签，能自动适应长宽： &lt;video src=&apos;&apos; type=&apos;video/mp4&apos; controls=&apos;controls&apos; width=&apos;100%&apos; height=&apos;100%&apos; autoplay=&quot;autoplay&quot;&gt;&lt;/video&gt; 其中type 可以不填，参考： https://developer.mozilla.org/en-US/docs/Web/HTML/Supported_media_formats参考： https://developer.mozilla.org/en-US/docs/Web/HTML/Supported_media_formats iframe标签： &lt;iframe src=&quot;/images/video/Faded.mp4&quot; height=498 width=510 frameborder=0 allowfullscreen &gt;&lt;/iframe&gt; 视频插件： hexo-tag-dplayer： https://github.com/MoePlayer/hexo-tag-dplayer 添加音频 注意：书写代码前面不能有空格或tab键，否则只显示文本。 html5 &lt;audio&gt;标签 &lt;audio src=&apos;/images/hexo/hexo_writing/see_you_again.mp3&apos; controls=&apos;controls&apos;&gt;&lt;/audio&gt; iframe标签： &lt;iframe src=&quot; frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 &gt;&lt;/iframe&gt; 或者使用插件： hexo-tag-aplayer：https://github.com/grzhan/hexo-tag-aplayer HTML 5 video 标签属性现在如果要在页面中使用video标签，需要考虑三种情况， 支持Ogg Theora或者VP8（如果这玩意儿没出事的话）的（Opera、Mozilla、Chrome）， 支持H.264的（Safari、IE 9、Chrome） 都不支持的（IE6、7、8）。 Video标签的使用 Video标签含有src、poster、preload、autoplay、loop、controls、type、width、height等几个属性， 以及一个内部使用的标签&lt;source&gt;。 1) src属性和poster属性 src属性是用于指定视频的地址。 poster属性用于指定一张图片，在当前视频数据无效时显示（预览图）。视频数据无效可能是视频正在加载，可能是视频地址错误等等。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; poster=&quot;http://www.youname.com/images/first.png&quot; autoplay=&quot;autoplay&quot;&gt;&lt;/video&gt; 2) preload属性 此属性用于定义视频是否预加载。属性有三个可选择的值：none、metadata、auto。如果不使用此属性，默认为auto。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot;&gt;&lt;/video&gt; None：不进行预加载。使用此属性值，可能是页面制作者认为用户不期望此视频，或者减少HTTP请求。 Metadata：部分预加载。使用此属性值，代表页面制作者认为用户不期望此视频，但为用户提供一些元数据（包括尺寸，第一帧，曲目列表，持续时间等等）。 Auto：全部预加载。 3) autoplay属性 Autoplay属性用于设置视频是否自动播放，是一个布尔属性。当出现时，表示自动播放，去掉是表示不自动播放。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot;&gt;&lt;/video&gt; 注意： HTML中布尔属性的值不是true和false。 正确的用法是，在标签中使用此属性表示true，此时属性要么没有值，要么其值恒等于他的名字 （此处，自动播放为&lt;video autoplay /&gt;或者&lt;video autoplay=”autoplay” /&gt;）； 而在标签中不使用此属性表示false（此处不进行自动播放为&lt;video /&gt;）。 4) loop属性 loop属性用于指定视频是否循环播放，同样是一个布尔属性。 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; loop=&quot;loop&quot;&gt;&lt;/video&gt; 5) controls属性 &lt;video width=&quot;658&quot; height=&quot;444&quot; src=&quot;http://www.youname.com/images/first.mp4&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot; controls=&quot;controls&quot;&gt;&lt;/video&gt; Controls属性用于向浏览器指明页面制作者没有使用脚本生成播放控制器，需要浏览器启用本身的播放控制栏。 控制栏须包括播放暂停控制，播放进度控制，音量控制等等。 每个浏览器默认的播放控制栏在界面上不一样。 6) width属性和height属性 值最好都用100%，自动适应长宽 7) source标签 &lt;video width=&quot;658&quot; height=&quot;444&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot; controls=&quot;controls&quot;&gt; &lt;source src=&quot;http://www.youname.com/images/first.ogv&quot; /&gt; &lt;source src=&quot;http://www.youname.com/images/first.ogg&quot; /&gt; &lt;/video&gt; Source标签用于给媒体（因为audio标签同样可以包含此标签，所以这儿用媒体，而不是视频）指定多个可选择的（浏览器最终只能选一个）文件地址，且只能在媒体标签没有使用src属性时使用。 浏览器按source标签的顺序检测标签指定的视频是否能够播放（可能是视频格式不支持，视频不存在等等），如果不能播放，换下一个。此方法多用于兼容不同的浏览器。Source标签本身不代表任何含义，不能单独出现。 此标签包含src、type、media三个属性。 src属性：用于指定媒体的地址，和video标签的一样。 Type属性：用于说明src属性指定媒体的类型，帮助浏览器在获取媒体前判断是否支持此类别的媒体格式。 video/MP4 = 带有 H.264 视频编码和 AAC 音频编码的 MPEG 4 文件 video/WebM = 带有 VP8 视频编码和 Vorbis 音频编码的 WebM 文件 video/Ogg = 带有 Theora 视频编码和 Vorbis 音频编码的 Ogg 文件 参考： https://developer.mozilla.org/en-US/docs/Web/HTML/Supported_media_formats Media属性：用于说明媒体在何种媒介中使用，不设置时默认值为all，表示支持所有媒介。你想到&lt;style&gt;标签的media属性了么？一样一样一样的。 8) 一个完整的例子 &lt;video width=&quot;658&quot; height=&quot;444&quot; poster=&quot;http://www.youname.com/images/first.png&quot; autoplay=&quot;autoplay&quot; preload=&quot;none&quot; controls=&quot;controls&quot;&gt;&lt;source src=&quot;http://www.youname.com/images/first.ogv&quot; /&gt;&lt;source src=&quot;http://www.youname.com/images/first.ogg&quot; /&gt;&lt;/video&gt; 这段代码在页面中定义了一个视频，此视频的预览图为poster的属性值，显示浏览器的默认媒体控制栏，预加载视频的元数据，循环播放，宽度为900像素，高度为240像素。 第一选择视频地址为第一个source标签的src属性值，视频类别为Ogg视频，视频编码译码器为Theora，音频编码译码器为Vorbis，播放媒 介为显示器；第二选择视频地址不再累述。如果你还要兼容IE的话，可以在最后一个source标签后再加上Flash播放器的标签集，或者使用一点 JavaScript代码。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo nexT 主题安装配置]]></title>
    <url>%2Fhexo%2Fhexo%20nexT%20%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[安装更新hexo： npm update hexo 下载next主题 git clone --depth 1 https://github.com/theme-next/hexo-theme-next /data/hexo_blog/themes/next ## 升级 cd /data/hexo_blog/themes/next git pull ## 修改hexo 配置文件中的主题 /data/hexo_blog/_config.yml theme: next 创建菜单项对应文件目录,以分类、标签、关于为例 hexo new page categories hexo new page tags hexo new page about 选择 Scheme更改 NexT 主题配置文件 文件 /data/hexo_blog/themes/next/_config.yml 选择的 Scheme 主题前去掉 # (没有注释掉的就是当前选择主题) # Schemes #scheme: Muse #scheme: Mist #scheme: Pisces scheme: Gemini 配置搜索在你站点的根目录下 $ npm install hexo-generator-searchdb --save 打开Hexo 站点的_config.yml,添加配置 search: path: search.xml field: post format: html limit: 10000 打开themes/next下的_config.yml,搜索关键字local_search,设置为true local_search: enable: true 说明： path - file path. By default is search.xml . If the file extension is .json, the output format will be JSON. Otherwise XML format file will be exported. field - the search scope you want to search, you can chose: post (Default) - will only covers all the posts of your blog. page - will only covers all the pages of your blog. all - will covers all the posts and pages of your blog. format - the form of the page contents, works with xml mode, options are: html (Default) - original html string being minified. raw - markdown text of each posts or pages. excerpt - only collect excerpt. more - act as you think. limit - define the maximum number of posts being indexed, always prefer the newest. 分页插件在hexo根目录下的_config.yml配置文件末尾添加以下内容以设置分页参数 # Plugins index_generator: path: &apos;&apos; per_page: 10 ##首页默认10篇文章标题，如果值为0不分页 order_by: -date archive_generator: per_page: 10 ##归档页面默认10篇文章标题，如果值为0不分页 yearly: true ##生成年视图 monthly: true ##生成月视图 tag_generator: per_page: 10 ##标签页面默认10篇文章，如果值为0不分页 category_generator: per_page: 10 ##分类页面默认10篇文章，如果值为0不分页 如何在首页隐藏指定的文章文章里添加hide元素变量 --- title: { { title } } hide: true --- 修改next主题文件夹下的layout中的index.swig文件 themes/next/layout/index.swig 定位修改 post_template.render(post, true) {% if ! post.hide %} 或 {% if post.hide == true %} 123456789&#123;% block content %&#125; &lt;section id=&quot;posts&quot; class=&quot;posts-expand&quot;&gt; &#123;% for post in page.posts %&#125; &#123;% if ! post.hide %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endif %&#125; &#123;% endfor %&#125; &lt;/section&gt; Front-matter 定制位于scaffolds目录下的md文件。 Front-matter 是 md 文件最上方以 — 分隔的区域，用于指定个别文件的变量，包括 title ， date ，tag 等信息。 文件的开头是属性，采用统一的 yaml 格式，用三条短横线分隔。下面是文章正文。 title 和 date 可以设置成自动，english_title 最好自己写一个清晰的，这个是网址中的真实名称。 --- title: { { title } } english_title: urlname: top: 5 date: { { date } } categories: [Blog,Hexo] tag: [Hexo,NexT] --- RSS 设置更改 主题配置文件 ，设定 rss 字段的值： false：禁用 RSS，不在页面上显示 RSS 连接。 留空：使用 Hexo 生成的 Feed 链接。 你需要先安装 hexo-generator-feed 插件。 具体的链接地址：适用于已经烧制过 Feed 的情形。 修改文章底部的那个带#号的标签打开themes/next/layout/_macro/下的post.swig文件,搜索rel=&quot;tag&quot;&gt;#,将 # 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; &lt;div class=&quot;post-tags&quot;&gt; {% for tag in post.tags %} {{ tag.name }} {% endfor %} &lt;/div&gt; 隐藏网页底部Hexo 强力驱动打开主题配置文件,搜索关键字copyright，如下: copyright: false powered: enable: false version: false theme: enable: false version: false 添加顶部加载条打开themes/next下的_config.yml，搜索关键字pace,设置为true,可以更换加载样式 开启版权声明主题配置文件下,搜索关键字post_copyright,enable改为true post_copyright: enable: true license: &lt;a href=&quot;https://creativecommons.org/licenses/by-nc-sa/4.0/&quot; rel=&quot;external nofollow&quot; target=&quot;_blank&quot;&gt;CC BY-NC-SA 4.0&lt;/a&gt; 添加文章封面文章封面的意思就是：在博客首页的时候会显示文章的封面图片，进入这篇文章的详细页面后，将不显示这张图片。 如果想添加文章封面的话，需要添加一个字段属性：summary_img，summary_img 的值是图片的路径。 123456789---title: CSS 各种Hack手段date: 2017-06-25 03:25:24categories: 前端tags: [CSS]comments: falsesummary_img: /images/css-hack-1.png--- 修改 \themes\next\layout\_macro\post.swing 文件。 12345678910&#123;% if is_index %&#125; &lt;!-- 自定义,用于添加文章摘要图片，文章中不显示 --&gt; &#123;% if post.summary_img %&#125; &lt;div class=&quot;out-img-topic&quot;&gt; &lt;img src=&#123;&#123; post.summary_img &#125;&#125; class=&quot;img-topic&quot;&gt; &lt;/div&gt; &#123;% endif %&#125; &lt;!-- 自定义结束 --&gt; &#123;% if post.description and theme.excerpt_description %&#125; &#123;&#123; post.description &#125;&#125; 开启了文章封面的文章，我建议将 &lt;!-- more --&gt; 放在文章内容的开头 内容自动截断在index页面，，如果文章内容没有添加&lt;!-- more --&gt;, 就自动截断，不全部显示。 自动截断，显示格式不友好，最好还是手动添加&lt;!-- more --&gt; auto_excerpt: enable: true length: 150 添加头像打开themes/next下的_config.yml文件，搜索 Sidebar Avatar关键字，去掉avatar前面的# # Sidebar Avatar avatar: url: #/images/avatar.gif rounded: false opacity: 1 rotated: false 设置头像边框为圆形框 打开位于themes/next/source/css/_common/components/sidebar/下的sidebar-author.syl文件,修改如下 .site-author-image { display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; // 修改头像边框 border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; } 网站logo设置favicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xml 文章加密访问**方法一：简单加密,效果不好** 打开themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,在meta下位置插入这样一段代码： 12345678910&lt;script&gt; (function()&#123; if(&apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; if (prompt(&apos;请输入文章密码&apos;) !== &apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; alert(&apos;密码错误！&apos;); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 然后在文章上写成类似这样： --- title: {{ title }} date: {{ date }} categories: tags: password: password --- **方法二：真正意义的加密** # 插件地址: https://github.com/edolphin-ydf/hexo-encrypt # 安装： npm install hexo-encrypt --save # 配置 # hexo 的根目录下，编辑package.json, 在 dependencies 下添加&quot;hexo-encrypt&quot;: &quot;^0.2.0&quot;, { &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: { &quot;version&quot;: &quot;3.7.1&quot; }, &quot;dependencies&quot;: { ..... &quot;hexo-encrypt&quot;: &quot;^0.2.0&quot;, ..... } } # 功能 用AES加密一篇文章内容 使用qiniu私人空间作为你的img仓库（如果你想使用这个功能，你应该首先得到一个qiniu帐户，搜索谷歌寻求帮助） 将本地img编码为base64类型，然后将其内联到html中 # 缺点 章节不会显示 首页显示不加密，所以需要配合隐藏功能 # 编辑hexo配置文件_config.yml，启用加密 # encrypt encrypt: password: 123456 # 密码 #pwdfile: encrypt_password # 密码存放在一个文档里 # 编辑博客文件md,在front-format 添加 --- encrypt: true enc_pwd: 123456 #不采用默认密码，指定特定密码 --- 自动按照source 目录下的文件夹生成categories# 安装 $ npm install hexo-auto-category --save # 配置 # 在站点根目录下的_config.yml添加： # Generate categories from directory-tree # Dependencies: https://github.com/xu-song/hexo-auto-category # depth: the depth of directory-tree you want to generate, should &gt; 0 auto_category: enable: true depth: # 编译 &amp; 部署 $ hexo clean &amp;&amp; hexo g &amp;&amp; hexo d # 高级配置 # 如果只想生成第一级目录分类，可以设置depth属性，比如： auto_category: enable: true depth: 1 # 缺点： 不支持加密文档 只适合生成静态文件，动态服务，会不断重新创建 修改字体大小打开\themes\next\source\css\ _variables\base.styl文件，将$font-size-base改成16px，如下所示： $font-size-base =16px 如何更改内容区域的宽度？NexT 对于内容的宽度的设定如下： 700px，当屏幕宽度 &lt; 1600px 900px，当屏幕宽度 &gt;= 1600px 移动设备下，宽度自适应 如果你需要修改内容的宽度，同样需要编辑样式文件。 编辑主题的 source/css/_variables/custom.styl 文件，新增变量： // 修改成你期望的宽度 $content-desktop = 700px // 当视窗超过 1600px 后的宽度 $content-desktop-large = 900px 侧边栏推荐阅读打开主题配置文件修改成这样就行了(links里面写你想要的链接): # Blogrolls links_title: 推荐阅读 #links_layout: block links_layout: inline links: 优设: http://www.uisdc.com/ 张鑫旭: http://www.zhangxinxu.com/ Web前端导航: http://www.alloyteam.com/nav/ 前端书籍资料: http://www.36zhen.com/t?id=3448 百度前端技术学院: http://ife.baidu.com/ google前端开发基础: http://wf.uisdc.com/cn/ 文章压缩在站点的根目录下执行以下命令： 123456789101112131415161718192021222324252627282930313233343536373839$ npm install gulp -g$ npm install gulp-minify-css gulp-uglify gulp-htmlmin gulp-htmlclean gulp --save新建 gulpfile.js ，并填入以下内容：var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');// 压缩 public 目录 cssgulp.task('minify-css', function() &#123; return gulp.src('./public/**/*.css') .pipe(minifycss()) .pipe(gulp.dest('./public'));&#125;);// 压缩 public 目录 htmlgulp.task('minify-html', function() &#123;return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public'))&#125;);// 压缩 public/js 目录 jsgulp.task('minify-js', function() &#123; return gulp.src('./public/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public'));&#125;);// 执行 gulp 命令时执行的任务gulp.task('default', [ 'minify-html','minify-css','minify-js']); 生成博文是执行 hexo g &amp;&amp; gulp 就会根据 gulpfile.js 中的配置，对 public 目录中的静态资源文件进行压缩。 其它高亮代码显示插件https://github.com/ele828/hexo-prism-plugin Hexo-Prism-Plugin NPM Since highlight.js didn&apos;t support JSX syntax properly, I wrote this plugin to replace Hexo&apos;s default code highlight plugin. Install npm i -S hexo-prism-plugin Usage Firstly, you should edit your _config.yml by adding following configuration. prism_plugin: mode: &apos;preprocess&apos; # realtime/preprocess theme: &apos;default&apos; line_number: false # default false custom_css: &apos;path/to/your/custom.css&apos; # optional After that, check highlight option in _config.yml. Make sure that default code highlight plugin is disabled. highlight: enable: false Finally, clean and re-generate your project by running following commands: hexo clean hexo generate pdf 插件https://github.com/superalsrk/hexo-pdf hexo-pdf MIT VERSION Hexo tag for embeded pdf Install $ npm install --save hexo-pdf Usage Normal PDF {% pdf http://7xov2f.com1.z0.glb.clouddn.com/bash_freshman.pdf %} or {% pdf ./bash_freshman.pdf %} Google drive {% pdf https://drive.google.com/file/d/0B6qSwdwPxPRdTEliX0dhQ2JfUEU/preview %} Slideshare {% pdf http://www.slideshare.net/slideshow/embed_code/key/8Jl0hUt2OKUOOE %} 参考：https://segmentfault.com/a/1190000009544924 https://www.jianshu.com/p/3ff20be8574c]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[install hexo on centos 7]]></title>
    <url>%2Fhexo%2Finstall%20hexo%20on%20centos%207%2F</url>
    <content type="text"><![CDATA[hexo 官网https://hexo.io/zh-cn/docs/index.html 安装gityum install git 配置git全局信息git config --global user.email &quot;share2030cn@126.com&quot; git config --global user.name &quot;dolphincn&quot; 安装Nodejs123456789101112131415161718192021222324## 安装Nodejs 8, 自动安装npm## 配置 nodejs yum 源# vi /etc/yum.repo.d/nodejs.repo[nodesource]name=Node.js Packages for Enterprise Linux 7 - $basearchbaseurl=https://rpm.nodesource.com/pub_8.x/el/7/$basearchfailovermethod=priorityenabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/NODESOURCE-GPG-SIGNING-KEY-EL[nodesource-source]name=Node.js for Enterprise Linux 7 - $basearch - Sourcebaseurl=https://rpm.nodesource.com/pub_8.x/el/7/SRPMSfailovermethod=priorityenabled=0gpgkey=file:///etc/pki/rpm-gpg/NODESOURCE-GPG-SIGNING-KEY-ELgpgcheck=1## 安装# yum install nodejs 通过二进制包安装nodejs123456789101112131415wget https://nodejs.org/dist/v8.11.2/node-v8.11.2-linux-x64.tar.gztar -zxf node-v8.11.2-linux-x64.tar.gz -C /usr/local/mv /usr/local/node-v8.11.2-linux-x64 /usr/local/nodejsvi /etc/profile.d/nodejs.shexport NODE_HOME=/usr/local/nodejsexport PATH=$NODE_HOME/bin:$PATHsource /etc/profile.d/nodejs.sh## 检查版本node -vnpm -v 安装hexo12345678910111213141516171819202122232425262728293031## npm 全局安装hexo-cli，这个在系统安装一次就可以了npm install -g hexo-cli/usr/bin/hexo -&gt; /usr/lib/node_modules/hexo-cli/bin/hexo## 安装hexo 服务及大部分常用插件## 此命令安装绝大部分常用插件，属于局部安装，会在当前目录下创建node_modules文件夹npm install## 常用插件，大部分已安装npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked --savenpm install hexo-renderer-stylus --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-json-content --save 安装配置blog步骤1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586## 全局安装hexo-clinpm install -g hexo-cli## 创建blog目录 mkdir -p /data/hexo_blog## 初始化blog目录, 并建立blog站点hexo init /data/hexo_blogcd /data/hexo_blog## 安装hexo 服务及大部分常用插件npm install## 新建完成后，指定文件夹的目录如下：.├── _config.yml ## 网站的 配置 信息，您可以在此配置大部分的参数。├── package.json ## 应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。├── scaffolds ## 模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。├── source ## 资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。| ├── _drafts| └── _posts└── themes ## 主题 文件夹。Hexo 会根据主题来生成静态页面。## 下载next主题和安装插件git clone --depth 1 https://github.com/theme-next/hexo-theme-next /data/hexo_blog/themes/nextnpm install hexo-generator-searchdb --save## 配置支持 githubnpm install hexo-deployer-git --save## 修改## repo: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git## 注意，如果用github拥有者的名字建立仓库，如[&lt;username&gt;.github.io]，则可以通过互联网直接访问username.github.io网站内容vi ./_config.....# Deployment## Docs: https://hexo.io/docs/deployment.html deploy:type: gitrepo: git@github.com:dolphincn/dolphincn.github.io.gitbranch: mastermaster message: 'site update: &#123;&#123;now("YYYY-MM-DD HH/mm/ss")&#125;&#125;'## 配置搜索# 在你站点的根目录下npm install hexo-generator-searchdb --save# 打开Hexo 站点的_config.yml,添加配置search: path: search.xml field: all format: html limit: 10000# 打开themes/next下的_config.yml,搜索关键字local_search,设置为truelocal_search: enable: true## 安装图片浏览器$ rm -rf themes/next/source/lib/fancybox$ git clone --depth 1 https://github.com/theme-next/theme-next-fancybox3 themes/next/source/lib/fancybox# 编辑next 主题配置文件 _config.yml: fancybox: true## 安装书签保存插件$ rm -rf themes/next/source/lib/bookmark$ git clone --depth 1 https://github.com/theme-next/theme-next-bookmark.git themes/next/source/lib/bookmark# 编辑next 主题配置文件 _config.yml: bookmark: true 其它主题## 下载bluelake主题和插件 git clone --depth 1 https://github.com/chaooo/hexo-theme-BlueLake.git /data/hexo_blog/themes/bluelake cd /data/hexo_blog npm install hexo-renderer-jade@0.3.0 --save npm install hexo-renderer-stylus --save npm install hexo-generator-json-content@2.2.0 --save ## hexo 管理命令1234567891011121314151617181920212223242526## 启动本地hexo blog服务hexo server# 或者hexo server -i 192.168.100.10 -p 80## 清空hexo clean## 生成静态页面hexo generate## 发布blog 到 githubhexo deploy## 创建一个页面hexo new "a new post"## 将草稿从_drafts移到_posts目录下hexo publish articlename 设置支持txt渲染为html# 如果markdown 文件扩展名保存为txt # 编辑 hexo 配置文件_config.yml,修改 new_post_name: :title.md 改为 new_post_name: :title.txt # 修改内容渲染模块, 照葫芦画瓢，添加一行txt文件的渲染 vi ./node_modules/hexo-renderer-marked/index.js ........ hexo.extend.renderer.register(&apos;txt&apos;, &apos;html&apos;, renderer, true); hexo.extend.renderer.register(&apos;md&apos;, &apos;html&apos;, renderer, true); 配置nginx反向代理123456789101112131415161718192021222324252627282930313233343536 cat &gt; /etc/yum.repos.d/nginx.repo &lt;&lt; EOF# nginx.repo[nginx]name="nginx repo"baseurl=http://nginx.org/packages/rhel/7/x86_64/gpgcheck=1gpgkey=http://nginx.org/packages/keys/nginx_signing.keyenabled=1EOFyum install nginx cat &gt; /etc/nginx/conf.d/hexoblog.conf &lt;&lt; EOFserver &#123; listen 80; server_name blog.com; error_page 404 /404/; location / &#123; root /data/hexo_blog; index index.html; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; &#125;&#125;EOF hexo 命令说明指令 init $ hexo init [folder] 新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站。 new $ hexo new [layout] &lt;title&gt; 新建一篇文章。如果没有设置 layout 的话，默认使用 _config.yml 中的 default_layout 参数代替。如果标题包含空格的话，请使用引号括起来。 generate $ hexo generate 生成静态文件。 选项 描述 -d, --deploy 文件生成后立即部署网站 -w, --watch 监视文件变动 该命令可以简写为 $ hexo g publish $ hexo publish [layout] &lt;filename&gt; 发表草稿。 server $ hexo server -i 200.200.200.221 -p 80 启动服务器。默认情况下，访问网址为： http://localhost:4000/。 选项 描述 -p, --port 重设端口 -s, --static 只使用静态文件 -l, --log 启动日记记录，使用覆盖记录格式 deploy $ hexo deploy 部署网站。 参数 描述 -g, --generate 部署之前预先生成静态文件 该命令可以简写为： $ hexo d render $ hexo render &lt;file1&gt; [file2] ... 渲染文件。 参数 描述 -o, --output 设置输出路径 migrate $ hexo migrate &lt;type&gt; 从其他博客系统 迁移内容。 clean $ hexo clean 清除缓存文件 (db.json) 和已生成的静态文件 (public)。 在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。 list $ hexo list &lt;type&gt; 列出网站资料。 version $ hexo version 显示 Hexo 版本。 选项 安全模式 $ hexo --safe 在安全模式下，不会载入插件和脚本。当您在安装新插件遭遇问题时，可以尝试以安全模式重新执行。 调试模式 $ hexo --debug 在终端中显示调试信息并记录到 debug.log。当您碰到问题时，可以尝试用调试模式重新执行一次，并 提交调试信息到 GitHub。 简洁模式 $ hexo --silent 隐藏终端信息。 自定义配置文件的路径 $ hexo --config custom.yml 自定义配置文件的路径，执行后将不再使用 _config.yml。 显示草稿 $ hexo --draft 显示 source/_drafts 文件夹中的草稿文章。 自定义 CWD $ hexo --cwd /path/to/cwd 自定义当前工作目录（Current working directory）的路径。 站点配置文件说明站点配置文件的配置 .\hexo\_config.yml 。 # Hexo Configuration ## Docs: https://hexo.io/docs/configuration.html ## Source: https://github.com/hexojs/hexo/ # Site 网站 title: 为学 #网站标题 subtitle: 天下事有难易乎？为之，则难者亦易矣；不为，则易者亦难矣。 #网站副标题 description: 天下事有难易乎？为之，则难者亦易矣；不为，则易者亦难矣。 #网站描述 author: willxue #您的名字 language: zh-CN #网站使用的语言 timezone: #网站时区。Hexo 默认使用您电脑的时区 # URL 网址 ## 如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/。 url: http://willxue.top permalink: :year/:month/:day/:title/ #生成文件名字的格式我改成blog/:title:year:month:day/ permalink_defaults: # Directory 目录配置 source_dir: source #源文件夹，这个文件夹用来存放内容。 public_dir: public #公共文件夹，这个文件夹用于存放生成的站点文件。 tag_dir: tags #标签文件夹 archive_dir: archives #归档文件夹 category_dir: categories #分类文件夹 code_dir: downloads/code #nclude code 文件夹 i18n_dir: :lang #国际化（i18n）文件夹 skip_render: #跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。 # Writing 文章 new_post_name: :title.md # 新建文章默认文件名 default_layout: post # 默认布局 titlecase: false # Transform title into titlecase external_link: true # 在新标签中打开一个外部链接，默认为true filename_case: 0 #转换文件名，1代表小写；2代表大写；默认为0，意思就是创建文章的时候，是否自动帮你转换文件名，默认就行，意义不大。 render_drafts: false #是否渲染_drafts目录下的文章，默认为false post_asset_folder: false #启动 Asset 文件夹 relative_link: false #把链接改为与根目录的相对位址，默认false future: true #显示未来的文章，默认false highlight: #代码块的设置 enable: true line_number: true auto_detect: false tab_replace: # Category &amp; Tag 分类和标签的设置 default_category: uncategorized #默认分类 category_map: #分类别名 tag_map: #标签别名 # Date / Time format ## Hexo uses Moment.js to parse and display date ## You can customize the date format as defined in ## http://momentjs.com/docs/#/displaying/format/ date_format: YYYY-MM-DD time_format: HH:mm:ss # Pagination 分页 ## Set per_page to 0 to disable pagination per_page: 10 #每页显示的文章量 (0 = 关闭分页功能) pagination_dir: page #分页目录 # Extensions ## Plugins: https://hexo.io/plugins/ ## Themes: https://hexo.io/themes/ theme: next feed: type: atom #feed 类型 (atom/rss2) path: atom.xml #rss 路径 limit: 20 #在 rss 中最多生成的文章数(0显示所有) # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: https://github.com/imwillxue/imwillxue.github.com.git branch: master]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MariaDB 10.2 galera 集群安装]]></title>
    <url>%2Fmariadb%2FMariaDB%2010.2%20galera%20%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[环境:每台服务器安装CentOS 7.2 Minimal 版本，安装后使用yum update更新一下最新的系统内核和相关配置参数。 MariaDB galera集群建议最少3台服务器，2台无法保证数据完整性。 几台虚拟机ip设置如下： 节点名称 IP地址 cluster1 192.168.56.21 cluster2 192.168.56.22 cluster3 192.168.56.23 删除CentOS自带的老版本mariadb lib文件 查找安装的mariadb sudo rpm -qa | grep mariadb 删除查找到的lib文件 sudo rpm -e --nodeps (这里是查找到的mariadb lib 文件) 安全设置1) firewall 因为安装mariadb galera 需要打开 3306、4444、4567、4568四个端口，而且要降低安全审核级别。 使用以下命令设置防火墙开放这几个端口： 3306是MariaDB/mysql的服务端口，这个都不开那就不用跑MariaDB/MySQL服务了，需要开TCP端口； 4567是Galera做数据复制的通讯和数据传输端口，需要在防火墙放开TCP和UDP； 4568是Galera做增量数据传输使用的端口（Incremental State Transfer, IST），需要防火墙放开TCP； 4444是Galera做快照状态传输使用的端口（State Snapshot Transfer, SST），需要防火墙放开TCP。） sudo firewall-cmd --permanent --zone=public --add-port={3306,4567,4568,4444}/tcp sudo firewall-cmd --permanent --zone=public --add-port=4567/udp sudo firewall-cmd --reload （重新加载防火墙使修改生效） 2) selinux 在CentOS的SELinux配置文件中降低SELinux的安全审核级别，让mysqld可以正常运行，否则SELinux会限制集群数据传输 (setenforce 0 命令只能设置运行时的安全级别，想要完全设置安全级别，需要在SELinux的配置文件中进行配置更改) 使用vi 打开/etc/selinux/config配置文件，设置SELINUX=permissive sudo vi /etc/selinux/config 或者键入命令 semanage permissive -a mysqld_t 使用reboot命令重启服务器使SELinux安全级别更改生效 配置 yum源1) 配置 mariadb 10.2 yum源 官网地址 https://downloads.mariadb.org/ 选择最新稳定版本 MariaDB Galera Cluster 10.2 Series (原有下载地址太慢，需要换成国内的镜像地址) 1234567891011121314151617 cat &gt; /etc/yum.repos.d/mariadb.repo &lt;&lt; EOF[mariadb]name = MariaDB-10.2baseurl = http://yum.mariadb.org/10.2/centos7-amd64/gpgkey = https://yum.mariadb.org/RPM-GPG-KEY-MariaDB#baseurl = http://mirrors.ustc.edu.cn/mariadb/yum/10.2/centos7-amd64/#gpgkey = https://mirrors.ustc.edu.cn/mariadb/yum/RPM-GPG-KEY-MariaDBenabled = 1gpgcheck = 1EOF 2) 配置 percona yum源 1234567891011121314151617181920212223242526 cat &gt; /etc/yum.repos.d/percona.repo &lt;&lt; EOF[percona-release-$basearch]name = Percona-Release YUM repository - $basearchbaseurl = http://repo.percona.com/release/7Server/RPMS/$basearchenabled = 1gpgcheck = 1gpgkey = https://www.percona.com/downloads/RPM-GPG-KEY-percona[percona-release-noarch]name = Percona-Release YUM repository - noarchbaseurl = http://repo.percona.com/release/7Server/RPMS/noarchenabled = 1gpgcheck = 1gpgkey = https://www.percona.com/downloads/RPM-GPG-KEY-percona[percona-release-source]name = Percona-Release YUM repository - Source packagesbaseurl = http://repo.percona.com/release/7Server/SRPMSenabled = 0gpgcheck = 1gpgkey = https://www.percona.com/downloads/RPM-GPG-KEY-perconaEOF 3） 配置 epel 源 123456789101112 cat &gt; /etc/yum.repos.d/epel.repo &lt;&lt; EOF[epel]name=Extra Packages for Enterprise Linux 7 - $basearchbaseurl=http://dl.fedoraproject.org/pub/epel/7Server/x86_64/failovermethod=priorityenabled=1gpgcheck=1gpgkey=http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7ServerEOF 4）配置 centos base 源 12345678910111213141516171819202122232425262728293031323334353637383940 cat &gt; /etc/yum.repos.d/base.repo &lt;&lt; EOF[base]name=CentOS-$releasever - Basebaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#released updates[updates]name=CentOS-$releasever - Updatesbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/updates/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-$releasever - Extrasbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/extras/$basearch/gpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plusbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#contrib - packages by Centos Users[contrib]name=CentOS-$releasever - Contribbaseurl=http://olcentchan.chinacloudapp.cn/centos/$releasever/contrib/$basearch/gpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7EOF 安装1) 安装 mariadb yum install -y MariaDB-server MariaDB-client galera rsync 因为从10.1开始galera默认依赖，并且包含在mariadb源中，因此安装server和client就可以了。 rsync mariadb默认使用的集群同步工具，centos 7.3 默认已经安装。 2) 安装jemalloc, google 研发的高效内存管理模块，默认系统已安装 yum install jemalloc jemalloc-devel 3）安装Percona XtraBackup mariadb默认使用rsync进行节点间数据同步. 单rsync同步的时候会锁住节点，没有Percona提供的XtraBackup顺畅. 因此这里使用推荐的XtraBackup，需要下载安装 安装Percona XtraBackup 的yum安装源 yum install -y http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm 或者手动配置yum源 yum install percona-xtrabackup-24 在yum中查找最新版本进行安装 yum list | grep percona-xtrabackup yum install -y percona-xtrabackup-24 4）安装socat，否则xtrabackup备份同步方式在单节点故障后重启后在.err错误日志中会报类似以下错误 WSREP_SST: [ERROR] socat not found in path: /usr/sbin:/sbin.... yum install -y socat 5) 配置NTP（chrony） $ yum install chrony $ systemctl enable chronyd.service $ systemctl start chronyd.service $ systemctl status chronyd.service 6) 启动时，在run里自动创建mysql目录 vi /usr/lib/systemd/system/mariadb.service [Service] ...... #PermissionsStartOnly=true RuntimeDirectory=mysql RuntimeDirectoryMode=0755 User=mysql Group=mysql ...... 修改root用户默认密码本文中选择IP为192.168.56.21的虚机作为演示节点进行配置，mariadb安装后默认服务是启动的 1) 修改root用户默认密码 mysqladmin -u root password &quot;root的登录密码&quot; 或者 mysql_secure_installation (这种方式初学者可能会选错，所以建议用前一种方式) 2) 本文使用sst_user用户作为集群的数据同步用户，授予所有权限 进入mysql管理命令 mysql -uroot -p MariaDB&gt; CREATE USER &apos;sst_user&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sst_pass&apos;; MariaDB&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;sst_user&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sst_pass&apos;; # (如果想让用户拥有授有权限，在语句最后加WITH GRANT OPTION) MariaDB&gt; FLUSH PRIVILEGES; 关闭mysql服务，为后续配置做准备systemctl stop mariadb 数据目录准备：1) 安装 semanage 管理工具 yum -y install policycoreutils-python 2) 准备pid socket 目录，防止内存里 mkdir /var/run/mysql chown -R mysql:mysql /var/run/mysql mkdir -p /data/{mysql,tmp/mysql,log/mysql} 3) 数据目录权限和selinux上下文 chown -R mysql:mysql /data/mysql chmod -R 0755 /data/mysql semanage fcontext -a -t mysqld_db_t &quot;/data/mysql(/.*)?&quot; restorecon -RFv /data/mysql 4) 临时目录权限和selinux上下文 chown -R mysql:mysql /data/tmp/mysql chmod -R 0755 /data/tmp/mysql semanage fcontext -a -t mysqld_db_t &quot;/data/tmp/mysql(/.*)?&quot; restorecon -RFv /data/tmp/mysql 5） 日志目录权限和selinux上下文 chown -R mysql:mysql /data/log/mysql chmod -R 0755 /data/log/mysql semanage fcontext -a -t var_log_t &quot;/data/log/mysql(/.*)?&quot; restorecon -RFv /data/log/mysql 6) socket selinux设置 semanage fcontext -a -t mysqld_var_run_t &quot;${DB_datadir}/{mysql.sock，mysql.pid}&quot; restorecon -RFv ${DB_datadir}/{mysql.sock，mysql.pid} 7) 设置 端口 selinux semanage port -a -t mysqld_port_t -p tcp 3306 修改配置文件配置文件路径： /etc/my.cnf.d/server.cnf mariadb的配置文件很多，安装之后有 /etc/my.cnf /etc/my.cnf.d/mysql-clients.cnf /etc/my.cnf.d/server.cnf 其中/etc/my.cnf文件中包含了后两者 /etc/my.cnf.d/mysql-client.cnf中存放客户端连接时的配置信息， 例如[client]和[mysql]，/etc/my.cnf.d/server.cnf中存放服务器的配置信息 可以将所有信息添加到server.cnf，也可以分为client和server配置文件 查找配置文件所在位置以及配置信息的命令,按空格键下翻 mysqld –help –verbose | more 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226 vi /etc/my.cnf.d/server.cnf### 客户端连接配置 #####################################[client]port = 3306socket = /var/run/mysql/mysql.sock # 设置客户端连接socket文件路径，如果mariadb采用socket连接，且更改了默认socket路径配置，客户端就必须设置default-character-set = utf8 # 设置客户端连接默认连接字符类型[mysqld]### 默认或基本配置 #####################################bind-address = 0.0.0.0port = 3306socket = /run/mysql/mysql.sockbasedir = /usr # mysqld二进制文件存放的目录，或者说mysql安装目录datadir = /data/mysql # 数据库文件存放目录tmpdir = /data/tmp/mysqlpid_file = /run/mysql/mysql.pid # 存放数据库进程ID文件log_error = /data/log/mysql/mariadb.error.log # 错误日志文件#log_output = FILE # 参数log_output指定了慢查询输出的格式，默认为FILE，你可以将它设为TABLE，然后就可以查询mysql架构下的slow_log表了 #log-warnings = 1 # 将警告信息也记入到日志中 sync_binlog = 0 # 默认为0 ,就是由文件系统自己控制它的缓存的刷新，系统crash会丢失很多没刷新的事务日志；sync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据刷入磁盘。。此值可以设为100.open_files_limit = 65535 # 该参数用于控制MySQL实例能够同时打开使用的文件句柄数目。max_connections = 4096 # 最大连接数back_log = 500 #接受队列，对于没建立tcp连接的请求队列放入缓存中，队列大小为back_log，受限制与OS参数max_connect_errors = 10000 # 如果某个用户发起的连接error超过该数值，则该用户的下次连接将被阻塞，直到管理员执行flush hosts ; 命令；防止黑客 collation-server = utf8_general_ci # 查询比较不区分大小写character-set-server = utf8 # 数据库采用UTF8字符集#default-time-zone = system #服务器时区 # skip options skip-name-resolve # 取消域名解析，服务器连接等相关设置只能用IP不能用域名，这样加快访问速度 skip-symbolic-links # 不能使用连接文件 skip-external-locking # 不使用系统锁定，要使用myisamchk,必须关闭服务器 #skip-slave-start # 启动mysql时,不自动启动从复制 ### innodb引擎配置 #####################################default-storage-engine = innodb # 数据库默认引擎采用innodbinnodb_file_per_table = 1 # 采用innodb引擎是，每表存放一个文件innodb_buffer_pool_size = 1Ginnodb_open_files = 6000 # innodb 打开文件的最大数量，受限于系统文件打开的数量innodb_data_home_dir = /data/mysql # innodb数据文件存放路径innodb_data_file_path = ibdata1:100M:autoextend # 一般一个文件对一应一个磁盘innodb_log_group_home_dir = /data/mysql # innodb事物日志文件存放路径innodb_log_files_in_group = 2 # 两组事物日志 innodb_log_file_size = 128M # innodb事物日志大小，越大，恢复时间越长。innodb_log_buffer_size = 8M # innodb事物日志缓存，此值默认8M，对系统提升不高innodb_flush_log_at_trx_commit = 2 # 2 为1秒内刷新日志，适合于游戏之类的服务器；1 为每事务刷新一次，适合对数据要求极高的；0 适合数据不太重要，追求效率的innodb_lock_wait_timeout = 50 # InnoDB事务在被回滚之前可以等待一个锁定的超时秒数。InnoDB在它自己的 锁定表中自动检测事务死锁并且回滚事务。InnoDB用LOCK TABLES语句注意到锁定设置。默认值是50秒innodb_autoinc_lock_mode = 2 # 用于控制自增主键的锁机制，该参数可以设置的值为0/1/2。# 建议将参数设置改为2，则表示所有情况插入都使用轻量级别的mutex锁(只针对row模式)，这样就可以避免auto_inc的死锁，同时在INSERT … SELECT 的场景下会提升很大的性能（注意该参数设置为2，binlog的格式需要设置为row）。# 参数设置为1，表示InnoDB使用轻量级别的mutex锁来获取自增锁，替代最原始的表级锁，但是在load data（包括：INSERT … SELECT, REPLACE … SELECT）场景下会使用自增表锁，这样会则可能导致应用在并发导入数据出现死锁。innodb_flush_method = O_DSYNC innodb_max_dirty_pages_pct = 90 # innodb主线程刷新缓存池中的数据，使脏数据比例小于90% #innodb_doublewrite = 1 # 集群默认必须设置为1#innodb_thread_concurrency = 16#innodb-read-io-threads=4#innodb-write-io-threads=4### 数据二进制日志 #####################################binlog_format = ROW # 集群和主从复制需要设置expire_logs_days = 10 #binlog_cache_size = 1M# 下面只有主从设置时才需要#server_id = 10#log-bin = mysql-bin #这些路径相对于datadir #log-bin-index = mysql-bin.index#relayrelay-log = relay-log#relayrelay_log_index = relay-log.index#expire_logs_days = 10 # 日志保存几天，超时自动删除#binlog-do-db = bitnami_magento # 主从同步的库，一般设置在从服务，同步那个数据库#binlog-do-db = test_magento#binlog_ignore_db = mysql#binlog_ignore_db = performance_schema # 不同步哪个数据库#binlog_ignore_db = information_schema#log-slave-updates = 1 # A-B-C， 如果三级主从，B就需要开启，用于将从主读取的日志写入自己的log-bin中用于自己的从服务器同步#slave-skip-errors = 1### 超时设置 ##################################wait-timeout = 28800 #等待关闭连接的时间 #interactive-timeout = 28800 #关闭连接之前，允许interactive_timeout（取代了wait_timeout）秒的不活动时间。客户端的会话wait_timeout变量被设为会话interactive_timeout变量的值。 #connect-timeout = 10 #连接超时之前的最大秒数,在Linux平台上，该超时也用作等待服务器首次回应的时间 #slave-net-timeout = 600 #从服务器也能够处理网络连接中断。但是，只有从服务器超过slave_net_timeout秒没有从主服务器收到数据才通知网络中断 #net_read_timeout = 30 #从服务器读取信息的超时 #net_write_timeout = 60 #从服务器写入信息的超时 #net_retry_count = 10 #如果某个通信端口的读操作中断了，在放弃前重试多次 #net_buffer_length = 16384 #包消息缓冲区初始化为net_buffer_length字节，但需要时可以增长到max_allowed_packet字节### 缓存 ######################################tmp_table_size = 512M #临时表大小，如果超过该值，则结果放到磁盘中 #max_heap_table_size = 512M #该变量设置MEMORY (HEAP)表可以增长到的最大空间大小,参数目的是防止建立超大的内存临时表max_allowed_packet = 16Mread_buffer_size = 2Msort_buffer_size = 2Mjoin_buffer_size = 2Mread_rnd_buffer_size = 4Mtable_cache = 512 # 所有线程打开的表的数目。增大该值可以增加mysqld需要的文件描述符的数量 table_open_cache = 256thread_stack = 192K # 每个线程的堆栈大小 thread_cache_size = 8 # 线程缓存 #thread_concurrency = 8 # 同时运行的线程的数据 此处最好为CPU个数两倍。本机配置为CPU的个数 query_cache_size =0#query_cache_size = 256M #查询缓存大小 query_cache_limit = 4M #不缓存查询大于该值的结果 query_cache_min_res_unit = 2K #查询缓存分配的最小块大小 key_buffer_size = 256M### 慢查询 #####################################slow_query_log = 1 long-query-time = 5 #慢查询时间 超过1秒则为慢查询 slow_query_log_file = /data/log/mysql/slow.log #log-queries-not-using-indexes #log-slow-slave-statements ### 集群配置 ###################################### 集群相关配置，注意集群服务器必须设置default_storage_engine=InnoDB, binlog_format=ROW, innodb_autoinc_lock_mode=2[galera]wsrep_on = ON #(决定是否启动节点间同步,该配置项从10.1.1版本增加的，必须配置ON选项。)wsrep_provider = /usr/lib64/galera/libgalera_smm.so #(指定Galera的库,galera 的同步c++库位置)wsrep_provider_options = "gcache.size=2G; gcache.page_size=1G"wsrep_cluster_name = "db_cluster" #(整个集群的名称，所有节点一致,字符开头，可以包含数字和下划线)#wsrep_cluster_address = "gcomm://" # 当整个集群都停机后，第一台启动时设置为空，注意此机必须是最后一台关机的服务器wsrep_cluster_address = "gcomm://10.100.120.4,10.100.120.5,10.100.120.6" #(集群中所有节点的地址列表，在Percona中第一个启动的节点必须是空值才能启动，MariaDB已无此限制)wsrep_node_name = db01 #(节点名称，其它两个节点需要修改)wsrep_node_address = 10.100.120.4 #(节点地址，其它两个节点需要修改)wsrep_sst_method = rsync#wsrep_sst_method = xtrabackup-v2 #默认是rsync全量拷贝，但是需要在donor节点上执行全局读锁(flushtables with read lock)，建议采用xtrabackup热备份方式，只有在备份.frm表结构文件才会锁表# SST authentication string. This will be used to send SST to joining nodes.#wsrep_sst_auth = sst_user:sst_pass #集群间的身份验证 # enable "strictly synchronous" semantics for read operations# deprecated#wsrep_causal_reads=ON #节点应用完事务才返回查询请求， 避免脏读#--wsrep-sync-wait=0# 二进制日志的格式必须为ROW格式。binlog_format = ROW#指定默认存储引擎为innodb。集群只支持innodb和xtradbdefault_storage_engine = InnoDBinnodb_autoinc_lock_mode=2# How many threads will process writesets from other nodeswsrep_slave_threads=1 #可以指定wsrep的线程数，提高复制效率。# to enable debug level logging, set this to 1wsrep_debug=0wsrep_convert_LOCK_to_trx=0# how many times to retry deadlocked autocommitswsrep_retry_autocommit=1# replicate myisamwsrep_replicate_myisam=1# retry autoinc insert, which failed for duplicate key errorwsrep_drupal_282555_workaround=0# Generate fake primary keys for non-PK tables (required for multi-master# and parallel applying operation)#为没有显式申明主键的表生成一个用于certificationtest的主键，默认为ON wsrep_certify_nonPK=1 # change auto_increment_increment and auto_increment_offset automaticallywsrep_auto_increment_control=1# Maximum number of rows in write setwsrep_max_ws_rows=131072# Maximum size of write setwsrep_max_ws_size=1073741824# Address for incoming client connections. Autodetect by default.#wsrep_node_incoming_address=10.100.120.4# Address on THIS node to receive SST at. DON'T SET IT TO DONOR ADDRESS!!!# (SST method dependent. Defaults to the first IP of the first interface)#wsrep_sst_receive_address=10.100.120.4### 其它配置 #####################################[mysqld_safe]# 使用jemalloc作为内存管理，需要安装jemalloc jemalloc-develmalloc-lib=/usr/lib64/libjemalloc.sobasedir = /usr # mysqld二进制文件存放的目录，或者说mysql安装目录datadir = /data/mysql # 数据库文件存放目录pid_file = /var/run/mysql/mysql.pid # 存放数据库进程ID文件log_error = /data/log/mysql/mariadb.error.log # 错误日志文件[mysqldump]quickmax_allowed_packet = 16M[mysql]no-auto-rehashdefault-character-set = utf8socket = /run/mysql/mysql.sock[myisamchk]key_buffer_size = 128Msort_buffer_size = 128Mread_buffer = 2Mwrite_buffer = 2M[mysqlhotcopy]interactive-timeout 启动初始化及注意事项1) 在其它两个节点上复制配置文件，注意其中的wsrep_node_name和wsrep_node_address需要根据节点实际情况修改 2) 初始化所有节点的数据库 mkdir /var/run/mysql chown -R mysql:mysql /var/run/mysql rm -rf /var/lib/mysql/* rm -rf /data/mysql/* mysql_install_db --basedir=/usr --datadir=/data/mysql --user=mysql 测试结果，所有节点配置一样，如果第一个节点有数据，运行galera_new_cluster启动cluster，后面的加入的节点数据目录可以为空。 临时关闭安全 setenforce 0 systemctl stop firewalld 12345678910111213141516171819202122 # 集群最简单配置，如果复杂配置启动不了，可以先用最简单配置，然后重做初始数据库 cat &gt; /etc/my.cnf.d/server.cnf &lt;&lt; EOF[galera]wsrep_on=ONwsrep_provider=/usr/lib64/galera/libgalera_smm.sowsrep_cluster_address="gcomm://10.100.120.4,10.100.120.5,10.100.120.6"wsrep_provider_options = "gcache.size=2G; gcache.page_size=1G"wsrep_cluster_name="db_cluster"wsrep_node_address="10.100.120.5"wsrep_node_name="db05"wsrep_sst_method=rsyncwsrep_sst_auth=sst_user:sst_passbinlog_format=rowdefault_storage_engine=InnoDBinnodb_autoinc_lock_mode=2bind-address=0.0.0.0EOF 3) 使用专有命令启动第一个节点 galera_new_cluster 该命令暗示现在没有已存在的集群，启动的这台服务器是这个集群中的第一个，会产生新的集群UUID. 如果集群已经存在还使用该命令会导致启动的服务器和已存在的集群不在一个集群体系中，因为产生了不一样的集群UUID 3) 在保证第一个节点启动后逐个启动其它节点，不要并行启动，可能会出预料不到的问题，如果第一个节点没启动，其它节点无法正常启动。 systemctl start mariadb # 查看集群大小 mysql -u root -p -e &quot;SHOW STATUS LIKE &apos;wsrep_cluster_size&apos;&quot; mysql -uroot -p -e &quot;CREATE DATABASE IF NOT EXISTS tocloud DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci;&quot; mysql -uroot -p -e &quot;GRANT ALL ON tocloud.* TO test@&apos;%&apos; IDENTIFIED BY &apos;test.9898&apos;;&quot; 如果使用xtrabackup-v2作为同步组件，创建后续在集群同步中拥有同步权限的用户并赋予最基本权限 mysql&gt; GRANT RELOAD, LOCK TABLES, PROCESS, REPLICATION CLIENT ON *.* TO &apos;sst_user&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;sst_pass&apos;; mysql&gt; FLUSH PRIVILEGES; 或者 mysql -uroot -p -e &quot;grant all privileges on *.* to &apos;sst_user&apos;@&apos;%&apos; identified by &apos;sst_pass&apos;;FLUSH PRIVILEGES;&quot; 4) 一定注意集群中最后关闭的服务器应该是下次启动的第一个服务器，因为集群判断这台服务器最后关闭所以具有最完整的数据，所以会设置在这台服务器之前关闭的服务器无法正常手动启动，如果强制启动需要手动将grastate.dat文件中的safe_to_boostrap设置为1后强行启动。 重启集群需要修改，最后一个关闭的服务器配置文件下面这个参数为： wsrep_cluster_address=&quot;gcomm://“ 然后重启最后关闭的服务器，再重启其它服务器，最后改回第一台的配置重新启动 最后用此命令查看配置id 集群id 及状态是否一致 mysql -u root -p -e &quot;SHOW STATUS LIKE &apos;wsrep_cluster%&apos;&quot; Restarting the cluster If you shut down all nodes, you effectively terminated the cluster (not the data of course, but the running cluster), hence the right way is to start the all the nodes with gcomm://&lt;node1 address&gt;,&lt;node2 address&gt;,...?pc.wait_prim=no again. On one of the nodes set global wsrep_provider_options=&quot;pc.bootstrap=true&quot;;. Bootstrapping a new cluster: $ mysqld --wsrep-new-cluster Adding another node to a cluster: $ mysqld --wsrep_cluster_address=gcomm://192.168.0.1 # DNS names work as well 5) 初始化 # mysql_secure_installation # 添加超级用户： grant all on *.* to suroot@&apos;127.0.0.1&apos; identified by &apos;lion.net&apos; with grant option; grant all on *.* to suroot@&apos;::1&apos; identified by &apos;lion.net&apos; with grant option; grant all on *.* to suroot@&apos;localhost&apos; identified by &apos;lion.net&apos; with grant option; # 删除空用户和默认用户： drop user root@&apos;127.0.0.1&apos;; drop user root@&apos;::1&apos;; drop user root@&apos;localhost&apos;; drop user &apos;root&apos;@&apos;test-db-vm01&apos;; drop user &apos;&apos;@&apos;test-db-vm01&apos;; drop user &apos;&apos;@localhost; # 删除测试数据库 drop database test; MariaDB负载均衡当MariaDB Galera Cluster集群搭建完成后，通过任意一个节点都可以连接进行数据操作。 当然我们可以借助于haproxy或lvs来实现MySQL数据库集群之间的负载均衡 使用mysql-router代理最好在每个应用的的服务器上安装mysqlrouter 应用最好使用socket连接mysqlrouter 1234567891011121314151617181920212223242526272829303132333435363738 # yum 安装命令 yum install mysqlrouter # 配置 mysqlrouter yum 源 cat &gt; /etc/yum.repos.d/mysql.repo &lt;&lt; EOF[mysql-connectors-community]name=MySQL Connectors Communitybaseurl=http://repo.mysql.com/yum/mysql-connectors-community/el/7/\$basearch/enabled=1gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysql[mysql-tools-community]name=MySQL Tools Communitybaseurl=http://repo.mysql.com/yum/mysql-tools-community/el/7/\$basearch/enabled=1gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysql[mysql57-community]name=MySQL 5.7 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.7-community/el/7/\$basearch/enabled=0gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysql[mysql80-community]name=MySQL 8.0 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-8.0-community/el/7/\$basearch/enabled=1gpgcheck=1gpgkey=http://repo.mysql.com/RPM-GPG-KEY-mysqlEOF 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 # mysqlrouter 配置 cat &gt; /etc/mysqlrouter/mysqlrouter.conf &lt;&lt; EOF[DEFAULT]logging_folder = /var/log/mysqlrouter/plugin_folder = /usr/lib64/mysqlrouterruntime_folder = /var/run/mysqlrouterconfig_folder = /etc/mysqlrouter[logger]## INFO (default), DEBUG, WARNING, ERROR, and FATALlevel = WARNING[keepalive]interval = 60## 主数据库，用于写[routing:primary]bind_address = 0.0.0.0bind_port=7001socket = /run/mysqlrouter/mysqlrouter.sockdestinations = 200.200.200.221:3306,200.200.200.222:3306,200.200.200.223:3306## first-available适用于cluster写集群；next-available适用于主从互备，主挂了将永远移除，除非重启mysqlrouter；round-robin适用于只读模式routing_strategy = first-available# 连接到 MySQL Router 的最大连接数, 类似 MySQL Server 中的 max_connections 选项, 有效的值为 1 ~ 65535;max_connections = 512## 有效的值为 1 ~ 65535;# 工具连接后端 MySQL Server 的超时时间,单位秒, 默认为 1s, 有效的值为 1 ~ 65535;connect_timeout = 1## 从数据库，用于读[routing:secondary]bind_address = 0.0.0.0bind_port = 7002destinations = 200.200.200.221:3307,200.200.200.222:3307,200.200.200.223:3307routing_strategy = round-robin## 1-4294967296max_connect_errors = 100## 2 and 31536000client_connect_timeout = 9EOF 123456789101112131415161718192021# vi /usr/lib/systemd/system/mysqlrouter.service [Unit] Description=MySQL Router After=syslog.target After=network.target [Service] Type=simple User=mysqlrouter Group=mysqlrouter PIDFile=/var/run/mysqlrouter/mysqlrouter.pid ExecStart=/usr/bin/mysqlrouter -c /etc/mysqlrouter/mysqlrouter.conf PrivateTmp=true [Install] WantedBy=multi-user.target 安装设置haproxy1) 安装 yum install -y haproxy 2) 设置日志，编辑rsyslog # 取消下面两项注释，并添加一行： vi /etc/rsyslog.conf # Provides UDP syslog reception $ModLoad imudp $UDPServerRun 514 # 设置rsyslog系统日志配置 echo &apos;local2.* /var/log/haproxy.log&apos; &gt; /etc/rsyslog.d/haproxy.conf 3) 编辑配置文件 cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bk 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 cat &gt; /etc/haproxy/haproxy.cfg &lt;&lt; EOFglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats mode 600 level admindefaults mode tcp log global option dontlognull option redispatch retries 3 timeout queue 45s timeout connect 5s timeout client 1m timeout server 1m timeout check 10s maxconn 1020#---------------------------------------------------------------------# HAProxy statistics backend#---------------------------------------------------------------------listen haproxy-monitoring *:9000 mode http stats enable stats show-legends stats refresh 5s stats uri /stats stats realm Haproxy\ Statistics stats auth test_user:test_pass stats admin if TRUE stats hide-versionfrontend mariadb # change on 2nd HAProxy bind *:3030 default_backend mariadb_clusterbackend mariadb_cluster balance leastconn ##default-server port 9200 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxconn 64 maxqueue 128 weight 100 server nodeA 10.100.120.4:3306 maxconn 151 check port 3306 inter 3s fastinter 1s downinter 5s rise 3 fall 3 server nodeB 10.100.120.5:3306 maxconn 151 check port 3306 inter 3s fastinter 1s downinter 5s rise 3 fall 3 server nodeC 10.100.120.6:3306 maxconn 151 backup check port 3306 inter 3s fastinter 1s downinter 5s rise 3 fall 3EOF 4) 配置haproxy的防护墙 firewall-cmd --permanent --add-port=9000/tcp firewall-cmd --permanent --add-port=3030/tcp firewall-cmd --reload 5) 客户端访问测试 mysql -u root -p -h 192.168.210.252 -P 3030 -e &quot;select Host, User, Password from mysql.user&quot; 错误排查1）xtrabackup方式的备份同步在单节点故障后重启会查找配置文件中的这个文件夹，否则会报类似以下错误 .err日志文件错误如下： rm: cannot remove ‘/var/lib/mysql//innobackup.prepare.log’: No such file or directory rm: cannot remove ‘/var/lib/mysql//innobackup.move.log’: No such file or directory WSREP_SST: [INFO] Moving the backup to /var/lib/mysql/ (20170725 11:10:34.925) WSREP_SST: [INFO] Evaluating innobackupex –no-version-check –move-back –force-non-empty-directories ${DATA} &amp;&gt;${DATA}/innobackup.move.log (20170725 11:10:34.928) WSREP_SST: [ERROR] Cleanup after exit with status:1 (20170725 11:10:34.937) 2017-07-25 11:10:34 140292539795200 [ERROR] WSREP: Process completed with error: wsrep_sst_xtrabackup-v2 –role ‘joiner’ –address ‘192.168.56.12’ –datadir ‘/var/lib/mysql/’ –parent ‘3212’ ” : 1 (Operation not permitted) 2017-07-25 11:10:34 140292539795200 [ERROR] WSREP: Failed to read uuid:seqno and wsrep_gtid_domain_id from joiner script. 2017-07-25 11:10:34 140292899555456 [ERROR] WSREP: SST failed: 1 (Operation not permitted) 2017-07-25 11:10:34 140292899555456 [ERROR] Aborting innobackup.move.log 日志文件错误如下： Error: datadir must be specified 2）脑裂问题： 执行下面命令，通过这个命令来强制恢复出现脑裂的节点。 set global wsrep_provider_options=&quot;pc.bootstrap=true&quot;; 3）避免脏读 Galera Cluster不是真正意义上的全同步复制，存在延迟。 wsrep_causal_reads=ON; 4） 启动不了mairadb setenforce 0 mkdir /run/mysql chown mysql:mysql /run/mysql systemctl restart mariadb 检查集群是否构建成功# mysql -e &quot;show status like &apos;wsrep_%&apos;&quot; +------------------------------+----------------------------------------------------------+ | Variable_name | Value | +------------------------------+----------------------------------------------------------+ | wsrep_apply_oooe | 0.000000 | | wsrep_apply_oool | 0.000000 | | wsrep_apply_window | 0.000000 | | wsrep_causal_reads | 0 | | wsrep_cert_deps_distance | 0.000000 | | wsrep_cert_index_size | 0 | | wsrep_cert_interval | 0.000000 | | wsrep_cluster_conf_id | 5 | | wsrep_cluster_size | 3 | | wsrep_cluster_state_uuid | 963cd314-7072-11e6-ac31-16d397a77e7e | | wsrep_cluster_status | Primary | | wsrep_commit_oooe | 0.000000 | | wsrep_commit_oool | 0.000000 | | wsrep_commit_window | 0.000000 | | wsrep_connected | ON | | wsrep_flow_control_paused | 0.000000 | | wsrep_flow_control_paused_ns | 0 | | wsrep_flow_control_recv | 0 | | wsrep_flow_control_sent | 0 | | wsrep_incoming_addresses | 172.29.32.200:3306,172.29.32.201:3306,172.29.32.202:3306 | | wsrep_last_committed | 0 | | wsrep_local_bf_aborts | 0 | | wsrep_local_cached_downto | 18446744073709551615 | | wsrep_local_cert_failures | 0 | | wsrep_local_commits | 0 | | wsrep_local_index | 0 | | wsrep_local_recv_queue | 0 | | wsrep_local_recv_queue_avg | 0.083333 | | wsrep_local_replays | 0 | | wsrep_local_send_queue | 0 | | wsrep_local_send_queue_avg | 0.000000 | | wsrep_local_state | 4 | | wsrep_local_state_comment | Synced | | wsrep_local_state_uuid | 963cd314-7072-11e6-ac31-16d397a77e7e | | wsrep_protocol_version | 5 | | wsrep_provider_name | Galera | | wsrep_provider_vendor | Codership Oy &lt;info@codership.com&gt; | | wsrep_provider_version | 3.5(rXXXX) | | wsrep_ready | ON | | wsrep_received | 12 | | wsrep_received_bytes | 1360 | | wsrep_repl_data_bytes | 0 | | wsrep_repl_keys | 0 | | wsrep_repl_keys_bytes | 0 | | wsrep_repl_other_bytes | 0 | | wsrep_replicated | 0 | | wsrep_replicated_bytes | 0 | | wsrep_thread_count | 2 | +------------------------------+----------------------------------------------------------+ 具体参数含义解释: 以下参数能对整个集群的做集群完整性检查、节点状态检查、复制健康状态检查、网络瓶颈检查、冲突或死锁检测等，具体参数如下： wsrep_cluster_state_uuid #此参数的值是集群的UUID，每个节点应该一致，可以由此看出节点是否还是集群的一员。 wsrep_cluster_status #集群节点的状态， 正常应该返回primary，其他状态异常，说明出现”分区”或是”split-brain”状况。 wsrep_cluster_conf_id #显示集群变更次数，所有节点应该一致， 反之说明有节点与集群断开了。 wsrep_cluster_size #集群中节点的数量。 wsrep_incoming_addresses #集群中成员的IP地址和端口。 wsrep_connected #当前是否连接中，如果该值为Off，且wsrep_ready的值也为Off，则说明该节点没有连接到集群。 wsrep_flow_control_paused #表示复制停止了多长时间，即表明集群因为Slave延迟而慢的程度，值为0~1，越靠近0越好。值为1表示复制完全停止，可优化wsrep_slave_threads的值来改善。 wsrep_flow_control_sent wsrep_flow_control_sent #表示该节点已经停止复制了多少次。 wsrep_last_committed #最新提交事物的记录。 wsrep_local_commits #本地SQL提交记录。 wsrep_local_cert_failures #本地事物提交失败记录。 wsrep_local_bf_aborts #本地事物回滚的次数。 wsrep_local_send_queue wsrep_local_recv_queue #本地发送和接收的队列。 wsrep_local_send_queue_avg wsrep_local_recv_queue_avg #表示slave事务队列的平均长度，slave瓶颈的预兆。 wsrep_local_state_comment #是否在同步中，如果wsrep_connected为On，但wsrep_ready为OFF，则可以从该项查看原因。 wsrep_ready #插件是否应用中。 wsrep_replicated #随着复制发出的次数。 wsrep_replicated_bytes #随着复制发出的字节数。 动态增加节点关于动态增加节点，只需要在/etc/my.cnf.d/server.conf 修改 wsrep_cluster_address=”gcomm://192.168.1.200″ 地址为cluster其中一个节点即可， 然后通过service mysql start 启动服务，会自动增加到集群节点中 注意点:集群是乐观的并发控制，如果有两个事务同时向集群中不同的节点同一行写入并提交，失败的节点将中止,会造成死锁问题 通过设置单点写入多点读取的方式可以解决此问题。下面链接是其中一种解决方案 http://www.severalnines.com/blog/avoiding-deadlocks-galera-set-haproxy-single-node-writes-and-multi-node-reads 目前存在的一些问题可以参考 https://mariadb.com/kb/en/mariadb/documentation/replication-cluster-multi-master/galera/mariadb-galera-cluster-known-limitations/ wsrep_provider_optionhttps://severalnines.com/blog/understanding-gcache-galera 1） 查看: mysql&gt; SHOW VARIABLES LIKE &apos;wsrep_provider_options&apos;\G ... base_port=4567;gcache.mem_size = 0; gcache.name = /var/lib/mysql/galera.cache; gcache.size = 128M; gcache.page_size = 128M; ... 2) 相关设置 gcache.name 可单独设置缓存文件到另外一个磁盘，提高IO并发 gcache.size 此参数定义作为‘IST增量同步’的内容源的galera.cache文件的大小。此文件设置的大些以便节点重新加入集群式更有可能采用IST而非SST。(默认128M) base_port 同步的专用端口 偏移量 auto_increment当更多的 MariaDB 加入到集群之后，集群中的数据库会自动进行协调，并且自动定义偏移量， 这个比较人性化，自动化，如下描述 MariaDB [tocloud]&gt; show variables like &apos;auto_increment%&apos;; +--------------------------+-------+ | Variable_name | Value | +--------------------------+-------+ | auto_increment_increment | 3 | | auto_increment_offset | 2 | +--------------------------+-------+ 配置haproxy实现功能： 1）健康检查，down机的mysql自动从业务去除 2）负载均衡，配置专用的mysql读，写集群ip，程序通过该IP处理业务 下面haproxy配置使用自带的mysql检测功能，只能检测mysql是否存活。 如果要检测数据库一致性，需要配置xinetd服务写检测脚本通过option httpchk实现（略） 1）安装haproxy wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.23.tar.gz tar xvzfhaproxy-1.4.23.tar.gz cd haproxy-1.4.23 make TARGET=generic make install 2)添加mysql用户，在集群任何一台操作即可，会自动同步 添加权限，用于haproxy检测，不需要任何权限，haproxy只检测是否能正常连接关闭mysql mysql -uroot -p GRANT USAGE ON test.* to gaojinbo@’10.10.10.1′; 3)建立haproxy配置文件 vi /etc/haproxy.cfg global maxconn 40000 #debug daemon #quiet user haproxy group haproxy nbproc 1 log 127.0.0.1 local3 spread-checks 2 defaults timeout server 5m timeout connect 5m timeout client 5m timeout http-request 30s timeout queue 5m frontend db_haproxy_status bind :80 default_backend db_status frontend db_write bind 10.10.10.21:3306 default_backend cluster_db_write frontend db_read bind 10.10.10.22:3306 default_backend cluster_db_read backend cluster_db_write mode tcp option tcpka balance roundrobin option mysql-check user gaojinbo server mdb1 10.10.10.11:3306 weight 1 check port 3306 server mdb2 10.10.10.12:3306 weight 1 check port 3306 server mdb3 10.10.10.13:3306 weight 1 check port 3306 backend cluster_db_read mode tcp option tcpka balance roundrobin option mysql-check user gaojinbo server mdb1 10.10.10.11:3306 weight 1 check port 3306 server mdb2 10.10.10.12:3306 weight 1 check port 3306 server mdb3 10.10.10.13:3306 weight 1 check port 3306 backend db_status mode http stats enable #stats scope #stats hide-version stats refresh 5s stats uri /status stats realm Haproxy statistics stats auth gaojinbo:gaojinbo.com 说明： haproxy配置的5分钟超时，如果需要mysql长连接的话，修改超时设置即可 4)启动haproxy haproxy -f /etc/haproxy.cfg 总结通过上面的一系列测试，最后总结一下： 1. 在生产环境下应该避免使用大事务，不建议在高并发写入场景下使用Galera Cluster架构，会导致集群限流，从而引起整个集群hang住，出现生产故障。针对这种情况可以考虑主从，实现读写分离等手段。 2. 对数据一致性要求较高，并且数据写入不频繁，数据库容量也不大（50GB左右），网络状况良好的情况下，可以考虑使用Galera方案 3. MyISAM存储的表，Galera不支持同步。它仅支持XtraDB/ InnoDB存储引擎（虽然有对MyISAM实验支持，具体看wsrep_replicate_myisam系统变量）。 参考：https://my.oschina.net/ioooi/blog/1476604 http://blog.csdn.net/jiangshouzhuang/article/details/62468778 http://www.cnblogs.com/sweetchildomine/p/7884960.html]]></content>
      <categories>
        <category>mariadb</category>
        <category>install</category>
      </categories>
      <tags>
        <tag>mariadb</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongoDB常用命令]]></title>
    <url>%2Fmongdb%2FmongoDB%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[安装mongoDB官网下载安装（Windows安装方法） 基础知识集合——对应关系数据库中的表 文档——对应关系数据库中的行 启动数据库服务定位到安装目录下的bin文件夹里后 &gt; mongod --dbpath ../data/db 如没有data/db文件夹，需先创建，dbpath用于指定数据存放位置 开启一个客户端访问数据库同样的bin文件夹下执行 &gt; mongo 默认连接至test数据库 显示帮助&gt; help 显示所有数据库名称&gt; show dbs 切换数据库&gt; use test 显示当前连接的数据库名称&gt; db 显示当前数据库所有集合&gt; show collections 显示数据库支持的方法&gt; db.help() 显示集合支持的方法&gt; db.users.help() 创建集合&gt; db.createCollection(&quot;users&quot;) 插入操作insert&gt; db.users.insert({&quot;name&quot;:&quot;kiinlam&quot;,&quot;age&quot;:28}) 查询操作find查找所有文档&gt; db.users.find() 查找指定文档&gt; db.users.find({&quot;name&quot;:&quot;kiinlam&quot;}) 查询一条&gt; db.users.findOne({&quot;name&quot;:&quot;kiinlam&quot;}) 大于$gt&gt; db.users.find({&quot;age&quot;:{$gt:22}}) 大于等于$gte&gt; db.users.find({&quot;age&quot;:{$gte:22}}) 小于$lt&gt; db.users.find({&quot;age&quot;:{$lt:22}}) 小于等于$gte&gt; db.users.find({&quot;age&quot;:{$lte:22}}) 不等于$ne&gt; db.users.find(&quot;age&quot;:{$ne:22}) 或$or&gt; db.users.find({$or:[{&quot;name&quot;:&quot;kiinlam&quot;},{&quot;name&quot;:&quot;cheungkiinlam&quot;}]}) 在集合中$in&gt; db.users.find(&quot;name&quot;:{$in:[&quot;kiinlam&quot;,&quot;cheungkiinlam&quot;]}) 不在集合中$nin&gt; db.users.find(&quot;name&quot;:{$nin:[&quot;kiinlam&quot;,&quot;cheungkiinlam&quot;]}) 正则查询&gt; db.users.find({&quot;name&quot;:/^k/,&quot;name&quot;:/m$/}) 筛选查询$where// 使用js function作为筛选条件 &gt; db.users.find({$where: function(){return this.name==&apos;kiinlam&apos;}}) 限制查询数量limit&gt; db.users.find({&quot;age&quot;:22}).limit(10) 更新操作update指定文档全部更新，等于覆盖&gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {&quot;name&quot;:&quot;cheungkiinlam&quot;,&quot;age&quot;:27}) 局部更新一：增量更新$inc// age增加2，其他不变 &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$inc:{&quot;age&quot;:2}}) 局部更新二：字段修改$set// age改为20 &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$set:{&quot;age&quot;:20}}) 新增更新：如果不存在，就新增一条// 第三个参数为true &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$set:{&quot;age&quot;:18}}, true) 批量更新// 如果匹配多条，默认只改第一条，将第四个参数设为true可全部更新 &gt; db.users.update({&quot;name&quot;:&quot;kiinlam&quot;}, {$set:{&quot;age&quot;:18}}, true, true) 保存操作save// 插入新文档，如果不提供&quot;_id&quot;字段 &gt; db.users.save({&quot;name&quot;:&quot;kiinlam&quot;, &quot;age&quot;:28}) // 更新已存在的文档 &gt; db.users.save({&quot;_id&quot;:&quot;xxx&quot;,&quot;name&quot;:&quot;kiinlam&quot;, &quot;age&quot;:28}) 删除操作remove删除操作不可恢复 删除所有，但不删除索引&gt; db.users.remove({}) 删除指定文档&gt; db.users.remove({&quot;name&quot;:&quot;kiinlam&quot;}) 删除一条指定文档，如果有多条结果&gt; db.users.remove({&quot;name&quot;:&quot;kiinlam&quot;}, true) 完全删除集合，包括索引，应当使用drop 大量删除时，采用复制需要保留的文档到新集合，再用drop删除集合。 删除数据库&gt; db.dropDatabase() 删除集合&gt; db.users.drop() 计数操作count&gt; db.users.count() &gt; db.users.count({&quot;age&quot;:29}) 唯一值查询distinct指定字段有多个相同时，只取一个，返回指定字段的值组合成的数组&gt; db.users.distinct(&quot;age&quot;) 分组操作group按照age进行分组操作，分组结果存放在user中，值为对应age的name值的数组 key：分组依据 initial：初始化函数，每个不同的age组共享同一个函数 $reduce： 第一个参数为当前文档，第二参数为前一次函数操作的累计对象，第一次为initial对应的对象 &gt; db.users.group({ &quot;key&quot;: {&quot;age&quot;: true}, &quot;initial&quot;: {&quot;user&quot;: []}, &quot;$reduce&quot;: function(cur,prev){ prev.user.push(cur.name); } }) 假设有数据如下： { &quot;_id&quot; : ObjectId(&quot;55910457607379845607d9e2&quot;), &quot;name&quot; : &quot;kiinlam&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55910468607379845607d9e3&quot;), &quot;name&quot; : &quot;shadow&quot;, &quot;age&quot; : 26 } { &quot;_id&quot; : ObjectId(&quot;55910992607379845607d9e5&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55911fca607379845607d9e6&quot;), &quot;name&quot; : &quot;dd&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fd3607379845607d9e7&quot;), &quot;name&quot; : &quot;mm&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fdf607379845607d9e8&quot;), &quot;name&quot; : &quot;gg&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911feb607379845607d9e9&quot;), &quot;name&quot; : &quot;jj&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55920545ff40738c1fd0a839&quot;), &quot;name&quot; : &quot;zz&quot;, &quot;age&quot; : 1 } 分组结果为： [ { &quot;age&quot; : 29, &quot;user&quot; : [ &quot;kiinlam&quot;, &quot;foo&quot; ] }, { &quot;age&quot; : 26, &quot;user&quot; : [ &quot;shadow&quot; ] }, { &quot;age&quot; : 22, &quot;user&quot; : [ &quot;dd&quot;, &quot;mm&quot;, &quot;gg&quot;, &quot;jj&quot; ] }, { &quot;age&quot; : 1, &quot;user&quot; : [ &quot;zz&quot; ] } ] 更多分组功能可选参数: condition 和 finalize。 `condition` —— 过滤条件 `finalize` —— 函数，分组完成后执行 过滤掉age大于22的文档，增加属性标明分组中文档的数量 &gt; db.users.group({ &quot;key&quot;: {&quot;age&quot;: true}, &quot;initial&quot;: {&quot;user&quot;: []}, &quot;$reduce&quot;: function(cur,prev){ prev.user.push(cur.name); }, &quot;condition&quot;: {&quot;age&quot;:{$lte:22}}, &quot;finalize&quot;: function(out){ out.count = out.user.length; } }) 分组结果为： [ { &quot;age&quot; : 22, &quot;user&quot; : [ &quot;dd&quot;, &quot;mm&quot;, &quot;gg&quot;, &quot;jj&quot; ], &quot;count&quot; : 4 }, { &quot;age&quot; : 1, &quot;user&quot; : [ &quot;zz&quot; ], &quot;count&quot; : 1 } ] mapReducemap：映射函数，内部调用emit(key,value)，集合按照key进行映射分组。 reduce：简化函数，对map分组后的数据进行分组简化，reduce(key,value)中的key是emit中的key，而value则是emit分组结果的集合。 mapReduce：最后执行的函数，参数为map、reduce和一些可选参数。 &gt; db.users.mapReduce function ( map , reduce , optionsOrOutString ){ var c = { mapreduce : this._shortName , map : map , reduce : reduce }; assert( optionsOrOutString , &quot;need to supply an optionsOrOutString&quot; ) if ( typeof( optionsOrOutString ) == &quot;string&quot; ) c[&quot;out&quot;] = optionsOrOutString; else Object.extend( c , optionsOrOutString ); var raw = this._db.runCommand( c ); if ( ! raw.ok ){ __mrerror__ = raw; throw Error( &quot;map reduce failed:&quot; + tojson(raw) ); } return new MapReduceResult( this._db , raw ); } 创建map函数 function (){ emit(this.name,{count:1}); } 创建reduce函数 function (key,value){ var result = {count:0}; for(var i = 0; i &lt; value.length; i++){ result.count += value[i].count; } return result; } 执行mapReduce操作 &gt; db.users.mapReduce(map,reduce,{&quot;out&quot;:&quot;collection&quot;}) 假设有数据如下 { &quot;_id&quot; : ObjectId(&quot;55910457607379845607d9e2&quot;), &quot;name&quot; : &quot;kiinlam&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55910468607379845607d9e3&quot;), &quot;name&quot; : &quot;shadow&quot;, &quot;age&quot; : 26 } { &quot;_id&quot; : ObjectId(&quot;55910992607379845607d9e5&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 29 } { &quot;_id&quot; : ObjectId(&quot;55920545ff40738c1fd0a839&quot;), &quot;name&quot; : &quot;zz&quot;, &quot;age&quot; : 1 } { &quot;_id&quot; : ObjectId(&quot;55911fca607379845607d9e6&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fd3607379845607d9e7&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911fdf607379845607d9e8&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;55911feb607379845607d9e9&quot;), &quot;name&quot; : &quot;foo&quot;, &quot;age&quot; : 22 } 输出结果 { &quot;result&quot; : &quot;collection&quot;, // 存放最终结果的集合名 &quot;timeMillis&quot; : 28, &quot;counts&quot; : { &quot;input&quot; : 8, // 传入文档的次数 &quot;emit&quot; : 8, // emit函数被调用次数 &quot;reduce&quot; : 1, // reduce函数被调用次数 &quot;output&quot; : 4 // 最后返回文档的个数 }, &quot;ok&quot; : 1 } 查看集合collection中的结果 &gt; db.collection.find() 输出结果 { &quot;_id&quot; : &quot;foo&quot;, &quot;value&quot; : { &quot;count&quot; : 5 } } { &quot;_id&quot; : &quot;kiinlam&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } { &quot;_id&quot; : &quot;shadow&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } { &quot;_id&quot; : &quot;zz&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } 游标游标只表示一个引用，并不是真正的执行，在需要的时候，通过for循环或next()方法进行遍历读取，枚举结束后，游标销毁，不再返回数据。 申明一个游标 &gt; var list = db.collection.find() 通过forEach遍历游标 &gt; list.forEach(function(i){ print(i._id); }) 输出结果 foo kiinlam shadow zz 或者通过next遍历集合 &gt; var list = db.collection.find() &gt; list.next() { &quot;_id&quot; : &quot;foo&quot;, &quot;value&quot; : { &quot;count&quot; : 5 } } &gt; list.next() { &quot;_id&quot; : &quot;kiinlam&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } &gt; list.next() { &quot;_id&quot; : &quot;shadow&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } &gt; list.next() { &quot;_id&quot; : &quot;zz&quot;, &quot;value&quot; : { &quot;count&quot; : 1 } } &gt; list.next() 2015-07-01T11:27:38.186+0800 E QUERY Error: error hasNext: false at Error (&lt;anonymous&gt;) at DBQuery.next (src/mongo/shell/query.js:255:15) at (shell):1:6 at src/mongo/shell/query.js:255 &gt; list &gt; 索引ensureIndex建立索引// 1为升序，-1为降序 &gt; db.users.ensureIndex({&quot;name&quot;:1}) 唯一索引&gt; db.users.ensureIndex({&quot;name&quot;:1},{&quot;unique&quot;:true}) 组合索引&gt; db.users.ensureIndex({&quot;name&quot;:1, &quot;age&quot;:-1}) 查看索引&gt; db.users.getIndexes() 按指定索引查询&gt; db.users.find({&quot;name&quot;:&quot;kiinlam&quot;}).hint({&quot;name&quot;:1,&quot;age&quot;:1}) 删除索引// 删除所有自定义索引 &gt; db.users.dropIndexes() // 删除指定索引 &gt; db.users.dropIndex(&quot;name_1&quot;) 性能分析函数explain&gt; db.users.find().explain(&quot;executionStats&quot;) 主从数据库部署创建主数据库master&gt; mongod --dbpath=XXX --master 创建从数据库slave// 指定从数据库端口--port // 指定主数据库源--source &gt; mongod --dbpath=XXX --port=8888 --slave --source=127.0.0.1:27017 后期指定主数据库源&gt; mongod --dbpath=XXX --port=8888 --slave // 后期添加源 // 切换到local数据库 &gt; use local // 在sources中加入源地址 &gt; db.sources.insert({&quot;host&quot;:&quot;127.0.0.1:27017&quot;}) 副本集replSet该架构没有特定的主数据库，一个数据库宕机了，另一个数据库会顶上 创建第一个数据库服务器// 需要指定集群名及下一个数据库地址 &gt; mongod --dbpath=XXX --port 2222 --replSet mySet/127.0.0.1:3333 创建第二个数据库服务器&gt; mongod --dbpath=XXX --port 3333 --replSet mySet/127.0.0.1:2222 初始化副本集// 进入任一数据库的admin集合 &gt; mongo 127.0.0.1:2222/admin // 执行初始化操作 &gt; db.runCommand({ &quot;replSetInitiate&quot;:{ &quot;_id&quot;:&quot;mySet&quot;, &quot;members&quot;:[ { &quot;_id&quot;:1, &quot;host&quot;:&quot;127.0.0.1:2222&quot; }, { &quot;_id&quot;:2, &quot;host&quot;:&quot;127.0.0.1:3333&quot; } ] } }) 仲裁服务器// 启动仲裁服务器 &gt; mongod --dbpath=XXX --port 4444 --replSet mySet/127.0.0.1:2222 // 回到admin集合中添加仲裁服务器 &gt; mongo 127.0.0.1:2222/admin &gt; rs.addArb(&quot;127.0.0.1:4444&quot;) // 查看服务器集群状态 &gt; rs.status() 分片技术将集合进行拆分，将拆分的数据均摊到几个分片上。 主要参与者： 客户端 路由服务器mongos 配置服务器 分片数据库实例 开启配置服务器config&gt; mongod --dbpath=XXX --port 2222 开启路由服务器mongos// 指定配置服务器 &gt; mongos --port 3333 --configdb=127.0.0.1:2222 开启分片数据库服务器mongod&gt; mongod --dbpath=XXX --port 4444 &gt; mongod --dbpath=XXX --port 5555 服务配置// 进入mongos数据库admin集合 &gt; mongo 127.0.0.1:3333/admin // 添加分片服务器addshard &gt; db.runCommand({ &quot;addshard&quot;:&quot;127.0.0.1:4444&quot;, &quot;allowLocal&quot;:true }) &gt; db.runCommand({ &quot;addshard&quot;:&quot;127.0.0.1:5555&quot;, &quot;allowLocal&quot;:true }) // 开启数据库test的分片功能enablesharding &gt; db.runCommand({&quot;enablesharding&quot;:&quot;test&quot;}) // 指定集合中分片的片键users.name &gt; db.runCommand({&quot;shardcollection&quot;:&quot;test.users&quot;,&quot;key&quot;:{&quot;name&quot;:1}}) // 在mongos中查看数据分片情况 &gt; use test &gt; db.printShardingStatus() 运维运维通常会涉及到以下4个方面 安装部署 状态监控 安全认证 备份和恢复 安装部署为windows服务// 指定日志路径，添加install参数 &gt; mongod --dbpath=XXX --logpath=XXX --port=2222 --install // 启动服务 &gt; net start MongoDB 状态监控静态统计db.stats() // 查看单个数据库状态 &gt; db.stats() stats比较简单，可以参考db.stats()一文 db.serverStatus() // 查看整个mongodb的状态 // 进入admin集合 &gt; mongo 127.0.0.1:2222/admin // 查看状态 &gt; db.serverStatus() serverStatus的参数很多，可以参考db.serverStatus()一文 实时统计&gt; mongostat --port 2222 安全认证TODO 有点复杂，偷懒了，参考安全认证 备份和恢复// 备份test数据库到D:\mongodb\backup &gt; mongodump --port 2222 -d test -o D:\mongodb\backup // 恢复数据，drop表示恢复前删除原有数据 &gt; mongorestore --port 2222 -d test --drop D:\mongodb\backup 参考资料 mongoDB MongoDB文档 install-mongodb-on-windows 8天学通MongoDB系列]]></content>
      <categories>
        <category>mongoDB</category>
      </categories>
      <tags>
        <tag>mongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy 12345678910111213POST /task?id=1 HTTP/1.1Host: example.orgContent-Type: application/json; charset=utf-8Content-Length: 137&#123; "status": "ok", "extended": true, "results": [ &#123;"value": 0, "type": "int64"&#125;, &#123;"value": 1.0e+3, "type": "decimal"&#125; ]&#125; More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[categories]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
